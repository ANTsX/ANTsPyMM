<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>antspymm.mm API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>antspymm.mm</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">__all__ = [&#39;version&#39;,
    &#39;mm_read&#39;,
    &#39;mm_read_to_3d&#39;,
    &#39;image_write_with_thumbnail&#39;,
    &#39;nrg_format_path&#39;,
    &#39;highest_quality_repeat&#39;,
    &#39;match_modalities&#39;,
    &#39;mc_resample_image_to_target&#39;,
    &#39;nrg_filelist_to_dataframe&#39;,
    &#39;merge_timeseries_data&#39;,
    &#39;timeseries_reg&#39;,
    &#39;merge_dwi_data&#39;,
    &#39;outlierness_by_modality&#39;,
    &#39;bvec_reorientation&#39;,
    &#39;get_dti&#39;,
    &#39;dti_reg&#39;,
    &#39;mc_reg&#39;,
    &#39;get_data&#39;,
    &#39;get_models&#39;,
    &#39;get_valid_modalities&#39;,
    &#39;dewarp_imageset&#39;,
    &#39;super_res_mcimage&#39;,
    &#39;segment_timeseries_by_meanvalue&#39;,
    &#39;get_average_rsf&#39;,
    &#39;get_average_dwi_b0&#39;,
    &#39;dti_template&#39;,
    &#39;t1_based_dwi_brain_extraction&#39;,
    &#39;mc_denoise&#39;,
    &#39;tsnr&#39;,
    &#39;dvars&#39;,
    &#39;slice_snr&#39;,
    &#39;impute_fa&#39;,
    &#39;trim_dti_mask&#39;,
    &#39;dipy_dti_recon&#39;,
    &#39;concat_dewarp&#39;,
    &#39;joint_dti_recon&#39;,
    &#39;middle_slice_snr&#39;,
    &#39;foreground_background_snr&#39;,
    &#39;quantile_snr&#39;,
    &#39;mask_snr&#39;,
    &#39;dwi_deterministic_tracking&#39;,
    &#39;dwi_closest_peak_tracking&#39;,
    &#39;dwi_streamline_pairwise_connectivity&#39;,
    &#39;dwi_streamline_connectivity&#39;,
    &#39;hierarchical_modality_summary&#39;,
    &#39;tra_initializer&#39;,
    &#39;neuromelanin&#39;,
    &#39;resting_state_fmri_networks&#39;,
    &#39;write_bvals_bvecs&#39;,
    &#39;crop_mcimage&#39;,
    &#39;mm&#39;,
    &#39;write_mm&#39;,
    &#39;mm_nrg&#39;,
    &#39;mm_csv&#39;,
    &#39;collect_blind_qc_by_modality&#39;,
    &#39;alffmap&#39;,
    &#39;alff_image&#39;,
    &#39;down2iso&#39;,
    &#39;read_mm_csv&#39;,
    &#39;assemble_modality_specific_dataframes&#39;,
    &#39;bind_wide_mm_csvs&#39;,
    &#39;merge_mm_dataframe&#39;,
    &#39;augment_image&#39;,
    &#39;boot_wmh&#39;,
    &#39;threaded_bind_wide_mm_csvs&#39;,
    &#39;get_names_from_data_frame&#39;,
    &#39;average_mm_df&#39;,
    &#39;quick_viz_mm_nrg&#39;,
    &#39;blind_image_assessment&#39;,
    &#39;average_blind_qc_by_modality&#39;,
    &#39;best_mmm&#39;,
    &#39;nrg_2_bids&#39;,
    &#39;bids_2_nrg&#39;,
    &#39;parse_nrg_filename&#39;,
    &#39;novelty_detection_svm&#39;,
    &#39;novelty_detection_ee&#39;,
    &#39;novelty_detection_lof&#39;,
    &#39;novelty_detection_loop&#39;,
    &#39;novelty_detection_quantile&#39;,
    &#39;generate_mm_dataframe&#39;,
    &#39;aggregate_antspymm_results&#39;,
    &#39;aggregate_antspymm_results_sdf&#39;,
    &#39;study_dataframe_from_matched_dataframe&#39;,
    &#39;merge_wides_to_study_dataframe&#39;,
    &#39;filter_image_files&#39;,
    &#39;docsamson&#39;,
    &#39;enantiomorphic_filling_without_mask&#39;,
    &#39;wmh&#39;,
    &#39;remove_elements_from_numpy_array&#39;,
    &#39;score_fmri_censoring&#39;,
    &#39;remove_volumes_from_timeseries&#39;,
    &#39;loop_timeseries_censoring&#39;,
    &#39;clean_tmp_directory&#39;,
    &#39;validate_nrg_file_format&#39;,
    &#39;dict_to_dataframe&#39;]

from pathlib import Path
from pathlib import PurePath
import os
import pandas as pd
import math
import os.path
from os import path
import pickle
import sys
import numpy as np
import random
import functools
from operator import mul
from scipy.sparse.linalg import svds
from scipy.stats import pearsonr
import re
import datetime as dt
from collections import Counter
import tempfile
import warnings

from dipy.core.histeq import histeq
import dipy.reconst.dti as dti
from dipy.core.gradients import (gradient_table, gradient_table_from_gradient_strength_bvecs)
from dipy.io.gradients import read_bvals_bvecs
from dipy.segment.mask import median_otsu
from dipy.reconst.dti import fractional_anisotropy, color_fa
import nibabel as nib

import ants
import antspynet
import antspyt1w
import siq
import tensorflow as tf

from multiprocessing import Pool
import glob as glob

DATA_PATH = os.path.expanduser(&#39;~/.antspymm/&#39;)

def version( ):
    &#34;&#34;&#34;
    report versions of this package and primary dependencies

    Arguments
    ---------
    None

    Returns
    -------
    a dictionary with package name and versions

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.version()
    &#34;&#34;&#34;
    import pkg_resources
    return {
              &#39;tensorflow&#39;: pkg_resources.require(&#34;tensorflow&#34;)[0].version,
              &#39;antspyx&#39;: pkg_resources.require(&#34;antspyx&#34;)[0].version,
              &#39;antspynet&#39;: pkg_resources.require(&#34;antspynet&#34;)[0].version,
              &#39;antspyt1w&#39;: pkg_resources.require(&#34;antspyt1w&#34;)[0].version,
              &#39;antspymm&#39;: pkg_resources.require(&#34;antspymm&#34;)[0].version
              }

def nrg_filename_to_subjectvisit(s, separator=&#39;-&#39;):
    &#34;&#34;&#34;
    Extracts a pattern from the input string.
    
    Parameters:
    - s: The input string from which to extract the pattern.
    - separator: The separator used in the string (default is &#39;-&#39;).
    
    Returns:
    - A string in the format of &#39;PREFIX-Number-Date&#39;
    &#34;&#34;&#34;
    parts = os.path.basename(s).split(separator)
    # Assuming the pattern is always in the form of PREFIX-Number-Date-...
    # and PREFIX is always &#34;PPMI&#34;, extract the first three parts
    extracted = separator.join(parts[:3])
    return extracted


def validate_nrg_file_format(path, separator):
    &#34;&#34;&#34;
    is your path nrg-etic?
    Validates if a given path conforms to the NRG file format, taking into account known extensions
    and the expected directory structure.

    :param path: The file path to validate.
    :param separator: The separator used in the filename and directory structure.
    :return: A tuple (bool, str) indicating whether the path is valid and a message explaining the validation result.

    : example

    ntfn=&#39;/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses-1/rsfMRI_RL/000/ANTsLIMBIC_sub08C105120Yr_ses-1_rsfMRI_RL_000.nii.gz&#39;
    ntfngood=&#39;/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses_1/rsfMRI_RL/000/ANTsLIMBIC-sub08C105120Yr-ses_1-rsfMRI_RL-000.nii.gz&#39;

    validate_nrg_detailed(ntfngood, &#39;-&#39;)
    print( validate_nrg_detailed(ntfn, &#39;-&#39;) )
    print( validate_nrg_detailed(ntfn, &#39;_&#39;) )

    &#34;&#34;&#34;
    import re    

    def normalize_path(path):
        &#34;&#34;&#34;
        Replace multiple repeated &#39;/&#39; with just a single &#39;/&#39;
        
        :param path: The file path to normalize.
        :return: The normalized file path with single &#39;/&#39;.
        &#34;&#34;&#34;
        normalized_path = re.sub(r&#39;/+&#39;, &#39;/&#39;, path)
        return normalized_path

    def strip_known_extension(filename, known_extensions):
        &#34;&#34;&#34;
        Strips a known extension from the filename.

        :param filename: The filename from which to strip the extension.
        :param known_extensions: A list of known extensions to strip from the filename.
        :return: The filename with the known extension stripped off, if found.
        &#34;&#34;&#34;
        for ext in known_extensions:
            if filename.endswith(ext):
                # Strip the extension and return the modified filename
                return filename[:-len(ext)]
        # If no known extension is found, return the original filename
        return filename

    import warnings
    if normalize_path( path ) != path:
        path = normalize_path( path )
        warnings.warn(&#34;Probably had multiple repeated slashes eg /// in the file path.  this might cause issues. clean up with re.sub(r&#39;/+&#39;, &#39;/&#39;, path)&#34;)

    known_extensions = [&#34;.nii.gz&#34;, &#34;.nii&#34;, &#34;.mhd&#34;, &#34;.nrrd&#34;, &#34;.mha&#34;, &#34;.json&#34;, &#34;.bval&#34;, &#34;.bvec&#34;]
    known_extensions2 = [ext.lstrip(&#39;.&#39;) for ext in known_extensions]
    def get_extension(filename, known_extensions ):
        # List of known extensions in priority order
        for ext in known_extensions:
            if filename.endswith(ext):
                return ext.strip(&#39;.&#39;)
        return &#34;Invalid extension&#34;
    
    parts = path.split(&#39;/&#39;)
    if len(parts) &lt; 7:  # Checking for minimum path structure
        return False, &#34;Path structure is incomplete. Expected at least 7 components, found {}.&#34;.format(len(parts))
    
    # Extract directory components and filename
    directory_components = parts[1:-1]  # Exclude the root &#39;/&#39; and filename
    filename = parts[-1]
    filename_without_extension = strip_known_extension( filename, known_extensions )
    file_extension = get_extension( filename, known_extensions )
    
    # Validating file extension
    if file_extension not in known_extensions2:
        print( file_extension )
        return False, &#34;Invalid file extension: {}. Expected &#39;nii.gz&#39; or &#39;json&#39;.&#34;.format(file_extension)
    
    # Splitting the filename to validate individual parts
    filename_parts = filename_without_extension.split(separator)
    if len(filename_parts) != 5:  # Expecting 5 parts based on the NRG format
        print( filename_parts )
        return False, &#34;Filename does not have exactly 5 parts separated by &#39;{}&#39;. Found {} parts.&#34;.format(separator, len(filename_parts))
    
    # Reconstruct expected filename from directory components
    expected_filename_parts = directory_components[-5:]
    expected_filename = separator.join(expected_filename_parts)
    if filename_without_extension != expected_filename:
        print( filename_without_extension )
        print(&#34;--- vs expected ---&#34;)
        print( expected_filename )
        return False, &#34;Filename structure does not match directory structure. Expected filename: {}.&#34;.format(expected_filename)
    
    # Validate directory structure against NRG format
    study_name, subject_id, session, modality = directory_components[-4:-1] + [directory_components[-1].split(&#39;/&#39;)[0]]
    if not all([study_name, subject_id, session, modality]):
        return False, &#34;Directory structure does not follow NRG format. Ensure StudyName, SubjectID, Session (ses_x), and Modality are correctly specified.&#34;
    
    # If all checks pass
    return True, &#34;The path conforms to the NRG format.&#34;

def get_antsimage_keys(dictionary):
    &#34;&#34;&#34;
    Return the keys of the dictionary where the values are ANTsImages.

    :param dictionary: A dictionary to inspect
    :return: A list of keys for which the values are ANTsImages
    &#34;&#34;&#34;
    return [key for key, value in dictionary.items() if isinstance(value, ants.ANTsImage)]


def dict_to_dataframe(data_dict, convert_lists=True, convert_arrays=True, convert_images=True, verbose=False):
    &#34;&#34;&#34;
    Convert a dictionary to a pandas DataFrame, excluding items that cannot be processed by pandas.

    :param data_dict: Dictionary to be converted.
    :param convert_lists: boolean
    :param convert_arrays: boolean
    :param convert_images: boolean
    :param verbose: boolean
    :return: DataFrame representation of the dictionary.
    &#34;&#34;&#34;
    processed_data = {}
    list_length = None
    def mean_of_list(lst):
        if not lst:  # Check if the list is not empty
            return 0  # Return 0 or appropriate value for an empty list
        all_numeric = all(isinstance(item, (int, float)) for item in lst)
        if all_numeric:
            return sum(lst) / len(lst)
        return None
    
    for key, value in data_dict.items():
        # Check if value is a scalar
        if isinstance(value, (int, float, str, bool)):
            processed_data[key] = [value]
        # Check if value is a list of scalars
        elif isinstance(value, list) and all(isinstance(item, (int, float, str, bool)) for item in value) and convert_lists:
            meanvalue = mean_of_list( value )
            newkey = key+&#34;_mean&#34;
            if verbose:
                print( &#34; Key &#34; + key + &#34; is list with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
            if newkey not in data_dict.keys() and convert_lists:
                processed_data[newkey] = meanvalue
        elif isinstance(value, np.ndarray) and all(isinstance(item, (int, float, str, bool)) for item in value) and convert_arrays:
            meanvalue = value.mean()
            newkey = key+&#34;_mean&#34;
            if verbose:
                print( &#34; Key &#34; + key + &#34; is nparray with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
            if newkey not in data_dict.keys():
                processed_data[newkey] = meanvalue
        elif isinstance(value, ants.ANTsImage) and convert_images:
            meanvalue = value.mean()
            newkey = key+&#34;_mean&#34;
            if newkey not in data_dict.keys():
                if verbose:
                    print( &#34; Key &#34; + key + &#34; is antsimage with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
                processed_data[newkey] = meanvalue
            else:
                if verbose:
                    print( &#34; Key &#34; + key + &#34; is antsimage with mean &#34; + str(meanvalue) + &#34; but &#34; + newkey + &#34; already exists&#34; )

    return pd.DataFrame.from_dict(processed_data)


def clean_tmp_directory(age_hours=1., use_sudo=False, extensions=[ &#39;.nii&#39;, &#39;.nii.gz&#39; ], log_file_path=None):
    &#34;&#34;&#34;
    Clean the /tmp directory by removing files and directories older than a certain number of hours.
    Optionally uses sudo and can filter files by extensions.

    :param age_hours: Age in hours to consider files and directories for deletion.
    :param use_sudo: Whether to use sudo for removal commands.
    :param extensions: List of file extensions to delete. If None, all files are considered.
    :param log_file_path: Path to the log file. If None, a default path will be used based on the OS.

    # Usage
    # Example: clean_tmp_directory(age_hours=1, use_sudo=True, extensions=[&#39;.log&#39;, &#39;.tmp&#39;])
    &#34;&#34;&#34;
    import os
    import platform
    import subprocess
    from datetime import datetime, timedelta

    if not isinstance(age_hours, float):
        return

    # Determine the tmp directory based on the operating system
    tmp_dir = &#39;/tmp&#39;

    # Set the log file path
    if log_file_path is not None:
        log_file = log_file_path

    current_time = datetime.now()
    for item in os.listdir(tmp_dir):
        try:
            item_path = os.path.join(tmp_dir, item)
            item_stat = os.stat(item_path)

            # Calculate the age of the file/directory
            item_age = current_time - datetime.fromtimestamp(item_stat.st_mtime)
            if item_age &gt; timedelta(hours=age_hours):
                # Check for file extensions if provided
                if extensions is None or any(item.endswith(ext) for ext in extensions):
                    # Construct the removal command
                    rm_command = [&#39;sudo&#39;, &#39;rm&#39;, &#39;-rf&#39;, item_path] if use_sudo else [&#39;rm&#39;, &#39;-rf&#39;, item_path]
                    subprocess.run(rm_command)

                if log_file_path is not None:
                    with open(log_file, &#39;a&#39;) as log:
                        log.write(f&#34;{datetime.now()}: Deleted {item_path}\n&#34;)
        except Exception as e:
            if log_file_path is not None:
                with open(log_file, &#39;a&#39;) as log:
                    log.write(f&#34;{datetime.now()}: Error deleting {item_path}: {e}\n&#34;)



def docsamson(locmod, studycsv, outputdir, projid, sid, dtid, mysep, t1iid=None, verbose=True):
    &#34;&#34;&#34;
    Processes image file names based on the specified imaging modality and other parameters.

    The function selects file names from the provided dictionary `studycsv` based on the imaging modality.
    It supports various modalities like T1w, T2Flair, perf, NM2DMT, rsfMRI, DTI, and configures the filenames accordingly.
    The function can optionally print verbose output during processing.

    Parameters:
    locmod (str): The imaging modality. Options include &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;perf&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DTI&#39;.
    studycsv (dict): A dictionary with keys corresponding to imaging modalities and values as file names.
    outputdir (str): Base directory for output files.
    projid (str): Project identifier.
    sid (str): Subject identifier.
    dtid (str): Data acquisition time identifier.
    mysep (str): Separator used in file naming.
    t1iid (str, optional): Identifier related to T1-weighted images, used in naming output files when locmod is not &#39;T1w&#39;.
    verbose (bool, optional): If True, prints detailed information during execution.

    Returns:
    dict: A dictionary with keys &#39;modality&#39;, &#39;outprefix&#39;, and &#39;images&#39;.
        - &#39;modality&#39; (str): The imaging modality used.
        - &#39;outprefix&#39; (str): The prefix for output file paths.
        - &#39;images&#39; (list): A list of processed image file names.

    Notes:
    - The function is designed to work within a specific workflow and might require adaptation for general use.

    Examples:
    &gt;&gt;&gt; result = docsamson(&#39;T1w&#39;, studycsv, outputdir, projid, sid, dtid, mysep)
    &gt;&gt;&gt; print(result[&#39;modality&#39;])
    &#39;T1w&#39;
    &gt;&gt;&gt; print(result[&#39;outprefix&#39;])
    &#39;/path/to/output/directory/T1w/some_identifier&#39;
    &gt;&gt;&gt; print(result[&#39;images&#39;])
    [&#39;image1.nii&#39;, &#39;image2.nii&#39;]
    &#34;&#34;&#34;

    import os
    import re

    myimgsInput = []
    myoutputPrefix = None
    imfns = [&#39;filename&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;flairid&#39;]
    
    # Define image file names based on the modality
    if locmod == &#39;T1w&#39;:
        imfns=[&#39;filename&#39;]
    elif locmod == &#39;T2Flair&#39;:
        imfns=[&#39;flairid&#39;]
    elif locmod == &#39;perf&#39;:
        imfns=[&#39;perfid&#39;]
    elif locmod == &#39;NM2DMT&#39;:
        imfns=[]
        for i in range(11):
            imfns.append(&#39;nmid&#39; + str(i))
    elif locmod == &#39;rsfMRI&#39;:
        imfns=[]
        for i in range(4):
            imfns.append(&#39;rsfid&#39; + str(i))
    elif locmod == &#39;DTI&#39;:
        imfns=[]
        for i in range(4):
            imfns.append(&#39;dtid&#39; + str(i))

    # Process each file name
    for i in imfns:
        if verbose:
            print(i + &#34; &#34; + locmod)
        if i in studycsv.keys():
            fni = str(studycsv[i].iloc[0])
            if verbose:
                print(i + &#34; &#34; + fni + &#39; exists &#39; + str(os.path.exists(fni)))
            if os.path.exists(fni):
                myimgsInput.append(fni)
                temp = os.path.basename(fni)
                mysplit = temp.split(mysep)
                iid = re.sub(&#34;.nii.gz&#34;, &#34;&#34;, mysplit[-1])
                iid = re.sub(&#34;.mha&#34;, &#34;&#34;, iid)
                iid = re.sub(&#34;.nii&#34;, &#34;&#34;, iid)
                iid2 = iid
                if locmod != &#39;T1w&#39; and t1iid is not None:
                    iid2 = iid + &#34;_&#34; + t1iid
                else:
                    iid2 = t1iid
                myoutputPrefix = os.path.join(outputdir, projid, sid, dtid, locmod, iid, projid + mysep + sid + mysep + dtid + mysep + locmod + mysep + iid2)
    
    if verbose:
        print(locmod)
        print(myimgsInput)
        print(myoutputPrefix)
    
    return {
        &#39;modality&#39;: locmod,
        &#39;outprefix&#39;: myoutputPrefix,
        &#39;images&#39;: myimgsInput
    }


def get_valid_modalities( long=False, asString=False, qc=False ):
    &#34;&#34;&#34;
    return a list of valid modality identifiers used in NRG modality designation
    and that can be processed by this package.

    long - return the long version

    asString - concat list to string
    &#34;&#34;&#34;
    if long:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;, &#34;rsfMRILR&#34;, &#34;rsfMRIRL&#34;, &#34;DTI&#34;, &#34;DTI_LR&#34;,&#34;DTI_RL&#34;,  &#34;DTILR&#34;,&#34;DTIRL&#34;,&#34;T2Flair&#34;, &#34;dwi&#34;, &#34;dwi_ap&#34;, &#34;dwi_pa&#34;, &#34;func&#34;, &#34;func_ap&#34;, &#34;func_pa&#34;, &#34;perf&#34;]
    elif qc:
        mymod = [ &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39;, &#39;DTI&#39;, &#39;DTIdwi&#39;,&#39;DTIb0&#39;, &#39;rsfMRI&#39;, &#34;perf&#34; ]
    else:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;DTI&#34;,&#34;T2Flair&#34;, &#34;rsfMRI&#34;, &#34;perf&#34; ]
    if not asString:
        return mymod
    else:
        mymodchar=&#34;&#34;
        for x in mymod:
            mymodchar = mymodchar + &#34; &#34; + str(x)
        return mymodchar


def generate_mm_dataframe(
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename=[],
        rsf_filenames=[],
        dti_filenames=[],
        nm_filenames=[],
        perf_filename=[]
):
    &#34;&#34;&#34;
    Generate a DataFrame for medical imaging data with extensive validation of input parameters.

    This function creates a DataFrame containing information about medical imaging files,
    ensuring that filenames match expected patterns for their modalities and that all
    required images exist. It also validates the number of filenames provided for specific
    modalities like rsfMRI, DTI, and NM.

    Parameters:
    - projectID (str): Project identifier.
    - subjectID (str): Subject identifier.
    - date (str): Date of the imaging study.
    - imageUniqueID (str): Unique image identifier.
    - modality (str): Modality of the imaging study.
    - source_image_directory (str): Directory of the source images.
    - output_image_directory (str): Directory for output images.
    - t1_filename (str): Filename of the T1-weighted image.
    - flair_filename (list): List of filenames for FLAIR images.
    - rsf_filenames (list): List of filenames for rsfMRI images.
    - dti_filenames (list): List of filenames for DTI images.
    - nm_filenames (list): List of filenames for NM images.
    - perf_filename (list): List of filenames for perfusion images.

    Returns:
    - pandas.DataFrame: A DataFrame containing the validated imaging study information.

    Raises:
    - ValueError: If any validation checks fail or if the number of columns does not match the data.
    &#34;&#34;&#34;
    def check_pd_construction(data, columns):
        # Check if the length of columns matches the length of data in each row
        if all(len(row) == len(columns) for row in data):
            return True
        else:
            return False
    from os.path import exists
    valid_modalities = get_valid_modalities()
    if not isinstance(t1_filename, str):
        raise ValueError(&#34;t1_filename is not a string&#34;)
    if not exists(t1_filename):
        raise ValueError(&#34;t1_filename does not exist&#34;)
    if modality not in valid_modalities:
        raise ValueError(&#39;modality &#39; + str(modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))
    # if not exists( output_image_directory ):
    #    raise ValueError(&#34;output_image_directory does not exist&#34;)
    if not exists( source_image_directory ):
        raise ValueError(&#34;source_image_directory does not exist&#34;)
    if len( rsf_filenames ) &gt; 2:
        raise ValueError(&#34;len( rsf_filenames ) &gt; 2&#34;)
    if len( dti_filenames ) &gt; 3:
        raise ValueError(&#34;len( dti_filenames ) &gt; 3&#34;)
    if len( nm_filenames ) &gt; 11:
        raise ValueError(&#34;len( nm_filenames ) &gt; 11&#34;)
    if len( rsf_filenames ) &lt; 2:
        for k in range(len(rsf_filenames),2):
            rsf_filenames.append(None)
    if len( dti_filenames ) &lt; 3:
        for k in range(len(dti_filenames),3):
            dti_filenames.append(None)
    if len( nm_filenames ) &lt; 10:
        for k in range(len(nm_filenames),10):
            nm_filenames.append(None)
    # check modality names
    if not &#34;T1w&#34; in t1_filename:
        raise ValueError(&#34;T1w is not in t1 filename &#34; + t1_filename)
    if flair_filename is not None:
        if isinstance(flair_filename,list):
            if (len(flair_filename) == 0):
                flair_filename=None
            else:
                print(&#34;Take first entry from flair_filename list&#34;)
                flair_filename=flair_filename[0]
    if flair_filename is not None and not &#34;lair&#34; in flair_filename:
            raise ValueError(&#34;flair is not flair filename &#34; + flair_filename)
    ## perfusion
    if perf_filename is not None:
        if isinstance(perf_filename,list):
            if (len(perf_filename) == 0):
                perf_filename=None
            else:
                print(&#34;Take first entry from perf_filename list&#34;)
                perf_filename=perf_filename[0]
    if perf_filename is not None and not &#34;perf&#34; in perf_filename:
            raise ValueError(&#34;perf_filename is not perf filename &#34; + perf_filename)
    
    for k in nm_filenames:
        if k is not None:
            if not &#34;NM&#34; in k:
                raise ValueError(&#34;NM is not flair filename &#34; + k)
    for k in dti_filenames:
        if k is not None:
            if not &#34;DTI&#34; in k and not &#34;dwi&#34; in k:
                raise ValueError(&#34;DTI/DWI is not dti filename &#34; + k)
    for k in rsf_filenames:
        if k is not None:
            if not &#34;fMRI&#34; in k and not &#34;func&#34; in k:
                raise ValueError(&#34;rsfMRI/func is not rsfmri filename &#34; + k)
    if perf_filename is not None:
        if not &#34;perf&#34; in perf_filename:
                raise ValueError(&#34;perf_filename is not a valid perfusion (perf) filename &#34; + k)
    allfns = [t1_filename] + [flair_filename] + nm_filenames + dti_filenames + rsf_filenames + [perf_filename]
    for k in allfns:
        if k is not None:
            if not isinstance(k, str):
                raise ValueError(str(k) + &#34; is not a string&#34;)
            if not exists( k ):
                raise ValueError( &#34;image &#34; + k + &#34; does not exist&#34;)
    coredata = [
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename, 
        perf_filename]
    mydata0 = coredata +  rsf_filenames + dti_filenames
    mydata = mydata0 + nm_filenames
    corecols = [
        &#39;projectID&#39;,
        &#39;subjectID&#39;,
        &#39;date&#39;,
        &#39;imageID&#39;,
        &#39;modality&#39;,
        &#39;sourcedir&#39;,
        &#39;outputdir&#39;,
        &#39;filename&#39;,
        &#39;flairid&#39;,
        &#39;perfid&#39;]
    mycols0 = corecols + [
        &#39;rsfid1&#39;, &#39;rsfid2&#39;,
        &#39;dtid1&#39;, &#39;dtid2&#39;,&#39;dtid3&#39;]
    nmext = [
        &#39;nmid1&#39;, &#39;nmid2&#39; &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;,
        &#39;nmid6&#39;, &#39;nmid7&#39;,&#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;nmid11&#39;
    ]
    mycols = mycols0 + nmext
    if not check_pd_construction( [mydata], mycols ) :
        raise ValueError( &#34;Error in generate_mm_dataframe: len( mycols ) != len( mydata ) which indicates a bad input parameter to this function.&#34; )
    studycsv = pd.DataFrame([ mydata ], columns=mycols)
    return studycsv

import pandas as pd
from os.path import exists

def validate_filename(filename, valid_keywords, error_message):
    &#34;&#34;&#34;
    Validate if the given filename contains any of the specified keywords.

    Parameters:
    - filename (str): The filename to validate.
    - valid_keywords (list): A list of keywords to look for in the filename.
    - error_message (str): The error message to raise if validation fails.

    Raises:
    - ValueError: If none of the keywords are found in the filename.
    &#34;&#34;&#34;
    if filename is not None and not any(keyword in filename for keyword in valid_keywords):
        raise ValueError(error_message)

def validate_modality(modality, valid_modalities):
    if modality not in valid_modalities:
        valid_modalities_str = &#39;, &#39;.join(valid_modalities)
        raise ValueError(f&#39;Modality {modality} not a valid mm modality: {valid_modalities_str}&#39;)

def extend_list_to_length(lst, target_length, fill_value=None):
    return lst + [fill_value] * (target_length - len(lst))

def generate_mm_dataframe_gpt(
        projectID, subjectID, date, imageUniqueID, modality, 
        source_image_directory, output_image_directory, t1_filename, 
        flair_filename=[], rsf_filenames=[], dti_filenames=[], nm_filenames=[], perf_filename=[] ):
    &#34;&#34;&#34;
    see help for generate_mm_dataframe - same as this
    &#34;&#34;&#34;
    def check_pd_construction(data, columns):
        return all(len(row) == len(columns) for row in data)

    flair_filename.sort()
    rsf_filenames.sort()
    dti_filenames.sort()
    nm_filenames.sort()
    perf_filename.sort()

    valid_modalities = get_valid_modalities()  

    if not isinstance(t1_filename, str):
        raise ValueError(&#34;t1_filename is not a string&#34;)
    if not exists(t1_filename):
        raise ValueError(&#34;t1_filename does not exist&#34;)

    validate_modality(modality, valid_modalities)

    if not exists(source_image_directory):
        raise ValueError(&#34;source_image_directory does not exist&#34;)

    rsf_filenames = extend_list_to_length(rsf_filenames, 2)
    dti_filenames = extend_list_to_length(dti_filenames, 2)
    nm_filenames = extend_list_to_length(nm_filenames, 11)

    validate_filename(t1_filename, [&#34;T1w&#34;], &#34;T1w is not in t1 filename &#34; + t1_filename)

    if flair_filename:
        flair_filename = flair_filename[0] if isinstance(flair_filename, list) else flair_filename
        validate_filename(flair_filename, [&#34;lair&#34;], &#34;flair is not in flair filename &#34; + flair_filename)

    if perf_filename:
        perf_filename = perf_filename[0] if isinstance(perf_filename, list) else perf_filename
        validate_filename(perf_filename, [&#34;perf&#34;], &#34;perf_filename is not a valid perfusion (perf) filename&#34;)

    for k in nm_filenames:
        if k: validate_filename(k, [&#34;NM&#34;], &#34;NM is not in NM filename &#34; + k)

    for k in dti_filenames:
        if k: validate_filename(k, [&#34;DTI&#34;,&#34;dwi&#34;], &#34;DTI or dwi is not in DTI filename &#34; + k)

    for k in rsf_filenames:
        if k: validate_filename(k, [&#34;fMRI&#34;,&#34;func&#34;], &#34;rsfMRI or func is not in rsfMRI filename &#34; + k)

    allfns = [t1_filename, flair_filename] + nm_filenames + dti_filenames + rsf_filenames + [perf_filename]
    for k in allfns:
        if k and not exists(k):
            raise ValueError(&#34;image &#34; + k + &#34; does not exist&#34;)

    coredata = [projectID, subjectID, date, imageUniqueID, modality,
                source_image_directory, output_image_directory, t1_filename, 
                flair_filename, perf_filename]
    mydata0 = coredata + rsf_filenames + dti_filenames
    mydata = mydata0 + nm_filenames

    corecols = [&#39;projectID&#39;, &#39;subjectID&#39;, &#39;date&#39;, &#39;imageID&#39;, &#39;modality&#39;,
                &#39;sourcedir&#39;, &#39;outputdir&#39;, &#39;filename&#39;, &#39;flairid&#39;, &#39;perfid&#39;]
    mycols0 = corecols + [&#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;]
    nmext = [&#39;nmid1&#39;, &#39;nmid2&#39;, &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;,
             &#39;nmid6&#39;, &#39;nmid7&#39;, &#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;nmid11&#39;]
    mycols = mycols0 + nmext

    if not check_pd_construction([mydata], mycols):
        print( mydata )
        print( mycols )
        raise ValueError(&#34;Error in generate_mm_dataframe: len(mycols) != len(mydata), indicating bad input parameters.&#34;)

    studycsv = pd.DataFrame([mydata], columns=mycols)
    return studycsv



def filter_columns_by_nan_percentage(df, max_nan_percentage=50.0):
    &#34;&#34;&#34;
    Filter columns in a DataFrame based on a threshold for the percentage of NaN values.

    Parameters
    ----------
    df : pandas.DataFrame
        The input DataFrame from which columns are to be filtered.
    max_nan_percentage : float, optional
        The maximum allowed percentage of NaN values in a column. Columns with a higher
        percentage of NaN values than this threshold will be removed from the DataFrame.
        The default is 50.0, which means columns with more than 50% NaN values will be removed.

    Returns
    -------
    pandas.DataFrame
        A DataFrame with columns filtered based on the NaN values percentage criterion.

    Examples
    --------
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; data = {&#39;A&#39;: [1, 2, None, 4], &#39;B&#39;: [None, 2, 3, None], &#39;C&#39;: [1, 2, 3, 4]}
    &gt;&gt;&gt; df = pd.DataFrame(data)
    &gt;&gt;&gt; filtered_df = filter_columns_by_nan_percentage(df, 50.0)
    &gt;&gt;&gt; print(filtered_df)

    Notes
    -----
    The function calculates the percentage of NaN values in each column and filters out
    those columns where the percentage exceeds the `max_nan_percentage` threshold.
    &#34;&#34;&#34;
    # Calculate the percentage of NaN values for each column
    nan_percentage = df.isnull().mean() * 100

    # Filter columns where the percentage of NaN values is less than or equal to the threshold
    columns_to_keep = nan_percentage[nan_percentage &lt;= max_nan_percentage].index

    # Return the filtered DataFrame
    return df[columns_to_keep]



def parse_nrg_filename( x, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    split a NRG filename into its named parts
    &#34;&#34;&#34;
    temp = x.split( separator )
    if len(temp) != 5:
        raise ValueError(x + &#34; not a valid NRG filename&#34;)
    return {
        &#39;project&#39;:temp[0],
        &#39;subjectID&#39;:temp[1],
        &#39;date&#39;:temp[2],
        &#39;modality&#39;:temp[3],
        &#39;imageID&#39;:temp[4]
    }



def nrg_2_bids( nrg_filename ):
    &#34;&#34;&#34;
    Convert an NRG filename to BIDS path/filename.

    Parameters:
    nrg_filename (str): The NRG filename to convert.

    Returns:
    str: The BIDS path/filename.
    &#34;&#34;&#34;

    # Split the NRG filename into its components
    nrg_dirname, nrg_basename = os.path.split(nrg_filename)
    nrg_suffix = &#39;.&#39; + nrg_basename.split(&#39;.&#39;,1)[-1]
    nrg_basename = nrg_basename.replace(nrg_suffix, &#39;&#39;) # remove ext
    nrg_parts = nrg_basename.split(&#39;-&#39;)
    nrg_subject_id = nrg_parts[1]
    nrg_modality = nrg_parts[3]
    nrg_repeat= nrg_parts[4]

    # Build the BIDS path/filename
    bids_dirname = os.path.join(nrg_dirname, &#39;bids&#39;)
    bids_subject = f&#39;sub-{nrg_subject_id}&#39;
    bids_session = f&#39;ses-{nrg_repeat}&#39;

    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))

    if nrg_modality == &#39;T1w&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;T1w&#39;

    if nrg_modality == &#39;T2Flair&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;flair&#39;

    if nrg_modality == &#39;NM2DMT&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;nm2dmt&#39;

    if nrg_modality == &#39;DTI&#39; or nrg_modality == &#39;DTI_RL&#39; or nrg_modality == &#39;DTI_LR&#39; :
        bids_modality_folder = &#39;dwi&#39;
        bids_modality_filename = &#39;dwi&#39;

    if nrg_modality == &#39;rsfMRI&#39; or nrg_modality == &#39;rsfMRI_RL&#39; or nrg_modality == &#39;rsfMRI_LR&#39; :
        bids_modality_folder = &#39;func&#39;
        bids_modality_filename = &#39;func&#39;

    if nrg_modality == &#39;perf&#39;  :
        bids_modality_folder = &#39;perf&#39;
        bids_modality_filename = &#39;perf&#39;

    bids_suffix = nrg_suffix[1:]
    bids_filename = f&#39;{bids_subject}_{bids_session}_{bids_modality_filename}.{bids_suffix}&#39;

    # Return bids filepath/filename
    return os.path.join(bids_dirname, bids_subject, bids_session, bids_modality_folder, bids_filename)


def bids_2_nrg( bids_filename, project_name, date, nrg_modality=None ):
    &#34;&#34;&#34;
    Convert a BIDS filename to NRG path/filename.

    Parameters:
    bids_filename (str): The BIDS filename to convert
    project_name (str) : Name of project (i.e. PPMI)
    date (str) : Date of image acquisition


    Returns:
    str: The NRG path/filename.
    &#34;&#34;&#34;

    bids_dirname, bids_basename = os.path.split(bids_filename)
    bids_suffix = &#39;.&#39;+ bids_basename.split(&#39;.&#39;,1)[-1]
    bids_basename = bids_basename.replace(bids_suffix, &#39;&#39;) # remove ext
    bids_parts = bids_basename.split(&#39;_&#39;)
    nrg_subject_id = bids_parts[0].replace(&#39;sub-&#39;,&#39;&#39;)
    nrg_image_id = bids_parts[1].replace(&#39;ses-&#39;, &#39;&#39;)
    bids_modality = bids_parts[2]
    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality: &#34; + get_valid_modalities(asString=True))

    if bids_modality == &#39;anat&#39; and nrg_modality is None :
        nrg_modality = &#39;T1w&#39;

    if bids_modality == &#39;dwi&#39; and nrg_modality is None  :
        nrg_modality = &#39;DTI&#39;

    if bids_modality == &#39;func&#39; and nrg_modality is None  :
        nrg_modality = &#39;rsfMRI&#39;

    if bids_modality == &#39;perf&#39; and nrg_modality is None  :
        nrg_modality = &#39;perf&#39;

    nrg_suffix = bids_suffix[1:]
    nrg_filename = f&#39;{project_name}-{nrg_subject_id}-{date}-{nrg_modality}-{nrg_image_id}.{nrg_suffix}&#39;

    return os.path.join(project_name, nrg_subject_id, date, nrg_modality, nrg_image_id,nrg_filename)

def collect_blind_qc_by_modality( modality_path, set_index_to_fn=True ):
    &#34;&#34;&#34;
    Collects blind QC data from multiple CSV files with the same modality.

    Args:

    modality_path (str): The path to the folder containing the CSV files.

    set_index_to_fn: boolean

    Returns:
    Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.
    &#34;&#34;&#34;
    import glob as glob
    fns = glob.glob( modality_path )
    fns.sort()
    jdf = pd.DataFrame()
    for k in range(len(fns)):
        temp=pd.read_csv(fns[k])
        if not &#39;filename&#39; in temp.keys():
            temp[&#39;filename&#39;]=fns[k]
        jdf=pd.concat( [jdf,temp], axis=0, ignore_index=False )
    if set_index_to_fn:
        jdf.reset_index(drop=True)
        if &#34;Unnamed: 0&#34; in jdf.columns:
            holder=jdf.pop( &#34;Unnamed: 0&#34; )
        jdf.set_index(&#39;filename&#39;)
    return jdf


def outlierness_by_modality( qcdf, uid=&#39;filename&#39;, outlier_columns = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;], verbose=False ):
    &#34;&#34;&#34;
    Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.  LOF appears to be more conservative.  This function will impute missing columns with the mean.

    Args:
    - qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
    - uid: (str) Unique identifier for a subject. Default is &#39;filename&#39;.
    - outlier_columns: (list) List of columns containing outlier information. Default is [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;].
    - verbose: (bool) If True, prints information for each modality. Default is False.

    Returns:
    - qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the &#39;ol_loop&#39; and &#39;ol_lof&#39; column.  Higher values near 1 are more outlying.

    Raises:
    - ValueError: If uid is not present in the dataframe.

    Example:
    &gt;&gt;&gt; df = pd.read_csv(&#39;data.csv&#39;)
    &gt;&gt;&gt; outlierness_by_modality(df)
    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import LocalOutlierFactor
    qcdfout = qcdf.copy()
    pd.set_option(&#39;future.no_silent_downcasting&#39;, True)
    qcdfout.replace([np.inf, -np.inf], np.nan, inplace=True)
    if uid not in qcdfout.keys():
        raise ValueError( str(uid) + &#34; not in dataframe&#34;)
    if &#39;ol_loop&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_loop&#39;]=math.nan
    if &#39;ol_lof&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_lof&#39;]=math.nan
    didit=False
    for mod in get_valid_modalities( qc=True ):
        didit=True
        lof = LocalOutlierFactor()
        locsel = qcdfout[&#34;modality&#34;] == mod
        rr = qcdfout[locsel][outlier_columns]
        column_means = rr.mean()
        rr.fillna(column_means, inplace=True)
        if rr.shape[0] &gt; 1:
            if verbose:
                print(&#34;calc: &#34; + mod + &#34; outlierness &#34; )
            myneigh = np.min( [24, int(np.round(rr.shape[0]*0.5)) ] )
            temp = antspyt1w.loop_outlierness(rr.astype(float), standardize=True, extent=3, n_neighbors=myneigh, cluster_labels=None)
            qcdfout.loc[locsel,&#39;ol_loop&#39;]=temp.astype(&#39;float64&#39;)
            yhat = lof.fit_predict(rr)
            temp = lof.negative_outlier_factor_*(-1.0)
            temp = temp - temp.min()
            yhat[ yhat == 1] = 0
            yhat[ yhat == -1] = 1 # these are outliers
            qcdfout.loc[locsel,&#39;ol_lof_decision&#39;]=yhat
            qcdfout.loc[locsel,&#39;ol_lof&#39;]=temp/temp.max()
    if verbose:
        print( didit )
    return qcdfout


def nrg_format_path( projectID, subjectID, date, modality, imageID, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    create the NRG path on disk given the project, subject id, date, modality and image id

    Arguments
    ---------

    projectID : string for the project e.g. PPMI

    subjectID : string uniquely identifying the subject e.g. 0001

    date : string for the date usually 20550228 ie YYYYMMDD format

    modality : string should be one of T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)

    imageID : string uniquely identifying the specific image

    separator : default to -

    Returns
    -------
    the path where one would write the image on disk

    &#34;&#34;&#34;
    thedirectory = os.path.join( str(projectID), str(subjectID), str(date), str(modality), str(imageID) )
    thefilename = str(projectID) + separator + str(subjectID) + separator + str(date) + separator + str(modality) + separator + str(imageID)
    return os.path.join( thedirectory, thefilename )


def study_dataframe_from_matched_dataframe( matched_dataframe, rootdir, outputdir, verbose=False ):
    &#34;&#34;&#34;
    converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv

    matched_dataframe : output of antspymm.match_modalities

    rootdir : location for the input data root folder (in e.g. NRG format)

    outputdir : location for the output data

    verbose : boolean
    &#34;&#34;&#34;
    iext=&#39;.nii.gz&#39;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in matched_dataframe.keys():
            raise ValueError(&#39;matched_dataframe is missing column &#39; +musthavecols[k] + &#39; in study_dataframe_from_qc_dataframe&#39; )
    csvrow=matched_dataframe.dropna(axis=1)
    pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
    dt=str(csvrow[&#39;date&#39;].iloc[0])
    iid=str(csvrow[&#39;imageID&#39;].iloc[0])
    nrgt1fn=os.path.join( rootdir, pid, sid, dt, &#39;T1w&#39;, iid, str(csvrow[&#39;filename&#39;].iloc[0]+iext) )
    if not exists( nrgt1fn ):
        raise ValueError(&#34;T1 &#34; + nrgt1fn + &#34; does not exist in study_dataframe_from_qc_dataframe&#34;)
    flList=[]
    dtList=[]
    rsfList=[]
    nmList=[]
    if &#39;flairfn&#39; in csvrow.keys():
        flid=str(int(csvrow[&#39;flairid&#39;].iloc[0]))
        nrgt2fn=os.path.join( rootdir, pid, sid, dt, &#39;T2Flair&#39;, flid, str(csvrow[&#39;flairfn&#39;].iloc[0]+iext) )
        if exists( nrgt2fn ):
            flList.append( nrgt2fn )
    if &#39;dtfn1&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid1&#39;].iloc[0]))
        dtfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn1&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn1 ):
            dtList.append( dtfn1 )
    if &#39;dtfn2&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid2&#39;].iloc[0]))
        dtfn2=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn2&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn2 ):
            dtList.append( dtfn2 )
    if &#39;dtfn3&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid3&#39;].iloc[0]))
        dtfn3=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn3&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn3 ):
            dtList.append( dtfn3 )
    if &#39;rsffn1&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid1&#39;].iloc[0]))
        rsfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn1&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn1 ):
            rsfList.append( rsfn1 )
    if &#39;rsffn2&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid2&#39;].iloc[0]))
        rsfn2=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn2&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn2 ):
            rsfList.append( rsfn2 )
    for j in range(11):
        keyname=&#34;nmfn&#34;+str(j)
        keynameid=&#34;nmid&#34;+str(j)
        if keyname in csvrow.keys() and keynameid in csvrow.keys():
            nmid=str(int(csvrow[keynameid].iloc[0]))
            nmsearchpath=os.path.join( rootdir, pid, sid, dt, &#39;NM2DMT&#39;, nmid, &#34;*&#34;+nmid+iext)
            nmfn=glob.glob( nmsearchpath )
            nmfn=nmfn[0]
            if exists( nmfn ):
                nmList.append( nmfn )
    if verbose:
        print(&#34;assembled the image lists mapping to ....&#34;)
        print(nrgt1fn)
        print(&#34;NM&#34;)
        print(nmList)
        print(&#34;FLAIR&#34;)
        print(flList)
        print(&#34;DTI&#34;)
        print(dtList)
        print(&#34;rsfMRI&#34;)
        print(rsfList)
    studycsv = generate_mm_dataframe(
        pid,
        sid,
        dt,
        iid, # the T1 id
        &#39;T1w&#39;,
        rootdir,
        outputdir,
        t1_filename=nrgt1fn,
        flair_filename=flList,
        dti_filenames=dtList,
        rsf_filenames=rsfList,
        nm_filenames=nmList)
    return studycsv.dropna(axis=1)

def highest_quality_repeat(mxdfin, idvar, visitvar, qualityvar):
    &#34;&#34;&#34;
    This function returns a subset of the input dataframe that retains only the rows
    that correspond to the highest quality observation for each combination of ID and visit.

    Parameters:
    ----------
    mxdfin: pandas.DataFrame
        The input dataframe.
    idvar: str
        The name of the column that contains the ID variable.
    visitvar: str
        The name of the column that contains the visit variable.
    qualityvar: str
        The name of the column that contains the quality variable.

    Returns:
    -------
    pandas.DataFrame
        A subset of the input dataframe that retains only the rows that correspond
        to the highest quality observation for each combination of ID and visit.
    &#34;&#34;&#34;
    if visitvar not in mxdfin.columns:
        raise ValueError(&#34;visitvar not in dataframe&#34;)
    if idvar not in mxdfin.columns:
        raise ValueError(&#34;idvar not in dataframe&#34;)
    if qualityvar not in mxdfin.columns:
        raise ValueError(&#34;qualityvar not in dataframe&#34;)

    mxdfin[qualityvar] = mxdfin[qualityvar].astype(float)

    vizzes = mxdfin[visitvar].unique()
    uids = mxdfin[idvar].unique()
    useit = np.zeros(mxdfin.shape[0], dtype=bool)

    for u in uids:
        losel = mxdfin[idvar] == u
        vizzesloc = mxdfin[losel][visitvar].unique()

        for v in vizzesloc:
            losel = (mxdfin[idvar] == u) &amp; (mxdfin[visitvar] == v)
            mysnr = mxdfin.loc[losel, qualityvar]
            myw = np.where(losel)[0]

            if len(myw) &gt; 1:
                if any(~np.isnan(mysnr)):
                    useit[myw[np.argmax(mysnr)]] = True
                else:
                    useit[myw] = True
            else:
                useit[myw] = True

    return mxdfin[useit]


def match_modalities( qc_dataframe, unique_identifier=&#39;filename&#39;, outlier_column=&#39;ol_loop&#39;,  verbose=False ):
    &#34;&#34;&#34;
    Find the best multiple modality dataset at each time point

    :param qc_dataframe: quality control data frame with
    :param unique_identifier : the unique NRG filename for each image
    :param outlier_column: outlierness score used to identify the best image (pair) at a given date
    :param verbose: boolean
    :return: filtered matched modality data frame
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    qc_dataframe[&#39;filename&#39;]=qc_dataframe[&#39;filename&#39;].astype(str)
    qc_dataframe[&#39;ol_loop&#39;]=qc_dataframe[&#39;ol_loop&#39;].astype(float)
    qc_dataframe[&#39;ol_lof&#39;]=qc_dataframe[&#39;ol_lof&#39;].astype(float)
    qc_dataframe[&#39;ol_lof_decision&#39;]=qc_dataframe[&#39;ol_lof_decision&#39;].astype(float)
    mmdf = best_mmm( qc_dataframe, &#39;T1w&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    fldf = best_mmm( qc_dataframe, &#39;T2Flair&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    nmdf = best_mmm( qc_dataframe, &#39;NM2DMT&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    rsdf = best_mmm( qc_dataframe, &#39;rsfMRI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    dtdf = best_mmm( qc_dataframe, &#39;DTI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    mmdf[&#39;flairid&#39;] = None
    mmdf[&#39;flairfn&#39;] = None
    mmdf[&#39;flairloop&#39;] = None
    mmdf[&#39;flairlof&#39;] = None
    mmdf[&#39;dtid1&#39;] = None
    mmdf[&#39;dtfn1&#39;] = None
    mmdf[&#39;dtntimepoints1&#39;] = 0
    mmdf[&#39;dtloop1&#39;] = math.nan
    mmdf[&#39;dtlof1&#39;] = math.nan
    mmdf[&#39;dtid2&#39;] = None
    mmdf[&#39;dtfn2&#39;] = None
    mmdf[&#39;dtntimepoints2&#39;] = 0
    mmdf[&#39;dtloop2&#39;] = math.nan
    mmdf[&#39;dtlof2&#39;] = math.nan
    mmdf[&#39;rsfid1&#39;] = None
    mmdf[&#39;rsffn1&#39;] = None
    mmdf[&#39;rsfntimepoints1&#39;] = 0
    mmdf[&#39;rsfloop1&#39;] = math.nan
    mmdf[&#39;rsflof1&#39;] = math.nan
    mmdf[&#39;rsfid2&#39;] = None
    mmdf[&#39;rsffn2&#39;] = None
    mmdf[&#39;rsfntimepoints2&#39;] = 0
    mmdf[&#39;rsfloop2&#39;] = math.nan
    mmdf[&#39;rsflof2&#39;] = math.nan
    for k in range(1,11):
        myid=&#39;nmid&#39;+str(k)
        mmdf[myid] = None
        myid=&#39;nmfn&#39;+str(k)
        mmdf[myid] = None
        myid=&#39;nmloop&#39;+str(k)
        mmdf[myid] = math.nan
        myid=&#39;nmlof&#39;+str(k)
        mmdf[myid] = math.nan
    if verbose:
        print( mmdf.shape )
    for k in range(mmdf.shape[0]):
        if verbose:
            if k % 100 == 0:
                progger = str( k ) # np.round( k / mmdf.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        if dtdf is not None:
            locsel = (dtdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k])
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = dtdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = dtdf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = dtdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = float(dtdf[&#39;ol_lof_decision&#39;][locsel].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints1&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = dtdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = float(locdf[&#39;ol_lof_decision&#39;][locsel].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints1&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[0])
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn2&#34;)] = locdf[unique_identifier].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof2&#34;)] = float(locdf[&#39;ol_lof_decision&#39;][locsel].values[1])
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints2&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[1])
        if rsdf is not None:
            locsel = (rsdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k])
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = rsdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = rsdf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = rsdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = float(rsdf[&#39;ol_lof_decision&#39;].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints1&#34;)] = float(rsdf[&#39;dimt&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = rsdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints1&#34;)] = float(locdf[&#39;dimt&#39;][locsel].values[0])
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn2&#34;)] = locdf[unique_identifier].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof2&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[1])
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints2&#34;)] = float(locdf[&#39;dimt&#39;][locsel].values[1])

        if fldf is not None:
            locsel = fldf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = fldf[&#39;imageID&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = fldf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = fldf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = float(fldf[&#39;ol_lof_decision&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = fldf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[0])

        if nmdf is not None:
            locsel = nmdf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() &gt; 0:
                locdf = nmdf[locsel]
                for i in range(np.min( [10,locdf.shape[0]])):
                    nmid = &#34;nmid&#34;+str(i+1)
                    mmdf.loc[k,nmid] = locdf[&#39;imageID&#39;].iloc[i]
                    nmfn = &#34;nmfn&#34;+str(i+1)
                    mmdf.loc[k,nmfn] = locdf[&#39;imageID&#39;].iloc[i]
                    nmloop = &#34;nmloop&#34;+str(i+1)
                    mmdf.loc[k,nmloop] = locdf[outlier_column].iloc[i]
                    nmloop = &#34;nmlof&#34;+str(i+1)
                    mmdf.loc[k,nmloop] = float(locdf[&#39;ol_lof_decision&#39;].iloc[i])

    mmdf[&#39;rsf_total_timepoints&#39;]=mmdf[&#39;rsfntimepoints1&#39;]+mmdf[&#39;rsfntimepoints2&#39;]
    mmdf[&#39;dt_total_timepoints&#39;]=mmdf[&#39;dtntimepoints1&#39;]+mmdf[&#39;dtntimepoints2&#39;]
    return mmdf


def add_repeat_column(df, groupby_column):
    &#34;&#34;&#34;
    Adds a &#39;repeat&#39; column to the DataFrame that counts occurrences of each unique value
    in the specified &#39;groupby_column&#39;. The count increments from 1 for each identical entry.
    
    Parameters:
    - df: pandas DataFrame.
    - groupby_column: The name of the column to group by and count repeats.
    
    Returns:
    - Modified pandas DataFrame with an added &#39;repeat&#39; column.
    &#34;&#34;&#34;
    # Validate if the groupby_column exists in the DataFrame
    if groupby_column not in df.columns:
        raise ValueError(f&#34;Column &#39;{groupby_column}&#39; does not exist in the DataFrame.&#34;)
    
    # Count the occurrences of each unique value in the specified column and increment from 1
    df[&#39;repeat&#39;] = df.groupby(groupby_column).cumcount() + 1
    
    return df

def best_mmm( mmdf, wmod, mysep=&#39;-&#39;, outlier_column=&#39;ol_loop&#39;, verbose=False):
    &#34;&#34;&#34;
    Selects the best repeats per modality.

    Args:
    wmod (str): the modality of the image ( &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39; &#39;rsfMRI&#39;, &#39;DTI&#39;)

    mysep (str, optional): the separator used in the image file names. Defaults to &#39;-&#39;.

    outlier_name : column name for outlier score

    verbose (bool, optional): default True

    Returns:

    list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.

    &#34;&#34;&#34;
#    mmdf = mmdf.astype(str)
    mmdf[outlier_column]=mmdf[outlier_column].astype(float)
    msel = mmdf[&#39;modality&#39;] == wmod
    if wmod == &#39;rsfMRI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;rsfMRI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_RL&#39;
        msel = msel1 | msel2
        msel = msel | msel3
    if wmod == &#39;DTI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;DTI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;DTI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;DTI_RL&#39;
        msel4 = mmdf[&#39;modality&#39;] == &#39;DTIdwi&#39;
        msel5 = mmdf[&#39;modality&#39;] == &#39;DTIb0&#39;
        msel = msel1 | msel2 | msel3 | msel4 | msel5
    if sum(msel) == 0:
        return {&#39;raw&#39;: None, &#39;filt&#39;: None}
    metasub = mmdf[msel].copy()

    if verbose:
        print(f&#34;{wmod} {(metasub.shape[0])} pre&#34;)

    metasub[&#39;subjectID&#39;]=None
    metasub[&#39;date&#39;]=None
    metasub[&#39;subjectIDdate&#39;]=None
    metasub[&#39;imageID&#39;]=None
    metasub[&#39;negol&#39;]=math.nan
    for k in metasub.index:
        temp = metasub.loc[k, &#39;filename&#39;].split( mysep )
        metasub.loc[k,&#39;subjectID&#39;] = str( temp[1] )
        metasub.loc[k,&#39;date&#39;] = str( temp[2] )
        metasub.loc[k,&#39;subjectIDdate&#39;] = str( temp[1] + mysep + temp[2] )
        metasub.loc[k,&#39;imageID&#39;] = str( temp[4])


    if &#39;ol_&#39; in outlier_column:
        metasub[&#39;negol&#39;] = metasub[outlier_column].max() - metasub[outlier_column]
    else:
        metasub[&#39;negol&#39;] = metasub[outlier_column]
    if &#39;date&#39; not in metasub.keys():
        metasub[&#39;date&#39;]=None
    metasubq = add_repeat_column( metasub, &#39;subjectIDdate&#39; )
    metasubq = highest_quality_repeat(metasubq, &#39;filename&#39;, &#39;date&#39;, &#39;negol&#39;)

    if verbose:
        print(f&#34;{wmod} {metasubq.shape[0]} post&#34;)

#    metasub = metasub.astype(str)
#    metasubq = metasubq.astype(str)
    metasub[outlier_column]=metasub[outlier_column].astype(float)
    metasubq[outlier_column]=metasubq[outlier_column].astype(float)
    return {&#39;raw&#39;: metasub, &#39;filt&#39;: metasubq}

def mm_read( x, standardize_intensity=False, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - same as ants.image_read (for now)

    standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one

    modality : not used
    &#34;&#34;&#34;
    if x is None:
        raise ValueError( &#34; None passed to function antspymm.mm_read.&#34; )
    if not isinstance(x,str):
        raise ValueError( &#34; Non-string passed to function antspymm.mm_read.&#34; )
    if not os.path.exists( x ):
        raise ValueError( &#34; file &#34; + fni + &#34; does not exist.&#34; )
    img = ants.image_read( x, reorient=False )
    if standardize_intensity:
        img[img&lt;0.0]=0.0
        img=ants.iMath(img,&#39;Normalize&#39;)
    if modality == &#34;T1w&#34; and img.dimension == 4:
        print(&#34;WARNING: input image is 4D - we attempt a hack fix that works in some odd cases of PPMI data - please check this image: &#34; + x, flush=True )
        i1=ants.slice_image(img,3,0)
        i2=ants.slice_image(img,3,1)
        kk=np.concatenate( [i1.numpy(),i2.numpy()], axis=2 )
        kk=ants.from_numpy(kk)
        img=ants.copy_image_info(i1,kk)
    return img

def mm_read_to_3d( x, slice=None, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - and return as 3d or None if that is not possible
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if img.dimension &lt; 3:
        return None
    elif img.dimension == 4:
        nslices = img.shape[3]
        if slice is None:
            sl = np.round( nslices * 0.5 )
        else:
            sl = slice
        if sl &gt; nslices:
            sl = nslices-1
        return ants.slice_image( img, axis=3, idx=int(sl) )
    elif img.dimension == 3:
        return img
    return None

def timeseries_n3(x):
    &#34;&#34;&#34;
    Perform N3 bias field correction on a time-series image dataset using ANTsPy library.

    This function processes a multi-dimensional image dataset, where the last dimension
    represents different time points. It applies N3 bias field correction to each time point 
    individually to correct intensity non-uniformity.

    Parameters:
    x (ndarray): A multi-dimensional array where the last dimension represents time points. 
                 Each &#39;slice&#39; along this dimension is a separate image to be corrected.

    Returns:
    ndarray: A multi-dimensional array of the same shape as x, with N3 bias field correction 
             applied to each time slice.

    The function works as follows:
    - Initializes an empty list `mimg` to store the corrected images.
    - Determines the number of time points in the input image series.
    - Iterates over each time point, extracting the image slice and applying N3 bias 
      field correction.
    - The corrected images are then appended to the `mimg` list.
    - Finally, the list of corrected images is converted back into a multi-dimensional 
      array and returned.

    Example:
    corrected_images = timeseries_n3(image_data)
    &#34;&#34;&#34;
    mimg = []
    n = len(x.shape) - 1
    for kk in range(x.shape[n]):
        temp = ants.slice_image(x, axis=n, idx=kk)
        temp = ants.n3_bias_field_correction(temp, downsample_factor=2)
        mimg.append(temp)
    return ants.list_to_ndimage(x, mimg)

def image_write_with_thumbnail( x,  fn, y=None, thumb=True ):
    &#34;&#34;&#34;
    will write the image and (optionally) a png thumbnail with (optional) overlay/underlay
    &#34;&#34;&#34;
    ants.image_write( x, fn )
    if not thumb or x.components &gt; 1:
        return
    thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_3dthumb.png&#34;,fn)
    if thumb and x.dimension == 3:
        if y is None:
            try:
                ants.plot_ortho( x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            try:
                ants.plot_ortho( y, x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
    if thumb and x.dimension == 4:
        thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_4dthumb.png&#34;,fn)
        nslices = x.shape[3]
        sl = np.round( nslices * 0.5 )
        if sl &gt; nslices:
            sl = nslices-1
        xview = ants.slice_image( x, axis=3, idx=int(sl) )
        if y is None:
            try:
                ants.plot_ortho( xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            if y.dimension == 3:
                try:
                    ants.plot_ortho(y, xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
                except:
                    pass
    return

def convert_np_in_dict(data_dict):
    &#34;&#34;&#34;
    Convert values in the dictionary from nupmy float or int to regular float or int.

    :param data_dict: A dictionary with values of various types.
    :return: Dictionary with numpy values converted.
    &#34;&#34;&#34;
    converted_dict = {}
    for key, value in data_dict.items():
        if isinstance(value, (np.float32, np.float64)):
            converted_dict[key] = float(value)
        elif isinstance(value, (np.int8,  np.uint8, np.int16,  np.uint16, np.int32,  np.uint32, np.int64,  np.uint64)):
            converted_dict[key] = int(value)
        else:
            converted_dict[key] = value
    return converted_dict

def mc_resample_image_to_target( x , y, interp_type=&#39;linear&#39; ):
    &#34;&#34;&#34;
    multichannel version of resample_image_to_target
    &#34;&#34;&#34;
    xx=ants.split_channels( x )
    yy=ants.split_channels( y )[0]
    newl=[]
    for k in range(len(xx)):
        newl.append(  ants.resample_image_to_target( xx[k], yy, interp_type=interp_type ) )
    return ants.merge_channels( newl )

def nrg_filelist_to_dataframe( filename_list, myseparator=&#34;-&#34; ):
    &#34;&#34;&#34;
    convert a list of files in nrg format to a dataframe

    Arguments
    ---------
    filename_list : globbed list of files

    myseparator : string separator between nrg parts

    Returns
    -------

    df : pandas data frame

    &#34;&#34;&#34;
    def getmtime(x):
        x= dt.datetime.fromtimestamp(os.path.getmtime(x)).strftime(&#34;%Y-%m-%d %H:%M:%d&#34;)
        return x
    df=pd.DataFrame(columns=[&#39;filename&#39;,&#39;file_last_mod_t&#39;,&#39;else&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;uid&#39;])
    df.set_index(&#39;filename&#39;)
    df[&#39;filename&#39;] = pd.Series([file for file in filename_list ])
    # I applied a time modified file to df[&#39;file_last_mod_t&#39;] by getmtime function
    df[&#39;file_last_mod_t&#39;] = df[&#39;filename&#39;].apply(lambda x: getmtime(x))
    for k in range(df.shape[0]):
        locfn=df[&#39;filename&#39;].iloc[k]
        splitter=os.path.basename(locfn).split( myseparator )
        df[&#39;sid&#39;].iloc[k]=splitter[1]
        df[&#39;visitdate&#39;].iloc[k]=splitter[2]
        df[&#39;modality&#39;].iloc[k]=splitter[3]
        temp = os.path.splitext(splitter[4])[0]
        df[&#39;uid&#39;].iloc[k]=os.path.splitext(temp)[0]
    return df


def merge_timeseries_data( img_LR, img_RL, allow_resample=True ):
    &#34;&#34;&#34;
    merge time series data into space of reference_image

    img_LR : image

    img_RL : image

    allow_resample : boolean

    &#34;&#34;&#34;
    # concatenate the images into the reference space
    mimg=[]
    for kk in range( img_LR.shape[3] ):
        temp = ants.slice_image( img_LR, axis=3, idx=kk )
        mimg.append( temp )
    for kk in range( img_RL.shape[3] ):
        temp = ants.slice_image( img_RL, axis=3, idx=kk )
        if kk == 0:
            insamespace = ants.image_physical_space_consistency( temp, mimg[0] )
        if allow_resample and not insamespace :
            temp = ants.resample_image_to_target( temp, mimg[0] )
        mimg.append( temp )
    return ants.list_to_ndimage( img_LR, mimg )


def timeseries_reg(
    image,
    avg_b0,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=1.0,
    fdOffset=2.0,
    trim = 0,
    output_directory=None,
    return_numpy_motion_parameters=False,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion.

    Arguments
    ---------
    image: antsImage, usually ND where D=4.

    avg_b0: Fixed image b0 image

    type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

    fdOffset: offset value to use in framewise displacement calculation

    trim : integer - trim this many images off the front of the time series

    output_directory : string
            output will be placed in this directory plus a numeric extension.

    return_numpy_motion_parameters : boolean

    verbose: boolean

    kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD
        }

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/ts_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(&#39;bold motcorr with &#39; + type_of_transform)
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    # get a local deformation from slice to local avg space
    motion_parameters = list()
    motion_corrected = list()
    mask = ants.get_mask( avg_b0 )
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 ) + 1
    for k in range( nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k % 2).zfill(4)+&#34;_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if temp.numpy().var() &gt; 0:
            img1w = ants.apply_transforms( avg_b0,
                temp,
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(avg_b0)

    motion_parameters = motion_parameters[trim:len(motion_parameters)]
    if return_numpy_motion_parameters:
        motion_parameters = read_ants_transforms_to_numpy( motion_parameters )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( ants.get_spacing(image)[3] )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected[trim:len(motion_corrected)]),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD[trim:len(FD)]
    }


def merge_dwi_data( img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL ):
    &#34;&#34;&#34;
    merge motion and distortion corrected data if possible

    img_LRdwp : image

    bval_LR : array

    bvec_LR : array

    img_RLdwp : image

    bval_RL : array

    bvec_RL : array

    &#34;&#34;&#34;
    import warnings
    insamespace = ants.image_physical_space_consistency( img_LRdwp, img_RLdwp )
    if not insamespace :
        warnings.warn(&#39;not insamespace ... corrected image pair should occupy the same physical space; returning only the 1st set and wont join these data.&#39;)
        return img_LRdwp, bval_LR, bvec_LR
    
    bval_LR = np.concatenate([bval_LR,bval_RL])
    bvec_LR = np.concatenate([bvec_LR,bvec_RL])
    # concatenate the images
    mimg=[]
    for kk in range( img_LRdwp.shape[3] ):
            mimg.append( ants.slice_image( img_LRdwp, axis=3, idx=kk ) )
    for kk in range( img_RLdwp.shape[3] ):
            mimg.append( ants.slice_image( img_RLdwp, axis=3, idx=kk ) )
    img_LRdwp = ants.list_to_ndimage( img_LRdwp, mimg )
    return img_LRdwp, bval_LR, bvec_LR

def bvec_reorientation( motion_parameters, bvecs, rebase=None ):
    if motion_parameters is None:
        return bvecs
    n = len(motion_parameters)
    if n &lt; 1:
        return bvecs
    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs
    dipymoco = np.zeros( [n,3,3] )
    for myidx in range(n):
        if myidx &lt; bvecs.shape[0]:
            dipymoco[myidx,:,:] = np.eye( 3 )
            if motion_parameters[myidx] != &#39;NA&#39;:
                temp = motion_parameters[myidx]
                if len(temp) == 4 :
                    temp1=temp[3] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                elif len(temp) == 2 :
                    temp=temp[1] # FIXME should be composite of index 1 and 3
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                elif len(temp) == 3 :
                    temp1=temp[2] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                else:
                    temp=temp[0]
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                bvecs[myidx,:] = np.dot( Rinv, bvecs[myidx,:] )
                if rebase is not None:
                    # FIXME - should combine these operations
                    bvecs[myidx,:] = np.dot( rebase, bvecs[myidx,:] )
    return bvecs

def get_dti( reference_image, tensormodel, upper_triangular=True, return_image=False ):
    &#34;&#34;&#34;
    extract DTI data from a dipy tensormodel

    reference_image : antsImage defining physical space (3D)

    tensormodel : from dipy e.g. the variable myoutx[&#39;dtrecon_LR_dewarp&#39;][&#39;tensormodel&#39;] if myoutx is produced my joint_dti_recon

    upper_triangular: boolean otherwise use lower triangular coding

    return_image : boolean return the ANTsImage form of DTI otherwise return an array

    Returns
    -------
    either an ANTsImage (dim=X.Y.Z with 6 component voxels, upper triangular form)
        or a 5D NumPy array (dim=X.Y.Z.3.3)

    Notes
    -----
    DiPy returns lower triangular form but ANTs expects upper triangular.
        Here, we default to the ANTs standard but could generalize in the future 
        because not much here depends on ANTs standards of tensor data.
        ANTs xx,xy,xz,yy,yz,zz
        DiPy Dxx, Dxy, Dyy, Dxz, Dyz, Dzz

    &#34;&#34;&#34;
    # make the DTI - see 
    # https://dipy.org/documentation/1.7.0/examples_built/07_reconstruction/reconst_dti/#sphx-glr-examples-built-07-reconstruction-reconst-dti-py
    # By default, in DIPY, values are ordered as (Dxx, Dxy, Dyy, Dxz, Dyz, Dzz)
    # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
    reoind = np.array([0,1,3,2,4,5]) # arrays are faster than lists
    import dipy.reconst.dti as dti
    dtiut = dti.lower_triangular(tensormodel.quadratic_form)
    it = np.ndindex( reference_image.shape )
    yyind=2
    xzind=3
    if upper_triangular:
        yyind=3
        xzind=2
        for i in it: # convert to upper triangular
            dtiut[i] = dtiut[i][ reoind ] # do we care if this is doing extra work?
    if return_image:
        dtiAnts = ants.from_numpy(dtiut,has_components=True)
        ants.copy_image_info( reference_image, dtiAnts )
        return dtiAnts
    # copy these data into a tensor 
    dtinp = np.zeros(reference_image.shape + (3,3), dtype=float)  
    dtix = np.zeros((3,3), dtype=float)  
    it = np.ndindex( reference_image.shape )
    for i in it:
        dtivec = dtiut[i] # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
        dtix[0,0]=dtivec[0]
        dtix[1,1]=dtivec[yyind] # 2 for LT
        dtix[2,2]=dtivec[5] 
        dtix[0,1]=dtix[1,0]=dtivec[1]
        dtix[0,2]=dtix[2,0]=dtivec[xzind] # 3 for LT
        dtix[1,2]=dtix[2,1]=dtivec[4]
        dtinp[i]=dtix
    return dtinp

def triangular_to_tensor( image, upper_triangular=True ):
    &#34;&#34;&#34;
    convert triangular tensor image to a full tensor form (in numpy)

    image : antsImage holding dti in either upper or lower triangular format 

    upper_triangular: boolean

    Note
    --------
    see get_dti function for more details
    &#34;&#34;&#34;
    reoind = np.array([0,1,3,2,4,5]) # arrays are faster than lists
    it = np.ndindex( image.shape )
    yyind=2
    xzind=3
    if upper_triangular:
        yyind=3
        xzind=2
    # copy these data into a tensor 
    dtinp = np.zeros(image.shape + (3,3), dtype=float)
    dtix = np.zeros((3,3), dtype=float)
    it = np.ndindex( image.shape )
    dtiut = image.numpy()
    for i in it:
        dtivec = dtiut[i] # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
        dtix[0,0]=dtivec[0]
        dtix[1,1]=dtivec[yyind] # 2 for LT
        dtix[2,2]=dtivec[5] 
        dtix[0,1]=dtix[1,0]=dtivec[1]
        dtix[0,2]=dtix[2,0]=dtivec[xzind] # 3 for LT
        dtix[1,2]=dtix[2,1]=dtivec[4]
        dtinp[i]=dtix
    return dtinp


def dti_numpy_to_image( reference_image, tensorarray, upper_triangular=True):
    &#34;&#34;&#34;
    convert numpy DTI data to antsImage

    reference_image : antsImage defining physical space (3D)

    tensorarray : numpy array X,Y,Z,3,3 shape

    upper_triangular: boolean otherwise use lower triangular coding

    Returns
    -------
    ANTsImage

    Notes
    -----
    DiPy returns lower triangular form but ANTs expects upper triangular.
        Here, we default to the ANTs standard but could generalize in the future 
        because not much here depends on ANTs standards of tensor data.
        ANTs xx,xy,xz,yy,yz,zz
        DiPy Dxx, Dxy, Dyy, Dxz, Dyz, Dzz

    &#34;&#34;&#34;
    dtiut = np.zeros(reference_image.shape + (6,), dtype=float)  
    dtivec = np.zeros(6, dtype=float)  
    it = np.ndindex( reference_image.shape )
    yyind=2
    xzind=3
    if upper_triangular:
        yyind=3
        xzind=2
    for i in it:
        dtix = tensorarray[i] # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
        dtivec[0]=dtix[0,0]
        dtivec[yyind]=dtix[1,1] # 2 for LT
        dtivec[5]=dtix[2,2]
        dtivec[1]=dtix[0,1]
        dtivec[xzind]=dtix[2,0] # 3 for LT
        dtivec[4]=dtix[1,2]
        dtiut[i]=dtivec
    dtiAnts = ants.from_numpy( dtiut, has_components=True )
    ants.copy_image_info( reference_image, dtiAnts )
    return dtiAnts

def transform_and_reorient_dti( fixed, moving_dti, composite_transform, py_based=True, verbose=False, **kwargs):
    &#34;&#34;&#34;
    apply a transform to DTI in the style of ants.apply_transforms. this function
        expects a pre-computed composite transform which it will use to reorient 
        the DTI using preservation of principle directions.
    
    fixed : antsImage reference space

    moving_dti : antsImage DTI in upper triangular format

    composite_transform : should be a composition of all transforms to be applied stored on disk ( a filename ) ... might change this in the future.

    py_based : boolean

    verbose : boolean

    **kwargs : passed to ants.apply_transforms

    &#34;&#34;&#34;
    if moving_dti.dimension != 3:
        raise ValueError(&#39;moving image should have 3 dimensions&#39;)
    if moving_dti.components != 6:
        raise ValueError(&#39;moving image should have 6 components&#39;)
    # now apply the transform to the template
    # 1. transform the tensor components
    dtsplit = moving_dti.split_channels()
    dtiw = []
    for k in range(len(dtsplit)):
        dtiw.append( ants.apply_transforms( fixed, dtsplit[k], composite_transform ) )
    dtiw=ants.merge_channels(dtiw)
    if verbose:
        print(&#34;reorient tensors locally: compose and get reo image&#34;)
    locrot = ants.deformation_gradient( ants.image_read(composite_transform), 
        to_rotation = True, py_based=py_based )
    rebaser = np.dot( np.transpose( fixed.direction  ), moving_dti.direction )
    if verbose:
        print(&#34;convert UT to full tensor&#34;)
    dtiw2tensor = triangular_to_tensor( dtiw )
    if verbose:
        print(&#34;rebase tensors to new space via iterator&#34;)
    it = np.ndindex( fixed.shape )
    for i in it:
        # direction * dt * direction.transpose();
        mmm = dtiw2tensor[i]
        # transform rebase
        locrotx = np.reshape( locrot[i], [3,3] )
        mmm = np.dot( mmm, np.transpose( locrotx ) )
        mmm = np.dot( locrotx, mmm )
        # physical space rebase
        mmm = np.dot( mmm, np.transpose( rebaser ) )
        mmm = np.dot( rebaser, mmm )
        dtiw2tensor[i] = mmm
    if verbose:
        print(&#34;done with rebasing&#34;)
    return dti_numpy_to_image( fixed, dtiw2tensor )


def dti_reg(
    image,
    avg_b0,
    avg_dwi,
    bvals=None,
    bvecs=None,
    b0_idx=None,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=3.0,
    fdOffset=2.0,
    mask_csf=False,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with optional deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        avg_b0: Fixed image b0 image

        avg_dwi: Fixed dwi same space as b0 image

        bvals: bvalues (file or array)

        bvecs: bvecs (file or array)

        b0_idx: indices of b0

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        mask_csf: boolean

        output_directory : string
            output will be placed in this directory plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if bvals is not None and bvecs is not None:
        if isinstance(bvecs, str):
            bvals, bvecs = read_bvals_bvecs( bvals , bvecs  )
        else: # assume we already read them
            bvals = bvals.copy()
            bvecs = bvecs.copy()
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD,
            &#39;bvals&#39;:bvals,
            &#39;bvecs&#39;:bvecs
        }

    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/dti_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]
    # first get a local deformation from slice to local avg space
    # then get a global deformation from avg to ref space
    ab0, adw = get_average_dwi_b0( image )
    mask = ants.get_mask(adw)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)


    if verbose:
        print(&#34;begin global distortion correction&#34;)
    # initrig = tra_initializer(avg_b0, ab0, max_rotation=60, transform=[&#39;rigid&#39;], verbose=verbose)
    if mask_csf:
        bcsf = ants.threshold_image( avg_b0,&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf = ab0 * 0 + 1

    initrig = ants.registration( avg_b0, ab0,&#39;BOLDRigid&#39;,outprefix=ofnG)
    deftx = ants.registration( avg_dwi, adw, &#39;SyNOnly&#39;,
        syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=[50,50,20],
        multivariate_extras=[ [ &#34;CC&#34;, avg_b0, ab0, 1, 2 ]],
        initial_transform=initrig[&#39;fwdtransforms&#39;][0],
        outprefix=ofnG
        )[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;end global distortion correction&#34;)

    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 ) + 1
    for k in range(nTimePoints):
        if verbose and nTimePoints &gt; 0 and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k).zfill(4)+&#34;rig_&#34;
        txprefix2 = ofnL+str(k % 2).zfill(4)+&#34;def_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma, grad_step=0.1,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix2,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        if temp.numpy().var() &gt; 0:
            motion_parameters[k]=deftx+motion_parameters[k]
            img1w = ants.apply_transforms( avg_dwi,
                ants.slice_image(image, axis=idim - 1, idx=k),
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(fixed)

    if verbose:
        print(&#34;Reorient bvecs&#34;)
    if bvecs is not None:
        #    direction = target-&gt;GetDirection().GetTranspose() * img_mov-&gt;GetDirection().GetVnlMatrix();
        rebase = np.dot( np.transpose( avg_b0.direction  ), ab0.direction )
        bvecs = bvec_reorientation( motion_parameters, bvecs, rebase )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( 1.0 )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
    }


def mc_reg(
    image,
    fixed=None,
    type_of_transform=&#34;Rigid&#34;,
    mask=None,
    total_sigma=3.0,
    fdOffset=2.0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        fixed: Fixed image to register all timepoints to.  If not provided,
            mean image is used.

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        output_directory : string
            output will be named with this prefix plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data(&#39;ch2&#39;))
    &gt;&gt;&gt; mytx = ants.motion_correction( fi )
    &#34;&#34;&#34;
    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/mc_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)

    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    if fixed is None:
        fixed = ants.get_average_of_timeseries( image )
    if mask is None:
        mask = ants.get_mask(fixed)
    FD = np.zeros(nTimePoints)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = 0
    for k in range(nTimePoints):
        mycount = round(k / nTimePoints * 100)
        if verbose and mycount == counter:
            counter = counter + 10
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;Rigid&#39;,
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myreg[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
            img1w = ants.apply_transforms( fixed,
                ants.slice_image(image, axis=idim - 1, idx=k),
                myreg[&#34;fwdtransforms&#34;] )
            motion_corrected.append(img1w)
        else:
            motion_parameters.append(&#34;NA&#34;)
            motion_corrected.append(temp)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(image, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
    }

def map_scalar_to_labels(dataframe, label_image_template):
    &#34;&#34;&#34;
    Map scalar values from a DataFrame to associated integer image labels.

    Parameters:
    - dataframe (pd.DataFrame): A Pandas DataFrame containing a label column and scalar_value column.
    - label_image_template (ants.ANTsImage): ANTs image with (at least some of) the same values as labels.

    Returns:
    - ants.ANTsImage: A label image with scalar values mapped to associated integer labels.
    &#34;&#34;&#34;

    # Create an empty label image with the same geometry as the template
    mapped_label_image = label_image_template.clone() * 0.0

    # Loop through DataFrame and map scalar values to labels
    for index, row in dataframe.iterrows():
        label = int(row[&#39;label&#39;])  # Assuming the DataFrame has a &#39;label&#39; column
        scalar_value = row[&#39;scalar_value&#39;]  # Replace with your column name
        mapped_label_image[label_image_template == label] = scalar_value

    return mapped_label_image


def template_figure_with_overlay(scalar_label_df, prefix, outputfilename=None, template=&#39;cit168&#39;, xyz=None, mask_dilation=25, padding=12, verbose=True):
    &#34;&#34;&#34;
    Process and visualize images with mapped scalar values.

    Parameters:
    - scalar_label_df (pd.DataFrame): A Pandas DataFrame containing scalar values and labels.
    - prefix (str): The prefix for input image files.
    - template (str, optional): Template for selecting image data (default is &#39;cit168&#39;).
    - xyz (str, optional): The integer index of the slices to display.
    - mask_dilation (int, optional): Dilation factor for creating a mask (default is 25).
    - padding (int, optional): Padding value for the mapped images (default is 12).
    - verbose (bool, optional): Enable verbose mode for printing (default is True).

    Example Usage:
    &gt;&gt;&gt; scalar_label_df = pd.DataFrame({&#39;label&#39;: [1, 2, 3], &#39;scalar_value&#39;: [0.5, 0.8, 1.2]})
    &gt;&gt;&gt; prefix = &#39;../PPMI_template0_&#39;
    &gt;&gt;&gt; process_and_visualize_images(scalar_label_df, prefix, template=&#39;cit168&#39;, xyz=None, mask_dilation=25, padding=12, verbose=True)
    &#34;&#34;&#34;

    # Template image paths
    template_paths = {
        &#39;cit168&#39;: &#39;cit168lab.nii.gz&#39;,
        &#39;bf&#39;: &#39;bf.nii.gz&#39;,
        &#39;cerebellum&#39;: &#39;cerebellum.nii.gz&#39;,
        &#39;mtl&#39;: &#39;mtl.nii.gz&#39;,
        &#39;ctx&#39;: &#39;dkt_cortex.nii.gz&#39;,
        &#39;jhuwm&#39;: &#39;JHU_wm.nii.gz&#39;
    }

    if template not in template_paths:
        print( &#34;Valid options:&#34;)
        print( template_paths )
        raise ValueError(f&#34;Template option &#39;{template}&#39; does not exist.&#34;)

    template_image_path = template_paths[template]
    template_image = ants.image_read(f&#39;{prefix}{template_image_path}&#39;)

    # Load image data
    edgeimg = ants.image_read(f&#39;{prefix}edge.nii.gz&#39;)
    dktimg = ants.image_read(f&#39;{prefix}dkt_parcellation.nii.gz&#39;)
    segimg = ants.image_read(f&#39;{prefix}tissue_segmentation.nii.gz&#39;)
    ttl = &#39;&#39;

    # Load and process the template image
    ventricles = ants.threshold_image(dktimg, 4, 4) + ants.threshold_image(dktimg, 43, 43)
    seggm = ants.mask_image(segimg, segimg, [2, 4], binarize=False)
    edgeimg = edgeimg.clone()
    edgeimg[edgeimg == 0] = ventricles[edgeimg == 0]
    segwm = ants.threshold_image(segimg, 3, 4).morphology(&#34;open&#34;, 1)

    # Define cropping mask
    cmask = ants.threshold_image(template_image, 1, 1.e9).iMath(&#34;MD&#34;, mask_dilation)

    mapped_image = map_scalar_to_labels(scalar_label_df, template_image)
    tcrop = ants.crop_image(template_image, cmask)
    toviz = ants.crop_image(mapped_image, cmask)
    seggm = ants.crop_image(edgeimg, cmask)
       
    # Map scalar values to labels and visualize
    toviz = ants.pad_image(toviz, pad_width=(padding, padding, padding))
    seggm = ants.pad_image(seggm, pad_width=(padding, padding, padding))
    tcrop = ants.pad_image(tcrop, pad_width=(padding, padding, padding))

    if xyz is None:
        if template == &#39;cit168&#39;:
            xyz=[140, 89, 94]
        elif template == &#39;bf&#39;:
            xyz=[114,92,76]
        elif template == &#39;cerebellum&#39;:
            xyz=[169, 128, 137]
        elif template == &#39;mtl&#39;:
            xyz=[154, 112, 113]
        elif template == &#39;ctx&#39;:
            xyz=[233, 190, 174]
        elif template == &#39;jhuwm&#39;:
            xyz=[146, 133, 182]

    if verbose:
        print(&#34;plot xyz for &#34; + template )
        print( xyz )
        
    if outputfilename is None:
        temp = ants.plot_ortho( seggm, overlay=toviz, crop=False,
                        xyz=xyz, cbar_length=0.2, cbar_vertical=False,
                        flat=True, xyz_lines=False, resample=False, orient_labels=False,
                        title=ttl, titlefontsize=12, title_dy=-0.02, textfontcolor=&#39;red&#39;, 
                        cbar=True, allow_xyz_change=False)
    else:
        temp = ants.plot_ortho( seggm, overlay=toviz, crop=False,
                    xyz=xyz, cbar_length=0.2, cbar_vertical=False,
                    flat=True, xyz_lines=False, resample=False, orient_labels=False,
                    title=ttl, titlefontsize=12, title_dy=-0.02, textfontcolor=&#39;red&#39;, 
                    cbar=True, allow_xyz_change=False, filename=outputfilename )
    seggm = temp[&#39;image&#39;]
    toviz = temp[&#39;overlay&#39;]
    return { &#34;underlay&#34;: seggm, &#39;overlay&#39;: toviz, &#39;seg&#39;: tcrop  }

def get_data( name=None, force_download=False, version=23, target_extension=&#39;.csv&#39; ):
    &#34;&#34;&#34;
    Get ANTsPyMM data filename

    The first time this is called, it will download data to ~/.antspymm.
    After, it will just read data from disk.  The ~/.antspymm may need to
    be periodically deleted in order to ensure data is current.

    Arguments
    ---------
    name : string
        name of data tag to retrieve
        Options:
            - &#39;all&#39;

    force_download: boolean

    version: version of data to download (integer)

    Returns
    -------
    string
        filepath of selected data

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.get_data()
    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/16912366/versions/&#34; + str(version)
        target_file_name = &#34;16912366.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )


    files = []
    for fname in os.listdir(DATA_PATH):
        if ( fname.endswith(target_extension) ) :
            fname = os.path.join(DATA_PATH, fname)
            files.append(fname)

    if len( files ) == 0 :
        download_data( version = version )
        for fname in os.listdir(DATA_PATH):
            if ( fname.endswith(target_extension) ) :
                fname = os.path.join(DATA_PATH, fname)
                files.append(fname)

    if name == &#39;all&#39;:
        return files

    datapath = None

    for fname in os.listdir(DATA_PATH):
        mystem = (Path(fname).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        if ( name == mystem and fname.endswith(target_extension) ) :
            datapath = os.path.join(DATA_PATH, fname)

    return datapath


def get_models( version=3, force_download=True ):
    &#34;&#34;&#34;
    Get ANTsPyMM data models

    force_download: boolean

    Returns
    -------
    None

    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/21718412/versions/&#34;+str(version)
        target_file_name = &#34;21718412.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )
    return



def dewarp_imageset( image_list, initial_template=None,
    iterations=None, padding=0, target_idx=[0], **kwargs ):
    &#34;&#34;&#34;
    Dewarp a set of images

    Makes simplifying heuristic decisions about how to transform an image set
    into an unbiased reference space.  Will handle plenty of decisions
    automatically so beware.  Computes an average shape space for the images
    and transforms them to that space.

    Arguments
    ---------
    image_list : list containing antsImages 2D, 3D or 4D

    initial_template : optional

    iterations : number of template building iterations

    padding:  will pad the images by an integer amount to limit edge effects

    target_idx : the target indices for the time series over which we should average;
        a list of integer indices into the last axis of the input images.

    kwargs : keyword args
        arguments passed to ants registration - these must be set explicitly

    Returns
    -------
    a dictionary with the mean image and the list of the transformed images as
    well as motion correction parameters for each image in the input list

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    outlist = []
    avglist = []
    if len(image_list[0].shape) &gt; 3:
        imagetype = 3
        for k in range(len(image_list)):
            for j in range(len(target_idx)):
                avglist.append( ants.slice_image( image_list[k], axis=3, idx=target_idx[j] ) )
    else:
        imagetype = 0
        avglist=image_list

    pw=[]
    for k in range(len(avglist[0].shape)):
        pw.append( padding )
    for k in range(len(avglist)):
        avglist[k] = ants.pad_image( avglist[k], pad_width=pw  )

    if initial_template is None:
        initial_template = avglist[0] * 0
        for k in range(len(avglist)):
            initial_template = initial_template + avglist[k]/len(avglist)

    if iterations is None:
        iterations = 2

    btp = ants.build_template(
        initial_template=initial_template,
        image_list=avglist,
        gradient_step=0.5, blending_weight=0.8,
        iterations=iterations, **kwargs )

    # last - warp all images to this frame
    mocoplist = []
    mocofdlist = []
    reglist = []
    for k in range(len(image_list)):
        if imagetype == 3:
            moco0 = ants.motion_correction( image=image_list[k], fixed=btp, type_of_transform=&#39;BOLDRigid&#39; )
            mocoplist.append( moco0[&#39;motion_parameters&#39;] )
            mocofdlist.append( moco0[&#39;FD&#39;] )
            locavg = ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=0 ) * 0.0
            for j in range(len(target_idx)):
                locavg = locavg + ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=target_idx[j] )
            locavg = locavg * 1.0 / len(target_idx)
        else:
            locavg = image_list[k]
        reg = ants.registration( btp, locavg, **kwargs )
        reglist.append( reg )
        if imagetype == 3:
            myishape = image_list[k].shape
            mytslength = myishape[ len(myishape) - 1 ]
            mywarpedlist = []
            for j in range(mytslength):
                locimg = ants.slice_image( image_list[k], axis=3, idx = j )
                mywarped = ants.apply_transforms( btp, locimg,
                    reg[&#39;fwdtransforms&#39;] + moco0[&#39;motion_parameters&#39;][j], imagetype=0 )
                mywarpedlist.append( mywarped )
            mywarped = ants.list_to_ndimage( image_list[k], mywarpedlist )
        else:
            mywarped = ants.apply_transforms( btp, image_list[k], reg[&#39;fwdtransforms&#39;], imagetype=imagetype )
        outlist.append( mywarped )

    return {
        &#39;dewarpedmean&#39;:btp,
        &#39;dewarped&#39;:outlist,
        &#39;deformable_registrations&#39;: reglist,
        &#39;FD&#39;: mocofdlist,
        &#39;motionparameters&#39;: mocoplist }


def super_res_mcimage( image,
    srmodel,
    truncation=[0.0001,0.995],
    poly_order=&#39;hist&#39;,
    target_range=[0,1],
    isotropic = False,
    verbose=False ):
    &#34;&#34;&#34;
    Super resolution on a timeseries or multi-channel image

    Arguments
    ---------
    image : an antsImage

    srmodel : a tensorflow fully convolutional model

    truncation :  quantiles at which we truncate intensities to limit impact of outliers e.g. [0.005,0.995]

    poly_order : if not None, will fit a global regression model to map
        intensity back to original histogram space; if &#39;hist&#39; will match
        by histogram matching - ants.histogram_match_image

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

    isotropic : boolean

    verbose : boolean

    Returns
    -------
    super resolution version of the image

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    mcsr = list()
    for k in range(nTimePoints):
        if verbose and (( k % 5 ) == 0 ):
            mycount = round(k / nTimePoints * 100)
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image( image, axis=idim - 1, idx=k )
        temp = ants.iMath( temp, &#34;TruncateIntensity&#34;, truncation[0], truncation[1] )
        mysr = antspynet.apply_super_resolution_model_to_image( temp, srmodel,
            target_range = target_range )
        if poly_order is not None:
            bilin = ants.resample_image_to_target( temp, mysr )
            if poly_order == &#39;hist&#39;:
                mysr = ants.histogram_match_image( mysr, bilin )
            else:
                mysr = antspynet.regression_match_image( mysr, bilin, poly_order = poly_order )
        if isotropic:
            mysr = down2iso( mysr )
        if k == 0:
            upshape = list()
            for j in range(len(ishape)-1):
                upshape.append( mysr.shape[j] )
            upshape.append( ishape[ idim-1 ] )
            if verbose:
                print(&#34;SR will be of voxel size:&#34; + str(upshape) )
        mcsr.append( mysr )

    upshape = list()
    for j in range(len(ishape)-1):
        upshape.append( mysr.shape[j] )
    upshape.append( ishape[ idim-1 ] )
    if verbose:
        print(&#34;SR will be of voxel size:&#34; + str(upshape) )

    imageup = ants.resample_image( image, upshape, use_voxels = True )
    if verbose:
        print(&#34;Done&#34;)

    return ants.list_to_ndimage( imageup, mcsr )


def segment_timeseries_by_bvalue(bvals):
    &#34;&#34;&#34;
    Segments a time series based on a threshold applied to b-values.
    
    This function categorizes indices of the given b-values array into two groups:
    one for indices where b-values are above a near-zero threshold, and another
    where b-values are at or below this threshold. The threshold is set to 1e-12.
    
    Parameters:
    - bvals (numpy.ndarray): An array of b-values.

    Returns:
    - dict: A dictionary with two keys, &#39;lowermeans&#39; and &#39;highermeans&#39;, each containing
      the indices of bvals where the b-values are above and at/below the threshold, respectively.
    &#34;&#34;&#34;
    # Define the threshold
    threshold = 1e-12
    
    # Get indices where b-values are greater than the threshold
    lowermeans = list(np.where(bvals &gt; threshold)[0])
    
    # Get indices where b-values are less than or equal to the threshold
    highermeans = list(np.where(bvals &lt;= threshold)[0])
    
    return {
        &#39;lowermeans&#39;: lowermeans,
        &#39;highermeans&#39;: highermeans
    }

def segment_timeseries_by_meanvalue( image, quantile = 0.995 ):
    &#34;&#34;&#34;
    Identify indices of a time series where we assume there is a different mean
    intensity over the volumes.  The indices of volumes with higher and lower
    intensities is returned.  Can be used to automatically identify B0 volumes
    in DWI timeseries.

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    quantile : a quantile for splitting the indices of the volume - should be greater than 0.5

    Returns
    -------
    dictionary holding the two sets of indices

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    ishape = image.shape
    lastdim = len(ishape)-1
    meanvalues = list()
    for x in range(ishape[lastdim]):
        meanvalues.append(  ants.slice_image( image, axis=lastdim, idx=x ).mean() )
    myhiq = np.quantile( meanvalues, quantile )
    myloq = np.quantile( meanvalues, 1.0 - quantile )
    lowerindices = list()
    higherindices = list()
    for x in range(len(meanvalues)):
        hiabs = abs( meanvalues[x] - myhiq )
        loabs = abs( meanvalues[x] - myloq )
        if hiabs &lt; loabs:
            higherindices.append(x)
        else:
            lowerindices.append(x)

    return {
    &#39;lowermeans&#39;:lowerindices,
    &#39;highermeans&#39;:higherindices }


def get_average_rsf( x, min_t=10, max_t=35 ):
    &#34;&#34;&#34;
    automatically generates the average bold image with quick registration

    returns:
        avg_bold
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
    oavg = ants.slice_image( x, axis=3, idx=0 )
    if x.shape[3] &lt;= min_t:
        min_t=0
    if x.shape[3] &lt;= max_t:
        max_t=x.shape[3]
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    oavg = ants.image_clone( bavg )
    bavg = oavg * 0.0
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    return bavg
    # return ants.n4_bias_field_correction(bavg, mask=ants.get_mask( bavg ) )


def get_average_dwi_b0( x, fixed_b0=None, fixed_dwi=None, fast=False ):
    &#34;&#34;&#34;
    automatically generates the average b0 and dwi and outputs both;
    maps dwi to b0 space at end.

    x : input image

    fixed_b0 : alernative reference space

    fixed_dwi : alernative reference space

    fast : boolean

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    temp = segment_timeseries_by_meanvalue( x )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]
    if ( fixed_b0 is None and fixed_dwi is None ) or fast:
        xavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        fixed_b0_use = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        fixed_dwi_use = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
    else:
        temp_b0 = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        temp_dwi = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
        xavg = fixed_b0 * 0.0
        bavg = fixed_b0 * 0.0
        tempreg = ants.registration( fixed_b0, temp_b0,&#39;BOLDRigid&#39;)
        fixed_b0_use = tempreg[&#39;warpedmovout&#39;]
        fixed_dwi_use = ants.apply_transforms( fixed_b0, temp_dwi, tempreg[&#39;fwdtransforms&#39;] )
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        if not fast:
            if not myidx in b0_idx:
                xavg = xavg + ants.registration(fixed_dwi_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
            else:
                bavg = bavg + ants.registration(fixed_b0_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
        else:
            if not myidx in b0_idx:
                xavg = xavg + b0
            else:
                bavg = bavg + b0
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    xavg = ants.iMath( xavg, &#39;Normalize&#39; )
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    avgb0=ants.n4_bias_field_correction(bavg)
    avgdwi=ants.n4_bias_field_correction(xavg)
    avgdwi=ants.registration( avgb0, avgdwi, &#39;Rigid&#39; )[&#39;warpedmovout&#39;]
    return avgb0, avgdwi

def dti_template(
    b_image_list=None,
    w_image_list=None,
    iterations=5,
    gradient_step=0.5,
    mask_csf=False,
    average_both=True,
    verbose=False
):
    &#34;&#34;&#34;
    two channel version of build_template

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    mydeftx = tempfile.NamedTemporaryFile(delete=False,dir=output_directory).name
    tmp = tempfile.NamedTemporaryFile(delete=False,dir=output_directory,suffix=&#34;.nii.gz&#34;)
    wavgfn = tmp.name
    tmp2 = tempfile.NamedTemporaryFile(delete=False,dir=output_directory)
    comptx = tmp2.name
    weights = np.repeat(1.0 / len(b_image_list), len(b_image_list))
    weights = [x / sum(weights) for x in weights]
    w_initial_template = w_image_list[0]
    b_initial_template = b_image_list[0]
    b_initial_template = ants.iMath(b_initial_template,&#34;Normalize&#34;)
    w_initial_template = ants.iMath(w_initial_template,&#34;Normalize&#34;)
    if mask_csf:
        bcsf0 = ants.threshold_image( b_image_list[0],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
        bcsf1 = ants.threshold_image( b_image_list[1],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf0 = b_image_list[0] * 0 + 1
        bcsf1 = b_image_list[1] * 0 + 1
    bavg = b_initial_template.clone() * bcsf0
    wavg = w_initial_template.clone() * bcsf0
    bcsf = [ bcsf0, bcsf1 ]
    for i in range(iterations):
        for k in range(len(w_image_list)):
            fimg=wavg
            mimg=w_image_list[k] * bcsf[k]
            fimg2=bavg
            mimg2=b_image_list[k] * bcsf[k]
            w1 = ants.registration(
                fimg, mimg, type_of_transform=&#39;antsRegistrationSyNQuick[s]&#39;,
                    multivariate_extras= [ [ &#34;mattes&#34;, fimg2, mimg2, 1, 32 ]],
                    outprefix=mydeftx,
                    verbose=0 )
            txname = ants.apply_transforms(wavg, wavg,
                w1[&#34;fwdtransforms&#34;], compose=comptx )
            if k == 0:
                txavg = ants.image_read(txname) * weights[k]
                wavgnew = ants.apply_transforms( wavg,
                    w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                bavgnew = ants.apply_transforms( wavg,
                    b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
            else:
                txavg = txavg + ants.image_read(txname) * weights[k]
                if i &gt;= (iterations-2) and average_both:
                    wavgnew = wavgnew+ants.apply_transforms( wavg,
                        w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                    bavgnew = bavgnew+ants.apply_transforms( wavg,
                        b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
        if verbose:
            print(&#34;iteration:&#34;,str(i),str(txavg.abs().mean()))
        wscl = (-1.0) * gradient_step
        txavg = txavg * wscl
        ants.image_write( txavg, wavgfn )
        wavg = ants.apply_transforms(wavg, wavgnew, wavgfn).iMath(&#34;Normalize&#34;)
        bavg = ants.apply_transforms(bavg, bavgnew, wavgfn).iMath(&#34;Normalize&#34;)
    import shutil
    shutil.rmtree( output_directory, ignore_errors=True )
    if verbose:
        print(&#34;done&#34;)
    return bavg, wavg

def read_ants_transforms_to_numpy(transform_files ):
    &#34;&#34;&#34;
    Read a list of ANTs transform files and convert them to a NumPy array.
    The function filters out any files that are not .mat and will only  use
    the first .mat in each entry of the list.

    :param transform_files: List of lists of file paths to ANTs transform files.  
    :return: NumPy array of the transforms.
    &#34;&#34;&#34;
    extension = &#39;.mat&#39;
    # Filter the list of lists
    filtered_lists = [[string for string in sublist if string.endswith(extension)] 
                    for sublist in transform_files]
    transforms = []
    for file in filtered_lists:
        transform = ants.read_transform(file[0])
        np_transform = np.array(ants.get_ants_transform_parameters(transform)[0:9])
        transforms.append(np_transform)
    return np.array(transforms)

def t1_based_dwi_brain_extraction(
    t1w_head,
    t1w,
    dwi,
    b0_idx = None,
    transform=&#39;Rigid&#39;,
    deform=None,
    verbose=False
):
    &#34;&#34;&#34;
    Map a t1-based brain extraction to b0 and return a mask and average b0

    Arguments
    ---------
    t1w_head : an antsImage of the hole head

    t1w : an antsImage probably but not necessarily T1-weighted

    dwi : an antsImage holding B0 and DWI

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    transform : string Rigid or other ants.registration tx type

    deform : follow up transform with deformation

    Returns
    -------
    dictionary holding the avg_b0 and its mask

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    t1w_use = ants.iMath( t1w, &#34;Normalize&#34; )
    t1bxt = ants.threshold_image( t1w_use, 0.05, 1 ).iMath(&#34;FillHoles&#34;)
    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    # first get the average b0
    if len( b0_idx ) &gt; 1:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] ).iMath(&#34;Normalize&#34;)
        for n in range(1,len(b0_idx)):
            temp = ants.slice_image( dwi, axis=3, idx=b0_idx[n] )
            reg = ants.registration( b0_avg, temp, &#39;Rigid&#39; )
            b0_avg = b0_avg + ants.iMath( reg[&#39;warpedmovout&#39;], &#34;Normalize&#34;)
    else:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] )
    b0_avg = ants.iMath(b0_avg,&#34;Normalize&#34;)
    reg = tra_initializer( b0_avg, t1w, n_simulations=12,   verbose=verbose )
    if deform is not None:
        reg = ants.registration( b0_avg, t1w,
            &#39;SyNOnly&#39;,
            total_sigma=0.5,
            initial_transform=reg[&#39;fwdtransforms&#39;][0],
            verbose=False )
    outmsk = ants.apply_transforms( b0_avg, t1bxt, reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39;).threshold_image( 0.5, 1.0 )
    return  {
    &#39;b0_avg&#39;:b0_avg,
    &#39;b0_mask&#39;:outmsk }

def mc_denoise( x, ratio = 0.5 ):
    &#34;&#34;&#34;
    ants denoising for timeseries (4D)

    Arguments
    ---------
    x : an antsImage 4D

    ratio : weight between 1 and 0 - lower weights bring result closer to initial image

    Returns
    -------
    denoised time series

    &#34;&#34;&#34;
    dwpimage = []
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        dnzb0 = ants.denoise_image( b0, p=1,r=1,noise_model=&#39;Gaussian&#39; )
        dwpimage.append( dnzb0 * ratio + b0 * (1.0-ratio) )
    return ants.list_to_ndimage( x, dwpimage )

def tsnr( x, mask, indices=None ):
    &#34;&#34;&#34;
    3D temporal snr image from a 4D time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns a 3D image
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    stdM = np.std(M, axis=0 )
    stdM[np.isnan(stdM)] = 0
    tt = round( 0.975*100 )
    threshold_std = np.percentile( stdM, tt )
    tsnrimage = ants.make_image( mask, stdM )
    return tsnrimage

def dvars( x,  mask, indices=None ):
    &#34;&#34;&#34;
    dvars on a time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    DVARS = np.zeros( M.shape[0] )
    for i in range(1, M.shape[0] ):
        vecdiff = M[i-1,:] - M[i,:]
        DVARS[i] = np.sqrt( ( vecdiff * vecdiff ).mean() )
    DVARS[0] = DVARS.mean()
    return DVARS


def slice_snr( x,  background_mask, foreground_mask, indices=None ):
    &#34;&#34;&#34;
    slice-wise SNR on a time series image

    x: image

    background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask

    foreground_mask : mask - maybe cortex or WM or brain mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    xuse=ants.iMath(x,&#34;Normalize&#34;)
    MB = ants.timeseries_to_matrix( xuse, background_mask )
    MF = ants.timeseries_to_matrix( xuse, foreground_mask )
    if indices is not None:
        MB=MB[indices,:]
        MF=MF[indices,:]
    ssnr = np.zeros( MB.shape[0] )
    for i in range( MB.shape[0] ):
        ssnr[i]=MF[i,:].mean()/MB[i,:].std()
    ssnr[np.isnan(ssnr)] = 0
    return ssnr


def impute_fa( fa, md ):
    &#34;&#34;&#34;
    impute bad values in dti, fa, md
    &#34;&#34;&#34;
    def imputeit( x, fa ):
        badfa=ants.threshold_image(fa,1,1)
        if badfa.max() == 1:
            temp=ants.image_clone(x)
            temp[badfa==1]=0
            temp=ants.iMath(temp,&#39;GD&#39;,2)
            x[ badfa==1 ]=temp[badfa==1]
        return x
    md=imputeit( md, fa )
    fa=imputeit( ants.image_clone(fa), fa )
    return fa, md

def trim_dti_mask( fa, mask, param=4.0 ):
    &#34;&#34;&#34;
    trim the dti mask to get rid of bright fa rim

    this function erodes the famask by param amount then segments the rim into
    bright and less bright parts.  the bright parts are trimmed from the mask
    and the remaining edges are cleaned up a bit with closing.

    param: closing radius unit is in physical space
    &#34;&#34;&#34;
    spacing = ants.get_spacing(mask)
    spacing_product = np.prod( spacing )
    spcmin = min( spacing )
    paramVox = int(np.round( param / spcmin ))
    trim_mask = ants.image_clone( mask )
    trim_mask = ants.iMath( trim_mask, &#34;FillHoles&#34; )
    edgemask = trim_mask - ants.iMath( trim_mask, &#34;ME&#34;, paramVox )
    maxk=4
    edgemask = ants.threshold_image( fa * edgemask, &#34;Otsu&#34;, maxk )
    edgemask = ants.threshold_image( edgemask, maxk-1, maxk )
    trim_mask[edgemask &gt;= 1 ]=0
    trim_mask = ants.iMath(trim_mask,&#34;ME&#34;,paramVox-1)
    trim_mask = ants.iMath(trim_mask,&#39;GetLargestComponent&#39;)
    trim_mask = ants.iMath(trim_mask,&#34;MD&#34;,paramVox-1)
    return trim_mask

def dipy_dti_recon(
    image,
    bvalsfn,
    bvecsfn,
    mask = None,
    b0_idx = None,
    mask_dilation = 2,
    mask_closing = 5,
    fit_method=&#39;WLS&#39;,
    trim_the_mask=2.0,
    verbose=False ):
    &#34;&#34;&#34;
    DiPy DTI reconstruction - building on the DiPy basic DTI example

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    bvalsfn : bvalues  obtained by dipy read_bvals_bvecs or the values themselves

    bvecsfn : bvectors obtained by dipy read_bvals_bvecs or the values themselves

    mask : brain mask for the DWI/DTI reconstruction; if it is not in the same
        space as the image, we will resample directly to the image space.  This
        could lead to problems if the inputs are really incorrect.

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_bvalue

    mask_dilation : integer zero or more dilates the brain mask

    mask_closing : integer zero or more closes the brain mask

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) ... if None, will not reconstruct DTI.

    trim_the_mask : float &gt;=0 post-hoc method for trimming the mask

    verbose : boolean

    Returns
    -------
    dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)

    NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)

    NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect
        the tailing image volumes.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    if isinstance(bvecsfn, str):
        bvals, bvecs = read_bvals_bvecs( bvalsfn , bvecsfn   )
    else: # assume we already read them
        bvals = bvalsfn.copy()
        bvecs = bvecsfn.copy()

    b0_idx = segment_timeseries_by_bvalue( bvals )[&#39;highermeans&#39;]

    b0 = ants.slice_image( image, axis=3, idx=b0_idx[0] )
    bxtmod=&#39;bold&#39;
    bxtmod=&#39;t2&#39;
    constant_mask=False
    if mask is not None:
        constant_mask=True
        mask = ants.resample_image_to_target( mask, b0, interp_type=&#39;nearestNeighbor&#39;)
    else:
        mask = antspynet.brain_extraction( b0, bxtmod ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    if mask_closing &gt; 0 and not constant_mask :
        mask = ants.morphology( mask, &#34;close&#34;, mask_closing ) # good
    maskdil = ants.iMath( mask, &#34;MD&#34;, mask_dilation )

    if verbose:
        print(&#34;recon dti.TensorModel&#34;,flush=True)

    def justthefit( gtab, fit_method, imagein, maskin ):
        if fit_method is None:
            return None, None, None, None
        maskedimage=[]
        for myidx in range(imagein.shape[3]):
            b0 = ants.slice_image( imagein, axis=3, idx=myidx)
            maskedimage.append( b0 * maskin )
        maskedimage = ants.list_to_ndimage( imagein, maskedimage )
        maskdata = maskedimage.numpy()
        tenmodel = dti.TensorModel(gtab,fit_method=fit_method)
        tenfit = tenmodel.fit(maskdata)
        FA = fractional_anisotropy(tenfit.evals)
        FA[np.isnan(FA)] = 1
        FA = np.clip(FA, 0, 1)
        MD1 = dti.mean_diffusivity(tenfit.evals)
        MD1 = ants.copy_image_info( b0, ants.from_numpy( MD1.astype(np.float32) ) )
        FA = ants.copy_image_info(  b0, ants.from_numpy( FA.astype(np.float32) ) )
        FA, MD1 = impute_fa( FA, MD1 )
        RGB = color_fa(FA.numpy(), tenfit.evecs)
        RGB = ants.from_numpy( RGB.astype(np.float32) )
        RGB0 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=0 ) )
        RGB1 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=1 ) )
        RGB2 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=2 ) )
        RGB = ants.merge_channels( [RGB0,RGB1,RGB2] )
        return tenfit, FA, MD1, RGB

    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, maskdil )
    if verbose:
        print(&#34;recon dti.TensorModel done&#34;,flush=True)

    # change the brain mask based on high FA values
    if trim_the_mask &gt; 0 and fit_method is not None:
        mask = trim_dti_mask( FA, mask, trim_the_mask )
        tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, mask )

    return {
        &#39;tensormodel&#39; : tenfit,
        &#39;MD&#39; : MD1 ,
        &#39;FA&#39; : FA ,
        &#39;RGB&#39; : RGB,
        &#39;dwi_mask&#39;:mask,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
        }


def concat_dewarp(
        refimg,
        originalDWI,
        physSpaceDWI,
        dwpTx,
        motion_parameters,
        motion_correct=True,
        verbose=False ):
    &#34;&#34;&#34;
    Apply concatentated motion correction and dewarping transforms to timeseries image.

    Arguments
    ---------

    refimg : an antsImage defining the reference domain (3D)

    originalDWI : the antsImage in original (not interpolated space) (4D)

    physSpaceDWI : ants antsImage defining the physical space of the mapping (4D)

    dwpTx : dewarping transform

    motion_parameters : previously computed list of motion parameters

    motion_correct : boolean

    verbose : boolean

    &#34;&#34;&#34;
    # apply the dewarping tx to the original dwi and reconstruct again
    # NOTE: refimg must be in the same space for this to work correctly
    # due to the use of ants.list_to_ndimage( originalDWI, dwpimage )
    dwpimage = []
    for myidx in range(originalDWI.shape[3]):
        b0 = ants.slice_image( originalDWI, axis=3, idx=myidx)
        concatx = dwpTx.copy()
        if motion_correct:
            concatx = concatx + motion_parameters[myidx]
        if verbose and myidx == 0:
            print(&#34;dwp parameters&#34;)
            print( dwpTx )
            print(&#34;Motion parameters&#34;)
            print( motion_parameters[myidx] )
            print(&#34;concat parameters&#34;)
            print(concatx)
        warpedb0 = ants.apply_transforms( refimg, b0, concatx,
            interpolator=&#39;nearestNeighbor&#39; )
        dwpimage.append( warpedb0 )
    return ants.list_to_ndimage( physSpaceDWI, dwpimage )


def joint_dti_recon(
    img_LR,
    bval_LR,
    bvec_LR,
    jhu_atlas,
    jhu_labels,
    reference_B0,
    reference_DWI,
    srmodel = None,
    img_RL = None,
    bval_RL = None,
    bvec_RL = None,
    t1w = None,
    brain_mask = None,
    motion_correct = None,
    dewarp_modality = &#39;FA&#39;,
    denoise=False,
    fit_method=&#39;WLS&#39;,
    impute = False,
    censor = True,
    verbose = False ):
    &#34;&#34;&#34;
    1. pass in subject data and 1mm JHU atlas/labels
    2. perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)
    3. dewarp the images using dewarp_modality or T1w
    4. apply dewarping to the original data
        ===&gt; may want to apply SR at this step
    5. reconstruct DTI again
    6. label images and do registration
    7. return relevant outputs

    NOTE: RL images are optional; should pass t1w in this case.

    Arguments
    ---------

    img_LR : an antsImage holding B0 and DWI LR acquisition

    bval_LR : bvalue filename LR

    bvec_LR : bvector filename LR

    jhu_atlas : atlas FA image

    jhu_labels : atlas labels

    reference_B0 : the &#34;target&#34; B0 image space

    reference_DWI : the &#34;target&#34; DW image space

    srmodel : optional h5 (tensorflow) model

    img_RL : an antsImage holding B0 and DWI RL acquisition

    bval_RL : bvalue filename RL

    bvec_RL : bvector filename RL

    t1w : antsimage t1w neuroimage (brain-extracted)

    brain_mask : mask for the DWI - just 3D - provided brain mask should be in reference_B0 space

    motion_correct : None Rigid or SyN

    dewarp_modality : string average_dwi, average_b0, MD or FA

    denoise: boolean

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    impute : boolean

    censor : boolean

    verbose : boolean

    Returns
    -------
    dictionary holding the mean_fa, its summary statistics via JHU labels,
        the JHU registration, the JHU labels, the dewarping dictionary and the
        dti reconstruction dictionaries.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;Recon DTI on OR images ...&#34;)

    def fix_dwi_shape( img, bvalfn, bvecfn ):
        if isinstance(bvecfn, str):
            bvals, bvecs = read_bvals_bvecs( bvalfn , bvecfn   )
        else:
            bvals = bvalfn
            bvecs = bvecfn
        if bvecs.shape[0] &lt; img.shape[3]:
            imgout = ants.from_numpy( img[:,:,:,0:bvecs.shape[0]] )
            imgout = ants.copy_image_info( img, imgout )
            return( imgout )
        else:
            return( img )

    img_LR = fix_dwi_shape( img_LR, bval_LR, bvec_LR )
    if denoise :
        img_LR = mc_denoise( img_LR )
    if img_RL is not None:
        img_RL = fix_dwi_shape( img_RL, bval_RL, bvec_RL )
        if denoise :
            img_RL = mc_denoise( img_RL )

    if brain_mask is not None:
        maskInRightSpace = ants.image_physical_space_consistency( brain_mask, reference_B0 )
        if not maskInRightSpace :
            raise ValueError(&#39;not maskInRightSpace ... provided brain mask should be in reference_B0 space&#39;)

    if img_RL is not None :
        if verbose:
            print(&#34;img_RL correction&#34;)
        reg_RL = dti_reg(
            img_RL,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_RL,
            bvecs=bvec_RL,
            type_of_transform=motion_correct,
            verbose=True )
    else:
        reg_RL=None


    if verbose:
        print(&#34;img_LR correction&#34;)
    reg_LR = dti_reg(
            img_LR,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_LR,
            bvecs=bvec_LR,
            type_of_transform=motion_correct,
            verbose=True )

    ts_LR_avg = None
    ts_RL_avg = None
    reg_its = [100,50,10]
    img_LRdwp = ants.image_clone( reg_LR[ &#39;motion_corrected&#39; ] )
    if img_RL is not None:
        img_RLdwp = ants.image_clone( reg_RL[ &#39;motion_corrected&#39; ] )
        if srmodel is not None:
            if verbose:
                print(&#34;convert img_RL_dwp to img_RL_dwp_SR&#34;)
            img_RLdwp = super_res_mcimage( img_RLdwp, srmodel, isotropic=True,
                        verbose=verbose )
    if srmodel is not None:
        reg_its = [100] + reg_its
        if verbose:
            print(&#34;convert img_LR_dwp to img_LR_dwp_SR&#34;)
        img_LRdwp = super_res_mcimage( img_LRdwp, srmodel, isotropic=True,
                verbose=verbose )
    if verbose:
        print(&#34;recon after distortion correction&#34;, flush=True)

    if impute:
        img_LRdwp=impute_dwi( img_LRdwp, verbose=True )
    elif censor:
        img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;] = censor_dwi( img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;], verbose=True )
    if impute and img_RL is not None:
        img_RLdwp=impute_dwi( img_RLdwp, verbose=True )
    elif censor and img_RL is not None:
        img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;] = censor_dwi( img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;], verbose=True )

    if img_RL is not None:
        img_LRdwp, bval_LR, bvec_LR = merge_dwi_data(
            img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;],
            img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;]
        )
    else:
        bval_LR=reg_LR[&#39;bvals&#39;]
        bvec_LR=reg_LR[&#39;bvecs&#39;]

    if verbose:
        print(&#34;final recon&#34;, flush=True)
        print(img_LRdwp)
    recon_LR_dewarp = dipy_dti_recon(
            img_LRdwp, bval_LR, bvec_LR,
            mask = brain_mask,
            fit_method=fit_method,
            mask_dilation=0, verbose=True )
    if verbose:
        print(&#34;recon done&#34;, flush=True)

    if img_RL is not None:
        fdjoin = [ reg_LR[&#39;FD&#39;],
                   reg_RL[&#39;FD&#39;] ]
        framewise_displacement=np.concatenate( fdjoin )
    else:
        framewise_displacement=reg_LR[&#39;FD&#39;]

    motion_count = ( framewise_displacement &gt; 1.5  ).sum()
    reconFA = recon_LR_dewarp[&#39;FA&#39;]
    reconMD = recon_LR_dewarp[&#39;MD&#39;]

    if verbose:
        print(&#34;JHU reg&#34;,flush=True)

    OR_FA2JHUreg = ants.registration( reconFA, jhu_atlas,
        type_of_transform = &#39;SyN&#39;, syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=reg_its, verbose=False )
    OR_FA_jhulabels = ants.apply_transforms( reconFA, jhu_labels,
        OR_FA2JHUreg[&#39;fwdtransforms&#39;], interpolator=&#39;genericLabel&#39;)

    df_FA_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;FA_JHU_labels_edited&#39;,
        reconFA,
        OR_FA_jhulabels)
    df_FA_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_FA_JHU_ORRL&#39; : df_FA_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    df_MD_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;MD_JHU_labels_edited&#39;,
        reconMD,
        OR_FA_jhulabels)
    df_MD_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_MD_JHU_ORRL&#39; : df_MD_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    temp = segment_timeseries_by_meanvalue( img_LRdwp )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]

    nonbrainmask = ants.iMath( recon_LR_dewarp[&#39;dwi_mask&#39;], &#34;MD&#34;,2) - recon_LR_dewarp[&#39;dwi_mask&#39;]
    fgmask = ants.threshold_image( reconFA, 0.5 , 1.0).iMath(&#34;GetLargestComponent&#34;)
    bgmask = ants.threshold_image( reconFA, 1e-4 , 0.1)
    fa_SNR = 0.0
    fa_SNR = mask_snr( reconFA, bgmask, fgmask, bias_correct=False )
    fa_evr = antspyt1w.patch_eigenvalue_ratio( reconFA, 512, [16,16,16], evdepth = 0.9, mask=recon_LR_dewarp[&#39;dwi_mask&#39;] )

    dti_itself = get_dti( reconFA, recon_LR_dewarp[&#39;tensormodel&#39;], return_image=True )
    return convert_np_in_dict( {
        &#39;dti&#39;: dti_itself,
        &#39;recon_fa&#39;:reconFA,
        &#39;recon_fa_summary&#39;:df_FA_JHU_ORRL_bfwide,
        &#39;recon_md&#39;:reconMD,
        &#39;recon_md_summary&#39;:df_MD_JHU_ORRL_bfwide,
        &#39;jhu_labels&#39;:OR_FA_jhulabels,
        &#39;jhu_registration&#39;:OR_FA2JHUreg,
        &#39;reg_LR&#39;:reg_LR,
        &#39;reg_RL&#39;:reg_RL,
        &#39;dtrecon_LR_dewarp&#39;:recon_LR_dewarp,
        &#39;dwi_LR_dewarped&#39;:img_LRdwp,
        &#39;bval_LR&#39;:bval_LR,
        &#39;bvec_LR&#39;:bvec_LR,
        &#39;bval_RL&#39;:bval_RL,
        &#39;bvec_RL&#39;:bvec_RL,
        &#39;b0avg&#39;: reference_B0,
        &#39;dwiavg&#39;: reference_DWI,
        &#39;framewise_displacement&#39;:framewise_displacement,
        &#39;high_motion_count&#39;: motion_count,
        &#39;tsnr_b0&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;tsnr_dwi&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;dvars_b0&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;dvars_dwi&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;ssnr_b0&#39;: slice_snr( img_LRdwp, bgmask , fgmask, b0_idx),
        &#39;ssnr_dwi&#39;: slice_snr( img_LRdwp, bgmask, fgmask, non_b0_idx),
        &#39;fa_evr&#39;: fa_evr,
        &#39;fa_SNR&#39;: fa_SNR
    } )


def middle_slice_snr( x, background_dilation=5 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    &#34;&#34;&#34;
    xshp = x.shape
    xmidslice = ants.slice_image( x, 2, int( xshp[2]/2 )  )
    xmidslice = ants.iMath( xmidslice - xmidslice.min(), &#34;Normalize&#34; )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslicemask = ants.threshold_image( xmidslice, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmidslicemask, &#34;MD&#34;, background_dilation ) - xmidslicemask
    signal = (xmidslice[ xmidslicemask == 1] ).mean()
    noise = (xmidslice[ xbkgmask == 1] ).std()
    return signal / noise

def foreground_background_snr( x, background_dilation=10,
        erode_foreground=False):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    erode_foreground : boolean - 2nd option which erodes the initial
    foregound mask  to create a new foreground mask.  the background
    mask is the initial mask minus the eroded mask.

    &#34;&#34;&#34;
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xmask = ants.threshold_image( xbc, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmask, &#34;MD&#34;, background_dilation ) - xmask
    fgmask = xmask
    if erode_foreground:
        fgmask = ants.iMath( xmask, &#34;ME&#34;, background_dilation )
        xbkgmask = xmask - fgmask
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise

def quantile_snr( x,
    lowest_quantile=0.01,
    low_quantile=0.1,
    high_quantile=0.5,
    highest_quantile=0.95 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    lowest_quantile : float value &lt; 1 and &gt; 0

    low_quantile : float value &lt; 1 and &gt; 0

    high_quantile : float value &lt; 1 and &gt; 0

    highest_quantile : float value &lt; 1 and &gt; 0

    &#34;&#34;&#34;
    import numpy as np
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    y = xbc.numpy()
    ylowest = np.quantile( y[y&gt;0], lowest_quantile )
    ylo = np.quantile( y[y&gt;0], low_quantile )
    yhi = np.quantile( y[y&gt;0], high_quantile )
    yhiest = np.quantile( y[y&gt;0], highest_quantile )
    xbkgmask = ants.threshold_image( xbc, ylowest, ylo )
    fgmask = ants.threshold_image( xbc, yhi, yhiest )
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise

def mask_snr( x, background_mask, foreground_mask, bias_correct=True ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image using
    a user-defined foreground and background mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_mask : binary antsImage

    foreground_mask : binary antsImage

    bias_correct : boolean

    &#34;&#34;&#34;
    import numpy as np
    if foreground_mask.sum() &lt;= 1 or background_mask.sum() &lt;= 1:
        return 0
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    if bias_correct:
        xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    signal = (xbc[ foreground_mask == 1] ).mean()
    noise = (xbc[ background_mask == 1] ).std()
    return signal / noise


def dwi_deterministic_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1
    dti_model = dti.TensorModel(gtab,fit_method=fit_method)
    if verbose:
        print(&#34;begin tracking fit&#34;,flush=True)
    dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while
    evecs_img = dti_fit.evecs
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion
    stopping_criterion = ThresholdStoppingCriterion(fa.numpy(), fa_thresh)
    from dipy.data import get_sphere
    sphere = get_sphere(&#39;symmetric362&#39;)
    from dipy.direction import peaks_from_model
    if peak_indices is None:
        # problems with multi-threading ...
        # see https://github.com/dipy/dipy/issues/2519
        if verbose:
            print(&#34;begin peaks&#34;,flush=True)
        mynump=1
        # if os.getenv(&#34;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#34;):
        #    mynump = os.environ[&#39;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#39;]
        # current_openblas = os.environ.get(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
        # current_mkl = os.environ.get(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)
        # os.environ[&#39;DIPY_OPENBLAS_NUM_THREADS&#39;] = current_openblas
        # os.environ[&#39;DIPY_MKL_NUM_THREADS&#39;] = current_mkl
        # os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = &#39;1&#39;
        # os.environ[&#39;MKL_NUM_THREADS&#39;] = &#39;1&#39;
        peak_indices = peaks_from_model(
            model=dti_model,
            data=dwi_data,
            sphere=sphere,
            relative_peak_threshold=.5,
            min_separation_angle=25,
            mask=dwi_mask,
            npeaks=3, return_odf=False,
            return_sh=False,
            parallel=int(mynump) &gt; 1,
            num_processes=int(mynump)
            )
        if False:
            if &#39;DIPY_OPENBLAS_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
            if &#39;DIPY_MKL_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;MKL_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_MKL_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;MKL_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)

    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(
        peak_indices, stopping_criterion, seeds, affine=affine, step_size=step_size)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines,
          &#39;peak_indices&#39;: peak_indices
          }

def repair_bvecs( bvecs ):
    bvecnorm = np.linalg.norm(bvecs,axis=1).reshape( bvecs.shape[0],1 )
    # bvecnormnan = np.isnan( bvecnorm )
    # nan_indices = list( np.unique( np.where(np.isnan(bvecs))[0]))
    # bvecs = remove_elements_from_numpy_array( bvecs, nan_indices )
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009:
        warnings.warn( &#34;Warning: bvecs are not unit norm - we normalize them here but this may indicate a problem with the data.  Norm is : &#34; + str( np.linalg.norm(bvecs) ) + &#34; shape is &#34; + str( bvecs.shape[0] ) + &#34; &#34; + str( bvecs.shape[1] ))
        bvecs=np.where(bvecnorm &gt; 1e-16, bvecs / bvecnorm, 0)
    return bvecs


def dwi_closest_peak_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.core.gradients import gradient_table
    from dipy.data import small_sphere
    from dipy.direction import BootDirectionGetter, ClosestPeakDirectionGetter
    from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,
                                    auto_response_ssst)
    from dipy.reconst.shm import CsaOdfModel
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion

    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1


    response, ratio = auto_response_ssst(gtab, dwi_data, roi_radii=10, fa_thr=0.7)
    csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)
    csd_fit = csd_model.fit(dwi_data, mask=dwi_mask)
    csa_model = CsaOdfModel(gtab, sh_order=6)
    gfa = csa_model.fit(dwi_data, mask=dwi_mask).gfa
    stopping_criterion = ThresholdStoppingCriterion(gfa, .25)


    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)

    pmf = csd_fit.odf(small_sphere).clip(min=0)
    if verbose:
        print(&#34;ClosestPeakDirectionGetter begin ...&#34;, flush=True)
    peak_dg = ClosestPeakDirectionGetter.from_pmf(pmf, max_angle=30.,
                                                sphere=small_sphere)
    if verbose:
        print(&#34;local tracking begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(peak_dg, stopping_criterion, seeds,
                                            affine, step_size=.5)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines
          }

def dwi_streamline_pairwise_connectivity( streamlines, label_image, labels_to_connect=[1,None], verbose=False ):
    &#34;&#34;&#34;

    Return streamlines connecting all of the regions in the label set. Ideal
    for just 2 regions.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    labels_to_connect : list of 2 labels or [label,None]

    verbose : boolean

    Returns
    -------
    the subset of streamlines and a streamline count

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    from dipy.tracking.streamline import Streamlines
    keep_streamlines = Streamlines()
    affine = label_image.to_nibabel().affine
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, full=False ):
        if full:
            maxind=sl.shape[0]
            for index in range(maxind):
                pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
                mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
                if mylab == target_label[0] or mylab == target_label[1]:
                    return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
            mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
            if mylab == target_label[0] or mylab == target_label[1]:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    for k in range( len( streamlines ) ):
        sl = streamlines[k]
        mycheck = check_it( sl, labels_to_connect, label_image_np, index=0, full=True )
        if mycheck[&#39;ok&#39;]:
            otherind=1
            if mycheck[&#39;label&#39;] == labels_to_connect[1]:
                otherind=0
            lsl = len( sl )-1
            pt = utils._to_voxel_coordinates(sl[lsl,:], lin_T, offset)
            mylab_end = (label_image_np[ pt[0], pt[1], pt[2] ]).astype(int)
            accept_point = mylab_end == labels_to_connect[otherind]
            if verbose and accept_point:
                print( mylab_end )
            if labels_to_connect[1] is None:
                accept_point = mylab_end != 0
            if accept_point:
                keep_streamlines.append(sl)
                ct=ct+1
    return { &#39;streamlines&#39;: keep_streamlines, &#39;count&#39;: ct }

def dwi_streamline_pairwise_connectivity_old(
    streamlines,
    label_image,
    exclusion_label = None,
    verbose = False ):
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = np.unique( labels[ labels &gt; 0 ] )
    if exclusion_label is not None:
        ulabs = ulabs[ ulabs != exclusion_label ]
        exc_slice = labels == exclusion_label
    if verbose:
        print(&#34;Begin connectivity&#34;)
    tracts = []
    for k in range(len(ulabs)):
        cc_slice = labels == ulabs[k]
        cc_streamlines = utils.target(streamlines, affine, cc_slice)
        cc_streamlines = Streamlines(cc_streamlines)
        if exclusion_label is not None:
            cc_streamlines = utils.target(cc_streamlines, affine, exc_slice, include=False)
            cc_streamlines = Streamlines(cc_streamlines)
        for j in range(len(ulabs)):
            cc_slice2 = labels == ulabs[j]
            cc_streamlines2 = utils.target(cc_streamlines, affine, cc_slice2)
            cc_streamlines2 = Streamlines(cc_streamlines2)
            if exclusion_label is not None:
                cc_streamlines2 = utils.target(cc_streamlines2, affine, exc_slice, include=False)
                cc_streamlines2 = Streamlines(cc_streamlines2)
            tracts.append( cc_streamlines2 )
        if verbose:
            print(&#34;end connectivity&#34;)
    return {
          &#39;pairwise_tracts&#39;: tracts
          }


def dwi_streamline_connectivity(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    labels_to_connect = ulabs[ulabs &gt; 0]
    Ctdf = None
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, not_label = None ):
        pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
        mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
        if not_label is None:
            if ( mylab == target_label ).sum() &gt; 0 :
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            if ( mylab == target_label ).sum() &gt; 0 and ( mylab == not_label ).sum() == 0:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    which = lambda lst:list(np.where(lst)[0])
    myCount = np.zeros( [len(ulabs),len(ulabs)])
    for k in range( len( streamlines ) ):
            sl = streamlines[k]
            mycheck = check_it( sl, labels_to_connect, label_image_np, index=0 )
            if mycheck[&#39;ok&#39;]:
                exclabel=mycheck[&#39;label&#39;]
                lsl = len( sl )-1
                mycheck2 = check_it( sl, labels_to_connect, label_image_np, index=lsl, not_label=exclabel )
                if mycheck2[&#39;ok&#39;]:
                    myCount[ulabs == mycheck[&#39;label&#39;],ulabs == mycheck2[&#39;label&#39;]]+=1
                    ct=ct+1
    Ctdf = label_dataframe.copy()
    for k in range(len(ulabs)):
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
    Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
    return { &#39;connectivity_matrix&#39; :  myCount, &#39;connectivity_wide&#39; : Ctdfw }

def dwi_streamline_connectivity_old(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;streamline connections ...&#34;)

    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines

    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine

    if verbose:
        print(&#34;path length begin ... volUnit = &#34; + str( volUnit ) )
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    pathLmean = np.zeros( [len(ulabs)])
    pathLtot = np.zeros( [len(ulabs)])
    pathCt = np.zeros( [len(ulabs)])
    for k in range(len(ulabs)):
        cc_slice = labels == ulabs[k]
        cc_streamlines = utils.target(streamlines, affine, cc_slice)
        cc_streamlines = Streamlines(cc_streamlines)
        if len(cc_streamlines) &gt; 0:
            wmpl = path_length(cc_streamlines, affine, cc_slice)
            mean_path_length = wmpl[wmpl&gt;0].mean()
            total_path_length = wmpl[wmpl&gt;0].sum()
            pathLmean[int(k)] = mean_path_length
            pathLtot[int(k)] = total_path_length
            pathCt[int(k)] = len(cc_streamlines) * volUnit

    # convert paths to data frames
    pathdf = label_dataframe.copy()
    pathdf.insert(pathdf.shape[1], &#34;mean_path_length&#34;, pathLmean )
    pathdf.insert(pathdf.shape[1], &#34;total_path_length&#34;, pathLtot )
    pathdf.insert(pathdf.shape[1], &#34;streamline_count&#34;, pathCt )
    pathdfw =antspyt1w.merge_hierarchical_csvs_to_wide_format(
        {path_length:pathdf }, [&#39;mean_path_length&#39;, &#39;total_path_length&#39;, &#39;streamline_count&#39;] )
    allconnexwide = pathdfw

    if verbose:
        print(&#34;path length done ...&#34;)

    Mdfw = None
    Tdfw = None
    Mdf = None
    Tdf = None
    Ctdf = None
    Ctdfw = None
    if True:
        if verbose:
            print(&#34;Begin connectivity&#34;)
        M = np.zeros( [len(ulabs),len(ulabs)])
        T = np.zeros( [len(ulabs),len(ulabs)])
        myCount = np.zeros( [len(ulabs),len(ulabs)])
        for k in range(len(ulabs)):
            cc_slice = labels == ulabs[k]
            cc_streamlines = utils.target(streamlines, affine, cc_slice)
            cc_streamlines = Streamlines(cc_streamlines)
            for j in range(len(ulabs)):
                cc_slice2 = labels == ulabs[j]
                cc_streamlines2 = utils.target(cc_streamlines, affine, cc_slice2)
                cc_streamlines2 = Streamlines(cc_streamlines2)
                if len(cc_streamlines2) &gt; 0 :
                    wmpl = path_length(cc_streamlines2, affine, cc_slice2)
                    mean_path_length = wmpl[wmpl&gt;0].mean()
                    total_path_length = wmpl[wmpl&gt;0].sum()
                    M[int(j),int(k)] = mean_path_length
                    T[int(j),int(k)] = total_path_length
                    myCount[int(j),int(k)] = len( cc_streamlines2 ) * volUnit
        if verbose:
            print(&#34;end connectivity&#34;)
        Mdf = label_dataframe.copy()
        Tdf = label_dataframe.copy()
        Ctdf = label_dataframe.copy()
        for k in range(len(ulabs)):
            nn1 = &#34;CnxMeanPL&#34;+str(k).zfill(3)
            nn2 = &#34;CnxTotPL&#34;+str(k).zfill(3)
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Mdf.insert(Mdf.shape[1], nn1, M[k,:] )
            Tdf.insert(Tdf.shape[1], nn2, T[k,:] )
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
        Mdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkm&#39; : Mdf },  Mdf.keys()[2:Mdf.shape[1]] )
        Tdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkt&#39; : Tdf },  Tdf.keys()[2:Tdf.shape[1]] )
        Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
        allconnexwide = pd.concat( [
            pathdfw,
            Mdfw,
            Tdfw,
            Ctdfw ], axis=1, ignore_index=False )

    return {
          &#39;connectivity&#39;: allconnexwide,
          &#39;connectivity_matrix_mean&#39;: Mdf,
          &#39;connectivity_matrix_total&#39;: Tdf,
          &#39;connectivity_matrix_count&#39;: Ctdf
          }


def hierarchical_modality_summary(
    target_image,
    hier,
    transformlist,
    modality_name,
    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;],
    verbose = False ):
    &#34;&#34;&#34;

    Use output of antspyt1w.hierarchical to summarize a modality

    Arguments
    ---------

    target_image : the image to summarize - should be brain extracted

    hier : dictionary holding antspyt1w.hierarchical output

    transformlist : spatial transformations mapping from T1 to this modality (e.g. from ants.registration)

    modality_name : adds the modality name to the data frame columns

    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;] keys to return

    verbose : boolean

    Returns
    -------
    data frame holding summary statistics in wide format

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    dfout = pd.DataFrame()
    def myhelper( target_image, seg, mytx, mapname, modname, mydf, extra=&#39;&#39;, verbose=False ):
        if verbose:
            print( mapname )
        target_image_mask = ants.image_clone( target_image ) * 0.0
        target_image_mask[ target_image != 0 ] = 1
        cortmapped = ants.apply_transforms(
            target_image,
            seg,
            mytx, interpolator=&#39;nearestNeighbor&#39; ) * target_image_mask
        mapped = antspyt1w.map_intensity_to_dataframe(
            mapname,
            target_image,
            cortmapped )
        mapped.iloc[:,1] = modname + &#39;_&#39; + extra + mapped.iloc[:,1]
        mappedw = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            { &#39;x&#39; : mapped},
            col_names = return_keys )
        if verbose:
            print( mappedw.keys() )
        if mydf.shape[0] &gt; 0:
            mydf = pd.concat( [ mydf, mappedw], axis=1, ignore_index=False )
        else:
            mydf = mappedw
        return mydf
    if hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], transformlist,
            &#34;dkt&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose )
    if hier[&#39;deep_cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;deep_cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;deep_&#39;, verbose=verbose )
    if hier[&#39;cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    if hier[&#39;bf&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;bf&#39;], transformlist,
            &#34;nbm3CH13&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    # if hier[&#39;mtl&#39;] is not None:
    #    dfout = myhelper( target_image, hier[&#39;mtl&#39;], reg,
    #        &#34;mtl_description&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    return dfout

def get_rsf_outputs( coords ):
    if coords == &#39;powers&#39;:
        return list([ &#39;meanBold&#39;, &#39;fmri_template&#39;, &#39;alff&#39;, &#39;falff&#39;, &#39;PerAF&#39;, 
                   &#39;CinguloopercularTaskControl&#39;, &#39;DefaultMode&#39;, 
                   &#39;MemoryRetrieval&#39;, &#39;VentralAttention&#39;, &#39;Visual&#39;,
                   &#39;FrontoparietalTaskControl&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;, &#39;DorsalAttention&#39;])
    else:
        yeo = pd.read_csv( get_data(&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;, target_extension=&#34;.csv&#34;)) # yeo 2023 coordinates
        return list( yeo[&#39;SystemName&#39;].unique() )

def tra_initializer( fixed, moving, n_simulations=32, max_rotation=30,
    transform=[&#39;rigid&#39;], compreg=None, verbose=False ):
    &#34;&#34;&#34;
    multi-start multi-transform registration solution - based on ants.registration

    fixed: fixed image

    moving: moving image

    n_simulations : number of simulations

    max_rotation : maximum rotation angle

    transform : list of transforms to loop through

    compreg : registration results against which to compare

    verbose : boolean

    &#34;&#34;&#34;
    if True:
        output_directory = tempfile.mkdtemp()
        output_directory_w = output_directory + &#34;/tra_reg/&#34;
        os.makedirs(output_directory_w,exist_ok=True)
        bestmi = math.inf
        bestvar = 0.0
        myorig = list(ants.get_origin( fixed ))
        mymax = 0;
        for k in range(len( myorig ) ):
            if abs(myorig[k]) &gt; mymax:
                mymax = abs(myorig[k])
        maxtrans = mymax * 0.05
        if compreg is None:
            bestreg=ants.registration( fixed,moving,&#39;Translation&#39;,
                outprefix=output_directory_w+&#34;trans&#34;)
            initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        else :
            bestreg=compreg
            initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        for mytx in transform:
            regtx = &#39;Rigid&#39;
            with tempfile.NamedTemporaryFile(suffix=&#39;.h5&#39;) as tp:
                if mytx == &#39;translation&#39;:
                    regtx = &#39;Translation&#39;
                    rRotGenerator = ants.contrib.RandomTranslate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                elif mytx == &#39;affine&#39;:
                    regtx = &#39;Affine&#39;
                    rRotGenerator = ants.contrib.RandomRotate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                else:
                    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rotation*(-1.0), max_rotation ), reference=fixed )
                for k in range(n_simulations):
                    simtx = ants.compose_ants_transforms( [rRotGenerator.transform(), initx] )
                    ants.write_transform( simtx, tp.name )
                    if k &gt; 0:
                        reg = ants.registration( fixed, moving, regtx,
                            initial_transform=tp.name,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    else:
                        reg = ants.registration( fixed, moving,
                            regtx,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    mymi = math.inf
                    temp = reg[&#39;warpedmovout&#39;]
                    myvar = temp.numpy().var()
                    if verbose:
                        print( str(k) + &#34; : &#34; + regtx  + &#34; : &#34; + mytx + &#34; _var_ &#34; + str( myvar ) )
                    if myvar &gt; 0 :
                        mymi = ants.image_mutual_information( fixed, temp )
                        if mymi &lt; bestmi:
                            if verbose:
                                print( &#34;mi @ &#34; + str(k) + &#34; : &#34; + str(mymi), flush=True)
                            bestmi = mymi
                            bestreg = reg
                            bestvar = myvar
        if bestvar == 0.0 and compreg is not None:
            return compreg        
        return bestreg

def neuromelanin( list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8,
    bias_correct=True,
    denoise=None,
    srmodel=None,
    target_range=[0,1],
    poly_order=&#39;hist&#39;,
    normalize_nm = False,
    verbose=False ) :

  &#34;&#34;&#34;
  Outputs the averaged and registered neuromelanin image, and neuromelanin labels

  Arguments
  ---------
  list_nm_image : list of ANTsImages
    list of neuromenlanin repeat images

  t1 : ANTsImage
    input 3-D T1 brain image

  t1_head : ANTsImage
    input 3-D T1 head image

  t1lab : ANTsImage
    t1 labels that will be propagated to the NM

  brain_stem_dilation : integer default 8
    dilates the brain stem mask to better match coverage of NM

  bias_correct : boolean

  denoise : None or integer

  srmodel : None -- this is a work in progress feature, probably not optimal

  target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

  poly_order : if not None, will fit a global regression model to map
      intensity back to original histogram space; if &#39;hist&#39; will match
      by histogram matching - ants.histogram_match_image

  normalize_nm : boolean - WIP not validated

  verbose : boolean

  Returns
  ---------
  Averaged and registered neuromelanin image and neuromelanin labels and wide csv

  &#34;&#34;&#34;

  fnt=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni.nii.gz&#34; )
  fntNM=os.path.expanduser(&#34;~/.antspymm/CIT168_T1w_700um_pad_adni_NM_norm_avg.nii.gz&#34; )
  fntbst=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni_brainstem.nii.gz&#34;)
  fnslab=os.path.expanduser(&#34;~/.antspyt1w/CIT168_MT_Slab_adni.nii.gz&#34;)
  fntseg=os.path.expanduser(&#34;~/.antspyt1w/det_atlas_25_pad_LR_adni.nii.gz&#34;)

  template = mm_read( fnt )
  templateNM = ants.iMath( mm_read( fntNM ), &#34;Normalize&#34; )
  templatebstem = mm_read( fntbst ).threshold_image( 1, 1000 )
  # reg = ants.registration( t1, template, &#39;antsRegistrationSyNQuickRepro[s]&#39; )
  reg = ants.registration( t1, template, &#39;SyN&#39; )
  # map NM avg to t1 for neuromelanin processing
  nmavg2t1 = ants.apply_transforms( t1, templateNM,
    reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39; )
  slab2t1 = ants.threshold_image( nmavg2t1, &#34;Otsu&#34;, 2 ).threshold_image(1,2).iMath(&#34;MD&#34;,1).iMath(&#34;FillHoles&#34;)
  # map brain stem and slab to t1 for neuromelanin processing
  bstem2t1 = ants.apply_transforms( t1, templatebstem,
    reg[&#39;fwdtransforms&#39;],
    interpolator=&#39;nearestNeighbor&#39; ).iMath(&#34;MD&#34;,1)
  slab2t1B = ants.apply_transforms( t1, mm_read( fnslab ),
    reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39;)
  bstem2t1 = ants.crop_image( bstem2t1, slab2t1 )
  cropper = ants.decrop_image( bstem2t1, slab2t1 ).iMath(&#34;MD&#34;,brain_stem_dilation)

  # Average images in image_list
  nm_avg = list_nm_images[0]*0.0
  for k in range(len( list_nm_images )):
    if denoise is not None:
        list_nm_images[k] = ants.denoise_image( list_nm_images[k],
            shrink_factor=1,
            p=denoise,
            r=denoise+1,
            noise_model=&#39;Gaussian&#39; )
    if bias_correct :
        n4mask = ants.threshold_image( ants.iMath(list_nm_images[k], &#34;Normalize&#34; ), 0.05, 1 )
        list_nm_images[k] = ants.n4_bias_field_correction( list_nm_images[k], mask=n4mask )
    nm_avg = nm_avg + ants.resample_image_to_target( list_nm_images[k], nm_avg ) / len( list_nm_images )

  if verbose:
      print(&#34;Register each nm image in list_nm_images to the averaged nm image (avg)&#34;)
  nm_avg_new = nm_avg * 0.0
  txlist = []
  for k in range(len( list_nm_images )):
    if verbose:
        print(str(k) + &#34; of &#34; + str(len( list_nm_images ) ) )
    current_image = ants.registration( list_nm_images[k], nm_avg,
        type_of_transform = &#39;Rigid&#39; )
    txlist.append( current_image[&#39;fwdtransforms&#39;][0] )
    current_image = current_image[&#39;warpedfixout&#39;]
    nm_avg_new = nm_avg_new + current_image / len( list_nm_images )
  nm_avg = nm_avg_new

  if verbose:
      print(&#34;do slab registration to map anatomy to NM space&#34;)
  t1c = ants.crop_image( t1_head, slab2t1 ).iMath(&#34;Normalize&#34;) # old way
  nmavg2t1c = ants.crop_image( nmavg2t1, slab2t1 ).iMath(&#34;Normalize&#34;)
  # slabreg = ants.registration( nm_avg, nmavg2t1c, &#39;Rigid&#39; )
  slabreg = tra_initializer( nm_avg, t1c, verbose=verbose )
  if False:
      slabregT1 = tra_initializer( nm_avg, t1c, verbose=verbose  )
      miNM = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg0[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      miT1 = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg1[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      if miT1 &lt; miNM:
        slabreg = slabregT1
  labels2nm = ants.apply_transforms( nm_avg, t1lab, slabreg[&#39;fwdtransforms&#39;],
    interpolator = &#39;genericLabel&#39; )
  cropper2nm = ants.apply_transforms( nm_avg, cropper, slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
  nm_avg_cropped = ants.crop_image( nm_avg, cropper2nm )

  if verbose:
      print(&#34;now map these labels to each individual nm&#34;)
  crop_mask_list = []
  crop_nm_list = []
  for k in range(len( list_nm_images )):
      concattx = []
      concattx.append( txlist[k] )
      concattx.append( slabreg[&#39;fwdtransforms&#39;][0] )
      cropmask = ants.apply_transforms( list_nm_images[k], cropper,
        concattx, interpolator = &#39;nearestNeighbor&#39; )
      crop_mask_list.append( cropmask )
      temp = ants.crop_image( list_nm_images[k], cropmask )
      crop_nm_list.append( temp )

  if srmodel is not None:
      if verbose:
          print( &#34; start sr &#34; + str(len( crop_nm_list )) )
      for k in range(len( crop_nm_list )):
          if verbose:
              print( &#34; do sr &#34; + str(k) )
              print( crop_nm_list[k] )
          temp = antspynet.apply_super_resolution_model_to_image(
                crop_nm_list[k], srmodel, target_range=target_range,
                regression_order=None )
          if poly_order is not None:
              bilin = ants.resample_image_to_target( crop_nm_list[k], temp )
              if poly_order == &#39;hist&#39;:
                  temp = ants.histogram_match_image( temp, bilin )
              else:
                  temp = antspynet.regression_match_image( temp, bilin, poly_order = poly_order )
          crop_nm_list[k] = temp

  nm_avg_cropped = crop_nm_list[0]*0.0
  if verbose:
      print( &#34;cropped average&#34; )
      print( nm_avg_cropped )
  for k in range(len( crop_nm_list )):
      nm_avg_cropped = nm_avg_cropped + ants.apply_transforms( nm_avg_cropped,
        crop_nm_list[k], txlist[k] ) / len( crop_nm_list )
  for loop in range( 3 ):
      nm_avg_cropped_new = nm_avg_cropped * 0.0
      for k in range(len( crop_nm_list )):
            myreg = ants.registration(
                ants.iMath(nm_avg_cropped,&#34;Normalize&#34;),
                ants.iMath(crop_nm_list[k],&#34;Normalize&#34;),
                &#39;BOLDRigid&#39; )
            warpednext = ants.apply_transforms(
                nm_avg_cropped_new,
                crop_nm_list[k],
                myreg[&#39;fwdtransforms&#39;] )
            nm_avg_cropped_new = nm_avg_cropped_new + warpednext
      nm_avg_cropped = nm_avg_cropped_new / len( crop_nm_list )

  slabregUpdated = tra_initializer( nm_avg_cropped, t1c, compreg=slabreg,verbose=verbose  )
  tempOrig = ants.apply_transforms( nm_avg_cropped_new, t1c, slabreg[&#39;fwdtransforms&#39;] )
  tempUpdate = ants.apply_transforms( nm_avg_cropped_new, t1c, slabregUpdated[&#39;fwdtransforms&#39;] )
  miUpdate = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempUpdate,&#34;Normalize&#34;) )
  miOrig = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempOrig,&#34;Normalize&#34;) )
  if miUpdate &lt; miOrig :
      slabreg = slabregUpdated

  if normalize_nm:
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;TruncateIntensity&#34;,0.05,0.95)
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )

  labels2nm = ants.apply_transforms( nm_avg_cropped, t1lab,
        slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )

  # fix the reference region - keep top two parts
  def get_biggest_part( x, labeln ):
      temp33 = ants.threshold_image( x, labeln, labeln ).iMath(&#34;GetLargestComponent&#34;)
      x[ x == labeln] = 0
      x[ temp33 == 1 ] = labeln

  get_biggest_part( labels2nm, 33 )
  get_biggest_part( labels2nm, 34 )

  if verbose:
      print( &#34;map summary measurements to wide format&#34; )
  nmdf = antspyt1w.map_intensity_to_dataframe(
          &#39;CIT168_Reinf_Learn_v1_label_descriptions_pad&#39;,
          nm_avg_cropped,
          labels2nm)
  if verbose:
      print( &#34;merge to wide format&#34; )
  nmdf_wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;NM&#39; : nmdf},
              col_names = [&#39;Mean&#39;] )
  if verbose:
      print( &#34;nm done&#34; )

  rr_mask = ants.mask_image( labels2nm, labels2nm, [33,34] , binarize=True )
  sn_mask = ants.mask_image( labels2nm, labels2nm, [7,9,23,25] , binarize=True )
  nmavgsnr = mask_snr( nm_avg_cropped, rr_mask, sn_mask, bias_correct = False )

  snavg = nm_avg_cropped[ sn_mask == 1].mean()
  rravg = nm_avg_cropped[ rr_mask == 1].mean()
  snstd = nm_avg_cropped[ sn_mask == 1].std()
  rrstd = nm_avg_cropped[ rr_mask == 1].std()
  snvol = np.prod( ants.get_spacing(sn_mask) ) * sn_mask.sum()

  # get the mean voxel position of the SN
  if snvol &gt; 0:
      sn_z = ants.transform_physical_point_to_index( sn_mask, ants.get_center_of_mass(sn_mask ))[2]
      sn_z = sn_z/sn_mask.shape[2] # around 0.5 would be nice
  else:
      sn_z = math.nan

  nm_evr = antspyt1w.patch_eigenvalue_ratio( nm_avg, 512, [6,6,6], evdepth = 0.9, mask=cropper2nm )

  return{
      &#39;NM_avg&#39; : nm_avg,
      &#39;NM_avg_cropped&#39; : nm_avg_cropped,
      &#39;NM_labels&#39;: labels2nm,
      &#39;NM_cropped&#39;: crop_nm_list,
      &#39;NM_midbrainROI&#39;: cropper2nm,
      &#39;NM_dataframe&#39;: nmdf,
      &#39;NM_dataframe_wide&#39;: nmdf_wide,
      &#39;t1_to_NM&#39;: slabreg[&#39;warpedmovout&#39;],
      &#39;t1_to_NM_transform&#39; : slabreg[&#39;fwdtransforms&#39;],
      &#39;NM_avg_signaltonoise&#39; : nmavgsnr,
      &#39;NM_avg_substantianigra&#39; : snavg,
      &#39;NM_std_substantianigra&#39; : snstd,
      &#39;NM_volume_substantianigra&#39; : snvol,
      &#39;NM_avg_refregion&#39; : rravg,
      &#39;NM_std_refregion&#39; : rrstd,
      &#39;NM_min&#39; : nm_avg_cropped.min(),
      &#39;NM_max&#39; : nm_avg_cropped.max(),
      &#39;NM_mean&#39; : nm_avg_cropped.numpy().mean(),
      &#39;NM_sd&#39; : np.std( nm_avg_cropped.numpy() ),
      &#39;NM_q0pt05&#39; : np.quantile( nm_avg_cropped.numpy(), 0.05 ),
      &#39;NM_q0pt10&#39; : np.quantile( nm_avg_cropped.numpy(), 0.10 ),
      &#39;NM_q0pt90&#39; : np.quantile( nm_avg_cropped.numpy(), 0.90 ),
      &#39;NM_q0pt95&#39; : np.quantile( nm_avg_cropped.numpy(), 0.95 ),
      &#39;NM_substantianigra_z_coordinate&#39; : sn_z,
      &#39;NM_evr&#39; : nm_evr,
      &#39;NM_count&#39;: len( list_nm_images )
       }



def estimate_optimal_pca_components(data, variance_threshold=0.80, plot=False):
    &#34;&#34;&#34;
    Estimate the optimal number of PCA components to represent the given data.

    :param data: The data matrix (samples x features).
    :param variance_threshold: Threshold for cumulative explained variance (default 0.95).
    :param plot: If True, plot the cumulative explained variance graph (default False).
    :return: The optimal number of principal components.
    &#34;&#34;&#34;
    import numpy as np
    from sklearn.decomposition import PCA
    import matplotlib.pyplot as plt

    # Perform PCA
    pca = PCA()
    pca.fit(data)

    # Calculate cumulative explained variance
    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)

    # Determine the number of components for desired explained variance
    n_components = np.where(cumulative_variance &gt;= variance_threshold)[0][0] + 1

    # Optionally plot the explained variance
    if plot:
        plt.figure(figsize=(8, 4))
        plt.plot(cumulative_variance, linewidth=2)
        plt.axhline(y=variance_threshold, color=&#39;r&#39;, linestyle=&#39;--&#39;)
        plt.axvline(x=n_components - 1, color=&#39;r&#39;, linestyle=&#39;--&#39;)
        plt.xlabel(&#39;Number of Components&#39;)
        plt.ylabel(&#39;Cumulative Explained Variance&#39;)
        plt.title(&#39;Explained Variance by Number of Principal Components&#39;)
        plt.show()

    return n_components

import numpy as np

def compute_PerAF_voxel(time_series):
    &#34;&#34;&#34;
    Compute the Percentage Amplitude Fluctuation (PerAF) for a given time series.

    10.1371/journal.pone.0227021

    PerAF = 100/n * sum(|(x_i - m)/m|) 
    where m = 1/n * sum(x_i), x_i is the signal intensity at each time point, 
    and n is the total number of time points.

    :param time_series: Numpy array of time series data
    :return: Computed PerAF value
    &#34;&#34;&#34;
    n = len(time_series)
    m = np.mean(time_series)
    perAF = 100 / n * np.sum(np.abs((time_series - m) / m))
    return perAF

def calculate_trimmed_mean(data, proportion_to_trim):
    &#34;&#34;&#34;
    Calculate the trimmed mean for a given data array.

    :param data: A numpy array of data.
    :param proportion_to_trim: Proportion (0 to 0.5) of data to trim from each end.
    :return: The trimmed mean of the data.
    &#34;&#34;&#34;
    from scipy import stats
    return stats.trim_mean(data, proportion_to_trim)

def PerAF( x, mask, globalmean=True ):
    &#34;&#34;&#34;
    Compute the Percentage Amplitude Fluctuation (PerAF) for a given time series.

    10.1371/journal.pone.0227021

    PerAF = 100/n * sum(|(x_i - m)/m|) 
    where m = 1/n * sum(x_i), x_i is the signal intensity at each time point, 
    and n is the total number of time points.

    :param x: time series antsImage
    :param mask: brain mask
    :param globalmean: boolean if True divide by the globalmean in the brain mask
    :return: Computed PerAF image
    &#34;&#34;&#34;
    time_series = ants.timeseries_to_matrix( x, mask )
    n = time_series.shape[1]
    vec = np.zeros( n )
    for i in range(n):
        vec[i] = compute_PerAF_voxel( time_series[:,i] )
    outimg = ants.make_image( mask, vec )
    if globalmean:
        outimg = outimg / calculate_trimmed_mean( vec, 0.01 )
    return outimg


def resting_state_fmri_networks( fmri, fmri_template, t1, t1segmentation,
    f=[0.03, 0.08],
    FD_threshold=5.0,
    spa = None,
    spt = None,
    nc = 5,
    outlier_threshold=0.250,
    ica_components = 0,
    impute = True,
    censor = True,
    despike = 2.5,
    motion_as_nuisance = True,
    powers = False,
    upsample = 3.0,
    clean_tmp = None,
    paramset=&#39;unset&#39;,
    verbose=False ):
  &#34;&#34;&#34;
  Compute resting state network correlation maps based on the J Power labels.
  This will output a map for each of the major network systems.  This function 
  will by optionally upsample data to 2mm during the registration process if data 
  is below that resolution.

  registration - despike - anatomy - smooth - nuisance - bandpass - regress.nuisance - censor - falff - correlations

  Arguments
  ---------
  fmri : BOLD fmri antsImage

  fmri_template : reference space for BOLD

  t1 : ANTsImage
    input 3-D T1 brain image (brain extracted)

  t1segmentation : ANTsImage
    t1 segmentation - a six tissue segmentation image in T1 space

  f : band pass limits for frequency filtering; we use high-pass here as per Shirer 2015

  spa : gaussian smoothing for spatial component (physical coordinates)

  spt : gaussian smoothing for temporal component

  nc  : number of components for compcor filtering; if less than 1 we estimate on the fly based on explained variance; 10 wrt Shirer 2015 5 from csf and 5 from wm

  ica_components : integer if greater than 0 then include ica components

  impute : boolean if True, then use imputation in f/ALFF, PerAF calculation

  censor : boolean if True, then use censoring (censoring)

  despike : if this is greater than zero will run voxel-wise despiking in the 3dDespike (afni) sense; after motion-correction

  motion_as_nuisance: boolean will add motion and first derivative of motion as nuisance

  powers : boolean if True use Powers nodes otherwise 2023 Yeo 500 homotopic nodes (10.1016/j.neuroimage.2023.120010)

  upsample : float optionally isotropically upsample data to upsample (the parameter value) in mm during the registration process if data is below that resolution; if the input spacing is less than that provided by the user, the data will simply be resampled to isotropic resolution

  clean_tmp : will automatically try to clean the tmp directory - not recommended but can be used in distributed computing systems to help prevent failures due to accumulation of tmp files when doing large-scale processing.  if this is set, the float value clean_tmp will be interpreted as the age in hours of files to be cleaned.

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  References
  ---------

  10.1162/netn_a_00071 &#34;Methods that included global signal regression were the most consistently effective de-noising strategies.&#34;

  10.1016/j.neuroimage.2019.116157 &#34;frontal and default model networks are most reliable whereas subcortical neteworks are least reliable&#34;  &#34;the most comprehensive studies of pipeline effects on edge-level reliability have been done by shirer (2015) and Parkes (2018)&#34; &#34;slice timing correction has minimal impact&#34; &#34;use of low-pass or narrow filter (discarding  high frequency information) reduced both reliability and signal-noise separation&#34;

  10.1016/j.neuroimage.2017.12.073: Our results indicate that (1) simple linear regression of regional fMRI time series against head motion parameters and WM/CSF signals (with or without expansion terms) is not sufficient to remove head motion artefacts; (2) aCompCor pipelines may only be viable in low-motion data; (3) volume censoring performs well at minimising motion-related artefact but a major benefit of this approach derives from the exclusion of high-motion individuals; (4) while not as effective as volume censoring, ICA-AROMA performed well across our benchmarks for relatively low cost in terms of data loss; (5) the addition of global signal regression improved the performance of nearly all pipelines on most benchmarks, but exacerbated the distance-dependence of correlations between motion and functional connec- tivity; and (6) group comparisons in functional connectivity between healthy controls and schizophrenia patients are highly dependent on preprocessing strategy. We offer some recommendations for best practice and outline simple analyses to facilitate transparent reporting of the degree to which a given set of findings may be affected by motion-related artefact.

  10.1016/j.dcn.2022.101087 : We found that: 1) the most efficacious pipeline for both noise removal and information recovery included censoring, GSR, bandpass filtering, and head motion parameter (HMP) regression, 2) ICA-AROMA performed similarly to HMP regression and did not obviate the need for censoring, 3) GSR had a minimal impact on connectome fingerprinting but improved ISC, and 4) the strictest censoring approaches reduced motion correlated edges but negatively impacted identifiability.

  &#34;&#34;&#34;

  import warnings

  if clean_tmp is not None:
    clean_tmp_directory( age_hours = clean_tmp )

  if nc &gt; 1:
    nc = int(nc)
  else:
    nc=float(nc)

  type_of_transform=&#39;Rigid&#39; # , # should probably not change this
  remove_it=True
  output_directory = tempfile.mkdtemp()
  output_directory_w = output_directory + &#34;/ts_t1_reg/&#34;
  os.makedirs(output_directory_w,exist_ok=True)
  ofnt1tx = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;t1_deformation&#39;,dir=output_directory_w).name

  import numpy as np
# Assuming core and utils are modules or packages with necessary functions

  if upsample &gt; 0.0:
      spc = ants.get_spacing( fmri )
      minspc = upsample
      if min(spc[0:3]) &lt; minspc:
          minspc = min(spc[0:3])
      newspc = [minspc,minspc,minspc]
      fmri_template = ants.resample_image( fmri_template, newspc, interp_type=0 )

  def temporal_derivative_same_shape(array):
    &#34;&#34;&#34;
    Compute the temporal derivative of a 2D numpy array along the 0th axis (time)
    and ensure the output has the same shape as the input.

    :param array: 2D numpy array with time as the 0th axis.
    :return: 2D numpy array of the temporal derivative with the same shape as input.
    &#34;&#34;&#34;
    derivative = np.diff(array, axis=0)
    
    # Append a row to maintain the same shape
    # You can choose to append a row of zeros or the last row of the derivative
    # Here, a row of zeros is appended
    zeros_row = np.zeros((1, array.shape[1]))
    return np.vstack((zeros_row, derivative ))

  def compute_tSTD(M, quantile, x=0, axis=0):
    stdM = np.std(M, axis=axis)
    # set bad values to x
    stdM[stdM == 0] = x
    stdM[np.isnan(stdM)] = x
    tt = round(quantile * 100)
    threshold_std = np.percentile(stdM, tt)
    return {&#39;tSTD&#39;: stdM, &#39;threshold_std&#39;: threshold_std}

  def get_compcor_matrix(boldImage, mask, quantile):
    &#34;&#34;&#34;
    Compute the compcor matrix.

    :param boldImage: The bold image.
    :param mask: The mask to apply, if None, it will be computed.
    :param quantile: Quantile for computing threshold in tSTD.
    :return: The compor matrix.
    &#34;&#34;&#34;
    if mask is None:
        temp = ants.slice_image(boldImage, axis=boldImage.dimension - 1, idx=0)
        mask = ants.get_mask(temp)

    imagematrix = ants.timeseries_to_matrix(boldImage, mask)
    temp = compute_tSTD(imagematrix, quantile, 0)
    tsnrmask = ants.make_image(mask, temp[&#39;tSTD&#39;])
    tsnrmask = ants.threshold_image(tsnrmask, temp[&#39;threshold_std&#39;], temp[&#39;tSTD&#39;].max())
    M = ants.timeseries_to_matrix(boldImage, tsnrmask)
    return M


  from sklearn.decomposition import FastICA
  def find_indices(lst, value):
    return [index for index, element in enumerate(lst) if element &gt; value]

  def mean_of_list(lst):
    if not lst:  # Check if the list is not empty
        return 0  # Return 0 or appropriate value for an empty list
    return sum(lst) / len(lst)
  fmrispc = list( ants.get_spacing( fmri ) )
  if spa is None:
    spa = mean_of_list( fmrispc[0:3] ) * 1.0
  if spt is None:
    spt = fmrispc[3] * 0.5
      
  import numpy as np
  import pandas as pd
  import re
  import math
  # point data resources
  A = np.zeros((1,1))
  dfnname=&#39;DefaultMode&#39;
  if powers:
      powers_areal_mni_itk = pd.read_csv( get_data(&#39;powers_mni_itk&#39;, target_extension=&#34;.csv&#34;)) # power coordinates
      coords=&#39;powers&#39;
  else:
      powers_areal_mni_itk = pd.read_csv( get_data(&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;, target_extension=&#34;.csv&#34;)) # yeo 2023 coordinates
      coords=&#39;yeo_17_500_2023&#39;
  fmri = ants.iMath( fmri, &#39;Normalize&#39; )
  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;FillHoles&#34;)
  if verbose:
      print(&#34;Begin rsfmri motion correction&#34;)
  debug=False
  if debug:
      ants.image_write( fmri_template, &#39;/tmp/fmri_template.nii.gz&#39; )
      ants.image_write( fmri, &#39;/tmp/fmri.nii.gz&#39; )
      print(&#34;debug wrote fmri and fmri_template&#34;)
  # mot-co
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=type_of_transform,
    total_sigma=0.5,
    fdOffset=2.0,
    trim = 8,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5],
    return_numpy_motion_parameters=True )
  
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)
      print(&#34;=== next anatomically based mapping ===&#34;)

  despiking_count = np.zeros( corrmo[&#39;motion_corrected&#39;].shape[3] )
  if despike &gt; 0.0:
      corrmo[&#39;motion_corrected&#39;], despiking_count = despike_time_series_afni( corrmo[&#39;motion_corrected&#39;], c1=despike )

  despiking_count_summary = despiking_count.sum() / np.prod( corrmo[&#39;motion_corrected&#39;].shape )
  high_motion_count=(corrmo[&#39;FD&#39;] &gt; FD_threshold ).sum()
  high_motion_pct=high_motion_count / fmri.shape[3]

  # filter mask based on TSNR
  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,2)
  bmask = bmask * tsnrmask

  # anatomical mapping
  und = fmri_template * bmask
  t1reg = ants.registration( und, t1,
    &#34;SyNBold&#34;, outprefix=ofnt1tx )
  if verbose:
    print(&#34;t1 2 bold done&#34;)
  gmseg = ants.threshold_image( t1segmentation, 2, 2 )
  gmseg = gmseg + ants.threshold_image( t1segmentation, 4, 4 )
  gmseg = ants.threshold_image( gmseg, 1, 4 )
  gmseg = ants.iMath( gmseg, &#39;MD&#39;, 1 ) # FIXMERSF
  gmseg = ants.apply_transforms( und, gmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; ) * bmask
  csfAndWM = ( ants.threshold_image( t1segmentation, 1, 1 ) +
               ants.threshold_image( t1segmentation, 3, 3 ) ).morphology(&#34;erode&#34;,1)
  csfAndWM = ants.apply_transforms( und, csfAndWM,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  csf = ants.threshold_image( t1segmentation, 1, 1 )
  csf = ants.apply_transforms( und, csf, t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  wm = ants.threshold_image( t1segmentation, 3, 3 ).morphology(&#34;erode&#34;,1)
  wm = ants.apply_transforms( und, wm, t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  if powers:
    ch2 = mm_read( ants.get_ants_data( &#34;ch2&#34; ) )
  else:
    ch2 = mm_read( get_data( &#34;PPMI_template0_brain&#34;, target_extension=&#39;.nii.gz&#39; ) )
  treg = ants.registration( 
    # this is to make the impact of resolution consistent
    ants.resample_image(t1, [1.0,1.0,1.0], interp_type=0), 
    ch2, &#34;antsRegistrationSyNQuickRepro[s]&#34; )
  if powers:
    concatx2 = treg[&#39;invtransforms&#39;] + t1reg[&#39;invtransforms&#39;]
    pts2bold = ants.apply_transforms_to_points( 3, powers_areal_mni_itk, concatx2,
        whichtoinvert = ( True, False, True, False ) )
    locations = pts2bold.iloc[:,:3].values
    ptImg = ants.make_points_image( locations, bmask, radius = 2 )
  else:
    concatx2 = t1reg[&#39;fwdtransforms&#39;] + treg[&#39;fwdtransforms&#39;]    
    rsfsegfn = get_data(&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;, target_extension=&#34;.nii.gz&#34;)
    rsfsegimg = ants.image_read( rsfsegfn )
    ptImg = ants.apply_transforms( und, rsfsegimg, concatx2, interpolator=&#39;nearestNeighbor&#39; ) * bmask
    pts2bold = powers_areal_mni_itk
    # ants.plot( und, ptImg, crop=True, axis=2 )

  # optional smoothing
  tr = ants.get_spacing( corrmo[&#39;motion_corrected&#39;] )[3]
  smth = ( spa, spa, spa, spt ) # this is for sigmaInPhysicalCoordinates = TRUE
  simg = ants.smooth_image( corrmo[&#39;motion_corrected&#39;], smth, sigma_in_physical_coordinates = True )

  # collect censoring indices
  hlinds = find_indices( corrmo[&#39;FD&#39;], FD_threshold )
  if verbose:
    print(&#34;high motion indices&#34;)
    print( hlinds )
  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    fmrimotcorr, hlinds2 = loop_timeseries_censoring( corrmo[&#39;motion_corrected&#39;], 
      threshold=outlier_threshold, verbose=verbose )
    hlinds.extend( hlinds2 )
    del fmrimotcorr
  hlinds = list(set(hlinds)) # make unique

  # nuisance
  globalmat = ants.timeseries_to_matrix( corrmo[&#39;motion_corrected&#39;], bmask )
  globalsignal = np.nanmean( globalmat, axis = 1 )
  del globalmat
  compcorquantile=0.50
  nc_wm=nc_csf=nc
  if nc &lt; 1:
    globalmat = get_compcor_matrix( corrmo[&#39;motion_corrected&#39;], wm, compcorquantile )
    nc_wm = int(estimate_optimal_pca_components( data=globalmat, variance_threshold=nc))
    globalmat = get_compcor_matrix( corrmo[&#39;motion_corrected&#39;], csf, compcorquantile )
    nc_csf = int(estimate_optimal_pca_components( data=globalmat, variance_threshold=nc))
    del globalmat
  if verbose:
    print(&#34;include compcor components as nuisance: csf &#34; + str(nc_csf) + &#34; wm &#34; + str(nc_wm))
  mycompcor_csf = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc_csf, quantile=compcorquantile, mask = csf,
    filter_type=&#39;polynomial&#39;, degree=2 )
  mycompcor_wm = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc_wm, quantile=compcorquantile, mask = wm,
    filter_type=&#39;polynomial&#39;, degree=2 )
  nuisance = np.c_[ mycompcor_csf[ &#39;components&#39; ], mycompcor_wm[ &#39;components&#39; ] ]

  if motion_as_nuisance:
      if verbose:
          print(&#34;include motion as nuisance&#34;)
          print( corrmo[&#39;motion_parameters&#39;].shape )
      deriv = temporal_derivative_same_shape( corrmo[&#39;motion_parameters&#39;]  )
      nuisance = np.c_[ nuisance, corrmo[&#39;motion_parameters&#39;], deriv ]

  if ica_components &gt; 0:
    if verbose:
        print(&#34;include ica components as nuisance: &#34; + str(ica_components))
    ica = FastICA(n_components=ica_components, max_iter=10000, tol=0.001, random_state=42 )
    globalmat = ants.timeseries_to_matrix( corrmo[&#39;motion_corrected&#39;], csfAndWM )
    nuisance_ica = ica.fit_transform(globalmat)  # Reconstruct signals
    nuisance = np.c_[ nuisance, nuisance_ica ]
    del globalmat

  # concat all nuisance data
  # nuisance = np.c_[ nuisance, mycompcor[&#39;basis&#39;] ]
  # nuisance = np.c_[ nuisance, corrmo[&#39;FD&#39;] ]
  nuisance = np.c_[ nuisance, globalsignal ]

  if impute:
    simgimp = impute_timeseries( simg, hlinds, method=&#39;linear&#39;)
  else:
    simgimp = simg

  # falff/alff stuff  def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
  myfalff=alff_image( simgimp, bmask, flo=f[0], fhi=f[1], nuisance=nuisance  )

  # bandpass any data collected before here -- if bandpass requested
  if f[0] &gt; 0 and f[1] &lt; 1.0:
    if verbose:
        print( &#34;bandpass: &#34; + str(f[0]) + &#34; &lt;=&gt; &#34; + str( f[1] ) )
    nuisance = ants.bandpass_filter_matrix( nuisance, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
    globalmat = ants.timeseries_to_matrix( simg, bmask )
    globalmat = ants.bandpass_filter_matrix( globalmat, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
    simg = ants.matrix_to_timeseries( simg, globalmat, bmask )

  if verbose:
    print(&#34;now regress nuisance&#34;)


  if len( hlinds ) &gt; 0 :
    if censor:
        nuisance = remove_elements_from_numpy_array( nuisance, hlinds  )
        simg = remove_volumes_from_timeseries( simg, hlinds )

  gmmat = ants.timeseries_to_matrix( simg, bmask )
  gmmat = ants.regress_components( gmmat, nuisance )
  simg = ants.matrix_to_timeseries(simg, gmmat, bmask)


  # structure the output data
  outdict = {}
  outdict[&#39;paramset&#39;] = paramset
  outdict[&#39;upsampling&#39;] = upsample
  outdict[&#39;coords&#39;] = coords
  outdict[&#39;dfnname&#39;]=dfnname
  outdict[&#39;meanBold&#39;] = und

  # add correlation matrix that captures each node pair
  # some of the spheres overlap so extract separately from each ROI
  if powers:
    nPoints = int(pts2bold[&#39;ROI&#39;].max())
    pointrange = list(range(int(nPoints)))
  else:
    nPoints = int(ptImg.max())
    pointrange = list(range(int(nPoints)))
  nVolumes = simg.shape[3]
  meanROI = np.zeros([nVolumes, nPoints])
  roiNames = []
  if debug:
      ptImgAll = und * 0.
  for i in pointrange:
    # specify name for matrix entries that&#39;s links back to ROI number and network; e.g., ROI1_Uncertain
    netLabel = re.sub( &#34; &#34;, &#34;&#34;, pts2bold.loc[i,&#39;SystemName&#39;])
    netLabel = re.sub( &#34;-&#34;, &#34;&#34;, netLabel )
    netLabel = re.sub( &#34;/&#34;, &#34;&#34;, netLabel )
    roiLabel = &#34;ROI&#34; + str(pts2bold.loc[i,&#39;ROI&#39;]) + &#39;_&#39; + netLabel
    roiNames.append( roiLabel )
    if powers:
        ptImage = ants.make_points_image(pts2bold.iloc[[i],:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    else:
        #print(&#34;Doing &#34; + pts2bold.loc[i,&#39;SystemName&#39;] + &#34; at &#34; + str(i) )
        #ptImage = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==pts2bold.loc[i,&#39;SystemName&#39;]],binarize=True)
        ptImage=ants.threshold_image( ptImg, pts2bold.loc[i,&#39;ROI&#39;], pts2bold.loc[i,&#39;ROI&#39;] )
    if debug:
      ptImgAll = ptImgAll + ptImage
    if ptImage.sum() &gt; 0 :
        meanROI[:,i] = ants.timeseries_to_matrix( simg, ptImage).mean(axis=1)

  if debug:
      ants.image_write( simg, &#39;/tmp/simg.nii.gz&#39; )
      ants.image_write( ptImgAll, &#39;/tmp/ptImgAll.nii.gz&#39; )
      ants.image_write( und, &#39;/tmp/und.nii.gz&#39; )
      ants.image_write( und, &#39;/tmp/und.nii.gz&#39; )

  # get full correlation matrix
  corMat = np.corrcoef(meanROI, rowvar=False)
  outputMat = pd.DataFrame(corMat)
  outputMat.columns = roiNames
  outputMat[&#39;ROIs&#39;] = roiNames
  # add to dictionary
  outdict[&#39;fullCorrMat&#39;] = outputMat

  networks = powers_areal_mni_itk[&#39;SystemName&#39;].unique()
  # this is just for human readability - reminds us of which we choose by default
  if powers:
    netnames = [&#39;Cingulo-opercular Task Control&#39;, &#39;Default Mode&#39;,
                    &#39;Memory Retrieval&#39;, &#39;Ventral Attention&#39;, &#39;Visual&#39;,
                    &#39;Fronto-parietal Task Control&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
                    &#39;Dorsal Attention&#39;]
    numofnets = [3,5,6,7,8,9,10,11,13]
  else:
    netnames = networks
    numofnets = list(range(len(netnames)))
 
  ct = 0
  for mynet in numofnets:
    netname = re.sub( &#34; &#34;, &#34;&#34;, networks[mynet] )
    netname = re.sub( &#34;-&#34;, &#34;&#34;, netname )
    ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[mynet] )[0]
    if powers:
        dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    else:
        dfnImg = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==networks[mynet]],binarize=True)
    if dfnImg.max() &gt;= 1:
        if verbose:
            print(&#34;DO: &#34; + coords + &#34; &#34; + netname )
        dfnmat = ants.timeseries_to_matrix( simg, ants.threshold_image( dfnImg, 1, dfnImg.max() ) )
        dfnsignal = np.nanmean( dfnmat, axis = 1 )
        nan_count_dfn = np.count_nonzero( np.isnan( dfnsignal) )
        if nan_count_dfn &gt; 0 :
            warnings.warn( &#34; mynet &#34; + netnames[ mynet ] + &#34; vs &#34; +  &#34; mean-signal has nans &#34; + str( nan_count_dfn ) ) 
        gmmatDFNCorr = np.zeros( gmmat.shape[1] )
        if nan_count_dfn == 0:
            for k in range( gmmat.shape[1] ):
                nan_count_gm = np.count_nonzero( np.isnan( gmmat[:,k]) )
                if debug and False:
                    print( str( k ) +  &#34; nans gm &#34; + str(nan_count_gm)  )
                if nan_count_gm == 0:
                    gmmatDFNCorr[ k ] = pearsonr( dfnsignal, gmmat[:,k] )[0]
        corrImg = ants.make_image( bmask, gmmatDFNCorr  )
        outdict[ netname ] = corrImg * gmseg
    else:
        outdict[ netname ] = None
    ct = ct + 1

  A = np.zeros( ( len( numofnets ) , len( numofnets ) ) )
  A_wide = np.zeros( ( 1, len( numofnets ) * len( numofnets ) ) )
  newnames=[]
  newnames_wide=[]
  ct = 0
  for i in range( len( numofnets ) ):
      netnamei = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[i]] )
      netnamei = re.sub( &#34;-&#34;, &#34;&#34;, netnamei )
      newnames.append( netnamei  )
      ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[numofnets[i]] )[0]
      if powers:
          dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
      else:
          dfnImg = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==networks[numofnets[i]]],binarize=True)
      for j in range( len( numofnets ) ):
          netnamej = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[j]] )
          netnamej = re.sub( &#34;-&#34;, &#34;&#34;, netnamej )
          newnames_wide.append( netnamei + &#34;_2_&#34; + netnamej )
          A[i,j] = 0
          if dfnImg is not None and netnamej is not None:
            subbit = dfnImg == 1
            if subbit is not None:
                if subbit.sum() &gt; 0 and netnamej in outdict:
                    A[i,j] = outdict[ netnamej ][ subbit ].mean()
          A_wide[0,ct] = A[i,j]
          ct=ct+1

  A = pd.DataFrame( A )
  A.columns = newnames
  A[&#39;networks&#39;]=newnames
  A_wide = pd.DataFrame( A_wide )
  A_wide.columns = newnames_wide
  outdict[&#39;corr&#39;] = A
  outdict[&#39;corr_wide&#39;] = A_wide
  outdict[&#39;fmri_template&#39;] = fmri_template
  outdict[&#39;brainmask&#39;] = bmask
  outdict[&#39;gmmask&#39;] = gmseg
  outdict[&#39;alff&#39;] = myfalff[&#39;alff&#39;]
  outdict[&#39;falff&#39;] = myfalff[&#39;falff&#39;]
  # add global mean and standard deviation for post-hoc z-scoring
  outdict[&#39;alff_mean&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).mean()
  outdict[&#39;alff_sd&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).std()
  outdict[&#39;falff_mean&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).mean()
  outdict[&#39;falff_sd&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).std()

  perafimg = PerAF( simgimp, bmask )
  for k in pointrange:
    anatname=( pts2bold[&#39;AAL&#39;][k] )
    if isinstance(anatname, str):
        anatname = re.sub(&#34;_&#34;,&#34;&#34;,anatname)
    else:
        anatname=&#39;Unk&#39;
    if powers:
        kk = f&#34;{k:0&gt;3}&#34;+&#34;_&#34;
    else:
        kk = f&#34;{k % int(nPoints/2):0&gt;3}&#34;+&#34;_&#34;
    fname=&#39;falffPoint&#39;+kk+anatname
    aname=&#39;alffPoint&#39;+kk+anatname
    pname=&#39;perafPoint&#39;+kk+anatname
    localsel = ptImg == k
    if localsel.sum() &gt; 0 : # check if non-empty
        outdict[fname]=(outdict[&#39;falff&#39;][localsel]).mean()
        outdict[aname]=(outdict[&#39;alff&#39;][localsel]).mean()
        outdict[pname]=(perafimg[localsel]).mean()
    else:
        outdict[fname]=math.nan
        outdict[aname]=math.nan
        outdict[pname]=math.nan

  rsfNuisance = pd.DataFrame( nuisance )
  if remove_it:
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )

  if not powers:
    dfnsum=outdict[&#39;DefaultA&#39;]+outdict[&#39;DefaultB&#39;]+outdict[&#39;DefaultC&#39;]
    outdict[&#39;DefaultMode&#39;]=dfnsum
    dfnsum=outdict[&#39;VisCent&#39;]+outdict[&#39;VisPeri&#39;]
    outdict[&#39;Visual&#39;]=dfnsum

  nonbrainmask = ants.iMath( bmask, &#34;MD&#34;,2) - bmask
  trimmask = ants.iMath( bmask, &#34;ME&#34;,2)
  edgemask = ants.iMath( bmask, &#34;ME&#34;,1) - trimmask
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;PerAF&#39;] = perafimg
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;ssnr&#39;] = slice_snr( corrmo[&#39;motion_corrected&#39;], csfAndWM, gmseg )
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;bandpass_freq_0&#39;]=f[0]
  outdict[&#39;bandpass_freq_1&#39;]=f[1]
  outdict[&#39;censor&#39;]=int(censor)
  outdict[&#39;spatial_smoothing&#39;]=spa
  outdict[&#39;outlier_threshold&#39;]=outlier_threshold
  outdict[&#39;FD_threshold&#39;]=outlier_threshold
  outdict[&#39;high_motion_count&#39;] = high_motion_count
  outdict[&#39;high_motion_pct&#39;] = high_motion_pct
  outdict[&#39;despiking_count_summary&#39;] = despiking_count_summary
  outdict[&#39;FD_max&#39;] = corrmo[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = corrmo[&#39;FD&#39;].mean()
  outdict[&#39;FD_sd&#39;] = corrmo[&#39;FD&#39;].std()
  outdict[&#39;bold_evr&#39;] =  antspyt1w.patch_eigenvalue_ratio( und, 512, [16,16,16], evdepth = 0.9, mask = bmask )
  outdict[&#39;n_outliers&#39;] = len(hlinds)
  outdict[&#39;nc_wm&#39;] = int(nc_wm)
  outdict[&#39;nc_csf&#39;] = int(nc_csf)
  outdict[&#39;minutes_original_data&#39;] = ( tr * fmri.shape[3] ) / 60.0 # minutes of useful data
  outdict[&#39;minutes_censored_data&#39;] = ( tr * simg.shape[3] ) / 60.0 # minutes of useful data
  return convert_np_in_dict( outdict )


def calculate_CBF(Delta_M, M_0, mask,
                  Lambda=0.9, T_1=0.67, Alpha=0.68, w=1.0, Tau=1.5):
    &#34;&#34;&#34;
    Calculate the Cerebral Blood Flow (CBF) where Delta_M and M_0 are antsImages 
    and the other variables are scalars.  Guesses at default values are used here. 
    We use the pCASL equation.  NOT YET TESTED.

    Parameters:
    Delta_M (antsImage): Change in magnetization (matrix)
    M_0 (antsImage): Initial magnetization (matrix)
    mask ( antsImage ): where to do the calculation
    Lambda (float): Scalar
    T_1 (float): Scalar representing relaxation time
    Alpha (float): Scalar representing flip angle
    w (float): Scalar
    Tau (float): Scalar

    Returns:
    np.ndarray: CBF values (matrix)
    &#34;&#34;&#34;
    cbf = M_0 * 0.0
    m0thresh = np.quantile( M_0[mask==1], 0.1 )
    sel = mask == 1 and M_0 &gt; m0thresh
    cbf[ sel ] = Delta_M[ sel ] * 60. * 100. * (Lambda * T_1)/( M_0[sel] * 2.0 * Alpha * 
        (np.exp( -w * T_1) - np.exp(-(Tau + w) * T_1)))
    cbf[ cbf &lt; 0.0]=0.0
    return cbf

def despike_time_series_afni(image, c1=2.5, c2=4):
    &#34;&#34;&#34;
    Despike a time series image using L1 polynomial fitting and nonlinear filtering.
    Based on afni 3dDespike

    :param image: ANTsPy image object containing time series data.
    :param c1: Spike threshold value. Default is 2.5.
    :param c2: Upper range of allowed deviation. Default is 4.
    :return: Despiked ANTsPy image object.
    &#34;&#34;&#34;
    data = image.numpy()  # Convert to numpy array
    despiked_data = np.copy(data)  # Create a copy for despiked data
    curve = despiked_data * 0.0

    def l1_fit_polynomial(time_series, degree=2):
        &#34;&#34;&#34;
        Fit a polynomial of given degree to the time series using least squares.
        
        :param time_series: 1D numpy array of voxel time series data.
        :param degree: Degree of the polynomial to fit.
        :return: Fitted polynomial values for the time series.
        &#34;&#34;&#34;
        t = np.arange(len(time_series))
        coefs = np.polyfit(t, time_series, degree)
        polynomial = np.polyval(coefs, t)
        return polynomial

    # L1 fit a smooth-ish curve to each voxel time series
    # Curve fitting for each voxel
    for x in range(data.shape[0]):
        for y in range(data.shape[1]):
            for z in range(data.shape[2]):
                voxel_time_series = data[x, y, z, :]
                curve[x, y, z, :] = l1_fit_polynomial(voxel_time_series, degree=2)

    # Compute the MAD of the residuals
    residuals = data - curve
    mad = np.median(np.abs(residuals - np.median(residuals, axis=-1, keepdims=True)), axis=-1, keepdims=True)
    sigma = np.sqrt(np.pi / 2) * mad
    # Ensure sigma is not zero to avoid division by zero
    sigma_safe = np.where(sigma == 0, 1e-10, sigma)

    # Optionally, handle NaN or inf values in data, curve, or sigma
    data = np.nan_to_num(data, nan=0.0, posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)
    curve = np.nan_to_num(curve, nan=0.0, posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)
    sigma_safe = np.nan_to_num(sigma_safe, nan=1e-10, posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)

    # Despike algorithm
    spike_counts = np.zeros( image.shape[3] )
    for i in range(data.shape[-1]):
        s = (data[..., i] - curve[..., i]) / sigma_safe[..., 0]
        ww = s &gt; c1
        s_prime = np.where( ww, c1 + (c2 - c1) * np.tanh((s - c1) / (c2 - c1)), s)
        spike_counts[i] = ww.sum()
        despiked_data[..., i] = curve[..., i] + s_prime * sigma[..., 0]

    # Convert back to ANTsPy image
    despiked_image = ants.from_numpy(despiked_data)
    return ants.copy_image_info( image, despiked_image ), spike_counts

def despike_time_series(image, threshold=3.0, replacement=&#39;threshold&#39; ):
    &#34;&#34;&#34;
    Despike a time series image.
    
    :param image: ANTsPy image object containing time series data.
    :param threshold: z-score value to identify spikes. Default is 3.
    :param replacement: median or threshold - the latter is similar 3DDespike but simpler
    :return: Despiked ANTsPy image object.
    &#34;&#34;&#34;
    # Convert image to numpy array
    data = image.numpy()
    
    # Calculate the mean and standard deviation along the time axis
    mean = np.mean(data, axis=-1)
    std = np.std(data, axis=-1)

    # Identify spikes: points where the deviation from the mean exceeds the threshold
    spikes = np.abs(data - mean[..., np.newaxis]) &gt; threshold * std[..., np.newaxis]

    # Replace spike values
    spike_counts = np.zeros( image.shape[3] )
    for i in range(data.shape[-1]):
        slice = data[..., i]
        spike_locations = spikes[..., i]
        spike_counts[i] = spike_locations.sum()
        if replacement == &#39;median&#39;:
            slice[spike_locations] = np.median(slice)  # Replace with median or another method
        else:
            # Calculate threshold values (mean ± threshold * std)
            threshold_values = mean + np.sign(slice - mean) * threshold * std
            slice[spike_locations] = threshold_values[spike_locations]
        data[..., i] = slice
    # Convert back to ANTsPy image
    despike_image = ants.from_numpy(data)
    despike_image = ants.copy_image_info( image, despike_image )
    return despike_image, spike_counts



def bold_perfusion_minimal( 
        fmri, 
        m0_image = None,
        spa = (0., 0., 0., 0.),
        nc  = 0,
        tc=&#39;alternating&#39;,
        n_to_trim=0,
        outlier_threshold=0.250,
        plot_brain_mask=False,
        verbose=False ):
  &#34;&#34;&#34;
  Estimate perfusion from a BOLD time series image.  Will attempt to figure out the T-C labels from the data.  The function uses defaults to quantify CBF but these will usually not be correct for your own data.  See the function calculate_CBF for an example of how one might do quantification based on the outputs of this function specifically the perfusion, m0 and mask images that are part of the output dictionary.

  This function is intended for use in debugging/testing or when one lacks a T1w image.

  Arguments
  ---------

  fmri : BOLD fmri antsImage

  m0_image: a pre-defined m0 antsImage

  spa : gaussian smoothing for spatial and temporal component e.g. (1,1,1,0) in physical space coordinates

  nc  : number of components for compcor filtering

  tc: string either alternating or split (default is alternating ie CTCTCT; split is CCCCTTTT)

  n_to_trim: number of volumes to trim off the front of the time series to account for initial magnetic saturation effects or to allow the signal to reach a steady state. in some cases, trailing volumes or other outlier volumes may need to be rejected.  this code does not currently handle that issue.

  outlier_threshold (numeric): between zero (remove all) and one (remove none); automatically calculates outlierness and uses it to censor the time series.

  plot_brain_mask : boolean can help with checking data quality visually

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  &#34;&#34;&#34;
  import numpy as np
  import pandas as pd
  import re
  import math
  from sklearn.linear_model import RANSACRegressor, TheilSenRegressor, HuberRegressor, QuantileRegressor, LinearRegression, SGDRegressor
  from sklearn.multioutput import MultiOutputRegressor
  from sklearn.preprocessing import StandardScaler

  def replicate_list(user_list, target_size):
    # Calculate the number of times the list should be replicated
    replication_factor = target_size // len(user_list)
    # Replicate the list and handle any remaining elements
    replicated_list = user_list * replication_factor
    remaining_elements = target_size % len(user_list)
    replicated_list += user_list[:remaining_elements]
    return replicated_list

  def one_hot_encode(char_list):
    unique_chars = list(set(char_list))
    encoding_dict = {char: [1 if char == c else 0 for c in unique_chars] for char in unique_chars}
    encoded_matrix = np.array([encoding_dict[char] for char in char_list])
    return encoded_matrix
  
  A = np.zeros((1,1))
  fmri_template = ants.get_average_of_timeseries( fmri )
  if n_to_trim is None:
    n_to_trim=0
  mytrim=n_to_trim
  perf_total_sigma = 1.5
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=&#39;Rigid&#39;,
    total_sigma=perf_total_sigma,
    fdOffset=2.0,
    trim = mytrim,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5] )
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)

  if m0_image is not None:
      m0 = m0_image

  ntp = corrmo[&#39;motion_corrected&#39;].shape[3]
  fmri_template = ants.get_average_of_timeseries( corrmo[&#39;motion_corrected&#39;] )
  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
  if plot_brain_mask:
    ants.plot( fmri_template, bmask, axis=1, crop=True )
    ants.plot( fmri_template, bmask, axis=2, crop=True )

  if tc == &#39;alternating&#39;:
      tclist = replicate_list( [&#39;C&#39;,&#39;T&#39;], ntp )
  else:
      tclist = replicate_list( [&#39;C&#39;], int(ntp/2) ) + replicate_list( [&#39;T&#39;],  int(ntp/2) )

  tclist = one_hot_encode( tclist[0:ntp ] )
  fmrimotcorr=corrmo[&#39;motion_corrected&#39;]
  hlinds = None
  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    fmrimotcorr, hlinds = loop_timeseries_censoring( fmrimotcorr, outlier_threshold, mask=None, verbose=verbose )
    tclist = remove_elements_from_numpy_array( tclist, hlinds)
    corrmo[&#39;FD&#39;] = remove_elements_from_numpy_array( corrmo[&#39;FD&#39;], hlinds )

  # redo template and registration at (potentially) upsampled scale
  fmri_template = ants.iMath( ants.get_average_of_timeseries( fmrimotcorr ), &#34;Normalize&#34; )
  corrmo = timeseries_reg(
        fmri, fmri_template,
        type_of_transform=&#39;Rigid&#39;,
        total_sigma=perf_total_sigma,
        fdOffset=2.0,
        trim = mytrim,
        output_directory=None,
        verbose=verbose,
        syn_metric=&#39;cc&#39;,
        syn_sampling=2,
        reg_iterations=[40,20,5] )
  if verbose:
        print(&#34;End 2nd rsfmri motion correction&#34;)

  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    corrmo[&#39;motion_corrected&#39;] = remove_volumes_from_timeseries( corrmo[&#39;motion_corrected&#39;], hlinds )
    corrmo[&#39;FD&#39;] = remove_elements_from_numpy_array( corrmo[&#39;FD&#39;], hlinds )

  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
  if plot_brain_mask:
    ants.plot( fmri_template, bmask, axis=1, crop=True )
    ants.plot( fmri_template, bmask, axis=2, crop=True )

  regression_mask = bmask.clone()
  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,3)
  bmask = bmask * ants.iMath( tsnrmask, &#34;FillHoles&#34; )
  fmrimotcorr=corrmo[&#39;motion_corrected&#39;]
  und = fmri_template * bmask
  compcorquantile=0.50
  mycompcor = ants.compcor( fmrimotcorr,
    ncompcor=nc, quantile=compcorquantile, mask = bmask,
    filter_type=&#39;polynomial&#39;, degree=2 )
  tr = ants.get_spacing( fmrimotcorr )[3]
  simg = ants.smooth_image(fmrimotcorr, spa, sigma_in_physical_coordinates = True )
  nuisance = mycompcor[&#39;basis&#39;]
  nuisance = np.c_[ nuisance, mycompcor[&#39;components&#39;] ]
  if verbose:
    print(&#34;make sure nuisance is independent of TC&#34;)
  nuisance = ants.regress_components( nuisance, tclist )
  regression_mask = bmask.clone()
  gmmat = ants.timeseries_to_matrix( simg, regression_mask )
  regvars = np.hstack( (nuisance, tclist ))
  coefind = regvars.shape[1]-1
  regvars = regvars[:,range(coefind)]
  predictor_of_interest_idx = regvars.shape[1]-1
  valid_perf_models = [&#39;huber&#39;,&#39;quantile&#39;,&#39;theilsen&#39;,&#39;ransac&#39;, &#39;sgd&#39;, &#39;linear&#39;,&#39;SM&#39;]
  perfusion_regression_model=&#39;linear&#39;
  if verbose:
    print( &#34;begin perfusion estimation with &#34; + perfusion_regression_model + &#34; model &#34; )
  regression_model = LinearRegression()
  regression_model.fit( regvars, gmmat )
  coefind = regression_model.coef_.shape[1]-1
  perfimg = ants.make_image( regression_mask, regression_model.coef_[:,coefind] )
  gmseg = ants.image_clone( bmask )
  meangmval = ( perfimg[ gmseg == 1 ] ).mean()
  if meangmval &lt; 0:
      perfimg = perfimg * (-1.0)
  negative_voxels = ( perfimg &lt; 0.0 ).sum() / np.prod( perfimg.shape ) * 100.0
  perfimg[ perfimg &lt; 0.0 ] = 0.0 # non-physiological

  if m0_image is None:
    m0 = ants.get_average_of_timeseries( fmrimotcorr )
  else:
    # register m0 to current template
    m0reg = ants.registration( fmri_template, m0, &#39;Rigid&#39;, verbose=False )
    m0 = m0reg[&#39;warpedmovout&#39;]

  if ntp == 2 :
      img0 = ants.slice_image( corrmo[&#39;motion_corrected&#39;], axis=3, idx=0 )
      img1 = ants.slice_image( corrmo[&#39;motion_corrected&#39;], axis=3, idx=1 )
      if m0_image is None:
        if img0.mean() &lt; img1.mean():
            perfimg=img0
            m0=img1
        else:
            perfimg=img1
            m0=img0
      else:
        if img0.mean() &lt; img1.mean():
            perfimg=img1-img0
        else:
            perfimg=img0-img1
  
  cbf = calculate_CBF( Delta_M=perfimg, M_0=m0, mask=bmask )
  meangmval = ( perfimg[ gmseg == 1 ] ).mean()        
  meangmvalcbf = ( cbf[ gmseg == 1 ] ).mean()
  if verbose:
    print(&#34;perfimg.max() &#34; + str(  perfimg.max() ) )
  outdict = {}
  outdict[&#39;meanBold&#39;] = und
  outdict[&#39;brainmask&#39;] = bmask
  rsfNuisance = pd.DataFrame( nuisance )
  rsfNuisance[&#39;FD&#39;]=corrmo[&#39;FD&#39;]
  outdict[&#39;perfusion&#39;]=perfimg
  outdict[&#39;cbf&#39;]=cbf
  outdict[&#39;m0&#39;]=m0
  outdict[&#39;perfusion_gm_mean&#39;]=meangmval
  outdict[&#39;cbf_gm_mean&#39;]=meangmvalcbf
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;brain_mask&#39;] = bmask
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;FD_max&#39;] = rsfNuisance[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = rsfNuisance[&#39;FD&#39;].mean()
  outdict[&#39;FD_sd&#39;] = rsfNuisance[&#39;FD&#39;].std()
  outdict[&#39;outlier_volumes&#39;]=hlinds
  outdict[&#39;negative_voxels&#39;]=negative_voxels
  return convert_np_in_dict( outdict )


def bold_perfusion( fmri, t1head, t1, t1segmentation, t1dktcit,
                   FD_threshold=0.5,
                   spa = (0., 0., 0., 0.),
                   nc = 3,
                   type_of_transform=&#39;Rigid&#39;,
                   tc=&#39;alternating&#39;,
                   n_to_trim=0,
                   m0_image = None,
                   m0_indices=None,
                   outlier_threshold=0.250,
                   add_FD_to_nuisance=False,
                   n3=False,
                   segment_timeseries=False,
                   trim_the_mask=4.25,
                   upsample=True,
                   perfusion_regression_model=&#39;linear&#39;,
                   verbose=False ):
  &#34;&#34;&#34;
  Estimate perfusion from a BOLD time series image.  Will attempt to figure out the T-C labels from the data.  The function uses defaults to quantify CBF but these will usually not be correct for your own data.  See the function calculate_CBF for an example of how one might do quantification based on the outputs of this function specifically the perfusion, m0 and mask images that are part of the output dictionary.

  Arguments
  ---------
  fmri : BOLD fmri antsImage

  fmri_template : reference space for BOLD

  t1head : ANTsImage
    input 3-D T1 brain image (not brain extracted)

  t1 : ANTsImage
    input 3-D T1 brain image (brain extracted)

  t1segmentation : ANTsImage
    t1 segmentation - a six tissue segmentation image in T1 space

  t1dktcit : ANTsImage
    t1 dkt cortex plus cit parcellation

  spa : gaussian smoothing for spatial and temporal component e.g. (1,1,1,0) in physical space coordinates

  nc  : number of components for compcor filtering

  type_of_transform : SyN or Rigid

  tc: string either alternating or split (default is alternating ie CTCTCT; split is CCCCTTTT)

  n_to_trim: number of volumes to trim off the front of the time series to account for initial magnetic saturation effects or to allow the signal to reach a steady state. in some cases, trailing volumes or other outlier volumes may need to be rejected.  this code does not currently handle that issue.

  m0_image: a pre-defined m0 image - we expect this to be 3D.  if it is not, we naively 
    average over the 4th dimension.

  m0_indices: which indices in the perfusion image are the m0.  if set, n_to_trim will be ignored.

  outlier_threshold (numeric): between zero (remove all) and one (remove none); automatically calculates outlierness and uses it to censor the time series.

  add_FD_to_nuisance: boolean

  n3: boolean

  segment_timeseries : boolean

  trim_the_mask : float &gt;= 0 post-hoc method for trimming the mask

  upsample: boolean

  perfusion_regression_model: string &#39;linear&#39;, &#39;ransac&#39;, &#39;theilsen&#39;, &#39;huber&#39;, &#39;quantile&#39;, &#39;sgd&#39;; &#39;linear&#39; and &#39;huber&#39; are the only ones that work ok by default and are relatively quick to compute.

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  &#34;&#34;&#34;
  import numpy as np
  import pandas as pd
  import re
  import math
  from sklearn.linear_model import RANSACRegressor, TheilSenRegressor, HuberRegressor, QuantileRegressor, LinearRegression, SGDRegressor
  from sklearn.multioutput import MultiOutputRegressor
  from sklearn.preprocessing import StandardScaler

  # remove outlier volumes
  if segment_timeseries:
    lo_vs_high = segment_timeseries_by_meanvalue(fmri)
    fmri = remove_volumes_from_timeseries( fmri, lo_vs_high[&#39;lowermeans&#39;] )

  ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
  cnxcsvfn = ex_path + &#34;dkt_cortex_cit_deep_brain.csv&#34;

  if n3:
    fmri = timeseries_n3( fmri )

  if m0_image is not None:
    if m0_image.dimension == 4:
      m0_image = ants.get_average_of_timeseries( m0_image )

  def select_regression_model(regression_model, min_samples=10 ):
    if regression_model == &#39;sgd&#39; :
      sgd_regressor = SGDRegressor(penalty=&#39;elasticnet&#39;, alpha=1e-5, l1_ratio=0.15, max_iter=20000, tol=1e-3, random_state=42)
      return sgd_regressor
    elif regression_model == &#39;ransac&#39;:
      ransac = RANSACRegressor(
            min_samples=0.8,
            max_trials=10,         # Maximum number of iterations
#            min_samples=min_samples, # Minimum number samples to be chosen as inliers in each iteration
#            stop_probability=0.80,  # Probability to stop the algorithm if a good subset is found
#            stop_n_inliers=40,      # Stop if this number of inliers is found
#            stop_score=0.8,         # Stop if the model score reaches this value
#            n_jobs=int(os.getenv(&#34;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#34;)) # Use all available CPU cores for parallel processing
        )
      return ransac
    models = {
        &#39;sgd&#39;:SGDRegressor,
        &#39;ransac&#39;: RANSACRegressor,
        &#39;theilsen&#39;: TheilSenRegressor,
        &#39;huber&#39;: HuberRegressor,
        &#39;quantile&#39;: QuantileRegressor
    }
    return models.get(regression_model.lower(), LinearRegression)()

  def replicate_list(user_list, target_size):
    # Calculate the number of times the list should be replicated
    replication_factor = target_size // len(user_list)
    # Replicate the list and handle any remaining elements
    replicated_list = user_list * replication_factor
    remaining_elements = target_size % len(user_list)
    replicated_list += user_list[:remaining_elements]
    return replicated_list

  def one_hot_encode(char_list):
    unique_chars = list(set(char_list))
    encoding_dict = {char: [1 if char == c else 0 for c in unique_chars] for char in unique_chars}
    encoded_matrix = np.array([encoding_dict[char] for char in char_list])
    return encoded_matrix
  
  A = np.zeros((1,1))
  # fmri = ants.iMath( fmri, &#39;Normalize&#39; )
  fmri_template, hlinds = loop_timeseries_censoring( fmri, 0.10 )
  fmri_template = ants.get_average_of_timeseries( fmri_template )
  del hlinds
  rig = ants.registration( fmri_template, t1head, &#39;BOLDRigid&#39; )
  bmask = ants.apply_transforms( fmri_template, ants.threshold_image(t1segmentation,1,6), rig[&#39;fwdtransforms&#39;][0], interpolator=&#39;genericLabel&#39; )
  if m0_indices is None:
    if n_to_trim is None:
        n_to_trim=0
    mytrim=n_to_trim
  else:
    mytrim = 0
  perf_total_sigma = 1.5
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=type_of_transform,
    total_sigma=perf_total_sigma,
    fdOffset=2.0,
    trim = mytrim,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5] )
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)

  if m0_image is not None:
      m0 = m0_image
  elif m0_indices is not None:
    not_m0 = list( range( fmri.shape[3] ) )
    not_m0 = [x for x in not_m0 if x not in m0_indices]
    if verbose:
        print( m0_indices )
        print( not_m0 )
    # then remove it from the time series
    m0 = remove_volumes_from_timeseries( corrmo[&#39;motion_corrected&#39;], not_m0 )
    m0 = ants.get_average_of_timeseries( m0 )
    corrmo[&#39;motion_corrected&#39;] = remove_volumes_from_timeseries( 
        corrmo[&#39;motion_corrected&#39;], m0_indices )
    corrmo[&#39;FD&#39;] = remove_elements_from_numpy_array( corrmo[&#39;FD&#39;], m0_indices )
    fmri = remove_volumes_from_timeseries( fmri, m0_indices )

  ntp = corrmo[&#39;motion_corrected&#39;].shape[3]
  if tc == &#39;alternating&#39;:
      tclist = replicate_list( [&#39;C&#39;,&#39;T&#39;], ntp )
  else:
      tclist = replicate_list( [&#39;C&#39;], int(ntp/2) ) + replicate_list( [&#39;T&#39;],  int(ntp/2) )

  tclist = one_hot_encode( tclist[0:ntp ] )
  fmrimotcorr=corrmo[&#39;motion_corrected&#39;]
  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    fmrimotcorr, hlinds = loop_timeseries_censoring( fmrimotcorr, outlier_threshold, mask=None, verbose=verbose )
    tclist = remove_elements_from_numpy_array( tclist, hlinds)
    corrmo[&#39;FD&#39;] = remove_elements_from_numpy_array( corrmo[&#39;FD&#39;], hlinds )

  # redo template and registration at (potentially) upsampled scale
  fmri_template = ants.iMath( ants.get_average_of_timeseries( fmrimotcorr ), &#34;Normalize&#34; )
  if upsample:
      spc = ants.get_spacing( fmri )
      minspc = 2.0
      if min(spc[0:3]) &lt; minspc:
          minspc = min(spc[0:3])
      newspc = [minspc,minspc,minspc]
      fmri_template = ants.resample_image( fmri_template, newspc, interp_type=0 )

  rig = ants.registration( fmri_template, t1head, &#39;BOLDRigid&#39; )
  bmask = ants.apply_transforms( fmri_template, 
    ants.threshold_image(t1segmentation,1,6), 
    rig[&#39;fwdtransforms&#39;][0], 
    interpolator=&#39;genericLabel&#39; )
  corrmo = timeseries_reg(
        fmri, fmri_template,
        type_of_transform=type_of_transform,
        total_sigma=perf_total_sigma,
        fdOffset=2.0,
        trim = mytrim,
        output_directory=None,
        verbose=verbose,
        syn_metric=&#39;cc&#39;,
        syn_sampling=2,
        reg_iterations=[40,20,5] )
  if verbose:
        print(&#34;End 2nd rsfmri motion correction&#34;)

  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    corrmo[&#39;motion_corrected&#39;] = remove_volumes_from_timeseries( corrmo[&#39;motion_corrected&#39;], hlinds )
    corrmo[&#39;FD&#39;] = remove_elements_from_numpy_array( corrmo[&#39;FD&#39;], hlinds )

  regression_mask = bmask.clone()
  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,3)
  bmask = bmask * ants.iMath( tsnrmask, &#34;FillHoles&#34; )
  fmrimotcorr=corrmo[&#39;motion_corrected&#39;]
  und = fmri_template * bmask
  t1reg = ants.registration( und, t1, &#34;SyNBold&#34; )
  gmseg = ants.threshold_image( t1segmentation, 2, 2 )
  gmseg = gmseg + ants.threshold_image( t1segmentation, 4, 4 )
  gmseg = ants.threshold_image( gmseg, 1, 4 )
  gmseg = ants.iMath( gmseg, &#39;MD&#39;, 1 )
  gmseg = ants.apply_transforms( und, gmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;genericLabel&#39; ) * bmask
  csfseg = ants.threshold_image( t1segmentation, 1, 1 )
  wmseg = ants.threshold_image( t1segmentation, 3, 3 )
  csfAndWM = ( csfseg + wmseg ).morphology(&#34;erode&#34;,1)
  csfAndWM = ants.apply_transforms( und, csfAndWM,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  csfseg = ants.apply_transforms( und, csfseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  wmseg = ants.apply_transforms( und, wmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  compcorquantile=0.50
  mycompcor = ants.compcor( fmrimotcorr,
    ncompcor=nc, quantile=compcorquantile, mask = csfAndWM,
    filter_type=&#39;polynomial&#39;, degree=2 )
  tr = ants.get_spacing( fmrimotcorr )[3]
  simg = ants.smooth_image(fmrimotcorr, spa, sigma_in_physical_coordinates = True )
  nuisance = mycompcor[&#39;basis&#39;]
  nuisance = np.c_[ nuisance, mycompcor[&#39;components&#39;] ]
  if add_FD_to_nuisance:
    nuisance = np.c_[ nuisance, corrmo[&#39;FD&#39;] ]
  if verbose:
    print(&#34;make sure nuisance is independent of TC&#34;)
  nuisance = ants.regress_components( nuisance, tclist )
  regression_mask = bmask.clone()
  gmmat = ants.timeseries_to_matrix( simg, regression_mask )
  regvars = np.hstack( (nuisance, tclist ))
  coefind = regvars.shape[1]-1
  regvars = regvars[:,range(coefind)]
  predictor_of_interest_idx = regvars.shape[1]-1
  valid_perf_models = [&#39;huber&#39;,&#39;quantile&#39;,&#39;theilsen&#39;,&#39;ransac&#39;, &#39;sgd&#39;, &#39;linear&#39;,&#39;SM&#39;]
  if verbose:
    print( &#34;begin perfusion estimation with &#34; + perfusion_regression_model + &#34; model &#34; )
  if perfusion_regression_model == &#39;linear&#39;:
    regression_model = LinearRegression()
    regression_model.fit( regvars, gmmat )
    coefind = regression_model.coef_.shape[1]-1
    perfimg = ants.make_image( regression_mask, regression_model.coef_[:,coefind] )
  elif perfusion_regression_model == &#39;SM&#39;: #
    import statsmodels.api as sm
    coeffs = np.zeros( gmmat.shape[1] )
    # Loop over each outcome column in the outcomes matrix
    for outcome_idx in range(gmmat.shape[1]):
        outcome = gmmat[:, outcome_idx]  # Select one outcome column
        model = sm.RLM(outcome, sm.add_constant(regvars), M=sm.robust.norms.HuberT())  # Huber&#39;s T norm for robust regression
        results = model.fit()
        coefficients = results.params  # Coefficients of all predictors
        coeffs[outcome_idx] = coefficients[predictor_of_interest_idx]
    perfimg = ants.make_image( regression_mask, coeffs )
  elif perfusion_regression_model in valid_perf_models :
    scaler = StandardScaler()
    gmmat = scaler.fit_transform(gmmat)
    coeffs = np.zeros( gmmat.shape[1] )
    huber_regressor = select_regression_model( perfusion_regression_model )
    multioutput_model = MultiOutputRegressor(huber_regressor)
    multioutput_model.fit( regvars, gmmat )
    ct=0
    for i, estimator in enumerate(multioutput_model.estimators_):
      coefficients = estimator.coef_
      coeffs[ct]=coefficients[predictor_of_interest_idx]
      ct=ct+1
    perfimg = ants.make_image( regression_mask, coeffs )
  else:
    raise ValueError( perfusion_regression_model + &#34; regression model is not found.&#34;)
  meangmval = ( perfimg[ gmseg == 1 ] ).mean()
  if meangmval &lt; 0:
      perfimg = perfimg * (-1.0)
  negative_voxels = ( perfimg &lt; 0.0 ).sum() / np.prod( perfimg.shape ) * 100.0
  perfimg[ perfimg &lt; 0.0 ] = 0.0 # non-physiological

  # LaTeX code for Cerebral Blood Flow (CBF) calculation using ASL MRI
  &#34;&#34;&#34;
CBF = \\frac{\\Delta M \\cdot \\lambda}{2 \\cdot T_1 \\cdot \\alpha \\cdot M_0 \\cdot (e^{-\\frac{w}{T_1}} - e^{-\\frac{w + \\tau}{T_1}})}

Where:
- \\Delta M is the difference in magnetization between labeled and control images.
- \\lambda is the brain-blood partition coefficient, typically around 0.9 mL/g.
- T_1 is the longitudinal relaxation time of blood, which is a tissue-specific constant.
- \\alpha is the labeling efficiency.
- M_0 is the equilibrium magnetization of brain tissue (from the M0 image).
- w is the post-labeling delay, the time between the end of the labeling and the acquisition of the image.
- \\tau is the labeling duration.
  &#34;&#34;&#34;
  if m0_indices is None and m0_image is None:
    m0 = ants.get_average_of_timeseries( fmrimotcorr )
  else:
    # register m0 to current template
    m0reg = ants.registration( fmri_template, m0, &#39;Rigid&#39;, verbose=False )
    m0 = m0reg[&#39;warpedmovout&#39;]

  if ntp == 2 :
      img0 = ants.slice_image( corrmo[&#39;motion_corrected&#39;], axis=3, idx=0 )
      img1 = ants.slice_image( corrmo[&#39;motion_corrected&#39;], axis=3, idx=1 )
      if m0_image is None:
        if img0.mean() &lt; img1.mean():
            perfimg=img0
            m0=img1
        else:
            perfimg=img1
            m0=img0
      else:
        if img0.mean() &lt; img1.mean():
            perfimg=img1-img0
        else:
            perfimg=img0-img1

  cbf = calculate_CBF(
      Delta_M=perfimg, M_0=m0, mask=bmask )
  if trim_the_mask &gt; 0.0 :
    bmask = trim_dti_mask( cbf, bmask, trim_the_mask )
    perfimg = perfimg * bmask
    cbf = cbf * bmask

  meangmval = ( perfimg[ gmseg == 1 ] ).mean()        
  meangmvalcbf = ( cbf[ gmseg == 1 ] ).mean()
  if verbose:
    print(&#34;perfimg.max() &#34; + str(  perfimg.max() ) )
  outdict = {}
  outdict[&#39;meanBold&#39;] = und
  outdict[&#39;brainmask&#39;] = bmask
  rsfNuisance = pd.DataFrame( nuisance )
  rsfNuisance[&#39;FD&#39;]=corrmo[&#39;FD&#39;]

  if verbose:
      print(&#34;perfusion dataframe begin&#34;)
  dktseg = ants.apply_transforms( und, t1dktcit,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;genericLabel&#39; ) * bmask
  df_perf = antspyt1w.map_intensity_to_dataframe(
        &#39;dkt_cortex_cit_deep_brain&#39;,
        perfimg,
        dktseg)
  df_perf = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;perf&#39; : df_perf},
              col_names = [&#39;Mean&#39;] )
  df_cbf = antspyt1w.map_intensity_to_dataframe(
        &#39;dkt_cortex_cit_deep_brain&#39;,
        cbf,
        dktseg)
  df_cbf = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;cbf&#39; : df_cbf},
              col_names = [&#39;Mean&#39;] )
  df_cbf = df_cbf.add_prefix(&#39;cbf_&#39;)
  df_perf = pd.concat( [df_perf,df_cbf], axis=1, ignore_index=False )
  if verbose:
      print(&#34;perfusion dataframe end&#34;)

  outdict[&#39;perfusion&#39;]=perfimg
  outdict[&#39;cbf&#39;]=cbf
  outdict[&#39;m0&#39;]=m0
  outdict[&#39;perfusion_gm_mean&#39;]=meangmval
  outdict[&#39;cbf_gm_mean&#39;]=meangmvalcbf
  outdict[&#39;perf_dataframe&#39;]=df_perf
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;gmseg&#39;] = gmseg
  outdict[&#39;brain_mask&#39;] = bmask
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;ssnr&#39;] = slice_snr( corrmo[&#39;motion_corrected&#39;], csfAndWM, gmseg )
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;high_motion_count&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum()
  outdict[&#39;high_motion_pct&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum() / rsfNuisance.shape[0]
  outdict[&#39;FD_max&#39;] = rsfNuisance[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = rsfNuisance[&#39;FD&#39;].mean()
  outdict[&#39;FD_sd&#39;] = rsfNuisance[&#39;FD&#39;].std()
  outdict[&#39;bold_evr&#39;] =  antspyt1w.patch_eigenvalue_ratio( und, 512, [16,16,16], evdepth = 0.9, mask = bmask )
  outdict[&#39;t1reg&#39;] = t1reg
  outdict[&#39;outlier_volumes&#39;]=hlinds
  outdict[&#39;n_outliers&#39;]=len(hlinds)
  outdict[&#39;negative_voxels&#39;]=negative_voxels
  return convert_np_in_dict( outdict )


def write_bvals_bvecs(bvals, bvecs, prefix ):
    &#39;&#39;&#39; Write FSL FDT bvals and bvecs files

    adapted from dipy.external code

    Parameters
    -------------
    bvals : (N,) sequence
       Vector with diffusion gradient strength (one per diffusion
       acquisition, N=no of acquisitions)
    bvecs : (N, 3) array-like
       diffusion gradient directions
    prefix : string
       path to write FDT bvals, bvecs text files
       None results in current working directory.
    &#39;&#39;&#39;
    _VAL_FMT = &#39;   %e&#39;
    bvals = tuple(bvals)
    bvecs = np.asarray(bvecs)
    bvecs[np.isnan(bvecs)] = 0
    N = len(bvals)
    fname = prefix + &#39;.bval&#39;
    fmt = _VAL_FMT * N + &#39;\n&#39;
    myfile = open(fname, &#39;wt&#39;)
    myfile.write(fmt % bvals)
    myfile.close()
    fname = prefix + &#39;.bvec&#39;
    bvf = open(fname, &#39;wt&#39;)
    for dim_vals in bvecs.T:
        bvf.write(fmt % tuple(dim_vals))
    bvf.close()
    

def crop_mcimage( x, mask, padder=None ):
    &#34;&#34;&#34;
    crop a time series (4D) image by a 3D mask

    Parameters
    -------------

    x : raw image

    mask  : mask for cropping

    &#34;&#34;&#34;
    cropmask = ants.crop_image( mask, mask )
    myorig = list( ants.get_origin(cropmask) )
    myorig.append( ants.get_origin( x )[3] )
    croplist = []
    if len(x.shape) &gt; 3:
        for k in range(x.shape[3]):
            temp = ants.slice_image( x, axis=3, idx=k )
            temp = ants.crop_image( temp, mask )
            if padder is not None:
                temp = ants.pad_image( temp, pad_width=padder )
            croplist.append( temp )
        temp = ants.list_to_ndimage( x, croplist )
        temp.set_origin( myorig )
        return temp
    else:
        return( ants.crop_image( x, mask ) )


def mm(
    t1_image,
    hier,
    rsf_image=[],
    flair_image=None,
    nm_image_list=None,
    dw_image=[], bvals=[], bvecs=[],
    perfusion_image=None,
    srmodel=None,
    do_tractography = False,
    do_kk = False,
    do_normalization = None,
    group_template = None,
    group_transform = None,
    target_range = [0,1],
    dti_motion_correct = &#39;Rigid&#39;,
    dti_denoise = False,
    perfusion_trim=10,
    perfusion_m0_image=None,
    perfusion_m0=None,
    rsf_upsampling=3.0,
    test_run = False,
    verbose = False ):
    &#34;&#34;&#34;
    Multiple modality processing and normalization

    aggregates modality-specific processing under one roof.  see individual
    modality specific functions for details.

    Parameters
    -------------

    t1_image : raw t1 image

    hier  : output of antspyt1w.hierarchical ( see read hierarchical )

    rsf_image : list of resting state fmri

    flair_image : flair

    nm_image_list : list of neuromelanin images

    dw_image : list of diffusion weighted images

    bvals : list of bvals file names

    bvecs : list of bvecs file names

    perfusion_image : single perfusion image

    srmodel : optional srmodel

    do_tractography : boolean

    do_kk : boolean to control whether we compute kelly kapowski thickness image (slow)

    do_normalization : template transformation if available

    group_template : optional reference template corresponding to the group_transform

    group_transform : optional transforms corresponding to the group_template

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.
    
    dti_motion_correct : None Rigid or SyN

    dti_denoise : boolean

    perfusion_trim : optional integer number of time volumes to exclude from the front of the perfusion time series

    perfusion_m0_image : optional antsImage m0 associated with the perfusion time series

    perfusion_m0 : optional list containing indices of the m0 in the perfusion time series

    rsf_upsampling : optional upsampling parameter value in mm; if set to zero, no upsampling is done

    test_run : boolean 

    verbose : boolean

    &#34;&#34;&#34;
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_path_mm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    mycsvfn = ex_path + &#34;FA_JHU_labels_edited.csv&#34;
    citcsvfn = ex_path + &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad.csv&#34;
    dktcsvfn = ex_path + &#34;dkt.csv&#34;
    cnxcsvfn = ex_path + &#34;dkt_cortex_cit_deep_brain.csv&#34;
    JHU_atlasfn = ex_path + &#39;JHU-ICBM-FA-1mm.nii.gz&#39; # Read in JHU atlas
    JHU_labelsfn = ex_path + &#39;JHU-ICBM-labels-1mm.nii.gz&#39; # Read in JHU labels
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( mycsvfn ) or not exists( citcsvfn ) or not exists( cnxcsvfn ) or not exists( dktcsvfn ) or not exists( JHU_atlasfn ) or not exists( JHU_labelsfn ) or not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        raise ValueError(&#39;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#39;)
    mycsv = pd.read_csv(  mycsvfn )
    citcsv = pd.read_csv(  os.path.expanduser( citcsvfn ) )
    dktcsv = pd.read_csv(  os.path.expanduser( dktcsvfn ) )
    cnxcsv = pd.read_csv(  os.path.expanduser( cnxcsvfn ) )
    JHU_atlas = mm_read( JHU_atlasfn ) # Read in JHU atlas
    JHU_labels = mm_read( JHU_labelsfn ) # Read in JHU labels
    template = mm_read( templatefn ) # Read in template
    if group_template is None:
        group_template = template
        group_transform = do_normalization[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;Using group template:&#34;)
        print( group_template )
    #####################
    #  T1 hierarchical  #
    #####################
    t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
    t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    output_dict = {
        &#39;kk&#39;: None,
        &#39;rsf&#39;: None,
        &#39;flair&#39; : None,
        &#39;NM&#39; : None,
        &#39;DTI&#39; : None,
        &#39;FA_summ&#39; : None,
        &#39;MD_summ&#39; : None,
        &#39;tractography&#39; : None,
        &#39;tractography_connectivity&#39; : None,
        &#39;perf&#39; : None,
    }
    normalization_dict = {
        &#39;kk_norm&#39;: None,
        &#39;NM_norm&#39; : None,
        &#39;DTI_norm&#39;: None,
        &#39;FA_norm&#39; : None,
        &#39;MD_norm&#39; : None,
        &#39;perf_norm&#39; : None,
        &#39;alff_norm&#39; : None,
        &#39;falff_norm&#39; : None,
        &#39;CinguloopercularTaskControl_norm&#39; : None,
        &#39;DefaultMode_norm&#39; : None,
        &#39;MemoryRetrieval_norm&#39; : None,
        &#39;VentralAttention_norm&#39; : None,
        &#39;Visual_norm&#39; : None,
        &#39;FrontoparietalTaskControl_norm&#39; : None,
        &#39;Salience_norm&#39; : None,
        &#39;Subcortical_norm&#39; : None,
        &#39;DorsalAttention_norm&#39; : None
    }
    if test_run:
        return output_dict, normalization_dict

    if do_kk:
        if verbose:
            print(&#39;kk&#39;)
        output_dict[&#39;kk&#39;] = antspyt1w.kelly_kapowski_thickness( hier[&#39;brain_n4_dnz&#39;],
            labels=hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], iterations=45 )
    if  perfusion_image is not None:
        if perfusion_image.shape[3] &gt; 1: # FIXME - better heuristic?
            output_dict[&#39;perf&#39;] = bold_perfusion(
                perfusion_image,
                t1_image,
                hier[&#39;brain_n4_dnz&#39;],
                t1atropos,
                hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] + hier[&#39;cit168lab&#39;],
                n_to_trim = perfusion_trim,
                m0_image = perfusion_m0_image,
                m0_indices = perfusion_m0,
                verbose=verbose )
    ################################## do the rsf .....
    if len(rsf_image) &gt; 0:
        my_motion_tx = &#39;Rigid&#39;
        rsf_image = [i for i in rsf_image if i is not None]
        if verbose:
            print(&#39;rsf length &#39; + str( len( rsf_image ) ) )
        if len( rsf_image ) &gt;= 2: # assume 2 is the largest possible value
            rsf_image1 = rsf_image[0]
            rsf_image2 = rsf_image[1]
            # build a template then join the images
            if verbose:
                print(&#34;initial average for rsf&#34;)
            rsfavg1, hlinds = loop_timeseries_censoring( rsf_image1, 0.1 )
            rsfavg1=get_average_rsf(rsfavg1)
            rsfavg2, hlinds = loop_timeseries_censoring( rsf_image2, 0.1 )
            rsfavg2=get_average_rsf(rsfavg2)
            if verbose:
                print(&#34;template average for rsf&#34;)
            init_temp = ants.image_clone( rsfavg1 )
            if rsf_image1.shape[3] &lt; rsf_image2.shape[3]:
                init_temp = ants.image_clone( rsfavg2 )
            boldTemplate = ants.build_template(
                initial_template = init_temp,
                image_list=[rsfavg1,rsfavg2],
                iterations=5, verbose=False )
            if verbose:
                print(&#34;join the 2 rsf&#34;)
            if rsf_image1.shape[3] &gt; 10 and rsf_image2.shape[3] &gt; 10:
                leadvols = list(range(8))
                rsf_image2 = remove_volumes_from_timeseries( rsf_image2, leadvols )
                rsf_image = merge_timeseries_data( rsf_image1, rsf_image2 )
            elif rsf_image1.shape[3] &gt; rsf_image2.shape[3]:
                rsf_image = rsf_image1
            else:
                rsf_image = rsf_image2
        elif len( rsf_image ) == 1:
            rsf_image = rsf_image[0]
            boldTemplate, hlinds = loop_timeseries_censoring( rsf_image, 0.1 )
            boldTemplate = get_average_rsf(boldTemplate)
        if rsf_image.shape[3] &gt; 10: # FIXME - better heuristic?
            rsfprolist = [] # FIXMERSF
            # Create the parameter DataFrame
            df = pd.DataFrame({
                &#34;num&#34;: [134, 122, 129],
                &#34;loop&#34;: [0.50, 0.25, 0.50],
                &#34;cens&#34;: [True, True, True],
                &#34;HM&#34;: [1.0, 5.0, 0.5],
                &#34;ff&#34;: [&#34;tight&#34;, &#34;tight&#34;, &#34;tight&#34;],
                &#34;CC&#34;: [5, 5, 0.8],
                &#34;imp&#34;: [True, True, True],
                &#34;up&#34;: [rsf_upsampling, rsf_upsampling, rsf_upsampling],
                &#34;coords&#34;: [False,False,False]
            }, index=[0, 1, 2])
            for p in range(df.shape[0]):
                if verbose:
                    print(&#34;rsf parameters&#34;)
                    print( df.iloc[p] )
                if df[&#39;ff&#39;].iloc[p] == &#39;broad&#39;:
                    f=[ 0.008, 0.15 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;tight&#39;:
                    f=[ 0.03, 0.08 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;mid&#39;:
                    f=[ 0.01, 0.1 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;mid2&#39;:
                    f=[ 0.01, 0.08 ]
                else:
                    raise ValueError(&#34;we do not recognize this parameter choice for frequency filtering: &#34; + df[&#39;ff&#39;].iloc[p] )
                HM = df[&#39;HM&#39;].iloc[p]
                CC = df[&#39;CC&#39;].iloc[p]
                loop= df[&#39;loop&#39;].iloc[p]
                cens =df[&#39;cens&#39;].iloc[p]
                imp = df[&#39;imp&#39;].iloc[p]
                rsf0 = resting_state_fmri_networks(
                                            rsf_image,
                                            boldTemplate,
                                            hier[&#39;brain_n4_dnz&#39;],
                                            t1atropos,
                                            f=f,
                                            FD_threshold=HM, 
                                            spa = None, 
                                            spt = None, 
                                            nc = CC,
                                            outlier_threshold=loop,
                                            ica_components = 0,
                                            impute = imp,
                                            censor = cens,
                                            despike = 2.5,
                                            motion_as_nuisance = True,
                                            upsample=df[&#39;up&#39;].iloc[p],
                                            clean_tmp=0.66,
                                            paramset=df[&#39;num&#39;].iloc[p],
                                            powers=df[&#39;coords&#39;].iloc[p],
                                            verbose=verbose ) # default
                rsfprolist.append( rsf0 )
            output_dict[&#39;rsf&#39;] = rsfprolist
            if False:  # this is the old parameter search stuff
                # Initialize the parameters DataFrame
                # first - no censoring - just explore compcor
                df = pd.DataFrame()
                cens=False
                HM=1.0 # best by PTBP
                hmsearch = [0.5, 1.0, 5.0 ]
                loopsearch = [ 0.25, 0.5, 0.75, 1.0 ]
                loop = 1.0
                CCsearch = [ 5, 0.80 ]
                defaultf = [ 0.008, 0.15 ]
                freqsearch = [&#39;broad&#39;,&#39;mid&#39;,&#39;tight&#39;] # 
                # for debuggin
                # rsf_image = remove_volumes_from_timeseries( rsf_image, list(range(80,2000))) 
                docens=True                     # explore censoring
                for ff in freqsearch:
                    for CC in CCsearch:
                        local_df = pd.DataFrame({&#34;loop&#34;: [loop], &#34;cens&#34;: [cens], &#34;HM&#34;: [HM], &#34;ff&#34;: [ff], &#34;CC&#34;: [CC]})
                        if verbose:
                            print( local_df )
                        if df.shape[0] == 0:
                            df = local_df
                        else:
                            df = pd.concat([df, local_df], ignore_index=True)
                        f = defaultf
                        if ff == &#39;mid&#39;:
                            f = [0.01,0.1]
                        elif ff == &#39;tight&#39;:
                            f = [0.03,0.08]
                        rsf0 = resting_state_fmri_networks(
                            rsf_image, boldTemplate, hier[&#39;brain_n4_dnz&#39;], t1atropos,
                            f=f,
                            FD_threshold=HM,
                            spa = None, spt = None, 
                            nc = CC, 
                            outlier_threshold=loop,
                            ica_components = 0,
                            impute = False,
                            censor = cens,
                            despike = 2.5,
                            motion_as_nuisance = True,
                            upsample=False,
                            clean_tmp=0.66,
                            verbose=verbose ) # default
                        rsfprolist.append( rsf0 )

                # test impact of censoring
                if docens:
                    cens = True
                    for loop in loopsearch:
                        for HM in hmsearch:
                            for ff in freqsearch:
                                for CC in CCsearch:
                                    local_df = pd.DataFrame({&#34;loop&#34;: [loop], &#34;cens&#34;: [cens], &#34;HM&#34;: [HM], &#34;ff&#34;: [ff], &#34;CC&#34;: [CC]})
                                    if verbose:
                                        print( local_df )
                                    df = pd.concat([df, local_df], ignore_index=True)
                                    f = defaultf
                                    if ff == &#39;mid&#39;:
                                        f = [0.01,0.1]
                                    elif ff == &#39;tight&#39;:
                                        f = [0.03,0.08]
                                    rsf0 = resting_state_fmri_networks(
                                            rsf_image,
                                            boldTemplate,
                                            hier[&#39;brain_n4_dnz&#39;],
                                            t1atropos,
                                            f=f,
                                            FD_threshold=HM, 
                                            spa = None, 
                                            spt = None, 
                                            nc = CC,
                                            outlier_threshold=loop,
                                            ica_components = 0,
                                            impute = False,
                                            censor = cens,
                                            despike = 2.5,
                                            motion_as_nuisance = True,
                                            upsample=False,
                                            clean_tmp=0.66,
                                            verbose=verbose ) # default
                                    rsfprolist.append( rsf0 )
                output_dict[&#39;rsf&#39;] = rsfprolist
    if nm_image_list is not None:
        if verbose:
            print(&#39;nm&#39;)
        if srmodel is None:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], verbose=verbose )
        else:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], srmodel=srmodel, target_range=target_range, verbose=verbose  )
################################## do the dti .....
    if len(dw_image) &gt; 0 :
        if verbose:
            print(&#39;dti-x&#39;)
        if len( dw_image ) == 1: # use T1 for distortion correction and brain extraction
            if verbose:
                print(&#34;We have only one DTI: &#34; + str(len(dw_image)))
            dw_image = dw_image[0]
            btpB0,btpDW=get_average_dwi_b0(dw_image)
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            btpDW = ants.apply_transforms( btpDW, btpDW,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            btpB0 = ants.apply_transforms( btpB0, btpB0,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;nearestNeighbor&#39;)
            # dwimask = ants.iMath(dwimask,&#39;MD&#39;,1)
            t12dwi = ants.apply_transforms( btpDW, hier[&#39;brain_n4_dnz&#39;], tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;linear&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image,
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                motion_correct=dti_motion_correct, # set to False if using input from qsiprep
                denoise=dti_denoise,
                verbose = verbose)
        else :  # use phase encoding acquisitions for distortion correction and T1 for brain extraction
            if verbose:
                print(&#34;We have both DTI_LR and DTI_RL: &#34; + str(len(dw_image)))
            a1b,a1w=get_average_dwi_b0(dw_image[0])
            a2b,a2w=get_average_dwi_b0(dw_image[1],fixed_b0=a1b,fixed_dwi=a1w)
            btpB0, btpDW = dti_template(
                b_image_list=[a1b,a2b],
                w_image_list=[a1w,a2w],
                iterations=7, verbose=verbose )
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image[0],
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                img_RL=dw_image[1],
                bval_RL=bvals[1],
                bvec_RL=bvecs[1],
                motion_correct=&#39;SyN&#39;, # set to False if using input from qsiprep
                denoise=True,
                verbose = verbose)
        mydti = output_dict[&#39;DTI&#39;]
        # summarize dwi with T1 outputs
        # first - register ....
        reg = ants.registration( mydti[&#39;recon_fa&#39;], hier[&#39;brain_n4_dnz&#39;], &#39;SyNBold&#39;, total_sigma=1.0 )
        ##################################################
        output_dict[&#39;FA_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_fa&#39;],
            hier=hier,
            modality_name=&#39;fa&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        ##################################################
        output_dict[&#39;MD_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_md&#39;],
            hier=hier,
            modality_name=&#39;md&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        # these inputs should come from nicely processed data
        dktmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        citmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;cit168lab&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        dktmapped[ citmapped &gt; 0]=0
        mask = ants.threshold_image( mydti[&#39;recon_fa&#39;], 0.01, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
        if do_tractography: # dwi_deterministic_tracking dwi_closest_peak_tracking
            output_dict[&#39;tractography&#39;] = dwi_deterministic_tracking(
                mydti[&#39;dwi_LR_dewarped&#39;],
                mydti[&#39;recon_fa&#39;],
                mydti[&#39;bval_LR&#39;],
                mydti[&#39;bvec_LR&#39;],
                seed_density = 1,
                mask=mask,
                verbose = verbose )
            mystr = output_dict[&#39;tractography&#39;]
            output_dict[&#39;tractography_connectivity&#39;] = dwi_streamline_connectivity( mystr[&#39;streamlines&#39;], dktmapped+citmapped, cnxcsv, verbose=verbose )
    ################################## do the flair .....
    if flair_image is not None:
        if verbose:
            print(&#39;flair&#39;)
        wmhprior = None
        priorfn = ex_path_mm + &#39;CIT168_wmhprior_700um_pad_adni.nii.gz&#39;
        if ( exists( priorfn ) ):
            wmhprior = ants.image_read( priorfn )
            wmhprior = ants.apply_transforms( t1_image, wmhprior, do_normalization[&#39;invtransforms&#39;] )
        output_dict[&#39;flair&#39;] = boot_wmh( flair_image, t1_image, t1atropos,
            prior_probability=wmhprior, verbose=verbose )
    #################################################################
    ### NOTES: deforming to a common space and writing out images ###
    ### images we want come from: DTI, NM, rsf, thickness ###########
    #################################################################
    if do_normalization is not None:
        if verbose:
            print(&#39;normalization&#39;)
        # might reconsider this template space - cropped and/or higher res?
        # template = ants.resample_image( template, [1,1,1], use_voxels=False )
        # t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;], &#34;antsRegistrationSyNQuickRepro[s]&#34;)
        t1reg = do_normalization
        if do_kk:
            normalization_dict[&#39;kk_norm&#39;] = ants.apply_transforms( group_template, output_dict[&#39;kk&#39;][&#39;thickness_image&#39;], group_transform )
        if output_dict[&#39;DTI&#39;] is not None:
            mydti = output_dict[&#39;DTI&#39;]
            dtirig = ants.registration( hier[&#39;brain_n4_dnz&#39;], mydti[&#39;recon_fa&#39;], &#39;Rigid&#39; )
            normalization_dict[&#39;MD_norm&#39;] = ants.apply_transforms( group_template, mydti[&#39;recon_md&#39;],group_transform+dtirig[&#39;fwdtransforms&#39;] )
            normalization_dict[&#39;FA_norm&#39;] = ants.apply_transforms( group_template, mydti[&#39;recon_fa&#39;],group_transform+dtirig[&#39;fwdtransforms&#39;] )
            output_directory = tempfile.mkdtemp()
            do_dti_norm=False
            if do_dti_norm:
                comptx = ants.apply_transforms( group_template, group_template, group_transform+dtirig[&#39;fwdtransforms&#39;], compose = output_directory + &#39;/xxx&#39; )
                tspc=[2.,2.,2.]
                if srmodel is not None:
                    tspc=[1.,1.,1.]
                group_template2mm = ants.resample_image( group_template, tspc  )
                normalization_dict[&#39;DTI_norm&#39;] = transform_and_reorient_dti( group_template2mm, mydti[&#39;dti&#39;], comptx, py_based=True, verbose=True )
            import shutil
            shutil.rmtree(output_directory, ignore_errors=True )
        if output_dict[&#39;rsf&#39;] is not None:
            if False:
                rsfpro = output_dict[&#39;rsf&#39;] # FIXME
                rsfrig = ants.registration( hier[&#39;brain_n4_dnz&#39;], rsfpro[&#39;meanBold&#39;], &#39;Rigid&#39; )
                for netid in get_antsimage_keys( rsfpro ):
                    rsfkey = netid + &#34;_norm&#34;
                    normalization_dict[rsfkey] = ants.apply_transforms(
                        group_template, rsfpro[netid],
                        group_transform+rsfrig[&#39;fwdtransforms&#39;] )
        if output_dict[&#39;perf&#39;] is not None: # zizzer
            comptx = group_transform + output_dict[&#39;perf&#39;][&#39;t1reg&#39;][&#39;invtransforms&#39;]
            normalization_dict[&#39;perf_norm&#39;] = ants.apply_transforms( group_template,
                output_dict[&#39;perf&#39;][&#39;perfusion&#39;], comptx,
                whichtoinvert=[False,False,True,False] )
            normalization_dict[&#39;cbf_norm&#39;] = ants.apply_transforms( group_template,
                output_dict[&#39;perf&#39;][&#39;cbf&#39;], comptx,
                whichtoinvert=[False,False,True,False] )
        if nm_image_list is not None:
            nmpro = output_dict[&#39;NM&#39;]
            nmrig = nmpro[&#39;t1_to_NM_transform&#39;] # this is an inverse tx
            normalization_dict[&#39;NM_norm&#39;] = ants.apply_transforms( group_template, nmpro[&#39;NM_avg&#39;], group_transform+nmrig,
                whichtoinvert=[False,False,True])

    if verbose:
        print(&#39;mm done&#39;)
    return output_dict, normalization_dict


def write_mm( output_prefix, mm, mm_norm=None, t1wide=None, separator=&#39;_&#39;, verbose=False ):
    &#34;&#34;&#34;
    write the tabular and normalization output of the mm function

    Parameters
    -------------

    output_prefix : prefix for file outputs - modality specific postfix will be added

    mm  : output of mm function for modality-space processing should be a dictionary with 
        dictionary entries for each modality.

    mm_norm : output of mm function for normalized processing

    t1wide : wide output data frame from t1 hierarchical

    separator : string or character separator for filenames

    verbose : boolean

    Returns
    ---------

    both csv and image files written to disk.  the primary outputs will be
    output_prefix + separator + &#39;mmwide.csv&#39; and *norm.nii.gz images

    &#34;&#34;&#34;
    from dipy.io.streamline import save_tractogram
    if mm_norm is not None:
        for mykey in mm_norm:
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            if mm_norm[mykey] is not None:
                image_write_with_thumbnail( mm_norm[mykey], tempfn )
    thkderk = None
    if t1wide is not None:
        thkderk = t1wide.iloc[: , 1:]
    kkderk = None
    if &#39;kk&#39; in mm:
        if mm[&#39;kk&#39;] is not None:
            kkderk = mm[&#39;kk&#39;][&#39;thickness_dataframe&#39;].iloc[: , 1:]
            mykey=&#39;thickness_image&#39;
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( mm[&#39;kk&#39;][mykey], tempfn )
    nmderk = None
    if &#39;NM&#39; in mm:
        if mm[&#39;NM&#39;] is not None:
            nmderk = mm[&#39;NM&#39;][&#39;NM_dataframe_wide&#39;].iloc[: , 1:]
            for mykey in get_antsimage_keys( mm[&#39;NM&#39;] ):
                tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
                image_write_with_thumbnail( mm[&#39;NM&#39;][mykey], tempfn, thumb=False )

    faderk = mdderk = fat1derk = mdt1derk = None

    if &#39;DTI&#39; in mm:
        if mm[&#39;DTI&#39;] is not None:
            mydti = mm[&#39;DTI&#39;]
            myop = output_prefix + separator
            ants.image_write( mydti[&#39;dti&#39;],  myop + &#39;dti.nii.gz&#39; )
            write_bvals_bvecs( mydti[&#39;bval_LR&#39;], mydti[&#39;bvec_LR&#39;], myop + &#39;reoriented&#39; )
            image_write_with_thumbnail( mydti[&#39;dwi_LR_dewarped&#39;],  myop + &#39;dwi.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;dtrecon_LR_dewarp&#39;][&#39;RGB&#39;] ,  myop + &#39;DTIRGB.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;jhu_labels&#39;],  myop+&#39;dtijhulabels.nii.gz&#39;, mydti[&#39;recon_fa&#39;] )
            image_write_with_thumbnail( mydti[&#39;recon_fa&#39;],  myop+&#39;dtifa.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;recon_md&#39;],  myop+&#39;dtimd.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;b0avg&#39;],  myop+&#39;b0avg.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;dwiavg&#39;],  myop+&#39;dwiavg.nii.gz&#39; )
            faderk = mm[&#39;DTI&#39;][&#39;recon_fa_summary&#39;].iloc[: , 1:]
            mdderk = mm[&#39;DTI&#39;][&#39;recon_md_summary&#39;].iloc[: , 1:]
            fat1derk = mm[&#39;FA_summ&#39;].iloc[: , 1:]
            mdt1derk = mm[&#39;MD_summ&#39;].iloc[: , 1:]
    if &#39;tractography&#39; in mm:
        if mm[&#39;tractography&#39;] is not None:
            ofn = output_prefix + separator + &#39;tractogram.trk&#39;
            save_tractogram( mm[&#39;tractography&#39;][&#39;tractogram&#39;], ofn )
    cnxderk = None
    if &#39;tractography_connectivity&#39; in mm:
        if mm[&#39;tractography_connectivity&#39;] is not None:
            cnxderk = mm[&#39;tractography_connectivity&#39;][&#39;connectivity_wide&#39;].iloc[: , 1:] # NOTE: connectivity_wide is not much tested
            ofn = output_prefix + separator + &#39;dtistreamlineconn.csv&#39;
            pd.DataFrame(mm[&#39;tractography_connectivity&#39;][&#39;connectivity_matrix&#39;]).to_csv( ofn )

    dlist = [
        thkderk,
        kkderk,
        nmderk,
        faderk,
        mdderk,
        fat1derk,
        mdt1derk,
        cnxderk
        ]
    is_all_none = all(element is None for element in dlist)
    if is_all_none:
        mm_wide = pd.DataFrame({&#39;u_hier_id&#39;: [output_prefix] })
    else:
        mm_wide = pd.concat( dlist, axis=1, ignore_index=False )

    mm_wide = mm_wide.copy()
    if &#39;NM&#39; in mm:
        if mm[&#39;NM&#39;] is not None:
            nmwide = dict_to_dataframe( mm[&#39;NM&#39;] )
            if mm_wide.shape[0] &gt; 0 and nmwide.shape[0] &gt; 0:
                nmwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, nmwide ], axis=1, ignore_index=False )
    if &#39;flair&#39; in mm:
        if mm[&#39;flair&#39;] is not None:
            myop = output_prefix + separator + &#39;wmh.nii.gz&#39;
            pngfnb = output_prefix + separator + &#39;wmh_seg.png&#39;
            ants.plot( mm[&#39;flair&#39;][&#39;flair&#39;], mm[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;], axis=2, nslices=21, ncol=7, filename=pngfnb, crop=True )
            if mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;] is not None:
                image_write_with_thumbnail( mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;], myop, thumb=False )
            flwide = dict_to_dataframe( mm[&#39;flair&#39;] )
            if mm_wide.shape[0] &gt; 0 and flwide.shape[0] &gt; 0:
                flwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, flwide ], axis=1, ignore_index=False )
    if &#39;rsf&#39; in mm:
        if mm[&#39;rsf&#39;] is not None:
            fcnxpro=99
            rsfdata = mm[&#39;rsf&#39;]
            if not isinstance( rsfdata, list ):
                rsfdata = [ rsfdata ]
            for rsfpro in rsfdata:
                fcnxpro=str( rsfpro[&#39;paramset&#39;]  )
                pronum = &#39;fcnxpro&#39;+str(fcnxpro)+&#34;_&#34;
                if verbose:
                    print(&#34;Collect rsf data &#34; + pronum)
                new_rsf_wide = dict_to_dataframe( rsfpro )
                new_rsf_wide = pd.concat( [new_rsf_wide, rsfpro[&#39;corr_wide&#39;] ], axis=1, ignore_index=False )
                new_rsf_wide = new_rsf_wide.add_prefix( pronum )
                new_rsf_wide.set_index( mm_wide.index, inplace=True )
                ofn = output_prefix + separator + pronum + &#39;.csv&#39;
                new_rsf_wide.to_csv( ofn )
                mm_wide = pd.concat( [mm_wide, new_rsf_wide ], axis=1, ignore_index=False )
                for mykey in get_antsimage_keys( rsfpro ):
                    myop = output_prefix + separator + pronum + mykey + &#39;.nii.gz&#39;
                    image_write_with_thumbnail( rsfpro[mykey], myop, thumb=True )
                ofn = output_prefix + separator + pronum + &#39;rsfcorr.csv&#39;
                rsfpro[&#39;corr&#39;].to_csv( ofn )
                # apply same principle to new correlation matrix, doesn&#39;t need to be incorporated with mm_wide
                ofn2 = output_prefix + separator + pronum + &#39;nodescorr.csv&#39;
                rsfpro[&#39;fullCorrMat&#39;].to_csv( ofn2 )
    if &#39;DTI&#39; in mm:
        if mm[&#39;DTI&#39;] is not None:
            mydti = mm[&#39;DTI&#39;]
            mm_wide[&#39;dti_tsnr_b0_mean&#39;] =  mydti[&#39;tsnr_b0&#39;].mean()
            mm_wide[&#39;dti_tsnr_dwi_mean&#39;] =  mydti[&#39;tsnr_dwi&#39;].mean()
            mm_wide[&#39;dti_dvars_b0_mean&#39;] =  mydti[&#39;dvars_b0&#39;].mean()
            mm_wide[&#39;dti_dvars_dwi_mean&#39;] =  mydti[&#39;dvars_dwi&#39;].mean()
            mm_wide[&#39;dti_ssnr_b0_mean&#39;] =  mydti[&#39;ssnr_b0&#39;].mean()
            mm_wide[&#39;dti_ssnr_dwi_mean&#39;] =  mydti[&#39;ssnr_dwi&#39;].mean()
            mm_wide[&#39;dti_fa_evr&#39;] =  mydti[&#39;fa_evr&#39;]
            mm_wide[&#39;dti_fa_SNR&#39;] =  mydti[&#39;fa_SNR&#39;]
            if mydti[&#39;framewise_displacement&#39;] is not None:
                mm_wide[&#39;dti_high_motion_count&#39;] =  mydti[&#39;high_motion_count&#39;]
                mm_wide[&#39;dti_FD_mean&#39;] = mydti[&#39;framewise_displacement&#39;].mean()
                mm_wide[&#39;dti_FD_max&#39;] = mydti[&#39;framewise_displacement&#39;].max()
                mm_wide[&#39;dti_FD_sd&#39;] = mydti[&#39;framewise_displacement&#39;].std()
                fdfn = output_prefix + separator + &#39;_fd.csv&#39;
            else:
                mm_wide[&#39;dti_FD_mean&#39;] = mm_wide[&#39;dti_FD_max&#39;] = mm_wide[&#39;dti_FD_sd&#39;] = &#39;NA&#39;

    if &#39;perf&#39; in mm:
        if mm[&#39;perf&#39;] is not None:
            perfpro = mm[&#39;perf&#39;]
            prwide = dict_to_dataframe( perfpro )
            if mm_wide.shape[0] &gt; 0 and prwide.shape[0] &gt; 0:
                prwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, prwide ], axis=1, ignore_index=False )
            if &#39;perf_dataframe&#39; in perfpro.keys():
                pderk = perfpro[&#39;perf_dataframe&#39;].iloc[: , 1:]
                pderk.set_index( mm_wide.index, inplace=True )
                mm_wide = pd.concat( [ mm_wide, pderk ], axis=1, ignore_index=False )
            else:
                print(&#34;FIXME - perfusion dataframe&#34;)
            for mykey in get_antsimage_keys( mm[&#39;perf&#39;] ):
                tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
                image_write_with_thumbnail( mm[&#39;perf&#39;][mykey], tempfn, thumb=False )

    mmwidefn = output_prefix + separator + &#39;mmwide.csv&#39;
    mm_wide.to_csv( mmwidefn )
    if verbose:
        print( output_prefix + &#34; write_mm done.&#34; )
    return


def mm_nrg(
    studyid,   # pandas data frame
    sourcedir = os.path.expanduser( &#34;~/data/PPMI/MV/example_s3_b/images/PPMI/&#34; ),
    sourcedatafoldername = &#39;images&#39;, # root for source data
    processDir = &#34;processed&#34;, # where output will go - parallel to sourcedatafoldername
    mysep = &#39;-&#39;, # define a separator for filename components
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    visualize = True,
    nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;DTI&#34;,&#34;T2Flair&#34;, &#34;rsfMRI&#34; ],
    verbose = True
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function assumes NRG format for the input data ....
    we also assume that t1w hierarchical (if already done) was written
    via its standardized write function.
    NRG = https://github.com/stnava/biomedicalDataOrganization

    this function is verbose

    Parameters
    -------------

    studyid : must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required.  rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.  see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    sourcedatafoldername : root for source data e.g. &#34;images&#34;

    processDir : where output will go - parallel to sourcedatafoldername e.g.
        &#34;processed&#34;

    mysep : define a character separator for filename components

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    visualize : True - will plot some results to png

    nrg_modality_list : list of permissible modalities - always include [T1w] as base

    verbose : boolean

    Returns
    ---------

    writes output to disk and potentially produces figures that may be
    captured in a ipynb / html file.

    &#34;&#34;&#34;
    studyid = studyid.dropna(axis=1)
    if studyid.shape[0] &lt; 1:
        raise ValueError(&#39;studyid has no rows&#39;)
    musthavecols = [&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studyid.keys():
            raise ValueError(&#39;studyid is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = &#39;-&#39; ):
        return x + separator + &#39;mmwide.csv&#39;
    if nrg_modality_list[0] != &#39;T1w&#39;:
        nrg_modality_list.insert(0, &#34;T1w&#34; )
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studyid
    sid = str(studyid[&#39;subjectID&#39;].iloc[0])
    dtid = str(studyid[&#39;date&#39;].iloc[0])
    iid = str(studyid[&#39;imageID&#39;].iloc[0])
    subjectrootpath = os.path.join(sourcedir,sid, dtid)
    if verbose:
        print(&#34;subjectrootpath: &#34;+ subjectrootpath )
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, iid, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + iid + &#39; @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    hierfn0 = re.sub( sourcedatafoldername, processDir, t1fn)
    hierfn0 = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfn0)
    hierfn = re.sub( &#34;T1w&#34;, &#34;T1wHierarchical&#34;, hierfn0)
    hierfn = hierfn + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    regout = hierfn0 + mysep + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;-&lt;REGISTRATION EXISTENCE&gt;-: \n&#34; + 
              &#34;NAMING: &#34; + regout+&#39;0GenericAffine.mat&#39; + &#34; \n &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfnSR = re.sub( sourcedatafoldername, processDir, t1fn)
        hierfnSR = re.sub( &#34;T1w&#34;, &#34;T1wHierarchicalSR&#34;, hierfnSR)
        hierfnSR = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfnSR)
        hierfnSR = hierfnSR + mysep
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    nimages = len(myimgsInput)
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.&#34;)
    for overmodX in nrg_modality_list:
        counter=counter+1
        if counter &gt; (len(nrg_modality_list)+1):
            print(&#34;This is weird. &#34; + str(counter))
            return
        if overmodX == &#39;T1w&#39;:
            iidOtherMod = iid
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        elif overmodX == &#39;NM2DMT&#39; and (&#39;nmid1&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;nmid1&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            for nmnum in range(2,11):
                locnmnum = &#39;nmid&#39;+str(nmnum)
                if locnmnum in studyid.keys() :
                    iidOtherMod = str( int(studyid[locnmnum].iloc[0]) )
                    mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
                    myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;rsfMRI&#39; in overmodX and ( ( &#39;rsfid1&#39; in studyid.keys() ) or (&#39;rsfid2&#39; in studyid.keys() ) ):
            myimgsr = []
            if  &#39;rsfid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;rsfid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;DTI&#39; in overmodX and (  &#39;dtid1&#39; in studyid.keys() or  &#39;dtid2&#39; in studyid.keys() ):
            myimgsr = []
            if  &#39;dtid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;dtid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;T2Flair&#39; in overmodX and (&#39;flairid&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;flairid&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        if verbose:
            print( &#34;overmod &#34; + overmodX + &#34; &#34; + iidOtherMod )
            print(f&#34;modality search path: {mod_search_path}&#34;)
        myimgsr.sort()
        if len(myimgsr) &gt; 0:
            overmodXx = str(overmodX)
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodXx )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodXx == &#39;NM2DMT&#39;:
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                subjectpropath = os.path.dirname( myimgsr2[0] )
                subjectpropath = re.sub( sourcedatafoldername, processDir,subjectpropath )
                if verbose:
                    print( &#34;subjectpropath &#34; + subjectpropath )
                mysplit = subjectpropath.split( &#34;/&#34; )
                os.makedirs( subjectpropath, exist_ok=True  )
                mysplitCount = len( mysplit )
                project = mysplit[mysplitCount-5]
                subject = mysplit[mysplitCount-4]
                date = mysplit[mysplitCount-3]
                modality = mysplit[mysplitCount-2]
                uider = mysplit[mysplitCount-1]
                identifier = mysep.join([project, subject, date, modality ])
                identifier = identifier + &#34;_&#34; + iid
                mymm = subjectpropath + &#34;/&#34; + identifier
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount = 0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( myimg )
                        subjectpropath = re.sub( sourcedatafoldername, processDir, subjectpropath )
                        mysplit = subjectpropath.split(&#34;/&#34;)
                        mysplitCount = len( mysplit )
                        project = mysplit[mysplitCount-5]
                        date = mysplit[mysplitCount-4]
                        subject = mysplit[mysplitCount-3]
                        mymod = mysplit[mysplitCount-2] # FIXME system dependent
                        uid = mysplit[mysplitCount-1] # unique image id
                        os.makedirs( subjectpropath, exist_ok=True  )
                        if mymod == &#39;T1w&#39;:
                            identifier = mysep.join([project, date, subject, mymod, uid])
                        else:  # add the T1 unique id since that drives a lot of the analysis
                            identifier = mysep.join([project, date, subject, mymod, uid ])
                            identifier = identifier + &#34;_&#34; + iid
                        mymm = subjectpropath + &#34;/&#34; + identifier
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print(identifier)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    dfn=tabPro[&#39;rsf&#39;][&#39;dfnname&#39;]
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][dfn],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                dowrite=True
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if len( dtilrfn ) == 1:
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                srmodel_DTI_mdl=None
                                if srmodel_DTI is not False:
                                    temp = ants.get_spacing(img)
                                    dtspc=[temp[0],temp[1],temp[2]]
                                    bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                    if isinstance( srmodel_DTI, str ):
                                        srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                        mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                    if exists( mdlfn ):
                                        if verbose:
                                            print(mdlfn)
                                        srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                    else:
                                        print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                tabPro, normPro = mm( t1, hier,
                                    dw_image=imgList,
                                    bvals = bvalfnList,
                                    bvecs = bvecfnList,
                                    srmodel=srmodel_DTI_mdl,
                                    do_tractography=not test_run,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                mydti = tabPro[&#39;DTI&#39;]
                                if visualize:
                                    maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                    ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                    ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                    ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep, verbose=True )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize and normPro[mykey].components == 1 and False:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return



def mm_csv(
    studycsv,   # pandas data frame
    mysep = &#39;-&#39;, # or &#34;_&#34; for BIDS
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    dti_motion_correct = &#39;SyN&#39;,
    dti_denoise = True,
    nrg_modality_list = None,
    normalization_template = None,
    normalization_template_output = None,
    normalization_template_transform_type = &#34;antsRegistrationSyNRepro[s]&#34;,
    normalization_template_spacing=None,
    enantiomorphic=False,
    perfusion_trim = 10,
    perfusion_m0_image = None,
    perfusion_m0 = None,
    rsf_upsampling = 3.0
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function does not assume NRG format for the input data ....

    Parameters
    -------------

    studycsv : must have columns:
        - subjectID
        - date or session
        - imageID
        - modality
        - sourcedir
        - outputdir
        - filename (path to the t1 image)
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
        see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    outputdir : a study specific folder where individual output subject folders will go

    filename : the raw image filename (full path)

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    dti_motion_correct : None, Rigid or SyN

    dti_denoise : boolean

    nrg_modality_list : optional; defaults to None; use to focus on a given modality

    normalization_template : optional; defaults to None; if present, all images will
        be deformed into this space and the deformation will be stored with an extension
        related to this variable.  this should be a brain extracted T1w image.

    normalization_template_output : optional string; defaults to None; naming for the 
        normalization_template outputs which will be in the T1w directory.

    normalization_template_transform_type : optional string transform type passed to ants.registration

    normalization_template_spacing : 3-tuple controlling the resolution at which registration is computed 
    
    enantiomorphic: boolean (WIP)

    perfusion_trim : optional integer number of time volumes to exclude from the front of the perfusion time series

    perfusion_m0_image : optional m0 antsImage associated with the perfusion time series

    perfusion_m0 : optional list containing indices of the m0 in the perfusion time series

    rsf_upsampling : optional upsampling parameter value in mm; if set to zero, no upsampling is done

    Returns
    ---------

    writes output to disk and produces figures

    &#34;&#34;&#34;
    import traceback
    visualize = True
    verbose = True
    if verbose:
        print( version() )
    if nrg_modality_list is None:
        nrg_modality_list = get_valid_modalities()
    if studycsv.shape[0] &lt; 1:
        raise ValueError(&#39;studycsv has no rows&#39;)
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studycsv.keys():
            raise ValueError(&#39;studycsv is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = mysep ):
        return x + separator + &#39;mmwide.csv&#39;
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studycsv
    # musthavecols = [&#39;projectID&#39;,&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    projid = str(studycsv[&#39;projectID&#39;].iloc[0])
    sid = str(studycsv[&#39;subjectID&#39;].iloc[0])
    dtid = str(studycsv[&#39;date&#39;].iloc[0])
    iid = str(studycsv[&#39;imageID&#39;].iloc[0])
    t1iidUse=iid
    modality = str(studycsv[&#39;modality&#39;].iloc[0])
    sourcedir = str(studycsv[&#39;sourcedir&#39;].iloc[0])
    outputdir = str(studycsv[&#39;outputdir&#39;].iloc[0])
    filename = str(studycsv[&#39;filename&#39;].iloc[0])
    if not exists(filename):
            raise ValueError(&#39;mm_nrg cannot find filename &#39; + filename + &#39; in mm_csv&#39; )

    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1fn = filename
    if not exists( t1fn ):
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + t1fn )
    t1 = mm_read( t1fn, modality=&#39;T1w&#39; )
    minspc = np.min(ants.get_spacing(t1))
    minshape = np.min(t1.shape)
    if minspc &lt; 1e-16:
        warnings.warn(&#39;minimum spacing in T1w is too small - cannot process. &#39; + str(minspc) )
        return
    if minshape &lt; 32:
        warnings.warn(&#39;minimum shape in T1w is too small - cannot process. &#39; + str(minshape) )
        return

    if enantiomorphic:
        t1 = enantiomorphic_filling_without_mask( t1, axis=0 )[0]
    hierfn = outputdir + &#34;/&#34;  + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchical&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchical&#34; + mysep + iid + mysep
    hierfnSR = outputdir + &#34;/&#34; + projid + &#34;/&#34;  + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchicalSR&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchicalSR&#34; + mysep + iid + mysep
    hierfntest = hierfn + &#39;cerebellum.csv&#39;
    if verbose:
        print( hierfntest )
    regout = re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn) + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    groupTx = None
    # make the T1w directory
    os.makedirs( os.path.dirname(re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn)), exist_ok=True  )
    if normalization_template_output is not None:
        normout = re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn) +  normalization_template_output
        templateNormTx = {
            &#39;fwdtransforms&#39;: [ normout+&#39;1Warp.nii.gz&#39;, normout+&#39;0GenericAffine.mat&#39;],
            &#39;invtransforms&#39;: [ normout+&#39;0GenericAffine.mat&#39;, normout+&#39;1InverseWarp.nii.gz&#39;]  }
        groupTx = templateNormTx[&#39;fwdtransforms&#39;]
    if verbose:
        print( &#34;-&lt;REGISTRATION EXISTENCE&gt;-: \n&#34; + 
              &#34;NAMING: &#34; + regout+&#39;0GenericAffine.mat&#39; + &#34; \n &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) and exists( templateTx[&#39;fwdtransforms&#39;][0]) and exists( templateTx[&#39;fwdtransforms&#39;][1]) and exists( templateTx[&#39;invtransforms&#39;][0]) and exists( templateTx[&#39;invtransforms&#39;][1])
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if t1wide[&#39;resnetGrade&#39;].iloc[0] &lt; 0.35:
        rgrade = str( t1wide[&#39;resnetGrade&#39;].iloc[0] )
        warnings.warn(&#39;T1w quality check indicates failure: &#39; + rgrade + &#34; will not process.&#34; )
        return

    if srmodel_T1 is not False :
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]

    if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
        if verbose:
            print(&#39;start t1 registration&#39;)
        ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
        templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
        template = mm_read( templatefn )
        template = ants.resample_image( template, [1,1,1], use_voxels=False )
        t1reg = ants.registration( template, 
            hier[&#39;brain_n4_dnz&#39;],
            &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
        myjac = ants.create_jacobian_determinant_image( template,
            t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
        image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
        if visualize:
            ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
            ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )

    if normalization_template_output is not None and normalization_template is not None:
        if verbose:
            print(&#34;begin group template registration&#34;)
        if not exists( normout+&#39;0GenericAffine.mat&#39; ):
            if normalization_template_spacing is not None:
                normalization_template_rr=ants.resample_image(normalization_template,normalization_template_spacing)
            else:
                normalization_template_rr=normalization_template
            greg = ants.registration( 
                normalization_template_rr, 
                hier[&#39;brain_n4_dnz&#39;],
                normalization_template_transform_type,
                outprefix = normout, verbose=False )
            myjac = ants.create_jacobian_determinant_image( template,
                    greg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
            image_write_with_thumbnail( myjac, normout + &#34;logjacobian.nii.gz&#34;, thumb=False )
            if verbose:
                print(&#34;end group template registration&#34;)
        else:
            if verbose:
                print(&#34;group template registration already done&#34;)

    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    for overmodX in nrg_modality_list:
        # define 1. input images 2. output prefix
        mydoc = docsamson( overmodX, studycsv=studycsv, outputdir=outputdir, projid=projid, sid=sid, dtid=dtid, mysep=mysep,t1iid=t1iidUse )
        myimgsr = mydoc[&#39;images&#39;]
        mymm = mydoc[&#39;outprefix&#39;]
        mymod = mydoc[&#39;modality&#39;]
        if verbose:
            print( mydoc )
        if len(myimgsr) &gt; 0:
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodX )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodX == &#39;NM2DMT&#39;:
                subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                if verbose:
                    print(&#34;subjectpropath is&#34;)
                    print(subjectpropath)
                    os.makedirs( subjectpropath, exist_ok=True  )
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    try:
                        tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            group_template = normalization_template,
                            group_transform = groupTx,
                            test_run=test_run,
                            verbose=True )
                    except Exception as e:
                        error_info = traceback.format_exc()
                        print(error_info)
                        visualize=False
                        dowrite=False
                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                        pass
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount=0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                        if verbose:
                            print(&#34;subjectpropath is&#34;)
                            print(subjectpropath)
                        os.makedirs( subjectpropath, exist_ok=True  )
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            srmodel=None,
                                            do_tractography=False,
                                            do_kk=True,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3 and np.min(img.shape) &gt; 15:
                                dowrite=True
                                try:
                                    tabPro, normPro = mm( t1, hier,
                                        flair_image = img,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        group_template = normalization_template,
                                        group_transform = groupTx,
                                        test_run=test_run,
                                        verbose=True )
                                except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 or 1 in img2.shape:
                                        img2 = None
                                if 1 in img.shape:
                                    warnings.warn( &#39;rsfMRI image shape suggests it is an incorrectly converted mosaic image - will not process.&#39;)
                                    dowrite=False
                                    tabPro={&#39;rsf&#39;:None}
                                    normPro={&#39;rsf&#39;:None}
                                else:
                                    dowrite=True
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            rsf_image=[img,img2],
                                            srmodel=None,
                                            do_tractography=False,
                                            do_kk=False,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            rsf_upsampling = rsf_upsampling,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        tabPro={&#39;rsf&#39;:None}
                                        normPro={&#39;rsf&#39;:None}
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    for tpro in tabPro[&#39;rsf&#39;]: # FIXMERSF
                                        maxslice = np.min( [21, tpro[&#39;meanBold&#39;].shape[2] ] )
                                        tproprefix = mymm+mysep+str(tpro[&#39;paramset&#39;])+mysep
                                        ants.plot( tpro[&#39;meanBold&#39;],
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=tproprefix+&#34;meanBOLD.png&#34; )
                                        ants.plot( tpro[&#39;meanBold&#39;], ants.iMath(tpro[&#39;alff&#39;],&#34;Normalize&#34;),
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=tproprefix+&#34;boldALFF.png&#34; )
                                        ants.plot( tpro[&#39;meanBold&#39;], ants.iMath(tpro[&#39;falff&#39;],&#34;Normalize&#34;),
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=tproprefix+&#34;boldfALFF.png&#34; )
                                        dfn=tpro[&#39;dfnname&#39;]
                                        ants.plot( tpro[&#39;meanBold&#39;], tpro[dfn],
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=dfn, filename=tproprefix+&#34;boldDefaultMode.png&#34; )
                            if ( mymod == &#39;perf&#39; ) and ishapelen == 4:
                                dowrite=True
                                try:
                                    tabPro, normPro = mm( t1, hier,
                                        perfusion_image=img,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        group_template = normalization_template,
                                        group_transform = groupTx,
                                        test_run=test_run,
                                        perfusion_trim=perfusion_trim,
                                        perfusion_m0_image=perfusion_m0_image,
                                        perfusion_m0=perfusion_m0,
                                        verbose=True )
                                except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        tabPro={&#39;perf&#39;:None}
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if tabPro[&#39;perf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;perf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;perfusion&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;perfusion image&#39;, filename=mymm+mysep+&#34;perfusion.png&#34; )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;cbf&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;CBF image&#39;, filename=mymm+mysep+&#34;cbf.png&#34; )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;m0&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;M0 image&#39;, filename=mymm+mysep+&#34;m0.png&#34; )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                missing_dti_data=False # bval, bvec or images
                                if len( myimgsr ) == 2:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if exists( dtilrfn ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                elif len( myimgsr ) == 3:  # find DTI_RL
                                    print(&#34;DTI trinity&#34;)
                                    dtilrfn = myimgsr[myimgcount+1]
                                    dtilrfn2 = myimgsr[myimgcount+2]
                                    if exists( dtilrfn ) and exists( dtilrfn2 ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        bvalfnRL2 = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn2 )
                                        bvecfnRL2 = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn2 )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgRL2 = ants.image_read( dtilrfn2 )
                                        bvals, bvecs = read_bvals_bvecs( bvalfnRL , bvecfnRL  )
                                        print( bvals.max() )
                                        bvals2, bvecs2 = read_bvals_bvecs( bvalfnRL2 , bvecfnRL2  )
                                        print( bvals2.max() )
                                        temp = merge_dwi_data( imgRL, bvals, bvecs, imgRL2, bvals2, bvecs2  )
                                        imgList.append( temp[0] )
                                        bvalfnList.append( mymm+mysep+&#39;joined.bval&#39; )
                                        bvecfnList.append( mymm+mysep+&#39;joined.bvec&#39; )
                                        write_bvals_bvecs( temp[1], temp[2], mymm+mysep+&#39;joined&#39; )
                                        bvalsX, bvecsX = read_bvals_bvecs( bvalfnRL2 , bvecfnRL2  )
                                        print( bvalsX.max() )
                                # check existence of all files expected ...
                                for dtiex in bvalfnList+bvecfnList+myimgsr:
                                    if not exists(dtiex):
                                        print(&#39;mm_csv: missing dti data &#39; + dtiex )
                                        missing_dti_data=True
                                        dowrite=False
                                if not missing_dti_data:
                                    dowrite=True
                                    srmodel_DTI_mdl=None
                                    if srmodel_DTI is not False:
                                        temp = ants.get_spacing(img)
                                        dtspc=[temp[0],temp[1],temp[2]]
                                        bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                        mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                        if isinstance( srmodel_DTI, str ):
                                            srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                            mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                        if exists( mdlfn ):
                                            if verbose:
                                                print(mdlfn)
                                            srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                        else:
                                            print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            dw_image=imgList,
                                            bvals = bvalfnList,
                                            bvecs = bvecfnList,
                                            srmodel=srmodel_DTI_mdl,
                                            do_tractography=not test_run,
                                            do_kk=False,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            dti_motion_correct = dti_motion_correct,
                                            dti_denoise = dti_denoise,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                            error_info = traceback.format_exc()
                                            print(error_info)
                                            visualize=False
                                            dowrite=False
                                            tabPro={&#39;DTI&#39;:None}
                                            print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                            pass
                                    mydti = tabPro[&#39;DTI&#39;]
                                    if visualize and tabPro[&#39;DTI&#39;] is not None:
                                        maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                        ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                        ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                        ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None and normPro[mykey].components == 1:
                                        if visualize and False:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return

def spec_taper(x, p=0.1):
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    &#34;&#34;&#34;
    Computes a tapered version of x, with tapering p.

    Adapted from R&#39;s stats::spec.taper at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    &#34;&#34;&#34;

    p = np.r_[p]
    assert np.all((p &gt;= 0) &amp; (p &lt; 0.5)), &#34;&#39;p&#39; must be between 0 and 0.5&#34;

    x = np.r_[x].astype(&#39;float64&#39;)
    original_shape = x.shape

    assert len(original_shape) &lt;= 2, &#34;&#39;x&#39; must have at most 2 dimensions&#34;
    while len(x.shape) &lt; 2:
        x = np.expand_dims(x, axis=1)

    nr, nc = x.shape
    if len(p) == 1:
        p = p * np.ones(nc)
    else:
        assert len(p) == nc, &#34;length of &#39;p&#39; must be 1 or equal the number of columns of &#39;x&#39;&#34;

    for i in range(nc):
        m = int(np.floor(nr * p[i]))
        if m == 0:
            continue
        w = 0.5 * (1 - np.cos(np.pi * np.arange(1, 2 * m, step=2)/(2 * m)))
        x[:, i] = np.r_[w, np.ones(nr - 2 * m), w[::-1]] * x[:, i]

    x = np.reshape(x, original_shape)
    return x

def plot_spec(spec_res, coverage=None, ax=None, title=None):
    import matplotlib.pyplot as plt
    &#34;&#34;&#34;Convenience plotting method, also includes confidence cross in the same style as R.

    Note that the location of the cross is irrelevant; only width and height matter.&#34;&#34;&#34;
    f, Pxx = spec_res[&#39;freq&#39;], spec_res[&#39;spec&#39;]

    if coverage is not None:
        ci = spec_ci(spec_res[&#39;df&#39;], coverage=coverage)
        conf_x = (max(spec_res[&#39;freq&#39;]) - spec_res[&#39;bandwidth&#39;]) + np.r_[-0.5, 0.5] * spec_res[&#39;bandwidth&#39;]
        conf_y = max(spec_res[&#39;spec&#39;]) / ci[1]

    if ax is None:
        ax = plt.gca()

    ax.plot(f, Pxx, color=&#39;C0&#39;)
    ax.set_xlabel(&#39;Frequency&#39;)
    ax.set_ylabel(&#39;Log Spectrum&#39;)
    ax.set_yscale(&#39;log&#39;)
    if coverage is not None:
        ax.plot(np.mean(conf_x) * np.r_[1, 1], conf_y * ci, color=&#39;red&#39;)
        ax.plot(conf_x, np.mean(conf_y) * np.r_[1, 1], color=&#39;red&#39;)

    ax.set_title(spec_res[&#39;method&#39;] if title is None else title)

def spec_ci(df, coverage=0.95):
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    &#34;&#34;&#34;
    Computes the confidence interval for a spectral fit, based on the number of degrees of freedom.

    Adapted from R&#39;s stats::plot.spec at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    &#34;&#34;&#34;

    assert coverage &gt;= 0 and coverage &lt; 1, &#34;coverage probability out of range [0, 1)&#34;

    tail = 1 - coverage

    phi = stats.chi2.cdf(x=df, df=df)
    upper_quantile = 1 - tail * (1 - phi)
    lower_quantile = tail * phi

    return df / stats.chi2.ppf([upper_quantile, lower_quantile], df=df)

def spec_pgram(x, xfreq=1, spans=None, kernel=None, taper=0.1, pad=0, fast=True, demean=False, detrend=True,
               plot=True, **kwargs):
    &#34;&#34;&#34;
    Computes the spectral density estimate using a periodogram.  Optionally, it also:
    - Uses a provided kernel window, or a sequence of spans for convoluted modified Daniell kernels.
    - Tapers the start and end of the series to avoid end-of-signal effects.
    - Pads the provided series before computation, adding pad*(length of series) zeros at the end.
    - Pads the provided series before computation to speed up FFT calculation.
    - Performs demeaning or detrending on the series.
    - Plots results.

    Implemented to ensure compatibility with R&#39;s spectral functions, as opposed to reusing scipy&#39;s periodogram.

    Adapted from R&#39;s stats::spec.pgram at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    example:

    import numpy as np
    import antspymm
    myx = np.random.rand(100,1)
    myspec = antspymm.spec_pgram(myx,0.5)

    &#34;&#34;&#34;
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    def daniell_window_modified(m):
        &#34;&#34;&#34; Single-pass modified Daniell kernel window.

        Weight is normalized to add up to 1, and all values are the same, other than the first and the
        last, which are divided by 2.
        &#34;&#34;&#34;
        def w(k):
            return np.where(np.abs(k) &lt; m, 1 / (2*m), np.where(np.abs(k) == m, 1/(4*m), 0))

        return w(np.arange(-m, m+1))

    def daniell_window_convolve(v):
        &#34;&#34;&#34; Convolved version of multiple modified Daniell kernel windows.

        Parameter v should be an iterable of m values.
        &#34;&#34;&#34;

        if len(v) == 0:
            return np.r_[1]

        if len(v) == 1:
            return daniell_window_modified(v[0])

        return signal.convolve(daniell_window_modified(v[0]), daniell_window_convolve(v[1:]))

    # Ensure we can store non-integers in x, and that it is a numpy object
    x = np.r_[x].astype(&#39;float64&#39;)
    original_shape = x.shape

    # Ensure correct dimensions
    assert len(original_shape) &lt;= 2, &#34;&#39;x&#39; must have at most 2 dimensions&#34;
    while len(x.shape) &lt; 2:
        x = np.expand_dims(x, axis=1)

    N, nser = x.shape
    N0 = N

    # Ensure only one of spans, kernel is provided, and build the kernel window if needed
    assert (spans is None) or (kernel is None), &#34;must specify only one of &#39;spans&#39; or &#39;kernel&#39;&#34;
    if spans is not None:
        kernel = daniell_window_convolve(np.floor_divide(np.r_[spans], 2))

    # Detrend or demean the series
    if detrend:
        t = np.arange(N) - (N - 1)/2
        sumt2 = N * (N**2 - 1)/12
        x -= (np.repeat(np.expand_dims(np.mean(x, axis=0), 0), N, axis=0) + np.outer(np.sum(x.T * t, axis=1), t/sumt2).T)
    elif demean:
        x -= np.mean(x, axis=0)

    # Compute taper and taper adjustment variables
    x = spec_taper(x, taper)
    u2 = (1 - (5/8) * taper * 2)
    u4 = (1 - (93/128) * taper * 2)

    # Pad the series with copies of the same shape, but filled with zeroes
    if pad &gt; 0:
        x = np.r_[x, np.zeros((pad * x.shape[0], x.shape[1]))]
        N = x.shape[0]

    # Further pad the series to accelerate FFT computation
    if fast:
        newN = fft.next_fast_len(N, True)
        x = np.r_[x, np.zeros((newN - N, x.shape[1]))]
        N = newN

    # Compute the Fourier frequencies (R&#39;s spec.pgram convention style)
    Nspec = int(np.floor(N/2))
    freq = (np.arange(Nspec) + 1) * xfreq / N

    # Translations to keep same row / column convention as stats::mvfft
    xfft = fft.fft(x.T).T

    # Compute the periodogram for each i, j
    pgram = np.empty((N, nser, nser), dtype=&#39;complex&#39;)
    for i in range(nser):
        for j in range(nser):
            pgram[:, i, j] = xfft[:, i] * np.conj(xfft[:, j]) / (N0 * xfreq)
            pgram[0, i, j] = 0.5 * (pgram[1, i, j] + pgram[-1, i, j])

    if kernel is None:
        # Values pre-adjustment
        df = 2
        bandwidth = np.sqrt(1 / 12)
    else:
        def conv_circular(signal, kernel):
            &#34;&#34;&#34;
            Performs 1D circular convolution, in the same style as R::kernapply,
            assuming the kernel window is centered at 0.
            &#34;&#34;&#34;
            pad = len(signal) - len(kernel)
            half_window = int((len(kernel) + 1) / 2)
            indexes = range(-half_window, len(signal) - half_window)
            orig_conv = np.real(fft.ifft(fft.fft(signal) * fft.fft(np.r_[np.zeros(pad), kernel])))
            return orig_conv.take(indexes, mode=&#39;wrap&#39;)

        # Convolve pgram with kernel with circular conv
        for i in range(nser):
            for j in range(nser):
                pgram[:, i, j] = conv_circular(pgram[:, i, j], kernel)

        df = 2 / np.sum(kernel**2)
        m = (len(kernel) - 1)/2
        k = np.arange(-m, m+1)
        bandwidth = np.sqrt(np.sum((1/12 + k**2) * kernel))

    df = df/(u4/u2**2)*(N0/N)
    bandwidth = bandwidth * xfreq/N

    # Remove padded results
    pgram = pgram[1:(Nspec+1), :, :]

    spec = np.empty((Nspec, nser))
    for i in range(nser):
        spec[:, i] = np.real(pgram[:, i, i])

    if nser == 1:
        coh = None
        phase = None
    else:
        coh = np.empty((Nspec, int(nser * (nser - 1)/2)))
        phase = np.empty((Nspec, int(nser * (nser - 1)/2)))
        for i in range(nser):
            for j in range(i+1, nser):
                index = int(i + j*(j-1)/2)
                coh[:, index] = np.abs(pgram[:, i, j])**2 / (spec[:, i] * spec[:, j])
                phase[:, index] = np.angle(pgram[:, i, j])

    spec = spec / u2
    spec = spec.squeeze()

    results = {
        &#39;freq&#39;: freq,
        &#39;spec&#39;: spec,
        &#39;coh&#39;: coh,
        &#39;phase&#39;: phase,
        &#39;kernel&#39;: kernel,
        &#39;df&#39;: df,
        &#39;bandwidth&#39;: bandwidth,
        &#39;n.used&#39;: N,
        &#39;orig.n&#39;: N0,
        &#39;taper&#39;: taper,
        &#39;pad&#39;: pad,
        &#39;detrend&#39;: detrend,
        &#39;demean&#39;: demean,
        &#39;method&#39;: &#39;Raw Periodogram&#39; if kernel is None else &#39;Smoothed Periodogram&#39;
    }

    if plot:
        plot_spec(results, coverage=0.95, **kwargs)

    return results

def alffmap( x, flo=0.01, fhi=0.1, tr=1, detrend = True ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.
    same function in ANTsR.

    x input vector for the time series of interest
    flo low frequency, typically 0.01
    fhi high frequency, typically 0.1
    tr the period associated with the vector x (inverse of frequency)
    detrend detrend the input time series

    return vector is output showing ALFF and fALFF values
    &#34;&#34;&#34;
    temp = spec_pgram( x, xfreq=1.0/tr, demean=False, detrend=detrend, taper=0, fast=True, plot=False )
    fselect = np.logical_and( temp[&#39;freq&#39;] &gt;= flo, temp[&#39;freq&#39;] &lt;= fhi )
    denom = (temp[&#39;spec&#39;]).sum()
    numer = (temp[&#39;spec&#39;][fselect]).sum()
    return {  &#39;alff&#39;:numer, &#39;falff&#39;: numer/denom }


def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.

    x - input clean resting state fmri
    mask - mask over which to compute f/alff
    flo - low frequency, typically 0.01
    fhi - high frequency, typically 0.1
    nuisance - optional nuisance matrix

    return dictionary with ALFF and fALFF images
    &#34;&#34;&#34;
    xmat = ants.timeseries_to_matrix( x, mask )
    if nuisance is not None:
        xmat = ants.regress_components( xmat, nuisance )
    alffvec = xmat[0,:]*0
    falffvec = xmat[0,:]*0
    mytr = ants.get_spacing( x )[3]
    for n in range( xmat.shape[1] ):
        temp = alffmap( xmat[:,n], flo=flo, fhi=fhi, tr=mytr )
        alffvec[n]=temp[&#39;alff&#39;]
        falffvec[n]=temp[&#39;falff&#39;]
    alffi=ants.make_image( mask, alffvec )
    falffi=ants.make_image( mask, falffvec )
    alfftrimmedmean = calculate_trimmed_mean( alffvec, 0.01 )
    falfftrimmedmean = calculate_trimmed_mean( falffvec, 0.01 )
    alffi=alffi / alfftrimmedmean
    falffi=falffi / falfftrimmedmean
    return {  &#39;alff&#39;: alffi, &#39;falff&#39;: falffi }


def down2iso( x, interpolation=&#39;linear&#39;, takemin=False ):
    &#34;&#34;&#34;
    will downsample an anisotropic image to an isotropic resolution

    x: input image

    interpolation: linear or nearestneighbor

    takemin : boolean map to min space; otherwise max

    return image downsampled to isotropic resolution
    &#34;&#34;&#34;
    spc = ants.get_spacing( x )
    if takemin:
        newspc = np.asarray(spc).min()
    else:
        newspc = np.asarray(spc).max()
    newspc = np.repeat( newspc, x.dimension )
    if interpolation == &#39;linear&#39;:
        xs = ants.resample_image( x, newspc, interp_type=0)
    else:
        xs = ants.resample_image( x, newspc, interp_type=1)
    return xs


def read_mm_csv( x, is_t1=False, colprefix=None, separator=&#39;-&#39;, verbose=False ):
    splitter=os.path.basename(x).split( separator )
    lensplit = len( splitter )-1
    temp = os.path.basename(x)
    temp = os.path.splitext(temp)[0]
    temp = re.sub(separator+&#39;mmwide&#39;,&#39;&#39;,temp)
    idcols = [&#39;u_hier_id&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;mmimageuid&#39;,&#39;t1imageuid&#39;]
    df = pd.DataFrame( columns = idcols, index=range(1) )
    valstoadd = [temp] + splitter[1:(lensplit-1)]
    if is_t1:
        valstoadd = valstoadd + [splitter[(lensplit-1)],splitter[(lensplit-1)]]
    else:
        split2=splitter[(lensplit-1)].split( &#34;_&#34; )
        if len(split2) == 1:
            split2.append( split2[0] )
        if len(valstoadd) == 3:
            valstoadd = valstoadd + [split2[0]] + [math.nan] + [split2[1]]
        else:
            valstoadd = valstoadd + [split2[0],split2[1]]
    if verbose:
        print( valstoadd )
    df.iloc[0] = valstoadd
    if verbose:
        print( &#34;read xdf: &#34; + x )
    xdf = pd.read_csv( x )
    df.reset_index()
    xdf.reset_index(drop=True)
    if &#34;Unnamed: 0&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 0&#34; )
    if &#34;Unnamed: 1&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 1&#34; )
    if &#34;u_hier_id.1&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id.1&#34; )
    if &#34;u_hier_id&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id&#34; )
    if not is_t1:
        if &#39;resnetGrade&#39; in xdf.columns:
            index_no = xdf.columns.get_loc(&#39;resnetGrade&#39;)
            xdf = xdf.drop( xdf.columns[range(index_no+1)] , axis=1)

    if xdf.shape[0] == 2:
        xdfcols = xdf.columns
        xdf = xdf.iloc[1]
        ddnum = xdf.to_numpy()
        ddnum = ddnum.reshape([1,ddnum.shape[0]])
        newcolnames = xdf.index.to_list()
        if len(newcolnames) != ddnum.shape[1]:
            print(&#34;Cannot Merge : Shape MisMatch &#34; + str( len(newcolnames) ) + &#34; &#34; + str(ddnum.shape[1]))
        else:
            xdf = pd.DataFrame(ddnum, columns=xdfcols )
    if xdf.shape[1] == 0:
        return None
    if colprefix is not None:
        xdf.columns=colprefix + xdf.columns
    return pd.concat( [df,xdf], axis=1, ignore_index=False )

def merge_wides_to_study_dataframe( sdf, processing_dir, separator=&#39;-&#39;, sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False,
progress=False, verbose=False ):
    &#34;&#34;&#34;
    extend a study data frame with wide outputs

    sdf : the input study dataframe from antspymm QC output

    processing_dir:  the directory location of the processed data 

    separator : string usually &#39;-&#39; or &#39;_&#39;

    sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas

    date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas

    id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas

    report_missing : boolean combined with verbose will report missing modalities

    progress : integer reports percent progress modulo progress value 

    verbose : boolean
    &#34;&#34;&#34;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in sdf.keys():
            raise ValueError(&#39;sdf is missing column &#39; +musthavecols[k] + &#39; in merge_wides_to_study_dataframe&#39; )
    possible_iids = [ &#39;imageID&#39;, &#39;imageID&#39;, &#39;imageID&#39;, &#39;flairid&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;nmid1&#39;, &#39;nmid2&#39;, &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;, &#39;nmid6&#39;, &#39;nmid7&#39;, &#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;perfid&#39; ]
    modality_ids = [ &#39;T1wHierarchical&#39;, &#39;T1wHierarchicalSR&#39;, &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;DTI&#39;, &#39;DTI&#39;, &#39;rsfMRI&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;perf&#39;]
    alldf=pd.DataFrame()
    for myk in sdf.index:
        if progress &gt; 0 and int(myk) % int(progress) == 0:
            print( str( round( myk/sdf.shape[0]*100.0)) + &#34;%...&#34;, end=&#39;&#39;, flush=True)
        if verbose:
            print( &#34;DOROW &#34; + str(myk) + &#39; of &#39; + str( sdf.shape[0] ) )
        csvrow = sdf.loc[sdf.index == myk].dropna(axis=1)
        ct=-1
        for iidkey in possible_iids:
            ct=ct+1
            mod_name = modality_ids[ct]
            if iidkey in csvrow.keys():
                if id_is_int:
                    iid = str( int( csvrow[iidkey].iloc[0] ) )
                else:
                    iid = str( csvrow[iidkey].iloc[0] )
                if verbose:
                    print( &#34;iidkey &#34; + iidkey + &#34; modality &#34; + mod_name + &#39; iid &#39;+ iid )
                pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
                if sid_is_int:
                    sid=str(int(csvrow[&#39;subjectID&#39;].iloc[0] ))
                else:
                    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
                if date_is_int:
                    dt=str(int(csvrow[&#39;date&#39;].iloc[0]))
                else:
                    dt=str(csvrow[&#39;date&#39;].iloc[0])
                if id_is_int:
                    t1iid=str(int(csvrow[&#39;imageID&#39;].iloc[0]))
                else:
                    t1iid=str(csvrow[&#39;imageID&#39;].iloc[0])
                if t1iid != iid:
                    iidj=iid+&#34;_&#34;+t1iid
                else:
                    iidj=iid
                rootid = pid +separator+ sid +separator+dt+separator+mod_name+separator+iidj
                myext = rootid +separator+&#39;mmwide.csv&#39;
                nrgwidefn=os.path.join( processing_dir, pid, sid, dt, mod_name, iid, myext )
                moddersub = mod_name
                is_t1=False
                if mod_name == &#39;T1wHierarchical&#39;:
                    is_t1=True
                    moddersub=&#39;T1Hier&#39;
                elif mod_name == &#39;T1wHierarchicalSR&#39;:
                    is_t1=True
                    moddersub=&#39;T1HSR&#39;
                if exists( nrgwidefn ):
                    if verbose:
                        print( nrgwidefn + &#34; exists&#34;)
                    mm=read_mm_csv( nrgwidefn, colprefix=moddersub+&#39;_&#39;, is_t1=is_t1, separator=separator, verbose=verbose )
                    if mm is not None:
                        if mod_name == &#39;T1wHierarchical&#39;:
                            a=list( csvrow.keys() )
                            b=list( mm.keys() )
                            abintersect=list(set(b).intersection( set(a) ) )
                            if len( abintersect  ) &gt; 0 :
                                for qq in abintersect:
                                    mm.pop( qq )
                        # mm.index=csvrow.index
                        uidname = mod_name + &#39;_mmwide_filename&#39;
                        mm[ uidname ] = rootid
                        csvrow=pd.concat( [csvrow,mm], axis=1, ignore_index=False )
                else:
                    if verbose and report_missing:
                        print( nrgwidefn + &#34; absent&#34;)
        if alldf.shape[0] == 0:
            alldf = csvrow.copy()
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
        else:
            csvrow=csvrow.loc[:,~csvrow.columns.duplicated()]
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
            alldf = pd.concat( [alldf, csvrow], axis=0, ignore_index=True )
    return alldf

def assemble_modality_specific_dataframes( mm_wide_csvs, hierdfin, nrg_modality, separator=&#39;-&#39;, progress=None, verbose=False ):
    moddersub = re.sub( &#34;[*]&#34;,&#34;&#34;,nrg_modality)
    nmdf=pd.DataFrame()
    for k in range( hierdfin.shape[0] ):
        if progress is not None:
            if k % progress == 0:
                progger = str( np.round( k / hierdfin.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        temp = mm_wide_csvs[k]
        mypartsf = temp.split(&#34;T1wHierarchical&#34;)
        myparts = mypartsf[0]
        t1iid = str(mypartsf[1].split(&#34;/&#34;)[1])
        fnsnm = glob.glob(myparts+&#34;/&#34; + nrg_modality + &#34;/*/*&#34; + t1iid + &#34;*wide.csv&#34;)
        if len( fnsnm ) &gt; 0 :
            for y in fnsnm:
                temp=read_mm_csv( y, colprefix=moddersub+&#39;_&#39;, is_t1=False, separator=separator, verbose=verbose )
                if temp is not None:
                    nmdf=pd.concat( [nmdf, temp], axis=0, ignore_index=False )
    return nmdf

def bind_wide_mm_csvs( mm_wide_csvs, merge=True, separator=&#39;-&#39;, verbose = 0 ) :
    &#34;&#34;&#34;
    will convert a list of t1w hierarchical csv filenames to a merged dataframe

    returns a pair of data frames, the left side having all entries and the
        right side having row averaged entries i.e. unique values for each visit

    set merge to False to return individual dataframes ( for debugging )

    return alldata, row_averaged_data
    &#34;&#34;&#34;
    mm_wide_csvs.sort()
    if not mm_wide_csvs:
        print(&#34;No files found with specified pattern&#34;)
        return
    # 1. row-bind the t1whier data
    # 2. same for each other modality
    # 3. merge the modalities by the keys
    hierdf = pd.DataFrame()
    for y in mm_wide_csvs:
        temp=read_mm_csv( y, colprefix=&#39;T1Hier_&#39;, separator=separator, is_t1=True )
        if temp is not None:
            hierdf=pd.concat( [hierdf, temp], axis=0, ignore_index=False )
    if verbose &gt; 0:
        mypro=50
    else:
        mypro=None
    if verbose &gt; 0:
        print(&#34;thickness&#34;)
    thkdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T1w&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;flair&#34;)
    flairdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T2Flair&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;NM&#34;)
    nmdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;NM2DMT&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;rsf&#34;)
    rsfdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;rsfMRI*&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;dti&#34;)
    dtidf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;DTI*&#39;, progress=mypro, verbose=verbose==2 )
    if not merge:
        return hierdf, thkdf, flairdf, nmdf, rsfdf, dtidf
    hierdfmix = hierdf.copy()
    modality_df_suffixes = [
        (thkdf, &#34;_thk&#34;),
        (flairdf, &#34;_flair&#34;),
        (nmdf, &#34;_nm&#34;),
        (rsfdf, &#34;_rsf&#34;),
        (dtidf, &#34;_dti&#34;),
    ]
    for pair in modality_df_suffixes:
        hierdfmix = merge_mm_dataframe(hierdfmix, pair[0], pair[1])
    hierdfmix = hierdfmix.replace(r&#39;^\s*$&#39;, np.nan, regex=True)
    return hierdfmix, hierdfmix.groupby(&#34;u_hier_id&#34;, as_index=False).mean(numeric_only=True)

def merge_mm_dataframe(hierdf, mmdf, mm_suffix):
    try:
        hierdf = hierdf.merge(mmdf, on=[&#39;sid&#39;, &#39;visitdate&#39;, &#39;t1imageuid&#39;], suffixes=(&#34;&#34;,mm_suffix),how=&#39;left&#39;)
        return hierdf
    except KeyError:
        return hierdf

def augment_image( x,  max_rot=10, nzsd=1 ):
    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rot*(-1.0), max_rot ), reference=x )
    tx = rRotGenerator.transform()
    itx = ants.invert_ants_transform(tx)
    y = ants.apply_ants_transform_to_image( tx, x, x, interpolation=&#39;linear&#39;)
    y = ants.add_noise_to_image( y,&#39;additivegaussian&#39;, [0,nzsd] )
    return y, tx, itx

def boot_wmh( flair, t1, t1seg, mmfromconvexhull = 0.0, strict=True,
        probability_mask=None, prior_probability=None, n_simulations=16,
        verbose=False ) :
    if verbose and prior_probability is None:
        print(&#34;augmented flair&#34;)
    if verbose and prior_probability is not None:
        print(&#34;augmented flair with prior&#34;)
    wmh_sum_aug = 0
    wmh_sum_prior_aug = 0
    augprob = flair * 0.0
    augprob_prior = None
    if prior_probability is not None:
        augprob_prior = flair * 0.0
    for n in range(n_simulations):
        augflair, tx, itx = augment_image( ants.iMath(flair,&#34;Normalize&#34;), 5, 0.01 )
        locwmh = wmh( augflair, t1, t1seg, mmfromconvexhull = mmfromconvexhull,
            strict=strict, probability_mask=None, prior_probability=prior_probability )
        if verbose:
            print( &#34;flair sim: &#34; + str(n) + &#34; vol: &#34; + str( locwmh[&#39;wmh_mass&#39;] )+ &#34; vol-prior: &#34; + str( locwmh[&#39;wmh_mass_prior&#39;] )+ &#34; snr: &#34; + str( locwmh[&#39;wmh_SNR&#39;] ) )
        wmh_sum_aug = wmh_sum_aug + locwmh[&#39;wmh_mass&#39;]
        wmh_sum_prior_aug = wmh_sum_prior_aug + locwmh[&#39;wmh_mass_prior&#39;]
        temp = locwmh[&#39;WMH_probability_map&#39;]
        augprob = augprob + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
        if prior_probability is not None:
            temp = locwmh[&#39;WMH_posterior_probability_map&#39;]
            augprob_prior = augprob_prior + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
    augprob = augprob * (1.0/float( n_simulations ))
    if prior_probability is not None:
        augprob_prior = augprob_prior * (1.0/float( n_simulations ))
    wmh_sum_aug = wmh_sum_aug / float( n_simulations )
    wmh_sum_prior_aug = wmh_sum_prior_aug / float( n_simulations )
    return{
      &#39;flair&#39; : ants.iMath(flair,&#34;Normalize&#34;),
      &#39;WMH_probability_map&#39; : augprob,
      &#39;WMH_posterior_probability_map&#39; : augprob_prior,
      &#39;wmh_mass&#39;: wmh_sum_aug,
      &#39;wmh_mass_prior&#39;: wmh_sum_prior_aug,
      &#39;wmh_evr&#39;: locwmh[&#39;wmh_evr&#39;],
      &#39;wmh_SNR&#39;: locwmh[&#39;wmh_SNR&#39;]  }


def threaded_bind_wide_mm_csvs( mm_wide_csvs, n_workers ):
    from concurrent.futures import as_completed
    from concurrent import futures
    import concurrent.futures
    def chunks(l, n):
        &#34;&#34;&#34;Yield n number of sequential chunks from l.&#34;&#34;&#34;
        d, r = divmod(len(l), n)
        for i in range(n):
            si = (d+1)*(i if i &lt; r else r) + d*(0 if i &lt; r else i - r)
            yield l[si:si+(d+1 if i &lt; r else d)]
    import numpy as np
    newx = list( chunks( mm_wide_csvs, n_workers ) )
    import pandas as pd
    alldf = pd.DataFrame()
    alldfavg = pd.DataFrame()
    with futures.ThreadPoolExecutor(max_workers=n_workers) as executor:
        to_do = []
        for group in range(len(newx)) :
            future = executor.submit(bind_wide_mm_csvs, newx[group] )
            to_do.append(future)
        results = []
        for future in futures.as_completed(to_do):
            res0, res1 = future.result()
            alldf=pd.concat(  [alldf, res0 ], axis=0, ignore_index=False )
            alldfavg=pd.concat(  [alldfavg, res1 ], axis=0, ignore_index=False )
    return alldf, alldfavg


def get_names_from_data_frame(x, demogIn, exclusions=None):
    &#34;&#34;&#34;
    data = {&#39;Name&#39;:[&#39;Tom&#39;, &#39;nick&#39;, &#39;krish&#39;, &#39;jack&#39;], &#39;Age&#39;:[20, 21, 19, 18]}
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;a&#39;,&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df, exclusions=&#39;N&#39; )
    &#34;&#34;&#34;
    # Check if x is a string and convert it to a list
    if isinstance(x, str):
        x = [x]
    def get_unique( qq ):
        unique = []
        for number in qq:
            if number in unique:
                continue
            else:
                unique.append(number)
        return unique
    outnames = list(demogIn.columns[demogIn.columns.str.contains(x[0])])
    if len(x) &gt; 1:
        for y in x[1:]:
            outnames = [i for i in outnames if y in i]
    outnames = get_unique( outnames )
    if exclusions is not None:
        toexclude = [name for name in outnames if exclusions[0] in name ]
        if len(exclusions) &gt; 1:
            for zz in exclusions[1:]:
                toexclude.extend([name for name in outnames if zz in name ])
        if len(toexclude) &gt; 0:
            outnames = [name for name in outnames if name not in toexclude]
    return outnames


def average_mm_df( jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False ):
    &#34;&#34;&#34;
    jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )
    &#34;&#34;&#34;

    jmm = jmm_in.copy()
    dxcols=[&#39;subjectid1&#39;,&#39;subjectid2&#39;,&#39;modalityid&#39;,&#39;joinid&#39;,&#39;correlation&#39;,&#39;distance&#39;]
    joinDiagnostics = pd.DataFrame( columns = dxcols )
    nanList=[math.nan]
    def rob(x, y=0.99):
        x[x &gt; np.quantile(x, y, nan_policy=&#34;omit&#34;)] = np.nan
        return x

    jmm = jmm.replace(r&#39;^\s*$&#39;, np.nan, regex=True)

    if verbose:
        print(&#34;do rsfMRI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;rsfMRI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;rsfMRI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    if len( dt0 ) &gt; 0 and len( dt1 ) &gt; 0:
        flid = dt0[0]
        wrows = []
        for i in range(jmm.shape[0]):
            if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) :
                wrows.append(i)
        for k in wrows:
            v1 = jmm.iloc[k][dt0[1:]].astype(float)
            v2 = jmm.iloc[k][dt1[1:]].astype(float)
            vvec = [v1[0], v2[0]]
            if any(~np.isnan(vvec)):
                mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
                jmm.iloc[k][dt0[0]] = &#39;rsfMRI&#39;
                if len(mynna) == 1:
                    if mynna[0] == 0:
                        jmm.iloc[k][dt0[1:]] = v1
                    if mynna[0] == 1:
                        jmm.iloc[k][dt0[1:]] = v2
                elif len(mynna) &gt; 1:
                    if len(v2) &gt; diagnostic_n:
                        v1dx=v1[0:diagnostic_n]
                        v2dx=v2[0:diagnostic_n]
                    else :
                        v1dx=v1
                        v2dx=v2
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v1dx.values, v2dx.values )[0,1]
                    myerr=np.sqrt(np.mean((v1dx.values - v2dx.values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;rsfMRI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v1.values*0.5 + v2.values*0.5
                    else:
                        jmm.loc[k, dt0[1:]] = nanList * len(v1)
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0, ignore_index=False )

    if verbose:
        print(&#34;do DTI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;DTI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;DTI_LR&#34;, &#34;DTI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;DTI_LR&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    dt2 = get_names_from_data_frame( [&#34;DTI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    flid = dt0[0]
    wrows = []
    for i in range(jmm.shape[0]):
        if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) or not pd.isna(jmm[dt2[1]][i]):
            wrows.append(i)
    for k in wrows:
        v1 = jmm.loc[k, dt0[1:]].astype(float)
        v2 = jmm.loc[k, dt1[1:]].astype(float)
        v3 = jmm.loc[k, dt2[1:]].astype(float)
        checkcol = dt0[5]
        if not np.isnan(v1[checkcol]):
            if v1[checkcol] &lt; 0.25:
                v1.replace(np.nan, inplace=True)
        checkcol = dt1[5]
        if not np.isnan(v2[checkcol]):
            if v2[checkcol] &lt; 0.25:
                v2.replace(np.nan, inplace=True)
        checkcol = dt2[5]
        if not np.isnan(v3[checkcol]):
            if v3[checkcol] &lt; 0.25:
                v3.replace(np.nan, inplace=True)
        vvec = [v1[0], v2[0], v3[0]]
        if any(~np.isnan(vvec)):
            mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
            jmm.loc[k, dt0[0]] = &#39;DTI&#39;
            if len(mynna) == 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                if mynna[0] == 1:
                    jmm.loc[k, dt0[1:]] = v2
                if mynna[0] == 2:
                    jmm.loc[k, dt0[1:]] = v3
            elif len(mynna) &gt; 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                else:
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v2[0:diagnostic_n].values, v3[0:diagnostic_n].values )[0,1]
                    myerr=np.sqrt(np.mean((v2[0:diagnostic_n].values - v3[0:diagnostic_n].values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;DTI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v2.values*0.5 + v3.values*0.5
                    else: #
                        jmm.loc[k, dt0[1:]] = nanList * len( dt0[1:] )
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0, ignore_index=False )


    # first task - sort by u_hier_id
    jmm = jmm.sort_values( &#34;u_hier_id&#34; )
    # get rid of junk columns
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], jmm )
    jmm=jmm.drop(badnames, axis=1)
    jmm=jmm.set_index(&#34;u_hier_id&#34;,drop=False)
    # 2nd - get rid of duplicated u_hier_id
    jmmUniq = jmm.drop_duplicates( subset=&#34;u_hier_id&#34; ) # fast and easy
    # for each modality, count which ids have more than one
    mod_names = get_valid_modalities()
    for mod_name in mod_names:
        fl_names = get_names_from_data_frame([mod_name], jmm,
            exclusions=[&#39;Unnamed&#39;,&#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;rsfMRI_RL&#34;,&#34;rsfMRI_LR&#34;])
        if len( fl_names ) &gt; 1:
            if verbose:
                print(mod_name)
                print(fl_names)
            fl_id = fl_names[0]
            n_names = len(fl_names)
            locvec = jmm[fl_names[n_names-1]].astype(float)
            boolvec=~pd.isna(locvec)
            jmmsub = jmm[boolvec][ [&#39;u_hier_id&#39;]+fl_names]
            my_tbl = Counter(jmmsub[&#39;u_hier_id&#39;])
            gtoavg = [name for name in my_tbl.keys() if my_tbl[name] == 1]
            gtoavgG1 = [name for name in my_tbl.keys() if my_tbl[name] &gt; 1]
            if verbose:
                print(&#34;Join 1&#34;)
            jmmsub1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavg)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavg:
                jmmUniq.loc[u][fl_names[1:]] = jmmsub1.loc[u][fl_names[1:]]
            if verbose and len(gtoavgG1) &gt; 1:
                print(&#34;Join &gt;1&#34;)
            jmmsubG1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavgG1)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavgG1:
                temp = jmmsubG1.loc[u][ [&#39;u_hier_id&#39;]+fl_names ]
                dropnames = get_names_from_data_frame( [&#39;MM.ID&#39;], temp )
                tempVec = temp.drop(columns=dropnames)
                joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                id1=temp[fl_id].iloc[0]
                id2=temp[fl_id].iloc[1]
                v1=tempVec.iloc[0][1:].astype(float).to_numpy()
                v2=tempVec.iloc[1][1:].astype(float).to_numpy()
                if len(v2) &gt; diagnostic_n:
                    v1=v1[0:diagnostic_n]
                    v2=v2[0:diagnostic_n]
                mycorr = np.corrcoef( v1, v2 )[0,1]
                # mycorr=temparr[np.triu_indices_from(temparr, k=1)].mean()
                myerr=np.sqrt(np.mean((v1 - v2)**2))
                joinDiagnosticsLoc.iloc[0] = [id1,id2,mod_name,&#39;rowavg&#39;,mycorr,myerr]
                if verbose:
                    print( joinDiagnosticsLoc )
                temp = jmmsubG1.loc[u][fl_names[1:]].astype(float)
                if mycorr &gt; corr_thresh or len( v1 ) &lt; 10:
                    jmmUniq.loc[u][fl_names[1:]] = temp.mean(axis=0)
                else:
                    jmmUniq.loc[u][fl_names[1:]] = nanList * temp.shape[1]
                joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], 
                                            axis=0, ignore_index=False )

    return jmmUniq, jmm, joinDiagnostics



def quick_viz_mm_nrg(
    sourcedir, # root folder
    projectid, # project name
    sid , # subject unique id
    dtid, # date
    extract_brain=True,
    slice_factor = 0.55,
    show_it = None, # output path
    verbose = True
):
    &#34;&#34;&#34;
    This function creates visualizations of brain images for a specific subject in a project using ANTsPy.

    Args:

    sourcedir (str): Root folder.
    
    projectid (str): Project name.
    
    sid (str): Subject unique id.
    
    dtid (str): Date.
    
    extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.
    
    slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.
    
    show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.
    
    verbose (bool): If True, information will be printed while running the function. Default is True.

    Returns:
    vizlist (list): List of image visualizations.

    &#34;&#34;&#34;
    iid=&#39;*&#39;
    import glob as glob
    from os.path import exists
    import ants
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    subjectrootpath = os.path.join(sourcedir, projectid, sid, dtid)
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, &#34;*&#34;, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;quick_viz_mm_nrg cannot find the T1w @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    nimages = len(myimgsInput)
    vizlist=[]
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.  will visualize T1 NM rsfMRI DTIB0 DTIDWI FLAIR&#34;)
    # nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;rsfMRI_LR&#34;,&#34;rsfMRI_RL&#34;,&#34;DTI&#34;,&#34;DTI_LR&#34;, &#34;T2Flair&#34; ],
    nrg_modality_list = [ &#39;T1w&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DWI1&#39;, &#39;DWI2&#39;, &#39;T2Flair&#39; ]
    for nrgNum in [0,1,2,3,4,5]:
        overmodX = nrg_modality_list[nrgNum]
        if overmodX == &#39;T1w&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, iid, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) == 0:
                if verbose:
                    print(&#34;No t1 images: &#34; + sid + dtid )
                return None
            myimgsr.sort()
            myimgsr=myimgsr[0]
            vimg=ants.image_read( myimgsr )
        elif overmodX == &#39;DWI1&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;DWI2&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[len(myimgsr)-1]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;NM2DMT&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr0=myimgsr[0]
                vimg=ants.image_read( myimgsr0 )
                for k in range(1,len(myimgsr)):
                    temp = ants.image_read( myimgsr[k])
                    vimg=vimg+ants.resample_image_to_target(temp,vimg)
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;rsfMRI&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;rsfMRI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=mm_read_to_3d( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        else :
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        if True:
            if extract_brain and overmodX == &#39;T1w&#39;:
                vimg = vimg * antspyt1w.brain_extraction(vimg)
            if verbose:
                print(f&#34;modality search path: {myimgsr}&#34; + &#34; num: &#34; + str(nrgNum))
            if len( vimg.shape ) == 4 and ( overmodX == &#34;DWI2&#34;  ):
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttdw
            elif len( vimg.shape ) == 4 and overmodX == &#34;DWI1&#34;:
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttb0
            elif len( vimg.shape ) == 4 :
                vimg=ants.get_average_of_timeseries(vimg)
            msk=ants.get_mask(vimg)
            vimg=ants.crop_image(vimg,msk)
            if overmodX == &#39;T1w&#39;:
                refimg=ants.image_clone( vimg )
                noizimg = ants.add_noise_to_image( refimg*0, &#39;additivegaussian&#39;, [100,1] )
                vizlist.append( vimg )
            else:
                vimg = ants.resample_image_to_target( vimg, refimg )
                vimg = ants.iMath( vimg, &#39;TruncateIntensity&#39;,0.01,0.98)
                vizlist.append( ants.iMath( vimg, &#39;Normalize&#39; ) * 255 )

    listlen = len( vizlist )
    vizlist = np.asarray( vizlist )
    if show_it is not None:
        filenameout=None
        if verbose:
            print( show_it )
        for a in [0,1,2]:
            n=int(np.round( refimg.shape[a] * slice_factor ))
            slices=np.repeat( int(n), listlen  )
            if isinstance(show_it,str):
                filenameout=show_it+&#39;_ax&#39;+str(int(a))+&#39;_sl&#39;+str(n)+&#39;.png&#39;
                if verbose:
                    print( filenameout )
            ants.plot_grid(vizlist.reshape(2,3), slices.reshape(2,3), title=&#39;MM Subject &#39; + sid + &#39; &#39; + dtid, rfacecolor=&#39;white&#39;, axes=a, filename=filenameout )
    if verbose:
        print(&#34;viz complete.&#34;)
    return vizlist


def blind_image_assessment(
    image,
    viz_filename=None,
    title=False,
    pull_rank=False,
    resample=None,
    n_to_skip = 10,
    verbose=False
):
    &#34;&#34;&#34;
    quick blind image assessment and triplanar visualization of an image ... 4D input will be visualized and assessed in 3D.  produces a png and csv where csv contains:

    * reflection error ( estimates asymmetry )

    * brisq ( blind quality assessment )

    * patch eigenvalue ratio ( blind quality assessment )

    * PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)

    * mask volume ( estimates foreground object size )

    * spacing

    * dimension after cropping by mask

    image : character or image object usually a nifti image

    viz_filename : character for a png output image

    title : display a summary title on the png

    pull_rank : boolean

    resample : None, numeric max or min, resamples image to isotropy

    n_to_skip : 10 by default; samples time series every n_to_skip volume

    verbose : boolean

    &#34;&#34;&#34;
    import glob as glob
    from os.path import exists
    import ants
    import matplotlib.pyplot as plt
    from PIL import Image
    from pathlib import Path
    import json
    import re
    from dipy.io.gradients import read_bvals_bvecs
    mystem=&#39;&#39;
    if isinstance(image,list):
        isfilename=isinstance( image[0], str)
        image = image[0]
    else:
        isfilename=isinstance( image, str)
    outdf = pd.DataFrame()
    mymeta = None
    MagneticFieldStrength = None
    image_filename=&#39;&#39;
    if isfilename:
        image_filename = image
        if isinstance(image,list):
            image_filename=image[0]
        json_name = re.sub(&#34;.nii.gz&#34;,&#34;.json&#34;,image_filename)
        if exists( json_name ):
            try:
                with open(json_name, &#39;r&#39;) as fcc_file:
                    mymeta = json.load(fcc_file)
                    if verbose:
                        print(json.dumps(mymeta, indent=4))
                    fcc_file.close()
            except:
                pass
        mystem=Path( image ).stem
        mystem=Path( mystem ).stem
        image_reference = ants.image_read( image )
        image = ants.image_read( image )
    else:
        image_reference = ants.image_clone( image )
    ntimepoints = 1
    bvalueMax=None
    if image_reference.dimension == 4:
        ntimepoints = image_reference.shape[3]
        if &#34;DTI&#34; in image_filename:
            myTSseg = segment_timeseries_by_meanvalue( image_reference )
            image_b0, image_dwi = get_average_dwi_b0( image_reference, fast=True )
            image_b0 = ants.iMath( image_b0, &#39;Normalize&#39; )
            image_dwi = ants.iMath( image_dwi, &#39;Normalize&#39; )
            bval_name = re.sub(&#34;.nii.gz&#34;,&#34;.bval&#34;,image_filename)
            bvec_name = re.sub(&#34;.nii.gz&#34;,&#34;.bvec&#34;,image_filename)
            if exists( bval_name ) and exists( bvec_name ):
                bvals, bvecs = read_bvals_bvecs( bval_name , bvec_name  )
                bvalueMax = bvals.max()
        else:
            image_b0 = ants.get_average_of_timeseries( image_reference ).iMath(&#34;Normalize&#34;)
    else:
        image_compare = ants.smooth_image( image_reference, 3, sigma_in_physical_coordinates=False )
    for jjj in range(0,ntimepoints,n_to_skip):
        modality=&#39;unknown&#39;
        if &#34;rsfMRI&#34; in image_filename:
            modality=&#39;rsfMRI&#39;
        elif &#34;T1w&#34; in image_filename:
            modality=&#39;T1w&#39;
        elif &#34;T2Flair&#34; in image_filename:
            modality=&#39;T2Flair&#39;
        elif &#34;NM2DMT&#34; in image_filename:
            modality=&#39;NM2DMT&#39;
        if image_reference.dimension == 4:
            image = ants.slice_image( image_reference, idx=int(jjj), axis=3 )
            if &#34;DTI&#34; in image_filename:
                if jjj in myTSseg[&#39;highermeans&#39;]:
                    image_compare = ants.image_clone( image_b0 )
                    modality=&#39;DTIb0&#39;
                else:
                    image_compare = ants.image_clone( image_dwi )
                    modality=&#39;DTIdwi&#39;
            else:
                image_compare = ants.image_clone( image_b0 )
        # image = ants.iMath( image, &#39;TruncateIntensity&#39;,0.01,0.995)
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        if resample is not None:
            if resample == &#39;min&#39;:
                if minspc &lt; 1e-12:
                    minspc = np.max(ants.get_spacing(image))
                newspc = np.repeat( minspc, 3 )
            elif resample == &#39;max&#39;:
                newspc = np.repeat( maxspc, 3 )
            else:
                newspc = np.repeat( resample, 3 )
            image = ants.resample_image( image, newspc )
            image_compare = ants.resample_image( image_compare, newspc )
        else:
            # check for spc close to zero
            spc = list(ants.get_spacing(image))
            for spck in range(len(spc)):
                if spc[spck] &lt; 1e-12:
                    spc[spck]=1
            ants.set_spacing( image, spc )
            ants.set_spacing( image_compare, spc )
        # if &#34;NM2DMT&#34; in image_filename or &#34;FIXME&#34; in image_filename or &#34;SPECT&#34; in image_filename or &#34;UNKNOWN&#34; in image_filename:
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        msk = ants.threshold_image( ants.iMath(image,&#39;Normalize&#39;), 0.15, 1.0 )
        # else:
        #    msk = ants.get_mask( image )
        msk = ants.morphology(msk, &#34;close&#34;, 3 )
        bgmsk = msk*0+1-msk
        mskdil = ants.iMath(msk, &#34;MD&#34;, 4 )
        # ants.plot_ortho( image, msk, crop=False )
        nvox = int( msk.sum() )
        spc = ants.get_spacing( image )
        org = ants.get_origin( image )
        if ( nvox &gt; 0 ):
            image = ants.crop_image( image, mskdil ).iMath(&#34;Normalize&#34;)
            msk = ants.crop_image( msk, mskdil ).iMath(&#34;Normalize&#34;)
            bgmsk = ants.crop_image( bgmsk, mskdil ).iMath(&#34;Normalize&#34;)
            image_compare = ants.crop_image( image_compare, mskdil ).iMath(&#34;Normalize&#34;)           
            npatch = int( np.round(  0.1 * nvox ) )
            npatch = np.min(  [512,npatch ] )
            patch_shape = []
            for k in range( 3 ):
                p = int( 32.0 / ants.get_spacing( image  )[k] )
                if p &gt; int( np.round( image.shape[k] * 0.5 ) ):
                    p = int( np.round( image.shape[k] * 0.5 ) )
                patch_shape.append( p )
            if verbose:
                print(image)
                print( patch_shape )
                print( npatch )
            myevr = math.nan # dont want to fail if something odd happens in patch extraction
            try:
                myevr = antspyt1w.patch_eigenvalue_ratio( image, npatch, patch_shape,
                    evdepth = 0.9, mask=msk )
            except:
                pass
            if pull_rank:
                image = ants.rank_intensity(image)
            imagereflect = ants.reflect_image(image, axis=0)
            asym_err = ( image - imagereflect ).abs().mean()
            # estimate noise by center cropping, denoizing and taking magnitude of difference
            nocrop=False
            if image.dimension == 3:
                if image.shape[2] == 1:
                    nocrop=True        
            if maxspc/minspc &gt; 10:
                nocrop=True
            if nocrop:
                mycc = ants.image_clone( image )
            else:
                mycc = antspyt1w.special_crop( image,
                    ants.get_center_of_mass( msk *0 + 1 ), patch_shape )
            myccd = ants.denoise_image( mycc, p=2,r=2,noise_model=&#39;Gaussian&#39; )
            noizlevel = ( mycc - myccd ).abs().mean()
    #        ants.plot_ortho( image, crop=False, filename=viz_filename, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
    #        from brisque import BRISQUE
    #        obj = BRISQUE(url=False)
    #        mybrisq = obj.score( np.array( Image.open( viz_filename )) )
            msk_vol = msk.sum() * np.prod( spc )
            bgstd = image[ bgmsk == 1 ].std()
            fgmean = image[ msk == 1 ].mean()
            bgmean = image[ bgmsk == 1 ].mean()
            snrref = fgmean / bgstd
            cnrref = ( fgmean - bgmean ) / bgstd
            psnrref = antspynet.psnr(  image_compare, image  )
            ssimref = antspynet.ssim(  image_compare, image  )
            if nocrop:
                mymi = math.inf
            else:
                mymi = ants.image_mutual_information( image_compare, image )
        else:
            msk_vol = 0
            myevr = mymi = ssimref = psnrref = cnrref = asym_err = noizlevel = math.nan
            
        mriseries=None
        mrimfg=None
        mrimodel=None
        mriSAR=None
        BandwidthPerPixelPhaseEncode=None
        PixelBandwidth=None
        if mymeta is not None:
            # mriseries=mymeta[&#39;&#39;]
            try:
                mrimfg=mymeta[&#39;Manufacturer&#39;]
            except:
                pass
            try:
                mrimodel=mymeta[&#39;ManufacturersModelName&#39;]
            except:
                pass
            try:
                MagneticFieldStrength=mymeta[&#39;MagneticFieldStrength&#39;]
            except:
                pass
            try:
                PixelBandwidth=mymeta[&#39;PixelBandwidth&#39;]
            except:
                pass
            try:
                BandwidthPerPixelPhaseEncode=mymeta[&#39;BandwidthPerPixelPhaseEncode&#39;]
            except:
                pass
            try:
                mriSAR=mymeta[&#39;SAR&#39;]
            except:
                pass
        ttl=mystem + &#39; &#39;
        ttl=&#39;&#39;
        ttl=ttl + &#34;NZ: &#34; + &#34;{:0.4f}&#34;.format(noizlevel) + &#34; SNR: &#34; + &#34;{:0.4f}&#34;.format(snrref) + &#34; CNR: &#34; + &#34;{:0.4f}&#34;.format(cnrref) + &#34; PS: &#34; + &#34;{:0.4f}&#34;.format(psnrref)+ &#34; SS: &#34; + &#34;{:0.4f}&#34;.format(ssimref) + &#34; EVR: &#34; + &#34;{:0.4f}&#34;.format(myevr)+ &#34; MI: &#34; + &#34;{:0.4f}&#34;.format(mymi)
        if viz_filename is not None and ( jjj == 0 or (jjj % 30 == 0) ) and image.shape[2] &lt; 685:
            viz_filename_use = re.sub( &#34;.png&#34;, &#34;_slice&#34;+str(jjj).zfill(4)+&#34;.png&#34;, viz_filename )
            ants.plot_ortho( image, crop=False, filename=viz_filename_use, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0,  title=ttl, titlefontsize=12, title_dy=-0.02,textfontcolor=&#39;red&#39; )
        df = pd.DataFrame([[ 
            mystem, 
            image_reference.dimension, 
            noizlevel, snrref, cnrref, psnrref, ssimref, mymi, asym_err, myevr, msk_vol, 
            spc[0], spc[1], spc[2],org[0], org[1], org[2], 
            image.shape[0], image.shape[1], image.shape[2], ntimepoints, 
            jjj, modality, mriseries, mrimfg, mrimodel, MagneticFieldStrength, mriSAR, PixelBandwidth, BandwidthPerPixelPhaseEncode, bvalueMax ]], 
            columns=[
                &#39;filename&#39;, 
                &#39;dimensionality&#39;,
                &#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;,&#39;spc1&#39;,&#39;spc2&#39;,&#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;,&#39;dimx&#39;,&#39;dimy&#39;,&#39;dimz&#39;,&#39;dimt&#39;,&#39;slice&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39;, &#39;mriMagneticFieldStrength&#39;, &#39;mriSAR&#39;, &#39;mriPixelBandwidth&#39;, &#39;mriPixelBandwidthPE&#39;, &#39;dti_bvalueMax&#39; ])
        outdf = pd.concat( [outdf, df ], axis=0, ignore_index=False )
        if verbose:
            print( outdf )
    if viz_filename is not None:
        csvfn = re.sub( &#34;png&#34;, &#34;csv&#34;, viz_filename )
        outdf.to_csv( csvfn )
    return outdf

def remove_unwanted_columns(df):
    # Identify columns to drop: those named &#39;X&#39; or starting with &#39;Unnamed&#39;
    cols_to_drop = [col for col in df.columns if col == &#39;X&#39; or col.startswith(&#39;Unnamed&#39;)]
    
    # Drop the identified columns from the DataFrame, if any
    df_cleaned = df.drop(columns=cols_to_drop, errors=&#39;ignore&#39;)
    
    return df_cleaned

def process_dataframe_generalized(df, group_by_column):
    # Make sure the group_by_column is excluded from both numeric and other columns calculations
    numeric_cols = df.select_dtypes(include=&#39;number&#39;).columns.difference([group_by_column])
    other_cols = df.columns.difference(numeric_cols).difference([group_by_column])
    
    # Define aggregation functions: mean for numeric cols, mode for other cols
    # Update to handle empty mode results safely
    agg_dict = {col: &#39;mean&#39; for col in numeric_cols}
    agg_dict.update({
        col: lambda x: pd.Series.mode(x).iloc[0] if not pd.Series.mode(x).empty else None for col in other_cols
    })    
    # Group by the specified column, applying different aggregation functions to different columns
    processed_df = df.groupby(group_by_column, as_index=False).agg(agg_dict)
    return processed_df

def average_blind_qc_by_modality(qc_full,verbose=False):
    &#34;&#34;&#34;
    Averages time series qc results to yield one entry per image. this also filters to &#34;known&#34; columns.

    Args:
    qc_full: pandas dataframe containing the full qc data.

    Returns:
    pandas dataframe containing the processed qc data.
    &#34;&#34;&#34;
    qc_full = remove_unwanted_columns( qc_full )
    # Get unique modalities
    modalities = qc_full[&#39;modality&#39;].unique()
    modalities = modalities[modalities != &#39;unknown&#39;]
    # Get unique ids
    uid = qc_full[&#39;filename&#39;]
    to_average = uid.unique()
    meta = pd.DataFrame(columns=qc_full.columns )
    # Process each unique id
    n = len(to_average)
    for k in range(n):
        if verbose:
            if k % 100 == 0:
                progger = str( np.round( k / n * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        m1sel = uid == to_average[k]
        if sum(m1sel) &gt; 1:
            # If more than one entry for id, take the average of continuous columns,
            # maximum of the slice column, and the first entry of the other columns
            mfsub = process_dataframe_generalized(qc_full[m1sel],&#39;filename&#39;)
        else:
            mfsub = qc_full[m1sel]
        meta.loc[k] = mfsub.iloc[0]
    meta[&#39;modality&#39;] = meta[&#39;modality&#39;].replace([&#39;DTIdwi&#39;, &#39;DTIb0&#39;], &#39;DTI&#39;, regex=True)
    return meta

def wmh( flair, t1, t1seg,
    mmfromconvexhull = 3.0,
    strict=True,
    probability_mask=None,
    prior_probability=None,
    model=&#39;sysu&#39;,
    verbose=False ) :
    &#34;&#34;&#34;
    Outputs the WMH probability mask and a summary single measurement

    Arguments
    ---------
    flair : ANTsImage
        input 3-D FLAIR brain image (not skull-stripped).

    t1 : ANTsImage
        input 3-D T1 brain image (not skull-stripped).

    t1seg : ANTsImage
        T1 segmentation image

    mmfromconvexhull : float
        restrict WMH to regions that are WM or mmfromconvexhull mm away from the
        convex hull of the cerebrum.   we choose a default value based on
        Figure 4 from:
        https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf

    strict: boolean - if True, only use convex hull distance

    probability_mask : None - use to compute wmh just once - then this function
        just does refinement and summary

    prior_probability : optional prior probability image in space of the input t1

    model : either sysu or hyper

    verbose : boolean

    Returns
    ---------
    WMH probability map and a summary single measurement which is the sum of the WMH map

    &#34;&#34;&#34;
    import numpy as np
    import math
    t1_2_flair_reg = ants.registration(flair, t1, type_of_transform = &#39;Rigid&#39;) # Register T1 to Flair
    if probability_mask is None and model == &#39;sysu&#39;:
        if verbose:
            print(&#39;sysu&#39;)
        probability_mask = antspynet.sysu_media_wmh_segmentation( flair )
    elif probability_mask is None and model == &#39;hyper&#39;:
        if verbose:
            print(&#39;hyper&#39;)
        probability_mask = antspynet.hypermapp3r_segmentation( t1_2_flair_reg[&#39;warpedmovout&#39;], flair )
    # t1_2_flair_reg = tra_initializer( flair, t1, n_simulations=4, max_rotation=5, transform=[&#39;rigid&#39;], verbose=False )
    prior_probability_flair = None
    if prior_probability is not None:
        prior_probability_flair = ants.apply_transforms( flair, prior_probability,
            t1_2_flair_reg[&#39;fwdtransforms&#39;] )
    wmseg_mask = ants.threshold_image( t1seg,
        low_thresh = 3, high_thresh = 3).iMath(&#34;FillHoles&#34;)
    wmseg_mask_use = ants.image_clone( wmseg_mask )
    distmask = None
    if mmfromconvexhull &gt; 0:
            convexhull = ants.threshold_image( t1seg, 1, 4 )
            spc2vox = np.prod( ants.get_spacing( t1seg ) )
            voxdist = 0.0
            myspc = ants.get_spacing( t1seg )
            for k in range( t1seg.dimension ):
                voxdist = voxdist + myspc[k] * myspc[k]
            voxdist = math.sqrt( voxdist )
            nmorph = round( 2.0 / voxdist )
            convexhull = ants.morphology( convexhull, &#34;close&#34;, nmorph ).iMath(&#34;FillHoles&#34;)
            dist = ants.iMath( convexhull, &#34;MaurerDistance&#34; ) * -1.0
            distmask = ants.threshold_image( dist, mmfromconvexhull, 1.e80 )
            wmseg_mask = wmseg_mask + distmask
            if strict:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 2, 2 )
            else:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 1, 2 )
    ##############################################################################
    wmseg_2_flair = ants.apply_transforms(flair, wmseg_mask_use,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    seg_2_flair = ants.apply_transforms(flair, t1seg,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    csfmask = ants.threshold_image(seg_2_flair,1,1)
    flairsnr = mask_snr( flair, csfmask, wmseg_2_flair, bias_correct = False )
    probability_mask_WM = wmseg_2_flair * probability_mask # Remove WMH signal outside of WM
    wmh_sum = np.prod( ants.get_spacing( flair ) ) * probability_mask_WM.sum()
    wmh_sum_prior = math.nan
    probability_mask_posterior = None
    if prior_probability_flair is not None:
        probability_mask_posterior = prior_probability_flair * probability_mask # use prior
        wmh_sum_prior = np.prod( ants.get_spacing(flair) ) * probability_mask_posterior.sum()
    if math.isnan( wmh_sum ):
        wmh_sum=0
    if math.isnan( wmh_sum_prior ):
        wmh_sum_prior=0
    flair_evr = antspyt1w.patch_eigenvalue_ratio( flair, 512, [16,16,16], evdepth = 0.9, mask=wmseg_2_flair )
    return{
        &#39;WMH_probability_map_raw&#39;: probability_mask,
        &#39;WMH_probability_map&#39; : probability_mask_WM,
        &#39;WMH_posterior_probability_map&#39; : probability_mask_posterior,
        &#39;wmh_mass&#39;: wmh_sum,
        &#39;wmh_mass_prior&#39;: wmh_sum_prior,
        &#39;wmh_evr&#39; : flair_evr,
        &#39;wmh_SNR&#39; : flairsnr,
        &#39;convexhull_mask&#39;: distmask }


def replace_elements_in_numpy_array(original_array, indices_to_replace, new_value):
    &#34;&#34;&#34;
    Replace specified elements or rows in a numpy array with a new value.

    Parameters:
    original_array (numpy.ndarray): A numpy array in which elements or rows are to be replaced.
    indices_to_replace (list or numpy.ndarray): Indices of elements or rows to be replaced.
    new_value: The new value to replace the specified elements or rows.

    Returns:
    numpy.ndarray: A new numpy array with the specified elements or rows replaced. If the input array is None,
                   the function returns None.
    &#34;&#34;&#34;

    if original_array is None:
        return None

    max_index = original_array.size if original_array.ndim == 1 else original_array.shape[0]

    # Filter out invalid indices and check for any out-of-bounds indices
    valid_indices = []
    for idx in indices_to_replace:
        if idx &lt; max_index:
            valid_indices.append(idx)
        else:
            warnings.warn(f&#34;Warning: Index {idx} is out of bounds and will be ignored.&#34;)

    if original_array.ndim == 1:
        # Replace elements in a 1D array
        original_array[valid_indices] = new_value
    elif original_array.ndim == 2:
        # Replace rows in a 2D array
        original_array[valid_indices, :] = new_value
    else:
        raise ValueError(&#34;original_array must be either 1D or 2D.&#34;)

    return original_array



def remove_elements_from_numpy_array(original_array, indices_to_remove):
    &#34;&#34;&#34;
    Remove specified elements or rows from a numpy array.

    Parameters:
    original_array (numpy.ndarray): A numpy array from which elements or rows are to be removed.
    indices_to_remove (list or numpy.ndarray): Indices of elements or rows to be removed.

    Returns:
    numpy.ndarray: A new numpy array with the specified elements or rows removed. If the input array is None,
                   the function returns None.
    &#34;&#34;&#34;

    if original_array is None:
        return None

    if original_array.ndim == 1:
        # Remove elements from a 1D array
        return np.delete(original_array, indices_to_remove)
    elif original_array.ndim == 2:
        # Remove rows from a 2D array
        return np.delete(original_array, indices_to_remove, axis=0)
    else:
        raise ValueError(&#34;original_array must be either 1D or 2D.&#34;)

def remove_volumes_from_timeseries(time_series, volumes_to_remove):
    &#34;&#34;&#34;
    Remove specified volumes from a time series.

    :param time_series: ANTsImage representing the time series (4D image).
    :param volumes_to_remove: List of volume indices to remove.
    :return: ANTsImage with specified volumes removed.
    &#34;&#34;&#34;
    if not isinstance(time_series, ants.ANTsImage):
        raise ValueError(&#34;time_series must be an ANTsImage.&#34;)

    if time_series.dimension != 4:
        raise ValueError(&#34;time_series must be a 4D image.&#34;)

    # Create a boolean index for volumes to keep
    volumes_to_keep = [i for i in range(time_series.shape[3]) if i not in volumes_to_remove]

    # Select the volumes to keep
    filtered_time_series = ants.from_numpy( time_series[..., volumes_to_keep] )

    return ants.copy_image_info( time_series, filtered_time_series )

def remove_elements_from_list(original_list, elements_to_remove):
    &#34;&#34;&#34;
    Remove specified elements from a list.

    Parameters:
    original_list (list): The original list from which elements will be removed.
    elements_to_remove (list): A list of elements that need to be removed from the original list.

    Returns:
    list: A new list with the specified elements removed.
    &#34;&#34;&#34;
    return [element for element in original_list if element not in elements_to_remove]


def impute_timeseries(time_series, volumes_to_impute, method=&#39;linear&#39;, verbose=False):
    &#34;&#34;&#34;
    Impute specified volumes from a time series with interpolated values.

    :param time_series: ANTsImage representing the time series (4D image).
    :param volumes_to_impute: List of volume indices to impute.
    :param method: Interpolation method (&#39;linear&#39; or other methods if implemented).
    :param verbose: boolean
    :return: ANTsImage with specified volumes imputed.
    &#34;&#34;&#34;
    if not isinstance(time_series, ants.ANTsImage):
        raise ValueError(&#34;time_series must be an ANTsImage.&#34;)

    if time_series.dimension != 4:
        raise ValueError(&#34;time_series must be a 4D image.&#34;)

    # Convert time_series to numpy for manipulation
    time_series_np = time_series.numpy()
    total_volumes = time_series_np.shape[3]

    # Create a complement list of volumes not to impute
    volumes_not_to_impute = [i for i in range(total_volumes) if i not in volumes_to_impute]

    # Define the lower and upper bounds
    min_valid_index = min(volumes_not_to_impute)
    max_valid_index = max(volumes_not_to_impute)

    for vol_idx in volumes_to_impute:
        # Ensure the volume index is within the valid range
        if vol_idx &lt; 0 or vol_idx &gt;= total_volumes:
            raise ValueError(f&#34;Volume index {vol_idx} is out of bounds.&#34;)

        # Find the nearest valid lower index within the bounds
        lower_candidates = [v for v in volumes_not_to_impute if v &lt;= vol_idx]
        lower_idx = max(lower_candidates) if lower_candidates else min_valid_index

        # Find the nearest valid upper index within the bounds
        upper_candidates = [v for v in volumes_not_to_impute if v &gt;= vol_idx]
        upper_idx = min(upper_candidates) if upper_candidates else max_valid_index

        if verbose:
            print(f&#34;Imputing volume {vol_idx} using indices {lower_idx} and {upper_idx}&#34;)

        if method == &#39;linear&#39;:
            # Linear interpolation between the two nearest volumes
            lower_volume = time_series_np[..., lower_idx]
            upper_volume = time_series_np[..., upper_idx]
            interpolated_volume = (lower_volume + upper_volume) / 2
        else:
            # Placeholder for other interpolation methods
            raise NotImplementedError(&#34;Currently, only linear interpolation is implemented.&#34;)

        # Replace the specified volume with the interpolated volume
        time_series_np[..., vol_idx] = interpolated_volume

    # Convert the numpy array back to ANTsImage
    imputed_time_series = ants.from_numpy(time_series_np)
    imputed_time_series = ants.copy_image_info(time_series, imputed_time_series)

    return imputed_time_series

def impute_dwi( dwi, threshold = 0.20, imputeb0=False, mask=None, verbose=False ):
    &#34;&#34;&#34;
    Identify bad volumes in a dwi and impute them fully automatically.

    :param dwi: ANTsImage representing the time series (4D image).
    :param threshold: threshold (0,1) for outlierness (lower means impute more data)
    :param imputeb0: boolean will impute the b0 with dwi if True
    :param mask: restricts to a region of interest
    :param verbose: boolean
    :return: ANTsImage automatically imputed.
    &#34;&#34;&#34;
    list1 = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    if imputeb0:
        dwib = impute_timeseries( dwi, list1 ) # focus on the dwi - not the b0
        looped, list2 = loop_timeseries_censoring( dwib, threshold, mask )
    else:
        looped, list2 = loop_timeseries_censoring( dwi, threshold, mask )
    if verbose:
        print( list1 )
        print( list2 )
    complement = remove_elements_from_list( list2, list1 )
    if verbose:
        print( &#34;Imputing:&#34;)
        print( complement )
    if len( complement ) == 0:
        return dwi
    return impute_timeseries( dwi, complement )

def censor_dwi( dwi, bval, bvec, threshold = 0.20, imputeb0=False, mask=None, verbose=False ):
    &#34;&#34;&#34;
    Identify bad volumes in a dwi and impute them fully automatically.

    :param dwi: ANTsImage representing the time series (4D image).
    :param bval: bval array
    :param bvec: bvec array
    :param threshold: threshold (0,1) for outlierness (lower means impute more data)
    :param imputeb0: boolean will impute the b0 with dwi if True
    :param mask: restricts to a region of interest
    :param verbose: boolean
    :return: ANTsImage automatically imputed.
    &#34;&#34;&#34;
    list1 = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    if imputeb0:
        dwib = impute_timeseries( dwi, list1 ) # focus on the dwi - not the b0
        looped, list2 = loop_timeseries_censoring( dwib, threshold, mask )
    else:
        looped, list2 = loop_timeseries_censoring( dwi, threshold, mask )
    if verbose:
        print( list1 )
        print( list2 )
    complement = remove_elements_from_list( list2, list1 )
    if verbose:
        print( &#34;censoring:&#34;)
        print( complement )
    if len( complement ) == 0:
        return dwi, bval, bvec
    return remove_volumes_from_timeseries( dwi, complement ), remove_elements_from_numpy_array( bval, complement ), remove_elements_from_numpy_array( bvec, complement )


def flatten_time_series(time_series):
    &#34;&#34;&#34;
    Flatten a 4D time series into a 2D array.
    
    :param time_series: A 4D numpy array where the last dimension is time.
    :return: A 2D numpy array where each row is a flattened volume.
    &#34;&#34;&#34;
    n_volumes = time_series.shape[3]
    return time_series.reshape(-1, n_volumes).T

def calculate_loop_scores(flattened_series, n_neighbors=20):
    &#34;&#34;&#34;
    Calculate Local Outlier Probabilities for each volume.
    
    :param flattened_series: A 2D numpy array from flatten_time_series.
    :param n_neighbors: Number of neighbors to use for calculating LOF scores.
    :return: An array of LoOP scores.
    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    # replace nans with zero
    flattened_series=np.nan_to_num(flattened_series, nan=0)
    scaler = StandardScaler()
    scaler.fit(flattened_series)
    data = scaler.transform(flattened_series)
    data=np.nan_to_num(data, nan=0)
    if n_neighbors &gt; int(flattened_series.shape[0]/2.0):
        n_neighbors = int(flattened_series.shape[0]/2.0)
    neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=&#39;minkowski&#39;)
    neigh.fit(data)
    d, idx = neigh.kneighbors(data, return_distance=True)
    m = loop.LocalOutlierProbability(distance_matrix=d, neighbor_matrix=idx, n_neighbors=n_neighbors).fit()
    return m.local_outlier_probabilities[:]

def score_fmri_censoring(cbfts, csf_seg, gm_seg, wm_seg ):
    &#34;&#34;&#34;
    Process CBF time series to remove high-leverage points.
    Derived from the SCORE algorithm by Sudipto Dolui et. al.

    Parameters:
    cbfts (ANTsImage): 4D ANTsImage of CBF time series.
    csf_seg (ANTsImage): CSF binary map.
    gm_seg (ANTsImage): Gray matter binary map.
    wm_seg (ANTsImage): WM binary map.

    Returns:
    ANTsImage: Processed CBF time series.
    ndarray: Index of removed volumes.
    &#34;&#34;&#34;
    
    n_gm_voxels = np.sum(gm_seg.numpy()) - 1
    n_wm_voxels = np.sum(wm_seg.numpy()) - 1
    n_csf_voxels = np.sum(csf_seg.numpy()) - 1
    mask1img = gm_seg + wm_seg + csf_seg
    mask1 = (mask1img==1).numpy()
    
    cbfts_np = cbfts.numpy()
    gmbool = (gm_seg==1).numpy()
    csfbool = (csf_seg==1).numpy()
    wmbool = (wm_seg==1).numpy()
    gm_cbf_ts = ants.timeseries_to_matrix( cbfts, gm_seg )
    gm_cbf_ts = np.squeeze(np.mean(gm_cbf_ts, axis=1))
    
    median_gm_cbf = np.median(gm_cbf_ts)
    mad_gm_cbf = np.median(np.abs(gm_cbf_ts - median_gm_cbf)) / 0.675
    indx = np.abs(gm_cbf_ts - median_gm_cbf) &gt; (2.5 * mad_gm_cbf)
    
    # the spatial mean
    spatmeannp = np.mean(cbfts_np[:, :, :, ~indx], axis=3)
    spatmean = ants.from_numpy( spatmeannp )
    V = (
        n_gm_voxels * np.var(spatmeannp[gmbool])
        + n_wm_voxels * np.var(spatmeannp[wmbool])
        + n_csf_voxels * np.var(spatmeannp[csfbool])
    )
    V1 = math.inf
    ct=0
    while V &lt; V1:
        ct=ct+1
        V1 = V
        CC = np.zeros(cbfts_np.shape[3])
        for s in range(cbfts_np.shape[3]):
            if indx[s]:
                continue
            tmp1 = ants.from_numpy( cbfts_np[:, :, :, s] )
            CC[s] = ants.image_similarity( spatmean, tmp1, metric_type=&#39;Correlation&#39;, fixed_mask=mask1img )
        inx = np.argmin(CC)
        indx[inx] = True
        spatmeannp = np.mean(cbfts_np[:, :, :, ~indx], axis=3)
        spatmean = ants.from_numpy( spatmeannp )
        V = (
          n_gm_voxels * np.var(spatmeannp[gmbool]) + 
          n_wm_voxels * np.var(spatmeannp[wmbool]) + 
          n_csf_voxels * np.var(spatmeannp[csfbool])
        )
    cbfts_recon = cbfts_np[:, :, :, ~indx]
    cbfts_recon = np.nan_to_num(cbfts_recon)
    cbfts_recon_ants = ants.from_numpy(cbfts_recon)
    cbfts_recon_ants = ants.copy_image_info(cbfts, cbfts_recon_ants)
    return cbfts_recon_ants, indx

def loop_timeseries_censoring(x, threshold=0.5, mask=None, verbose=False):
    &#34;&#34;&#34;
    Censor high leverage volumes from a time series using Local Outlier Probabilities (LoOP).

    Parameters:
    x (ANTsImage): A 4D time series image.
    threshold (float): Threshold for determining high leverage volumes based on LoOP scores.
    mask (antsImage): restricts to a ROI
    verbose (bool)

    Returns:
    tuple: A tuple containing the censored time series (ANTsImage) and the indices of the high leverage volumes.
    &#34;&#34;&#34;
    import warnings
    if x.shape[3] &lt; 20: # just a guess at what we need here ...
        warnings.warn(&#34;Warning: the time dimension is &lt; 20 - too few samples for loop. just return the original data.&#34;)
        return x, []
    if mask is None:
        flattened_series = flatten_time_series(x.numpy())
    else:
        flattened_series = ants.timeseries_to_matrix( x, mask )
    loop_scores = calculate_loop_scores(flattened_series)
    high_leverage_volumes = np.where(loop_scores &gt; threshold)[0]
    if verbose:
        print(&#34;LOOP High Leverage Volumes:&#34;, high_leverage_volumes)
    new_asl = remove_volumes_from_timeseries(x, high_leverage_volumes)
    return new_asl, high_leverage_volumes


def novelty_detection_ee(df_train, df_test, contamination=0.05):
    &#34;&#34;&#34;
    This function performs novelty detection using Elliptic Envelope.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    import pandas as pd
    from sklearn.covariance import EllipticEnvelope
    # Fit the model on the training data
    clf = EllipticEnvelope(contamination=contamination,support_fraction=1)
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)



def novelty_detection_svm(df_train, df_test, nu=0.05, kernel=&#39;rbf&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using One-Class SVM.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)

    - kernel (str): kernel type used in the SVM algorithm (default: &#39;rbf&#39;)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    from sklearn.svm import OneClassSVM
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = OneClassSVM(nu=nu, kernel=kernel)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)



def novelty_detection_lof(df_train, df_test, n_neighbors=20):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOF (default: 20)

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, algorithm=&#39;auto&#39;,contamination=&#39;auto&#39;, novelty=True)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)


def novelty_detection_loop(df_train, df_test, n_neighbors=20, distance_metric=&#39;minkowski&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)

    - distance_metric : default minkowski

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    data = np.vstack( [scaler.transform(df_test),scaler.transform(df_train)])
    neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=distance_metric)
    neigh.fit(data)
    d, idx = neigh.kneighbors(data, return_distance=True)
    m = loop.LocalOutlierProbability(distance_matrix=d, neighbor_matrix=idx, n_neighbors=n_neighbors).fit()
    return m.local_outlier_probabilities[range(df_test.shape[0])]



def novelty_detection_quantile(df_train, df_test):
    &#34;&#34;&#34;
    This function performs novelty detection using quantiles for each column.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    Returns:

    - quantiles for the test sample at each column where values range in [0,1]
        and higher values mean the column is closer to the edge of the distribution

    &#34;&#34;&#34;
    myqs = df_test.copy()
    n = df_train.shape[0]
    df_trainkeys = df_train.keys()
    for k in range( df_train.shape[1] ):
        mykey = df_trainkeys[k]
        temp = (myqs[mykey][0] &gt;  df_train[mykey]).sum() / n
        myqs[mykey] = abs( temp - 0.5 ) / 0.5
    return myqs

def brainmap_figure(statistical_df, data_dictionary_path, output_prefix, brain_image, overlay_cmap=&#39;bwr&#39;, nslices=21, ncol=7, edge_image_dilation = 0, black_bg=True, axes = [0,1,2], fixed_overlay_range=None, crop=5, verbose=False ):
    &#34;&#34;&#34;
    Create figures based on statistical data and an underlying brain image.

    Assumes both ~/.antspyt1w and ~/.antspymm data is available

    Parameters:
    - statistical_df (pandas dataframe): with 2 columns named anat and values
        the anat column should have names that meet *partial matching* criterion 
        with respect to regions that are measured in antspymm.   value will be 
        the value to be displayed.   if two examples of a given region exist in 
        statistical_df, then the largest absolute value will be taken for display.
    - data_dictionary_path (str): Path to the data dictionary CSV file.
    - output_prefix (str): Prefix for the output figure filenames.
    - brain_image (antsImage): the brain image on which results will overlay.
    - overlay_cmap (str): see matplotlib
    - nslices (int): number of slices to show
    - ncol (int): number of columns to show
    - edge_image_dilation (int): integer greater than or equal to zero
    - black_bg (bool): boolean
    - axes (list): integer list typically [0,1,2] sagittal coronal axial
    - fixed_overlay_range (list): scalar pair will try to keep a constant cbar and will truncate the overlay at these min/max values
    - crop (int): crops the image to display by the extent of the overlay; larger values dilate the masks more.
    - verbose (bool): boolean

    Returns:
    an image with values mapped to the associated regions
    &#34;&#34;&#34;
    import re

    # Read the statistical file
    zz = statistical_df 
    
    # Read the data dictionary from a CSV file
    mydict = pd.read_csv(data_dictionary_path)
    mydict = mydict[~mydict[&#39;Measurement&#39;].str.contains(&#34;tractography-based connectivity&#34;, na=False)]

    # Load image and process it
    edgeimg = ants.iMath(brain_image,&#34;Normalize&#34;)
    if edge_image_dilation &gt; 0:
        edgeimg = ants.iMath( edgeimg, &#34;MD&#34;, edge_image_dilation)

    # Define lists and data frames
    postfix = [&#39;bf&#39;, &#39;cit168lab&#39;, &#39;mtl&#39;, &#39;cerebellum&#39;, &#39;dkt_cortex&#39;,&#39;brainstem&#39;,&#39;JHU_wm&#39;,&#39;yeo&#39;]
    atlas = [&#39;BF&#39;, &#39;CIT168&#39;, &#39;MTL&#39;, &#39;TustisonCobra&#39;, &#39;desikan-killiany-tourville&#39;,&#39;brainstem&#39;,&#39;JHU_wm&#39;,&#39;yeo&#39;]
    postdesc = [&#39;nbm3CH13&#39;, &#39;CIT168_Reinf_Learn_v1_label_descriptions_pad&#39;, &#39;mtl_description&#39;, &#39;cerebellum&#39;, &#39;dkt&#39;,&#39;CIT168_T1w_700um_pad_adni_brainstem&#39;,&#39;FA_JHU_labels_edited&#39;,&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;]
    statdf = pd.DataFrame({&#39;img&#39;: postfix, &#39;atlas&#39;: atlas, &#39;csvdescript&#39;: postdesc})
    templateprefix = &#39;~/.antspymm/PPMI_template0_&#39;
    # Iterate through columns and create figures
    col2viz = &#39;values&#39;
    if True:
        anattoshow = zz[&#39;anat&#39;].unique()
        if verbose:
            print(col2viz)
            print(anattoshow)
        # Rest of your code for figure creation goes here...
        addem = edgeimg * 0
        for k in range(len(anattoshow)):
            if verbose:
                print(str(k) +  &#34; &#34; + anattoshow[k]  )
            mysub = zz[zz[&#39;anat&#39;].str.contains(anattoshow[k])]
            anatsear=re.sub(&#34;dti.fa&#34;,&#34;&#34;,anattoshow[k])
            anatsear=re.sub(&#34;t1.volasym&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;t1.thkasym&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;t1.areaasym&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;t1.vol.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;t1.thk.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;t1.area.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;asymdp.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;asym.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;dti.md.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;dti.fa.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;dti.md&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;dti.mean.md.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;dti.mean.fa.&#34;,&#34;&#34;,anatsear)
            anatsear=re.sub(&#34;lravg&#34;,&#34;&#34;,anatsear)
            atlassearch = mydict[&#39;tidynames&#39;].str.contains(anatsear)
            if atlassearch.sum() &gt; 0:
                whichatlas = mydict[atlassearch][&#39;Atlas&#39;].iloc[0]
                oglabelname = mydict[atlassearch][&#39;Label&#39;].iloc[0]
            else:
                print(anatsear)
                oglabelname=&#39;unknown&#39;
                whichatlas=None
            if verbose:
                print(&#34;oglabelname &#34; + oglabelname )
            vals2viz = mysub[col2viz].agg([&#39;min&#39;, &#39;max&#39;])
            vals2viz = vals2viz[abs(vals2viz).idxmax()]
            myext = None
            if &#39;dktcortex&#39; in anattoshow[k]:
                myext = &#39;dkt_cortex&#39;
            elif &#39;cit168&#39; in anattoshow[k]:
                myext = &#39;cit168lab&#39;
            elif &#39;mtl&#39; in anattoshow[k]:
                myext = &#39;mtl&#39;
                oglabelname=re.sub(&#39;mtl&#39;, &#39;&#39;,anatsear)
            elif &#39;cerebellum&#39; in anattoshow[k]:
                myext = &#39;cerebellum&#39;
                oglabelname=re.sub(&#39;cerebellum&#39;, &#39;&#39;,anatsear)
                # oglabelname=oglabelname[2:]
            elif &#39;brainstem&#39; in anattoshow[k]:
                myext = &#39;brainstem&#39;
            elif any(item in anattoshow[k] for item in [&#39;nbm&#39;, &#39;bf&#39;]):
                myext = &#39;bf&#39;
                oglabelname=re.sub(r&#39;\.&#39;, &#39;_&#39;,anatsear)
            elif whichatlas == &#39;johns hopkins white matter&#39;:
                myext = &#39;JHU_wm&#39;
            elif whichatlas == &#39;desikan-killiany-tourville&#39;:
                myext = &#39;dkt_cortex&#39;
            elif whichatlas == &#39;CIT168&#39;:
                myext = &#39;cit168lab&#39;
            elif whichatlas == &#39;BF&#39;:
                myext = &#39;bf&#39;
                oglabelname=re.sub(&#39;bf&#39;, &#39;&#39;,oglabelname)
            elif whichatlas == &#39;yeo_homotopic&#39;:
                myext = &#39;yeo&#39;
            if myext is None and verbose:
                print( &#34;MYEXT &#34; + anattoshow[k] + &#39; unfound &#39; + whichatlas )
            else:
                if verbose:
                    print( &#34;MYEXT &#34; + myext )

            if myext == &#39;cit168lab&#39;:
                oglabelname=re.sub(&#34;cit168&#34;,&#34;&#34;,oglabelname)
            
            for j in postfix:
                if j == &#34;dkt_cortex&#34;:
                    j = &#39;dktcortex&#39;
                if j == &#34;deep_cit168lab&#34;:
                    j = &#39;deep_cit168&#39;
                anattoshow[k] = anattoshow[k].replace(j, &#34;&#34;)
            if verbose:
                print( anattoshow[k] + &#34; &#34; + str( vals2viz ) )
            myatlas = atlas[postfix.index(myext)]
            correctdescript = postdesc[postfix.index(myext)]
            locfilename =  templateprefix + myext + &#39;.nii.gz&#39;
            if verbose:
                print( locfilename )
            if myext == &#39;yeo&#39;:
                oglabelname=oglabelname.lower()
                oglabelname=re.sub(&#34;rsfmri_fcnxpro122_&#34;,&#34;&#34;,oglabelname)
                oglabelname=re.sub(&#34;rsfmri_fcnxpro129_&#34;,&#34;&#34;,oglabelname)
                oglabelname=re.sub(&#34;rsfmri_fcnxpro134_&#34;,&#34;&#34;,oglabelname)
                locfilename = &#34;~/.antspymm/ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic.nii.gz&#34;
                atlasDescript = pd.read_csv(f&#34;~/.antspymm/{correctdescript}.csv&#34;)
                atlasDescript.rename(columns={&#39;SystemName&#39;: &#39;Description&#39;}, inplace=True)
                atlasDescript.rename(columns={&#39;ROI&#39;: &#39;Label&#39;}, inplace=True)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.lower()
            else:
                atlasDescript = pd.read_csv(f&#34;~/.antspyt1w/{correctdescript}.csv&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.lower()
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34; &#34;, &#34;_&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;_left_&#34;, &#34;_&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;_right_&#34;, &#34;_&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;_left&#34;, &#34;&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;_right&#34;, &#34;&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;left_&#34;, &#34;&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;right_&#34;, &#34;&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;/&#34;,&#34;.&#34;)
                if myext == &#39;JHU_wm&#39;:
                    atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;fa-&#34;, &#34;&#34;)
                    atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;-left-&#34;, &#34;&#34;)
                    atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;-right-&#34;, &#34;&#34;)
                if myext == &#39;cerebellum&#39;:
                    atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;l_&#34;, &#34;&#34;)
                    atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;r_&#34;, &#34;&#34;)

            if verbose:
                print( atlasDescript )
            oglabelname = oglabelname.lower()
            oglabelname = re.sub(&#34; &#34;, &#34;_&#34;,oglabelname)
            oglabelname = re.sub(&#34;_left_&#34;, &#34;_&#34;,oglabelname)
            oglabelname = re.sub(&#34;_right_&#34;, &#34;_&#34;,oglabelname)
            oglabelname = re.sub(&#34;_left&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;_right&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;t1hier_vol_&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;t1hier_area_&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;t1hier_thk_&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;dktregions&#34;, &#34;&#34;,oglabelname)
            oglabelname = re.sub(&#34;dktcortex&#34;, &#34;&#34;,oglabelname)
            if myext == &#39;JHU_wm&#39;:
                oglabelname = re.sub(&#34;dti_mean_fa.&#34;, &#34;&#34;,oglabelname)
                oglabelname = re.sub(&#34;dti_mean_md.&#34;, &#34;&#34;,oglabelname)
                oglabelname = re.sub(&#34;.left.&#34;, &#34;&#34;,oglabelname)
                oglabelname = re.sub(&#34;.right.&#34;, &#34;&#34;,oglabelname)
                oglabelname = re.sub(&#34;.lravg.&#34;, &#34;&#34;,oglabelname)
                oglabelname = re.sub(&#34;.asym.&#34;, &#34;&#34;,oglabelname)

            if verbose:
                print(&#34;oglabelname &#34; + oglabelname )

            if myext == &#39;cerebellum&#39;:
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;l_&#34;, &#34;&#34;)
                atlasDescript[&#39;Description&#39;] = atlasDescript[&#39;Description&#39;].str.replace(&#34;r_&#34;, &#34;&#34;)
                whichindex = atlasDescript.index[atlasDescript[&#39;Description&#39;] == oglabelname].values[0]
            else:
                whichindex = atlasDescript.index[atlasDescript[&#39;Description&#39;].str.contains(oglabelname)]

            if type(whichindex) is np.int64:
                labelnums = atlasDescript.loc[whichindex, &#39;Label&#39;]
            else:
                labelnums = list(atlasDescript.loc[whichindex, &#39;Label&#39;])

            if myext == &#39;yeo&#39;:
                parts = re.findall(r&#39;\D+&#39;, oglabelname)
                oglabelname = [part.replace(&#39;_&#39;, &#39;&#39;) for part in parts if part.replace(&#39;_&#39;, &#39;&#39;)]
                filtered_df = atlasDescript[atlasDescript[&#39;Description&#39;].isin(oglabelname)]
                labelnums = filtered_df[&#39;Label&#39;].tolist()

            if not isinstance(labelnums, list):
                labelnums=[labelnums]
            addemiszero = ants.threshold_image(addem, 0, 0)
            temp = ants.image_read(locfilename)
            temp = ants.mask_image(temp, temp, level=labelnums, binarize=True)
            if verbose:
                print(&#34;DEBUG&#34;)
                print(  temp.sum() ) 
                print( labelnums )
            temp[temp == 1] = (vals2viz)
            temp[addemiszero == 0] = 0
            addem = addem + temp

        if verbose:
            print(&#39;Done Adding&#39;)
        for axx in axes:
            figfn=output_prefix+f&#34;fig{col2viz}ax{axx}_py.jpg&#34;
            if crop &gt; 0:
                cmask = ants.threshold_image( addem,1e-5, 1e9 ).iMath(&#34;MD&#34;,crop) + ants.threshold_image( addem,-1e9, -1e-5 ).iMath(&#34;MD&#34;,crop)
                addemC = ants.crop_image( addem, cmask )
                edgeimgC = ants.crop_image( edgeimg, cmask )
            else:
                addemC = addem
                edgeimgC = edgeimg
            if fixed_overlay_range is not None:
                addemC[0:3,0:3,0:3]=fixed_overlay_range[0]
                addemC[4:7,4:7,4:7]=fixed_overlay_range[1]
                addemC[ addemC &lt; fixed_overlay_range[0] ] = fixed_overlay_range[0]
                addemC[ addemC &gt; fixed_overlay_range[1] ] = fixed_overlay_range[1]
            ants.plot(edgeimgC, addemC, axis=axx, nslices=nslices, ncol=ncol,       
                overlay_cmap=overlay_cmap, resample=False,
                filename=figfn, cbar=axx==axes[0], crop=True, black_bg=black_bg )
        if verbose:
            print(f&#34;{col2viz} done&#34;)
    if verbose:
        print(&#34;DONE brain map figures&#34;)
    return addem

def filter_df(indf, myprefix):
    &#34;&#34;&#34;
    Process and filter a pandas DataFrame, removing certain columns, 
    filtering based on data types, computing the mean of numeric columns, 
    and adding a prefix to column names.

    Parameters:
    indf (pandas.DataFrame): The input DataFrame to be processed.
    myprefix (str): A string prefix to be added to the column names 
                    of the processed DataFrame.

    Steps:
    1. Removes columns with names containing &#39;Unnamed&#39;.
    2. If the DataFrame has no rows, it returns the empty DataFrame.
    3. Filters out columns based on the type of the first element, 
       keeping those that are of type `object`, `int`, or `float`.
    4. Removes columns that are of `object` dtype.
    5. Calculates the mean of the remaining columns, skipping NaN values.
    6. Adds the specified `myprefix` to the column names.

    Returns:
    pandas.DataFrame: A transformed DataFrame with a single row containing 
                      the mean values of the filtered columns, and with 
                      column names prefixed as specified.
    &#34;&#34;&#34;
    indf = indf.loc[:, ~indf.columns.str.contains(&#39;Unnamed*&#39;, na=False, regex=True)]
    if indf.shape[0] == 0:
        return indf
    nums = [isinstance(indf[col].iloc[0], (object, int, float)) for col in indf.columns]
    indf = indf.loc[:, nums]
    indf = indf.loc[:, indf.dtypes != &#39;object&#39;]
    indf = pd.DataFrame(indf.mean(axis=0, skipna=True)).T
    indf = indf.add_prefix(myprefix)
    return indf


def aggregate_antspymm_results(input_csv, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, date_column=&#39;ses-1&#39;, base_path=&#34;./Processed/ANTsExpArt/&#34;, hiervariable=&#39;T1wHierarchical&#39;, valid_modalities=None, verbose=False ):
    &#34;&#34;&#34;
    Aggregate ANTsPyMM results from the specified CSV file and save the aggregated results to a new CSV file.

    Parameters:
    - input_csv (str): File path of the input CSV file containing ANTsPyMM QC results averaged and with outlier measurements.
    - subject_col (str): Name of the column to store subject IDs.
    - date_col (str): Name of the column to store date information.
    - image_col (str): Name of the column to store image IDs.
    - date_column (str): Name of the column representing the date information.
    - base_path (str): Base path for search paths. Defaults to &#34;./Processed/ANTsExpArt/&#34;.
    - hiervariable (str) : the string variable denoting the Hierarchical output
    - valid_modalities (str array) : identifies for each modality; if None will be replaced by get_valid_modalities(long=True)
    - verbose : boolean

    Note:
    This function is tested under limited circumstances. Use with caution.

    Example usage:
    agg_df = aggregate_antspymm_results(&#34;qcdfaol.csv&#34;, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, date_column=&#39;ses-1&#39;, base_path=&#34;./Your/Custom/Path/&#34;)

    Author:
    Avants and ChatGPT
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    from glob import glob

    def myread_csv(x, cnms):
        &#34;&#34;&#34;
        Reads a CSV file and returns a DataFrame excluding specified columns.

        Parameters:
        - x (str): File path of the input CSV file describing the blind QC output
        - cnms (list): List of column names to exclude from the DataFrame.

        Returns:
        pd.DataFrame: DataFrame with specified columns excluded.
        &#34;&#34;&#34;
        df = pd.read_csv(x)
        return df.loc[:, ~df.columns.isin(cnms)]

    import warnings
    # Warning message for untested function
    warnings.warn(&#34;Warning: This function is not well tested. Use with caution.&#34;)

    if valid_modalities is None:
        valid_modalities = get_valid_modalities(&#39;long&#39;)

    # Read the input CSV file
    df = pd.read_csv(input_csv)

    # Filter rows where modality is &#39;T1w&#39;
    df = df[df[&#39;modality&#39;] == &#39;T1w&#39;]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)

    # Add new columns for subject ID, date, and image ID
    df[subject_col] = np.nan
    df[date_col] = date_column
    df[image_col] = np.nan
    df = df.astype({subject_col: str, date_col: str, image_col: str })

#    if verbose:
#        print( df.shape )
#        print( df.dtypes )

    # prefilter df for data that exists
    keep = np.tile( False, df.shape[0] )
    for x in range(df.shape[0]):
        temp = df[&#39;filename&#39;].iloc[x].split(&#34;_&#34;)
        # Generalized search paths
        path_template = f&#34;{base_path}{temp[0]}/{date_column}/*/*/*&#34;
        hierfn = sorted(glob( path_template + &#34;-&#34; + hiervariable + &#34;-*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            keep[x]=True

    
    df=df[keep]
    
    if verbose:
        print( &#34;original input had shape &#34; + str( df.shape[0] ) + &#34; (T1 only) and we find &#34; + str( (keep).sum() ) + &#34; with hierarchical output defined by variable: &#34; + hiervariable )
        print( df.shape )

    myct = 0
    for x in range( df.shape[0]):
        if verbose:
            print(f&#34;{x}...&#34;)
        locind = df.index[x]
        temp = df[&#39;filename&#39;].iloc[x].split(&#34;_&#34;)
        if verbose:
            print( temp )
        df[subject_col].iloc[x]=temp[0]
        df[date_col].iloc[x]=date_column
        df[image_col].iloc[x]=temp[1]

        # Generalized search paths
        path_template = f&#34;{base_path}{temp[0]}/{date_column}/*/*/*&#34;
        if verbose:
            print(path_template)
        hierfn = sorted(glob( path_template + &#34;-&#34; + hiervariable + &#34;-*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            hdf=t1df=dtdf=rsdf=perfdf=nmdf=flairdf=None
            if verbose:
                print(hierfn)
            hdf = pd.read_csv(hierfn[0])
            badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], hdf )
            hdf=hdf.drop(badnames, axis=1)
            nums = [isinstance(hdf[col].iloc[0], (int, float)) for col in hdf.columns]
            corenames = list(np.array(hdf.columns)[nums])
            hdf.loc[:, nums] = hdf.loc[:, nums].add_prefix(&#34;T1Hier_&#34;)
            myct = myct + 1
            dflist = [hdf]

            for mymod in valid_modalities:
                t1wfn = sorted(glob( path_template+ &#34;-&#34; + mymod + &#34;-*wide.csv&#34; ) )
                if len( t1wfn ) &gt; 0 :
                    if verbose:
                        print(t1wfn)
                    t1df = myread_csv(t1wfn[0], corenames)
                    t1df = filter_df( t1df, mymod+&#39;_&#39;)
                    dflist = dflist + [t1df]
                
            hdf = pd.concat( dflist, axis=1, ignore_index=False )
            if verbose:
                print( df.loc[locind,&#39;filename&#39;] )
            if myct == 1:
                subdf = df.iloc[[x]]
                hdf.index = subdf.index.copy()
                df = pd.concat( [df,hdf], axis=1, ignore_index=False )
            else:
                commcols = list(set(hdf.columns).intersection(df.columns))
                df.loc[locind, commcols] = hdf.loc[0, commcols]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)
    return( df )

def find_most_recent_file(file_list):
    &#34;&#34;&#34;
    Finds and returns the most recently modified file from a list of file paths.
    
    Parameters:
    - file_list: A list of strings, where each string is a path to a file.
    
    Returns:
    - The path to the most recently modified file in the list, or None if the list is empty or contains no valid files.
    &#34;&#34;&#34;
    # Filter out items that are not files or do not exist
    valid_files = [f for f in file_list if os.path.isfile(f)]
    
    # Check if the filtered list is not empty
    if valid_files:
        # Find the file with the latest modification time
        most_recent_file = max(valid_files, key=os.path.getmtime)
        return [most_recent_file]
    else:
        return None
    
def aggregate_antspymm_results_sdf(
    study_df, 
    project_col=&#39;projectID&#39;,
    subject_col=&#39;subjectID&#39;, 
    date_col=&#39;date&#39;, 
    image_col=&#39;imageID&#39;, 
    base_path=&#34;./&#34;, 
    hiervariable=&#39;T1wHierarchical&#39;, 
    splitsep=&#39;-&#39;,
    idsep=&#39;-&#39;,
    wild_card_modality_id=False,
    verbose=False ):
    &#34;&#34;&#34;
    Aggregate ANTsPyMM results from the specified study data frame and store the aggregated results in a new data frame.  This assumes data is organized on disk 
    as follows:  rootdir/projectID/subjectID/date/outputid/imageid/ where 
    outputid is modality-specific and created by ANTsPyMM processing.

    Parameters:
    - study_df (pandas df): pandas data frame, output of generate_mm_dataframe.
    - project_col (str): Name of the column that stores the project ID
    - subject_col (str): Name of the column to store subject IDs.
    - date_col (str): Name of the column to store date information.
    - image_col (str): Name of the column to store image IDs.
    - base_path (str): Base path for searching for processing outputs of ANTsPyMM.
    - hiervariable (str) : the string variable denoting the Hierarchical output
    - splitsep (str):  the separator used to split the filename
    - idsep (str): the separator used to partition subjectid date and imageid 
        for example, if idsep is - then we have subjectid-date-imageid
    - wild_card_modality_id (bool): keep if False for safer execution
    - verbose : boolean

    Note:
    This function is tested under limited circumstances. Use with caution.
    One particular gotcha is if the imageID is stored as a numeric value in the dataframe 
    but is meant to be a string.  E.g. &#39;000&#39; (string) would be interpreted as 0 in the 
    file name glob.  This would miss the extant (on disk) csv.

    Example usage:
    agg_df = aggregate_antspymm_results_sdf( studydf, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, base_path=&#34;./Your/Custom/Path/&#34;)

    Author:
    Avants and ChatGPT
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    from glob import glob

    def progress_reporter(current_step, total_steps, width=50):
        # Calculate the proportion of progress
        progress = current_step / total_steps
        # Calculate the number of &#39;filled&#39; characters in the progress bar
        filled_length = int(width * progress)
        # Create the progress bar string
        bar = &#39;█&#39; * filled_length + &#39;-&#39; * (width - filled_length)
        # Print the progress bar with percentage
        print(f&#39;\rProgress: |{bar}| {int(100 * progress)}%&#39;, end=&#39;\r&#39;)
        # Print a new line when the progress is complete
        if current_step == total_steps:
            print()

    def myread_csv(x, cnms):
        &#34;&#34;&#34;
        Reads a CSV file and returns a DataFrame excluding specified columns.

        Parameters:
        - x (str): File path of the input CSV file describing the blind QC output
        - cnms (list): List of column names to exclude from the DataFrame.

        Returns:
        pd.DataFrame: DataFrame with specified columns excluded.
        &#34;&#34;&#34;
        df = pd.read_csv(x)
        return df.loc[:, ~df.columns.isin(cnms)]

    import warnings
    # Warning message for untested function
    warnings.warn(&#34;Warning: This function is not well tested. Use with caution.&#34;)

    vmoddict = {}
    # Add key-value pairs
    vmoddict[&#39;imageID&#39;] = &#39;T1w&#39;
    vmoddict[&#39;flairid&#39;] = &#39;T2Flair&#39;
    vmoddict[&#39;perfid&#39;] = &#39;perf&#39;
    vmoddict[&#39;rsfid1&#39;] = &#39;rsfMRI&#39;
#    vmoddict[&#39;rsfid2&#39;] = &#39;rsfMRI&#39;
    vmoddict[&#39;dtid1&#39;] = &#39;DTI&#39;
#    vmoddict[&#39;dtid2&#39;] = &#39;DTI&#39;
    vmoddict[&#39;nmid1&#39;] = &#39;NM2DMT&#39;
#    vmoddict[&#39;nmid2&#39;] = &#39;NM2DMT&#39;

    # Filter rows where modality is &#39;T1w&#39;
    df = study_df[ study_df[&#39;modality&#39;] == &#39;T1w&#39;]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)
    # prefilter df for data that exists
    keep = np.tile( False, df.shape[0] )
    for x in range(df.shape[0]):
        myfn = os.path.basename( df[&#39;filename&#39;].iloc[x] )
        temp = myfn.split( splitsep )
        # Generalized search paths
        sid0 = str( temp[0] )
        sid = str( df[subject_col].iloc[x] )
        if sid0 != sid:
            warnings.warn(&#34;OUTER: the id derived from the filename &#34; + sid + &#34; does not match the id stored in the data frame &#34; + sid )
            warnings.warn( &#34;filename is : &#34; +  myfn )
            warnings.warn( &#34;sid is : &#34; + sid )
            warnings.warn( &#34;x is : &#34; + str(x) )
        myproj = str(df[project_col].iloc[x])
        mydate = str(df[date_col].iloc[x])
        myid = str(df[image_col].iloc[x])
        path_template = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + hiervariable + &#39;/&#39; + str(myid) + &#34;/&#34;
        hierfn = sorted(glob( path_template + &#34;*&#34; + hiervariable + &#34;*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            keep[x]=True

    df=df[keep]

    if not df.index.is_unique:
        warnings.warn(&#34;data frame does not have unique indices.  we therefore reset the index to allow the function to continue on.&#34; )
        df = df.reset_index()

    
    if verbose:
        print( &#34;original input had shape &#34; + str( df.shape[0] ) + &#34; (T1 only) and we find &#34; + str( (keep).sum() ) + &#34; with hierarchical output defined by variable: &#34; + hiervariable )
        print( df.shape )

    dfout = pd.DataFrame()
    myct = 0
    for x in range( df.shape[0]):
        if verbose:
            print(&#34;\n\n-------------------------------------------------&#34;)
            print(f&#34;{x}...&#34;)
        else:
            progress_reporter(x, df.shape[0], width=500)
        locind = df.index[x]
        myfn = os.path.basename( df[&#39;filename&#39;].iloc[x] )
        sid = str( df[subject_col].iloc[x] )
        tempB = myfn.split( splitsep )
        sid0 = str(tempB[1])
        if sid0 != sid and verbose:
            warnings.warn(&#34;INNER: the id derived from the filename &#34; + str(sid) + &#34; does not match the id stored in the data frame &#34; + str(sid0) )
            warnings.warn( &#34;filename is : &#34; +  str(myfn) )
            warnings.warn( &#34;sid is : &#34; + str(sid) )
            warnings.warn( &#34;x is : &#34; + str(x) )
            warnings.warn( &#34;index is : &#34; + str(locind) )
        myproj = str(df[project_col].iloc[x])
        mydate = str(df[date_col].iloc[x])
        myid = str(df[image_col].iloc[x])
        myt1id = myid
        if verbose:
            print( myfn )
            print( temp )
            print( &#34;id &#34; + sid  )
        path_template = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + hiervariable + &#39;/&#39; + str(myid) + &#34;/&#34;
        searchhier = path_template + &#34;*&#34; + hiervariable + &#34;*wide.csv&#34;
        if verbose:
            print( searchhier )
        hierfn = sorted( glob( searchhier ) )
        if len( hierfn ) &gt; 1:
            raise ValueError(&#34;there are &#34; + str( len( hierfn ) ) + &#34; number of hier fns with search path &#34; + searchhier )
        if len( hierfn ) == 1:
            hdf=t1df=dtdf=rsdf=perfdf=nmdf=flairdf=None
            if verbose:
                print(hierfn)
            hdf = pd.read_csv(hierfn[0])
            if verbose:
                print( hdf[&#39;vol_hemisphere_lefthemispheres&#39;] )
            badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], hdf )
            hdf=hdf.drop(badnames, axis=1)
            nums = [isinstance(hdf[col].iloc[0], (int, float)) for col in hdf.columns]
            corenames = list(np.array(hdf.columns)[nums])
            # hdf.loc[:, nums] = hdf.loc[:, nums].add_prefix(&#34;T1Hier_&#34;)
            hdf = hdf.add_prefix(&#34;T1Hier_&#34;)
            myct = myct + 1
            dflist = [hdf]

            for mymod in vmoddict.keys():
                if verbose:
                    print(&#34;\n\n************************* &#34; + mymod + &#34; *************************&#34;)
                modalityclass = vmoddict[ mymod ]
                if wild_card_modality_id:
                    mymodid = &#39;*&#39;
                else:
                    mymodid = str( df[mymod].iloc[x] )
                    if mymodid.lower() != &#34;nan&#34; and mymodid.lower() != &#34;na&#34;:
                        mymodid = os.path.basename( mymodid )
                        mymodid = os.path.splitext( mymodid )[0]
                        mymodid = os.path.splitext( mymodid )[0]
                        temp = mymodid.split( idsep )
                        mymodid = temp[ len( temp )-1 ]
                    else:
                        if verbose:
                            print(&#34;missing&#34;)
                        continue
                if verbose:
                    print( &#34;modality id is &#34; + mymodid + &#34; for modality &#34; + modalityclass + &#39; modality specific subj &#39; + sid + &#39; modality specific id is &#39; + myid + &#34; its date &#34; +  mydate )
                modalityclasssearch = modalityclass
                if modalityclass in [&#39;rsfMRI&#39;,&#39;DTI&#39;]:
                    modalityclasssearch=modalityclass+&#34;*&#34;
                path_template_m = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + modalityclasssearch + &#39;/&#39; + mymodid + &#34;/&#34;
                modsearch = path_template_m + &#34;*&#34; + modalityclasssearch + &#34;*wide.csv&#34;
                if verbose:
                    print( modsearch )
                t1wfn = sorted( glob( modsearch ) )
                if len( t1wfn ) &gt; 1:
                    nlarge = len(t1wfn)
                    t1wfn = find_most_recent_file( t1wfn )
                    warnings.warn(&#34;there are &#34; + str( nlarge ) + &#34; number of wide fns with search path &#34; + modsearch + &#34; we take the most recent of these &#34; + t1wfn[0] )
#                    raise ValueError(&#34;there are &#34; + str( len( t1wfn ) ) + &#34; number of wide fns with search path &#34; + modsearch )
                if len( t1wfn ) == 1:
                    if verbose:
                        print(t1wfn)
                    t1df = myread_csv(t1wfn[0], corenames)
                    t1df = filter_df( t1df, modalityclass+&#39;_&#39;)
                    dflist = dflist + [t1df]
                else:
                    if verbose:
                        print( &#34; cannot find &#34; + modsearch )
                
            hdf = pd.concat( dflist, axis=1, ignore_index=False)
            if verbose:
                print( &#34;count: &#34; + str( myct ) )
            subdf = df.iloc[[x]]
            hdf.index = subdf.index.copy()
            subdf = pd.concat( [subdf,hdf], axis=1, ignore_index=False)
            dfout = pd.concat( [dfout,subdf], axis=0, ignore_index=False )
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], dfout )
    dfout=dfout.drop(badnames, axis=1)
    return( dfout )

def enantiomorphic_filling_without_mask( image, axis=0, intensity=&#39;low&#39; ):
    &#34;&#34;&#34;
    Perform an enantiomorphic lesion filling on an image without a lesion mask.

    Args:
    image (antsImage): The ants image to flip and fill
    axis ( int ): the axis along which to reflect the image
    intensity ( str ) : low or high

    Returns:
    ants.ANTsImage: The image after enantiomorphic filling.
    &#34;&#34;&#34;
    imagen = ants.iMath( image, &#39;Normalize&#39; )
    imagen = ants.iMath( imagen, &#34;TruncateIntensity&#34;, 1e-6, 0.98 )
    imagen = ants.iMath( imagen, &#39;Normalize&#39; )
    # Create a mirror image (flipping left and right)
    mirror_image = ants.reflect_image(imagen, axis=0, tx=&#39;SyN&#39; )[&#39;warpedmovout&#39;]

    # Create a symmetric version of the image by averaging the original and the mirror image
    symmetric_image = imagen * 0.5 + mirror_image * 0.5

    # Identify potential lesion areas by finding differences between the original and symmetric image
    difference_image = image - symmetric_image
    diffseg = ants.threshold_image(difference_image, &#34;Otsu&#34;, 3 )
    if intensity == &#39;low&#39;:
        likely_lesion = ants.threshold_image( diffseg, 1,  1)
    else:
        likely_lesion = ants.threshold_image( diffseg, 3,  3)
    likely_lesion = ants.smooth_image( likely_lesion, 3.0 ).iMath(&#34;Normalize&#34;)
    lesionneg = ( imagen*0+1.0 ) - likely_lesion
    filled_image = ants.image_clone(imagen)    
    filled_image = imagen * lesionneg + mirror_image * likely_lesion

    return filled_image, diffseg



def filter_image_files(image_paths, criteria=&#39;largest&#39;):
    &#34;&#34;&#34;
    Filters a list of image file paths based on specified criteria and returns 
    the path of the image that best matches that criteria (smallest, largest, or brightest).

    Args:
    image_paths (list): A list of file paths to the images.
    criteria (str): Criteria for selecting the image (&#39;smallest&#39;, &#39;largest&#39;, &#39;brightest&#39;).

    Returns:
    str: The file path of the selected image, or None if no valid images are found.
    &#34;&#34;&#34;
    import numpy as np
    if not image_paths:
        return None

    selected_image_path = None
    if criteria == &#39;smallest&#39; or criteria == &#39;largest&#39;:
        extreme_volume = None

        for path in image_paths:
            try:
                image = ants.image_read(path)
                volume = np.prod(image.shape)

                if criteria == &#39;largest&#39;:
                    if extreme_volume is None or volume &gt; extreme_volume:
                        extreme_volume = volume
                        selected_image_path = path
                elif criteria == &#39;smallest&#39;:
                    if extreme_volume is None or volume &lt; extreme_volume:
                        extreme_volume = volume
                        selected_image_path = path

            except Exception as e:
                print(f&#34;Error processing image {path}: {e}&#34;)

    elif criteria == &#39;brightest&#39;:
        max_brightness = None

        for path in image_paths:
            try:
                image = ants.image_read(path)
                brightness = np.mean(image.numpy())

                if max_brightness is None or brightness &gt; max_brightness:
                    max_brightness = brightness
                    selected_image_path = path

            except Exception as e:
                print(f&#34;Error processing image {path}: {e}&#34;)

    else:
        raise ValueError(&#34;Criteria must be &#39;smallest&#39;, &#39;largest&#39;, or &#39;brightest&#39;.&#34;)

    return selected_image_path



def mm_match_by_qc_scoring(df_a, df_b, match_column, criteria, prefix=&#39;matched_&#39;, exclude_columns=None):
    &#34;&#34;&#34;
    Match each row in df_a to a row in df_b based on a matching column and criteria for selecting the best match,
    with options to prefix column names from df_b and exclude certain columns from the final output. Additionally,
    returns a DataFrame containing rows from df_b that were not matched to any row in df_a.

    Parameters:
    - df_a: DataFrame A.
    - df_b: DataFrame B.
    - match_column: The column name on which rows should match between DataFrame A and B.
    - criteria: A dictionary where keys are column names and values are &#39;min&#39; or &#39;max&#39;, indicating whether
                the column should be minimized or maximized for the best match.
    - prefix: A string prefix to add to column names from df_b in the final output to avoid duplication.
    - exclude_columns: A list of column names from df_b to exclude from the final output.
    
    Returns:
    - A tuple of two DataFrames: 
        1. A new DataFrame combining df_a with matched rows from df_b.
        2. A DataFrame containing rows from df_b that were not matched to df_a.
    &#34;&#34;&#34;
    from scipy.stats import zscore
    df_a = df_a.loc[:, ~df_a.columns.str.startswith(&#39;Unnamed:&#39;)]
    df_b = df_b.loc[:, ~df_b.columns.str.startswith(&#39;Unnamed:&#39;)].copy()
    
    # Normalize df_b based on criteria
    for col, crit in criteria.items():
        if crit == &#39;max&#39;:
            df_b.loc[df_b.index, f&#39;score_{col}&#39;] = zscore(-df_b[col])
        elif crit == &#39;min&#39;:
            df_b.loc[df_b.index, f&#39;score_{col}&#39;] = zscore(df_b[col])

    # Calculate &#39;best_score&#39; by summing all score columns
    score_columns = [f&#39;score_{col}&#39; for col in criteria.keys()]
    df_b[&#39;best_score&#39;] = df_b[score_columns].sum(axis=1)

    matched_indices = []  # Track indices of matched rows in df_b

    # Match rows
    matched_rows = []
    for _, row_a in df_a.iterrows():
        matches = df_b[df_b[match_column] == row_a[match_column]]
        if not matches.empty:
            best_idx = matches[&#39;best_score&#39;].idxmin()
            best_match = matches.loc[best_idx]
            matched_indices.append(best_idx)  # Track this index as matched
            matched_rows.append(best_match)
        else:
            matched_rows.append(pd.Series(dtype=&#39;float64&#39;))

    # Create a DataFrame from matched rows
    df_matched = pd.DataFrame(matched_rows).reset_index(drop=True)
    
    # Exclude specified columns and add prefix
    if exclude_columns is not None:
        df_matched = df_matched.drop(columns=exclude_columns, errors=&#39;ignore&#39;)
    df_matched = df_matched.rename(columns=lambda x: f&#34;{prefix}{x}&#34; if x != match_column and x in df_matched.columns else x)

    # Combine df_a with matched rows from df_b
    result_df = pd.concat([df_a.reset_index(drop=True), df_matched], axis=1)
    
    # Extract unmatched rows from df_b
    unmatched_df_b = df_b.drop(index=matched_indices).reset_index(drop=True)

    return result_df, unmatched_df_b


def fix_LR_RL_stuff(df, col1, col2, size_col1, size_col2, id1, id2 ):
    df_copy = df.copy()
    # Ensure columns contain strings for substring checks
    df_copy[col1] = df_copy[col1].astype(str)
    df_copy[col2] = df_copy[col2].astype(str)
    df_copy[id1] = df_copy[id1].astype(str)
    df_copy[id2] = df_copy[id2].astype(str)
    
    for index, row in df_copy.iterrows():
        col1_val = row[col1]
        col2_val = row[col2]
        size1 = row[size_col1]
        size2 = row[size_col2]
        
        # Check for &#39;RL&#39; or &#39;LR&#39; in each column and compare sizes
        if (&#39;RL&#39; in col1_val or &#39;LR&#39; in col1_val) and (&#39;RL&#39; in col2_val or &#39;LR&#39; in col2_val):
            continue
        elif &#39;RL&#39; not in col1_val and &#39;LR&#39; not in col1_val and &#39;RL&#39; not in col2_val and &#39;LR&#39; not in col2_val:
            if size1 &lt; size2:
                df_copy.at[index, col1] = df_copy.at[index, col2]
                df_copy.at[index, size_col1] = df_copy.at[index, size_col2]
                df_copy.at[index, id1] = df_copy.at[index, id2]
                df_copy.at[index, size_col2] = 0
                df_copy.at[index, col2] = None
                df_copy.at[index, id2] = None
            else:
                df_copy.at[index, col2] = None
                df_copy.at[index, size_col2] = 0
                df_copy.at[index, id2] = None
        elif &#39;RL&#39; in col1_val or &#39;LR&#39; in col1_val:
            if size1 &lt; size2:
                df_copy.at[index, col1] = df_copy.at[index, col2]
                df_copy.at[index, id1] = df_copy.at[index, id2]
                df_copy.at[index, size_col1] = df_copy.at[index, size_col2]
                df_copy.at[index, size_col2] = 0
                df_copy.at[index, col2] = None
                df_copy.at[index, id2] = None
            else:
                df_copy.at[index, col2] = None
                df_copy.at[index, id2] = None
                df_copy.at[index, size_col2] = 0
        elif &#39;RL&#39; in col2_val or &#39;LR&#39; in col2_val:
            if size2 &lt; size1:
                df_copy.at[index, id2] = None
                df_copy.at[index, col2] = None
                df_copy.at[index, size_col2] = 0
            else:
                df_copy.at[index, col1] = df_copy.at[index, col2]
                df_copy.at[index, id1] = df_copy.at[index, id2]
                df_copy.at[index, size_col1] = df_copy.at[index, size_col2]
                df_copy.at[index, size_col2] = 0
                df_copy.at[index, col2] = None    
                df_copy.at[index, id2] = None    
    return df_copy


def renameit(df, old_col_name, new_col_name):
    &#34;&#34;&#34;
    Renames a column in a pandas DataFrame in place. Raises an error if the specified old column name does not exist.

    Parameters:
    - df: pandas.DataFrame
        The DataFrame in which the column is to be renamed.
    - old_col_name: str
        The current name of the column to be renamed.
    - new_col_name: str
        The new name for the column.
    
    Raises:
    - ValueError: If the old column name does not exist in the DataFrame.
    
    Returns:
    None
    &#34;&#34;&#34;
    import warnings
    # Check if the old column name exists in the DataFrame
    if old_col_name not in df.columns:
        warnings.warn(f&#34;The column &#39;{old_col_name}&#39; does not exist in the DataFrame.&#34;)
        return
    
    # Proceed with renaming the column if it exists
    df.rename(columns={old_col_name: new_col_name}, inplace=True)


def mm_match_by_qc_scoring_all( qc_dataframe, fix_LRRL=True, verbose=True ):
    &#34;&#34;&#34;
    Processes a quality control (QC) DataFrame to perform modality-specific matching and filtering based
    on predefined criteria, optimizing for minimal outliers and noise, and maximal signal-to-noise ratio (SNR),
    expected value of randomness (EVR), and dimensionality time (dimt).

    This function iteratively matches dataframes derived from the QC dataframe for different imaging modalities,
    applying a series of filters to select the best matches based on the QC metrics. Matches are made with
    consideration to minimize outlier loop and noise, while maximizing SNR, EVR, and dimt for each modality.

    Parameters:
    ----------
    qc_dataframe : pandas.DataFrame
        The DataFrame containing QC metrics for different modalities and imaging data.
    fix_LRRL : bool, optional

    verbose : bool, optional
        If True, prints the progress and the shape of the DataFrame being processed in each step.

    Process:
    -------
    1. Standardizes modalities by merging DTI-related entries.
    2. Converts specific columns to appropriate data types for processing.
    3. Performs modality-specific matching and filtering based on the outlier column and criteria for each modality.
    4. Iteratively processes unmatched data for predefined modalities with specific prefixes to find further matches.
    
    Returns:
    -------
    pandas.DataFrame
        The matched and filtered DataFrame after applying all QC scoring and matching operations across specified modalities.

    &#34;&#34;&#34;
    qc_dataframe[&#39;modality&#39;] = qc_dataframe[&#39;modality&#39;].replace([&#39;DTIdwi&#39;, &#39;DTIb0&#39;], &#39;DTI&#39;, regex=True)
    qc_dataframe[&#39;filename&#39;]=qc_dataframe[&#39;filename&#39;].astype(str)
    qc_dataframe[&#39;ol_loop&#39;]=qc_dataframe[&#39;ol_loop&#39;].astype(float)
    qc_dataframe[&#39;ol_lof&#39;]=qc_dataframe[&#39;ol_lof&#39;].astype(float)
    qc_dataframe[&#39;ol_lof_decision&#39;]=qc_dataframe[&#39;ol_lof_decision&#39;].astype(float)
    outlier_column=&#39;ol_loop&#39;
    mmdf0 = best_mmm( qc_dataframe, &#39;T1w&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    fldf = best_mmm( qc_dataframe, &#39;T2Flair&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    nmdf = best_mmm( qc_dataframe, &#39;NM2DMT&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    rsdf = best_mmm( qc_dataframe, &#39;rsfMRI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    dtdf = best_mmm( qc_dataframe, &#39;DTI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]

    criteria = {&#39;ol_loop&#39;: &#39;min&#39;, &#39;noise&#39;: &#39;min&#39;, &#39;snr&#39;: &#39;max&#39;, &#39;EVR&#39;: &#39;max&#39;, &#39;reflection_err&#39;:&#39;min&#39;}
    xcl = [ &#39;mrimfg&#39;, &#39;mrimodel&#39;,&#39;mriMagneticFieldStrength&#39;, &#39;dti_failed&#39;, &#39;rsf_failed&#39;, &#39;subjectID&#39;, &#39;date&#39;, &#39;subjectIDdate&#39;,&#39;repeat&#39;]
    # Assuming df_a and df_b are already loaded
    mmdf, undffl = mm_match_by_qc_scoring(mmdf0, fldf, &#39;subjectIDdate&#39;, criteria, 
                        prefix=&#39;T2Flair_&#39;, exclude_columns=xcl )

    prefixes = [&#39;NM1_&#39;, &#39;NM2_&#39;, &#39;NM3_&#39;, &#39;NM4_&#39;, &#39;NM5_&#39;, &#39;NM6_&#39;]  
    undfmod = nmdf  # Initialize &#39;undfmod&#39; with &#39;nmdf&#39; for the first iteration
    if verbose:
        print(&#39;start NM&#39;)
        print( undfmod.shape )
    for prefix in prefixes:
        if undfmod.shape[0] &gt; 50:
            mmdf, undfmod = mm_match_by_qc_scoring(mmdf, undfmod, &#39;subjectIDdate&#39;, criteria, prefix=prefix, exclude_columns=xcl)
            if verbose:
                print( prefix )
                print( undfmod.shape )

    criteria = {&#39;ol_loop&#39;: &#39;min&#39;, &#39;noise&#39;: &#39;min&#39;, &#39;snr&#39;: &#39;max&#39;, &#39;EVR&#39;: &#39;max&#39;, &#39;dimt&#39;:&#39;max&#39;}
    # higher bvalues lead to more noise ...
    criteria = {&#39;ol_loop&#39;: &#39;min&#39;, &#39;noise&#39;: &#39;min&#39;,  &#39;dti_bvalueMax&#39;:&#39;min&#39;,  &#39;dimt&#39;:&#39;max&#39;}
    prefixes = [&#39;DTI1_&#39;, &#39;DTI2_&#39;, &#39;DTI3_&#39;]  # List of prefixes for each matching iteration
    undfmod = dtdf
    if verbose:
        print(&#39;start DT&#39;)
        print( undfmod.shape )
    for prefix in prefixes:
        if undfmod.shape[0] &gt; 50:
            mmdf, undfmod = mm_match_by_qc_scoring(mmdf, undfmod, &#39;subjectIDdate&#39;, criteria, prefix=prefix, exclude_columns=xcl)
            if verbose:
                print( prefix )
                print( undfmod.shape )

    prefixes = [&#39;rsf1_&#39;, &#39;rsf2_&#39;, &#39;rsf3_&#39;]  # List of prefixes for each matching iteration
    undfmod = rsdf  # Initialize &#39;undfmod&#39; with &#39;nmdf&#39; for the first iteration
    if verbose:
        print(&#39;start rsf&#39;)
        print( undfmod.shape )
    for prefix in prefixes:
        if undfmod.shape[0] &gt; 50:
            mmdf, undfmod = mm_match_by_qc_scoring(mmdf, undfmod, &#39;subjectIDdate&#39;, criteria, prefix=prefix, exclude_columns=xcl)
            if verbose:
                print( prefix )
                print( undfmod.shape )
    
    if fix_LRRL:
        #        mmdf=fix_LR_RL_stuff( mmdf, &#39;DTI1_filename&#39;, &#39;DTI2_filename&#39;, &#39;DTI1_dimt&#39;, &#39;DTI2_dimt&#39;)
        mmdf=fix_LR_RL_stuff( mmdf, &#39;rsf1_filename&#39;, &#39;rsf2_filename&#39;, &#39;rsf1_dimt&#39;, &#39;rsf2_dimt&#39;, &#39;rsf1_imageID&#39;, &#39;rsf2_imageID&#39;  )
    else:
        import warnings
        warnings.warn(&#34;FIXME: should fix LR and RL situation for the DTI and rsfMRI&#34;)

    # now do the necessary replacements
    
    renameit( mmdf, &#39;perf_imageID&#39;, &#39;perfid&#39; )
    renameit( mmdf, &#39;perf_filename&#39;, &#39;perffn&#39; )
    renameit( mmdf, &#39;T2Flair_imageID&#39;, &#39;flairid&#39; )
    renameit( mmdf, &#39;T2Flair_filename&#39;, &#39;flairfn&#39; )
    renameit( mmdf, &#39;rsf1_imageID&#39;, &#39;rsfid1&#39; )
    renameit( mmdf, &#39;rsf2_imageID&#39;, &#39;rsfid2&#39; )
    renameit( mmdf, &#39;rsf1_filename&#39;, &#39;rsffn1&#39; )
    renameit( mmdf, &#39;rsf2_filename&#39;, &#39;rsffn2&#39; )
    renameit( mmdf, &#39;DTI1_imageID&#39;, &#39;dtid1&#39; )
    renameit( mmdf, &#39;DTI2_imageID&#39;, &#39;dtid2&#39; )
    renameit( mmdf, &#39;DTI3_imageID&#39;, &#39;dtid3&#39; )
    renameit( mmdf, &#39;DTI1_filename&#39;, &#39;dtfn1&#39; )
    renameit( mmdf, &#39;DTI2_filename&#39;, &#39;dtfn2&#39; )
    renameit( mmdf, &#39;DTI3_filename&#39;, &#39;dtfn3&#39; )
    for x in range(1,6):
        temp0=&#34;NM&#34;+str(x)+&#34;_imageID&#34;
        temp1=&#34;nmid&#34;+str(x)
        renameit( mmdf, temp0, temp1 )
        temp0=&#34;NM&#34;+str(x)+&#34;_filename&#34;
        temp1=&#34;nmfn&#34;+str(x)
        renameit( mmdf, temp0, temp1 )
    return mmdf</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="antspymm.mm.aggregate_antspymm_results"><code class="name flex">
<span>def <span class="ident">aggregate_antspymm_results</span></span>(<span>input_csv, subject_col='subjectID', date_col='date', image_col='imageID', date_column='ses-1', base_path='./Processed/ANTsExpArt/', hiervariable='T1wHierarchical', valid_modalities=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate ANTsPyMM results from the specified CSV file and save the aggregated results to a new CSV file.</p>
<p>Parameters:
- input_csv (str): File path of the input CSV file containing ANTsPyMM QC results averaged and with outlier measurements.
- subject_col (str): Name of the column to store subject IDs.
- date_col (str): Name of the column to store date information.
- image_col (str): Name of the column to store image IDs.
- date_column (str): Name of the column representing the date information.
- base_path (str): Base path for search paths. Defaults to "./Processed/ANTsExpArt/".
- hiervariable (str) : the string variable denoting the Hierarchical output
- valid_modalities (str array) : identifies for each modality; if None will be replaced by get_valid_modalities(long=True)
- verbose : boolean</p>
<p>Note:
This function is tested under limited circumstances. Use with caution.</p>
<p>Example usage:
agg_df = aggregate_antspymm_results("qcdfaol.csv", subject_col='subjectID', date_col='date', image_col='imageID', date_column='ses-1', base_path="./Your/Custom/Path/")</p>
<p>Author:
Avants and ChatGPT</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_antspymm_results(input_csv, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, date_column=&#39;ses-1&#39;, base_path=&#34;./Processed/ANTsExpArt/&#34;, hiervariable=&#39;T1wHierarchical&#39;, valid_modalities=None, verbose=False ):
    &#34;&#34;&#34;
    Aggregate ANTsPyMM results from the specified CSV file and save the aggregated results to a new CSV file.

    Parameters:
    - input_csv (str): File path of the input CSV file containing ANTsPyMM QC results averaged and with outlier measurements.
    - subject_col (str): Name of the column to store subject IDs.
    - date_col (str): Name of the column to store date information.
    - image_col (str): Name of the column to store image IDs.
    - date_column (str): Name of the column representing the date information.
    - base_path (str): Base path for search paths. Defaults to &#34;./Processed/ANTsExpArt/&#34;.
    - hiervariable (str) : the string variable denoting the Hierarchical output
    - valid_modalities (str array) : identifies for each modality; if None will be replaced by get_valid_modalities(long=True)
    - verbose : boolean

    Note:
    This function is tested under limited circumstances. Use with caution.

    Example usage:
    agg_df = aggregate_antspymm_results(&#34;qcdfaol.csv&#34;, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, date_column=&#39;ses-1&#39;, base_path=&#34;./Your/Custom/Path/&#34;)

    Author:
    Avants and ChatGPT
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    from glob import glob

    def myread_csv(x, cnms):
        &#34;&#34;&#34;
        Reads a CSV file and returns a DataFrame excluding specified columns.

        Parameters:
        - x (str): File path of the input CSV file describing the blind QC output
        - cnms (list): List of column names to exclude from the DataFrame.

        Returns:
        pd.DataFrame: DataFrame with specified columns excluded.
        &#34;&#34;&#34;
        df = pd.read_csv(x)
        return df.loc[:, ~df.columns.isin(cnms)]

    import warnings
    # Warning message for untested function
    warnings.warn(&#34;Warning: This function is not well tested. Use with caution.&#34;)

    if valid_modalities is None:
        valid_modalities = get_valid_modalities(&#39;long&#39;)

    # Read the input CSV file
    df = pd.read_csv(input_csv)

    # Filter rows where modality is &#39;T1w&#39;
    df = df[df[&#39;modality&#39;] == &#39;T1w&#39;]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)

    # Add new columns for subject ID, date, and image ID
    df[subject_col] = np.nan
    df[date_col] = date_column
    df[image_col] = np.nan
    df = df.astype({subject_col: str, date_col: str, image_col: str })

#    if verbose:
#        print( df.shape )
#        print( df.dtypes )

    # prefilter df for data that exists
    keep = np.tile( False, df.shape[0] )
    for x in range(df.shape[0]):
        temp = df[&#39;filename&#39;].iloc[x].split(&#34;_&#34;)
        # Generalized search paths
        path_template = f&#34;{base_path}{temp[0]}/{date_column}/*/*/*&#34;
        hierfn = sorted(glob( path_template + &#34;-&#34; + hiervariable + &#34;-*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            keep[x]=True

    
    df=df[keep]
    
    if verbose:
        print( &#34;original input had shape &#34; + str( df.shape[0] ) + &#34; (T1 only) and we find &#34; + str( (keep).sum() ) + &#34; with hierarchical output defined by variable: &#34; + hiervariable )
        print( df.shape )

    myct = 0
    for x in range( df.shape[0]):
        if verbose:
            print(f&#34;{x}...&#34;)
        locind = df.index[x]
        temp = df[&#39;filename&#39;].iloc[x].split(&#34;_&#34;)
        if verbose:
            print( temp )
        df[subject_col].iloc[x]=temp[0]
        df[date_col].iloc[x]=date_column
        df[image_col].iloc[x]=temp[1]

        # Generalized search paths
        path_template = f&#34;{base_path}{temp[0]}/{date_column}/*/*/*&#34;
        if verbose:
            print(path_template)
        hierfn = sorted(glob( path_template + &#34;-&#34; + hiervariable + &#34;-*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            hdf=t1df=dtdf=rsdf=perfdf=nmdf=flairdf=None
            if verbose:
                print(hierfn)
            hdf = pd.read_csv(hierfn[0])
            badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], hdf )
            hdf=hdf.drop(badnames, axis=1)
            nums = [isinstance(hdf[col].iloc[0], (int, float)) for col in hdf.columns]
            corenames = list(np.array(hdf.columns)[nums])
            hdf.loc[:, nums] = hdf.loc[:, nums].add_prefix(&#34;T1Hier_&#34;)
            myct = myct + 1
            dflist = [hdf]

            for mymod in valid_modalities:
                t1wfn = sorted(glob( path_template+ &#34;-&#34; + mymod + &#34;-*wide.csv&#34; ) )
                if len( t1wfn ) &gt; 0 :
                    if verbose:
                        print(t1wfn)
                    t1df = myread_csv(t1wfn[0], corenames)
                    t1df = filter_df( t1df, mymod+&#39;_&#39;)
                    dflist = dflist + [t1df]
                
            hdf = pd.concat( dflist, axis=1, ignore_index=False )
            if verbose:
                print( df.loc[locind,&#39;filename&#39;] )
            if myct == 1:
                subdf = df.iloc[[x]]
                hdf.index = subdf.index.copy()
                df = pd.concat( [df,hdf], axis=1, ignore_index=False )
            else:
                commcols = list(set(hdf.columns).intersection(df.columns))
                df.loc[locind, commcols] = hdf.loc[0, commcols]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)
    return( df )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.aggregate_antspymm_results_sdf"><code class="name flex">
<span>def <span class="ident">aggregate_antspymm_results_sdf</span></span>(<span>study_df, project_col='projectID', subject_col='subjectID', date_col='date', image_col='imageID', base_path='./', hiervariable='T1wHierarchical', splitsep='-', idsep='-', wild_card_modality_id=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate ANTsPyMM results from the specified study data frame and store the aggregated results in a new data frame.
This assumes data is organized on disk
as follows:
rootdir/projectID/subjectID/date/outputid/imageid/ where
outputid is modality-specific and created by ANTsPyMM processing.</p>
<p>Parameters:
- study_df (pandas df): pandas data frame, output of generate_mm_dataframe.
- project_col (str): Name of the column that stores the project ID
- subject_col (str): Name of the column to store subject IDs.
- date_col (str): Name of the column to store date information.
- image_col (str): Name of the column to store image IDs.
- base_path (str): Base path for searching for processing outputs of ANTsPyMM.
- hiervariable (str) : the string variable denoting the Hierarchical output
- splitsep (str):
the separator used to split the filename
- idsep (str): the separator used to partition subjectid date and imageid
for example, if idsep is - then we have subjectid-date-imageid
- wild_card_modality_id (bool): keep if False for safer execution
- verbose : boolean</p>
<p>Note:
This function is tested under limited circumstances. Use with caution.
One particular gotcha is if the imageID is stored as a numeric value in the dataframe
but is meant to be a string.
E.g. '000' (string) would be interpreted as 0 in the
file name glob.
This would miss the extant (on disk) csv.</p>
<p>Example usage:
agg_df = aggregate_antspymm_results_sdf( studydf, subject_col='subjectID', date_col='date', image_col='imageID', base_path="./Your/Custom/Path/")</p>
<p>Author:
Avants and ChatGPT</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_antspymm_results_sdf(
    study_df, 
    project_col=&#39;projectID&#39;,
    subject_col=&#39;subjectID&#39;, 
    date_col=&#39;date&#39;, 
    image_col=&#39;imageID&#39;, 
    base_path=&#34;./&#34;, 
    hiervariable=&#39;T1wHierarchical&#39;, 
    splitsep=&#39;-&#39;,
    idsep=&#39;-&#39;,
    wild_card_modality_id=False,
    verbose=False ):
    &#34;&#34;&#34;
    Aggregate ANTsPyMM results from the specified study data frame and store the aggregated results in a new data frame.  This assumes data is organized on disk 
    as follows:  rootdir/projectID/subjectID/date/outputid/imageid/ where 
    outputid is modality-specific and created by ANTsPyMM processing.

    Parameters:
    - study_df (pandas df): pandas data frame, output of generate_mm_dataframe.
    - project_col (str): Name of the column that stores the project ID
    - subject_col (str): Name of the column to store subject IDs.
    - date_col (str): Name of the column to store date information.
    - image_col (str): Name of the column to store image IDs.
    - base_path (str): Base path for searching for processing outputs of ANTsPyMM.
    - hiervariable (str) : the string variable denoting the Hierarchical output
    - splitsep (str):  the separator used to split the filename
    - idsep (str): the separator used to partition subjectid date and imageid 
        for example, if idsep is - then we have subjectid-date-imageid
    - wild_card_modality_id (bool): keep if False for safer execution
    - verbose : boolean

    Note:
    This function is tested under limited circumstances. Use with caution.
    One particular gotcha is if the imageID is stored as a numeric value in the dataframe 
    but is meant to be a string.  E.g. &#39;000&#39; (string) would be interpreted as 0 in the 
    file name glob.  This would miss the extant (on disk) csv.

    Example usage:
    agg_df = aggregate_antspymm_results_sdf( studydf, subject_col=&#39;subjectID&#39;, date_col=&#39;date&#39;, image_col=&#39;imageID&#39;, base_path=&#34;./Your/Custom/Path/&#34;)

    Author:
    Avants and ChatGPT
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    from glob import glob

    def progress_reporter(current_step, total_steps, width=50):
        # Calculate the proportion of progress
        progress = current_step / total_steps
        # Calculate the number of &#39;filled&#39; characters in the progress bar
        filled_length = int(width * progress)
        # Create the progress bar string
        bar = &#39;█&#39; * filled_length + &#39;-&#39; * (width - filled_length)
        # Print the progress bar with percentage
        print(f&#39;\rProgress: |{bar}| {int(100 * progress)}%&#39;, end=&#39;\r&#39;)
        # Print a new line when the progress is complete
        if current_step == total_steps:
            print()

    def myread_csv(x, cnms):
        &#34;&#34;&#34;
        Reads a CSV file and returns a DataFrame excluding specified columns.

        Parameters:
        - x (str): File path of the input CSV file describing the blind QC output
        - cnms (list): List of column names to exclude from the DataFrame.

        Returns:
        pd.DataFrame: DataFrame with specified columns excluded.
        &#34;&#34;&#34;
        df = pd.read_csv(x)
        return df.loc[:, ~df.columns.isin(cnms)]

    import warnings
    # Warning message for untested function
    warnings.warn(&#34;Warning: This function is not well tested. Use with caution.&#34;)

    vmoddict = {}
    # Add key-value pairs
    vmoddict[&#39;imageID&#39;] = &#39;T1w&#39;
    vmoddict[&#39;flairid&#39;] = &#39;T2Flair&#39;
    vmoddict[&#39;perfid&#39;] = &#39;perf&#39;
    vmoddict[&#39;rsfid1&#39;] = &#39;rsfMRI&#39;
#    vmoddict[&#39;rsfid2&#39;] = &#39;rsfMRI&#39;
    vmoddict[&#39;dtid1&#39;] = &#39;DTI&#39;
#    vmoddict[&#39;dtid2&#39;] = &#39;DTI&#39;
    vmoddict[&#39;nmid1&#39;] = &#39;NM2DMT&#39;
#    vmoddict[&#39;nmid2&#39;] = &#39;NM2DMT&#39;

    # Filter rows where modality is &#39;T1w&#39;
    df = study_df[ study_df[&#39;modality&#39;] == &#39;T1w&#39;]
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], df )
    df=df.drop(badnames, axis=1)
    # prefilter df for data that exists
    keep = np.tile( False, df.shape[0] )
    for x in range(df.shape[0]):
        myfn = os.path.basename( df[&#39;filename&#39;].iloc[x] )
        temp = myfn.split( splitsep )
        # Generalized search paths
        sid0 = str( temp[0] )
        sid = str( df[subject_col].iloc[x] )
        if sid0 != sid:
            warnings.warn(&#34;OUTER: the id derived from the filename &#34; + sid + &#34; does not match the id stored in the data frame &#34; + sid )
            warnings.warn( &#34;filename is : &#34; +  myfn )
            warnings.warn( &#34;sid is : &#34; + sid )
            warnings.warn( &#34;x is : &#34; + str(x) )
        myproj = str(df[project_col].iloc[x])
        mydate = str(df[date_col].iloc[x])
        myid = str(df[image_col].iloc[x])
        path_template = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + hiervariable + &#39;/&#39; + str(myid) + &#34;/&#34;
        hierfn = sorted(glob( path_template + &#34;*&#34; + hiervariable + &#34;*wide.csv&#34; ) )
        if len( hierfn ) &gt; 0:
            keep[x]=True

    df=df[keep]

    if not df.index.is_unique:
        warnings.warn(&#34;data frame does not have unique indices.  we therefore reset the index to allow the function to continue on.&#34; )
        df = df.reset_index()

    
    if verbose:
        print( &#34;original input had shape &#34; + str( df.shape[0] ) + &#34; (T1 only) and we find &#34; + str( (keep).sum() ) + &#34; with hierarchical output defined by variable: &#34; + hiervariable )
        print( df.shape )

    dfout = pd.DataFrame()
    myct = 0
    for x in range( df.shape[0]):
        if verbose:
            print(&#34;\n\n-------------------------------------------------&#34;)
            print(f&#34;{x}...&#34;)
        else:
            progress_reporter(x, df.shape[0], width=500)
        locind = df.index[x]
        myfn = os.path.basename( df[&#39;filename&#39;].iloc[x] )
        sid = str( df[subject_col].iloc[x] )
        tempB = myfn.split( splitsep )
        sid0 = str(tempB[1])
        if sid0 != sid and verbose:
            warnings.warn(&#34;INNER: the id derived from the filename &#34; + str(sid) + &#34; does not match the id stored in the data frame &#34; + str(sid0) )
            warnings.warn( &#34;filename is : &#34; +  str(myfn) )
            warnings.warn( &#34;sid is : &#34; + str(sid) )
            warnings.warn( &#34;x is : &#34; + str(x) )
            warnings.warn( &#34;index is : &#34; + str(locind) )
        myproj = str(df[project_col].iloc[x])
        mydate = str(df[date_col].iloc[x])
        myid = str(df[image_col].iloc[x])
        myt1id = myid
        if verbose:
            print( myfn )
            print( temp )
            print( &#34;id &#34; + sid  )
        path_template = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + hiervariable + &#39;/&#39; + str(myid) + &#34;/&#34;
        searchhier = path_template + &#34;*&#34; + hiervariable + &#34;*wide.csv&#34;
        if verbose:
            print( searchhier )
        hierfn = sorted( glob( searchhier ) )
        if len( hierfn ) &gt; 1:
            raise ValueError(&#34;there are &#34; + str( len( hierfn ) ) + &#34; number of hier fns with search path &#34; + searchhier )
        if len( hierfn ) == 1:
            hdf=t1df=dtdf=rsdf=perfdf=nmdf=flairdf=None
            if verbose:
                print(hierfn)
            hdf = pd.read_csv(hierfn[0])
            if verbose:
                print( hdf[&#39;vol_hemisphere_lefthemispheres&#39;] )
            badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], hdf )
            hdf=hdf.drop(badnames, axis=1)
            nums = [isinstance(hdf[col].iloc[0], (int, float)) for col in hdf.columns]
            corenames = list(np.array(hdf.columns)[nums])
            # hdf.loc[:, nums] = hdf.loc[:, nums].add_prefix(&#34;T1Hier_&#34;)
            hdf = hdf.add_prefix(&#34;T1Hier_&#34;)
            myct = myct + 1
            dflist = [hdf]

            for mymod in vmoddict.keys():
                if verbose:
                    print(&#34;\n\n************************* &#34; + mymod + &#34; *************************&#34;)
                modalityclass = vmoddict[ mymod ]
                if wild_card_modality_id:
                    mymodid = &#39;*&#39;
                else:
                    mymodid = str( df[mymod].iloc[x] )
                    if mymodid.lower() != &#34;nan&#34; and mymodid.lower() != &#34;na&#34;:
                        mymodid = os.path.basename( mymodid )
                        mymodid = os.path.splitext( mymodid )[0]
                        mymodid = os.path.splitext( mymodid )[0]
                        temp = mymodid.split( idsep )
                        mymodid = temp[ len( temp )-1 ]
                    else:
                        if verbose:
                            print(&#34;missing&#34;)
                        continue
                if verbose:
                    print( &#34;modality id is &#34; + mymodid + &#34; for modality &#34; + modalityclass + &#39; modality specific subj &#39; + sid + &#39; modality specific id is &#39; + myid + &#34; its date &#34; +  mydate )
                modalityclasssearch = modalityclass
                if modalityclass in [&#39;rsfMRI&#39;,&#39;DTI&#39;]:
                    modalityclasssearch=modalityclass+&#34;*&#34;
                path_template_m = base_path + &#34;/&#34; + myproj +  &#34;/&#34; + sid + &#34;/&#34; + mydate + &#39;/&#39; + modalityclasssearch + &#39;/&#39; + mymodid + &#34;/&#34;
                modsearch = path_template_m + &#34;*&#34; + modalityclasssearch + &#34;*wide.csv&#34;
                if verbose:
                    print( modsearch )
                t1wfn = sorted( glob( modsearch ) )
                if len( t1wfn ) &gt; 1:
                    nlarge = len(t1wfn)
                    t1wfn = find_most_recent_file( t1wfn )
                    warnings.warn(&#34;there are &#34; + str( nlarge ) + &#34; number of wide fns with search path &#34; + modsearch + &#34; we take the most recent of these &#34; + t1wfn[0] )
#                    raise ValueError(&#34;there are &#34; + str( len( t1wfn ) ) + &#34; number of wide fns with search path &#34; + modsearch )
                if len( t1wfn ) == 1:
                    if verbose:
                        print(t1wfn)
                    t1df = myread_csv(t1wfn[0], corenames)
                    t1df = filter_df( t1df, modalityclass+&#39;_&#39;)
                    dflist = dflist + [t1df]
                else:
                    if verbose:
                        print( &#34; cannot find &#34; + modsearch )
                
            hdf = pd.concat( dflist, axis=1, ignore_index=False)
            if verbose:
                print( &#34;count: &#34; + str( myct ) )
            subdf = df.iloc[[x]]
            hdf.index = subdf.index.copy()
            subdf = pd.concat( [subdf,hdf], axis=1, ignore_index=False)
            dfout = pd.concat( [dfout,subdf], axis=0, ignore_index=False )
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], dfout )
    dfout=dfout.drop(badnames, axis=1)
    return( dfout )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.alff_image"><code class="name flex">
<span>def <span class="ident">alff_image</span></span>(<span>x, mask, flo=0.01, fhi=0.1, nuisance=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
are related measures that quantify the amplitude of low frequency
oscillations (LFOs).
This function outputs ALFF and fALFF for the input.</p>
<p>x - input clean resting state fmri
mask - mask over which to compute f/alff
flo - low frequency, typically 0.01
fhi - high frequency, typically 0.1
nuisance - optional nuisance matrix</p>
<p>return dictionary with ALFF and fALFF images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.

    x - input clean resting state fmri
    mask - mask over which to compute f/alff
    flo - low frequency, typically 0.01
    fhi - high frequency, typically 0.1
    nuisance - optional nuisance matrix

    return dictionary with ALFF and fALFF images
    &#34;&#34;&#34;
    xmat = ants.timeseries_to_matrix( x, mask )
    if nuisance is not None:
        xmat = ants.regress_components( xmat, nuisance )
    alffvec = xmat[0,:]*0
    falffvec = xmat[0,:]*0
    mytr = ants.get_spacing( x )[3]
    for n in range( xmat.shape[1] ):
        temp = alffmap( xmat[:,n], flo=flo, fhi=fhi, tr=mytr )
        alffvec[n]=temp[&#39;alff&#39;]
        falffvec[n]=temp[&#39;falff&#39;]
    alffi=ants.make_image( mask, alffvec )
    falffi=ants.make_image( mask, falffvec )
    alfftrimmedmean = calculate_trimmed_mean( alffvec, 0.01 )
    falfftrimmedmean = calculate_trimmed_mean( falffvec, 0.01 )
    alffi=alffi / alfftrimmedmean
    falffi=falffi / falfftrimmedmean
    return {  &#39;alff&#39;: alffi, &#39;falff&#39;: falffi }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.alffmap"><code class="name flex">
<span>def <span class="ident">alffmap</span></span>(<span>x, flo=0.01, fhi=0.1, tr=1, detrend=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
are related measures that quantify the amplitude of low frequency
oscillations (LFOs).
This function outputs ALFF and fALFF for the input.
same function in ANTsR.</p>
<p>x input vector for the time series of interest
flo low frequency, typically 0.01
fhi high frequency, typically 0.1
tr the period associated with the vector x (inverse of frequency)
detrend detrend the input time series</p>
<p>return vector is output showing ALFF and fALFF values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alffmap( x, flo=0.01, fhi=0.1, tr=1, detrend = True ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.
    same function in ANTsR.

    x input vector for the time series of interest
    flo low frequency, typically 0.01
    fhi high frequency, typically 0.1
    tr the period associated with the vector x (inverse of frequency)
    detrend detrend the input time series

    return vector is output showing ALFF and fALFF values
    &#34;&#34;&#34;
    temp = spec_pgram( x, xfreq=1.0/tr, demean=False, detrend=detrend, taper=0, fast=True, plot=False )
    fselect = np.logical_and( temp[&#39;freq&#39;] &gt;= flo, temp[&#39;freq&#39;] &lt;= fhi )
    denom = (temp[&#39;spec&#39;]).sum()
    numer = (temp[&#39;spec&#39;][fselect]).sum()
    return {  &#39;alff&#39;:numer, &#39;falff&#39;: numer/denom }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.assemble_modality_specific_dataframes"><code class="name flex">
<span>def <span class="ident">assemble_modality_specific_dataframes</span></span>(<span>mm_wide_csvs, hierdfin, nrg_modality, separator='-', progress=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assemble_modality_specific_dataframes( mm_wide_csvs, hierdfin, nrg_modality, separator=&#39;-&#39;, progress=None, verbose=False ):
    moddersub = re.sub( &#34;[*]&#34;,&#34;&#34;,nrg_modality)
    nmdf=pd.DataFrame()
    for k in range( hierdfin.shape[0] ):
        if progress is not None:
            if k % progress == 0:
                progger = str( np.round( k / hierdfin.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        temp = mm_wide_csvs[k]
        mypartsf = temp.split(&#34;T1wHierarchical&#34;)
        myparts = mypartsf[0]
        t1iid = str(mypartsf[1].split(&#34;/&#34;)[1])
        fnsnm = glob.glob(myparts+&#34;/&#34; + nrg_modality + &#34;/*/*&#34; + t1iid + &#34;*wide.csv&#34;)
        if len( fnsnm ) &gt; 0 :
            for y in fnsnm:
                temp=read_mm_csv( y, colprefix=moddersub+&#39;_&#39;, is_t1=False, separator=separator, verbose=verbose )
                if temp is not None:
                    nmdf=pd.concat( [nmdf, temp], axis=0, ignore_index=False )
    return nmdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.augment_image"><code class="name flex">
<span>def <span class="ident">augment_image</span></span>(<span>x, max_rot=10, nzsd=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def augment_image( x,  max_rot=10, nzsd=1 ):
    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rot*(-1.0), max_rot ), reference=x )
    tx = rRotGenerator.transform()
    itx = ants.invert_ants_transform(tx)
    y = ants.apply_ants_transform_to_image( tx, x, x, interpolation=&#39;linear&#39;)
    y = ants.add_noise_to_image( y,&#39;additivegaussian&#39;, [0,nzsd] )
    return y, tx, itx</code></pre>
</details>
</dd>
<dt id="antspymm.mm.average_blind_qc_by_modality"><code class="name flex">
<span>def <span class="ident">average_blind_qc_by_modality</span></span>(<span>qc_full, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Averages time series qc results to yield one entry per image. this also filters to "known" columns.</p>
<p>Args:
qc_full: pandas dataframe containing the full qc data.</p>
<p>Returns:
pandas dataframe containing the processed qc data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def average_blind_qc_by_modality(qc_full,verbose=False):
    &#34;&#34;&#34;
    Averages time series qc results to yield one entry per image. this also filters to &#34;known&#34; columns.

    Args:
    qc_full: pandas dataframe containing the full qc data.

    Returns:
    pandas dataframe containing the processed qc data.
    &#34;&#34;&#34;
    qc_full = remove_unwanted_columns( qc_full )
    # Get unique modalities
    modalities = qc_full[&#39;modality&#39;].unique()
    modalities = modalities[modalities != &#39;unknown&#39;]
    # Get unique ids
    uid = qc_full[&#39;filename&#39;]
    to_average = uid.unique()
    meta = pd.DataFrame(columns=qc_full.columns )
    # Process each unique id
    n = len(to_average)
    for k in range(n):
        if verbose:
            if k % 100 == 0:
                progger = str( np.round( k / n * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        m1sel = uid == to_average[k]
        if sum(m1sel) &gt; 1:
            # If more than one entry for id, take the average of continuous columns,
            # maximum of the slice column, and the first entry of the other columns
            mfsub = process_dataframe_generalized(qc_full[m1sel],&#39;filename&#39;)
        else:
            mfsub = qc_full[m1sel]
        meta.loc[k] = mfsub.iloc[0]
    meta[&#39;modality&#39;] = meta[&#39;modality&#39;].replace([&#39;DTIdwi&#39;, &#39;DTIb0&#39;], &#39;DTI&#39;, regex=True)
    return meta</code></pre>
</details>
</dd>
<dt id="antspymm.mm.average_mm_df"><code class="name flex">
<span>def <span class="ident">average_mm_df</span></span>(<span>jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def average_mm_df( jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False ):
    &#34;&#34;&#34;
    jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )
    &#34;&#34;&#34;

    jmm = jmm_in.copy()
    dxcols=[&#39;subjectid1&#39;,&#39;subjectid2&#39;,&#39;modalityid&#39;,&#39;joinid&#39;,&#39;correlation&#39;,&#39;distance&#39;]
    joinDiagnostics = pd.DataFrame( columns = dxcols )
    nanList=[math.nan]
    def rob(x, y=0.99):
        x[x &gt; np.quantile(x, y, nan_policy=&#34;omit&#34;)] = np.nan
        return x

    jmm = jmm.replace(r&#39;^\s*$&#39;, np.nan, regex=True)

    if verbose:
        print(&#34;do rsfMRI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;rsfMRI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;rsfMRI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    if len( dt0 ) &gt; 0 and len( dt1 ) &gt; 0:
        flid = dt0[0]
        wrows = []
        for i in range(jmm.shape[0]):
            if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) :
                wrows.append(i)
        for k in wrows:
            v1 = jmm.iloc[k][dt0[1:]].astype(float)
            v2 = jmm.iloc[k][dt1[1:]].astype(float)
            vvec = [v1[0], v2[0]]
            if any(~np.isnan(vvec)):
                mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
                jmm.iloc[k][dt0[0]] = &#39;rsfMRI&#39;
                if len(mynna) == 1:
                    if mynna[0] == 0:
                        jmm.iloc[k][dt0[1:]] = v1
                    if mynna[0] == 1:
                        jmm.iloc[k][dt0[1:]] = v2
                elif len(mynna) &gt; 1:
                    if len(v2) &gt; diagnostic_n:
                        v1dx=v1[0:diagnostic_n]
                        v2dx=v2[0:diagnostic_n]
                    else :
                        v1dx=v1
                        v2dx=v2
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v1dx.values, v2dx.values )[0,1]
                    myerr=np.sqrt(np.mean((v1dx.values - v2dx.values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;rsfMRI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v1.values*0.5 + v2.values*0.5
                    else:
                        jmm.loc[k, dt0[1:]] = nanList * len(v1)
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0, ignore_index=False )

    if verbose:
        print(&#34;do DTI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;DTI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;DTI_LR&#34;, &#34;DTI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;DTI_LR&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    dt2 = get_names_from_data_frame( [&#34;DTI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    flid = dt0[0]
    wrows = []
    for i in range(jmm.shape[0]):
        if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) or not pd.isna(jmm[dt2[1]][i]):
            wrows.append(i)
    for k in wrows:
        v1 = jmm.loc[k, dt0[1:]].astype(float)
        v2 = jmm.loc[k, dt1[1:]].astype(float)
        v3 = jmm.loc[k, dt2[1:]].astype(float)
        checkcol = dt0[5]
        if not np.isnan(v1[checkcol]):
            if v1[checkcol] &lt; 0.25:
                v1.replace(np.nan, inplace=True)
        checkcol = dt1[5]
        if not np.isnan(v2[checkcol]):
            if v2[checkcol] &lt; 0.25:
                v2.replace(np.nan, inplace=True)
        checkcol = dt2[5]
        if not np.isnan(v3[checkcol]):
            if v3[checkcol] &lt; 0.25:
                v3.replace(np.nan, inplace=True)
        vvec = [v1[0], v2[0], v3[0]]
        if any(~np.isnan(vvec)):
            mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
            jmm.loc[k, dt0[0]] = &#39;DTI&#39;
            if len(mynna) == 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                if mynna[0] == 1:
                    jmm.loc[k, dt0[1:]] = v2
                if mynna[0] == 2:
                    jmm.loc[k, dt0[1:]] = v3
            elif len(mynna) &gt; 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                else:
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v2[0:diagnostic_n].values, v3[0:diagnostic_n].values )[0,1]
                    myerr=np.sqrt(np.mean((v2[0:diagnostic_n].values - v3[0:diagnostic_n].values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;DTI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v2.values*0.5 + v3.values*0.5
                    else: #
                        jmm.loc[k, dt0[1:]] = nanList * len( dt0[1:] )
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0, ignore_index=False )


    # first task - sort by u_hier_id
    jmm = jmm.sort_values( &#34;u_hier_id&#34; )
    # get rid of junk columns
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], jmm )
    jmm=jmm.drop(badnames, axis=1)
    jmm=jmm.set_index(&#34;u_hier_id&#34;,drop=False)
    # 2nd - get rid of duplicated u_hier_id
    jmmUniq = jmm.drop_duplicates( subset=&#34;u_hier_id&#34; ) # fast and easy
    # for each modality, count which ids have more than one
    mod_names = get_valid_modalities()
    for mod_name in mod_names:
        fl_names = get_names_from_data_frame([mod_name], jmm,
            exclusions=[&#39;Unnamed&#39;,&#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;rsfMRI_RL&#34;,&#34;rsfMRI_LR&#34;])
        if len( fl_names ) &gt; 1:
            if verbose:
                print(mod_name)
                print(fl_names)
            fl_id = fl_names[0]
            n_names = len(fl_names)
            locvec = jmm[fl_names[n_names-1]].astype(float)
            boolvec=~pd.isna(locvec)
            jmmsub = jmm[boolvec][ [&#39;u_hier_id&#39;]+fl_names]
            my_tbl = Counter(jmmsub[&#39;u_hier_id&#39;])
            gtoavg = [name for name in my_tbl.keys() if my_tbl[name] == 1]
            gtoavgG1 = [name for name in my_tbl.keys() if my_tbl[name] &gt; 1]
            if verbose:
                print(&#34;Join 1&#34;)
            jmmsub1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavg)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavg:
                jmmUniq.loc[u][fl_names[1:]] = jmmsub1.loc[u][fl_names[1:]]
            if verbose and len(gtoavgG1) &gt; 1:
                print(&#34;Join &gt;1&#34;)
            jmmsubG1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavgG1)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavgG1:
                temp = jmmsubG1.loc[u][ [&#39;u_hier_id&#39;]+fl_names ]
                dropnames = get_names_from_data_frame( [&#39;MM.ID&#39;], temp )
                tempVec = temp.drop(columns=dropnames)
                joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                id1=temp[fl_id].iloc[0]
                id2=temp[fl_id].iloc[1]
                v1=tempVec.iloc[0][1:].astype(float).to_numpy()
                v2=tempVec.iloc[1][1:].astype(float).to_numpy()
                if len(v2) &gt; diagnostic_n:
                    v1=v1[0:diagnostic_n]
                    v2=v2[0:diagnostic_n]
                mycorr = np.corrcoef( v1, v2 )[0,1]
                # mycorr=temparr[np.triu_indices_from(temparr, k=1)].mean()
                myerr=np.sqrt(np.mean((v1 - v2)**2))
                joinDiagnosticsLoc.iloc[0] = [id1,id2,mod_name,&#39;rowavg&#39;,mycorr,myerr]
                if verbose:
                    print( joinDiagnosticsLoc )
                temp = jmmsubG1.loc[u][fl_names[1:]].astype(float)
                if mycorr &gt; corr_thresh or len( v1 ) &lt; 10:
                    jmmUniq.loc[u][fl_names[1:]] = temp.mean(axis=0)
                else:
                    jmmUniq.loc[u][fl_names[1:]] = nanList * temp.shape[1]
                joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], 
                                            axis=0, ignore_index=False )

    return jmmUniq, jmm, joinDiagnostics</code></pre>
</details>
</dd>
<dt id="antspymm.mm.best_mmm"><code class="name flex">
<span>def <span class="ident">best_mmm</span></span>(<span>mmdf, wmod, mysep='-', outlier_column='ol_loop', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Selects the best repeats per modality.</p>
<p>Args:
wmod (str): the modality of the image ( 'T1w', 'T2Flair', 'NM2DMT' 'rsfMRI', 'DTI')</p>
<p>mysep (str, optional): the separator used in the image file names. Defaults to '-'.</p>
<p>outlier_name : column name for outlier score</p>
<p>verbose (bool, optional): default True</p>
<p>Returns:</p>
<p>list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_mmm( mmdf, wmod, mysep=&#39;-&#39;, outlier_column=&#39;ol_loop&#39;, verbose=False):
    &#34;&#34;&#34;
    Selects the best repeats per modality.

    Args:
    wmod (str): the modality of the image ( &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39; &#39;rsfMRI&#39;, &#39;DTI&#39;)

    mysep (str, optional): the separator used in the image file names. Defaults to &#39;-&#39;.

    outlier_name : column name for outlier score

    verbose (bool, optional): default True

    Returns:

    list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.

    &#34;&#34;&#34;
#    mmdf = mmdf.astype(str)
    mmdf[outlier_column]=mmdf[outlier_column].astype(float)
    msel = mmdf[&#39;modality&#39;] == wmod
    if wmod == &#39;rsfMRI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;rsfMRI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_RL&#39;
        msel = msel1 | msel2
        msel = msel | msel3
    if wmod == &#39;DTI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;DTI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;DTI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;DTI_RL&#39;
        msel4 = mmdf[&#39;modality&#39;] == &#39;DTIdwi&#39;
        msel5 = mmdf[&#39;modality&#39;] == &#39;DTIb0&#39;
        msel = msel1 | msel2 | msel3 | msel4 | msel5
    if sum(msel) == 0:
        return {&#39;raw&#39;: None, &#39;filt&#39;: None}
    metasub = mmdf[msel].copy()

    if verbose:
        print(f&#34;{wmod} {(metasub.shape[0])} pre&#34;)

    metasub[&#39;subjectID&#39;]=None
    metasub[&#39;date&#39;]=None
    metasub[&#39;subjectIDdate&#39;]=None
    metasub[&#39;imageID&#39;]=None
    metasub[&#39;negol&#39;]=math.nan
    for k in metasub.index:
        temp = metasub.loc[k, &#39;filename&#39;].split( mysep )
        metasub.loc[k,&#39;subjectID&#39;] = str( temp[1] )
        metasub.loc[k,&#39;date&#39;] = str( temp[2] )
        metasub.loc[k,&#39;subjectIDdate&#39;] = str( temp[1] + mysep + temp[2] )
        metasub.loc[k,&#39;imageID&#39;] = str( temp[4])


    if &#39;ol_&#39; in outlier_column:
        metasub[&#39;negol&#39;] = metasub[outlier_column].max() - metasub[outlier_column]
    else:
        metasub[&#39;negol&#39;] = metasub[outlier_column]
    if &#39;date&#39; not in metasub.keys():
        metasub[&#39;date&#39;]=None
    metasubq = add_repeat_column( metasub, &#39;subjectIDdate&#39; )
    metasubq = highest_quality_repeat(metasubq, &#39;filename&#39;, &#39;date&#39;, &#39;negol&#39;)

    if verbose:
        print(f&#34;{wmod} {metasubq.shape[0]} post&#34;)

#    metasub = metasub.astype(str)
#    metasubq = metasubq.astype(str)
    metasub[outlier_column]=metasub[outlier_column].astype(float)
    metasubq[outlier_column]=metasubq[outlier_column].astype(float)
    return {&#39;raw&#39;: metasub, &#39;filt&#39;: metasubq}</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bids_2_nrg"><code class="name flex">
<span>def <span class="ident">bids_2_nrg</span></span>(<span>bids_filename, project_name, date, nrg_modality=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a BIDS filename to NRG path/filename.</p>
<p>Parameters:
bids_filename (str): The BIDS filename to convert
project_name (str) : Name of project (i.e. PPMI)
date (str) : Date of image acquisition</p>
<p>Returns:
str: The NRG path/filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bids_2_nrg( bids_filename, project_name, date, nrg_modality=None ):
    &#34;&#34;&#34;
    Convert a BIDS filename to NRG path/filename.

    Parameters:
    bids_filename (str): The BIDS filename to convert
    project_name (str) : Name of project (i.e. PPMI)
    date (str) : Date of image acquisition


    Returns:
    str: The NRG path/filename.
    &#34;&#34;&#34;

    bids_dirname, bids_basename = os.path.split(bids_filename)
    bids_suffix = &#39;.&#39;+ bids_basename.split(&#39;.&#39;,1)[-1]
    bids_basename = bids_basename.replace(bids_suffix, &#39;&#39;) # remove ext
    bids_parts = bids_basename.split(&#39;_&#39;)
    nrg_subject_id = bids_parts[0].replace(&#39;sub-&#39;,&#39;&#39;)
    nrg_image_id = bids_parts[1].replace(&#39;ses-&#39;, &#39;&#39;)
    bids_modality = bids_parts[2]
    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality: &#34; + get_valid_modalities(asString=True))

    if bids_modality == &#39;anat&#39; and nrg_modality is None :
        nrg_modality = &#39;T1w&#39;

    if bids_modality == &#39;dwi&#39; and nrg_modality is None  :
        nrg_modality = &#39;DTI&#39;

    if bids_modality == &#39;func&#39; and nrg_modality is None  :
        nrg_modality = &#39;rsfMRI&#39;

    if bids_modality == &#39;perf&#39; and nrg_modality is None  :
        nrg_modality = &#39;perf&#39;

    nrg_suffix = bids_suffix[1:]
    nrg_filename = f&#39;{project_name}-{nrg_subject_id}-{date}-{nrg_modality}-{nrg_image_id}.{nrg_suffix}&#39;

    return os.path.join(project_name, nrg_subject_id, date, nrg_modality, nrg_image_id,nrg_filename)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bind_wide_mm_csvs"><code class="name flex">
<span>def <span class="ident">bind_wide_mm_csvs</span></span>(<span>mm_wide_csvs, merge=True, separator='-', verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>will convert a list of t1w hierarchical csv filenames to a merged dataframe</p>
<p>returns a pair of data frames, the left side having all entries and the
right side having row averaged entries i.e. unique values for each visit</p>
<p>set merge to False to return individual dataframes ( for debugging )</p>
<p>return alldata, row_averaged_data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bind_wide_mm_csvs( mm_wide_csvs, merge=True, separator=&#39;-&#39;, verbose = 0 ) :
    &#34;&#34;&#34;
    will convert a list of t1w hierarchical csv filenames to a merged dataframe

    returns a pair of data frames, the left side having all entries and the
        right side having row averaged entries i.e. unique values for each visit

    set merge to False to return individual dataframes ( for debugging )

    return alldata, row_averaged_data
    &#34;&#34;&#34;
    mm_wide_csvs.sort()
    if not mm_wide_csvs:
        print(&#34;No files found with specified pattern&#34;)
        return
    # 1. row-bind the t1whier data
    # 2. same for each other modality
    # 3. merge the modalities by the keys
    hierdf = pd.DataFrame()
    for y in mm_wide_csvs:
        temp=read_mm_csv( y, colprefix=&#39;T1Hier_&#39;, separator=separator, is_t1=True )
        if temp is not None:
            hierdf=pd.concat( [hierdf, temp], axis=0, ignore_index=False )
    if verbose &gt; 0:
        mypro=50
    else:
        mypro=None
    if verbose &gt; 0:
        print(&#34;thickness&#34;)
    thkdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T1w&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;flair&#34;)
    flairdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T2Flair&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;NM&#34;)
    nmdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;NM2DMT&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;rsf&#34;)
    rsfdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;rsfMRI*&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;dti&#34;)
    dtidf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;DTI*&#39;, progress=mypro, verbose=verbose==2 )
    if not merge:
        return hierdf, thkdf, flairdf, nmdf, rsfdf, dtidf
    hierdfmix = hierdf.copy()
    modality_df_suffixes = [
        (thkdf, &#34;_thk&#34;),
        (flairdf, &#34;_flair&#34;),
        (nmdf, &#34;_nm&#34;),
        (rsfdf, &#34;_rsf&#34;),
        (dtidf, &#34;_dti&#34;),
    ]
    for pair in modality_df_suffixes:
        hierdfmix = merge_mm_dataframe(hierdfmix, pair[0], pair[1])
    hierdfmix = hierdfmix.replace(r&#39;^\s*$&#39;, np.nan, regex=True)
    return hierdfmix, hierdfmix.groupby(&#34;u_hier_id&#34;, as_index=False).mean(numeric_only=True)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.blind_image_assessment"><code class="name flex">
<span>def <span class="ident">blind_image_assessment</span></span>(<span>image, viz_filename=None, title=False, pull_rank=False, resample=None, n_to_skip=10, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>quick blind image assessment and triplanar visualization of an image &hellip; 4D input will be visualized and assessed in 3D.
produces a png and csv where csv contains:</p>
<ul>
<li>
<p>reflection error ( estimates asymmetry )</p>
</li>
<li>
<p>brisq ( blind quality assessment )</p>
</li>
<li>
<p>patch eigenvalue ratio ( blind quality assessment )</p>
</li>
<li>
<p>PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)</p>
</li>
<li>
<p>mask volume ( estimates foreground object size )</p>
</li>
<li>
<p>spacing</p>
</li>
<li>
<p>dimension after cropping by mask</p>
</li>
</ul>
<p>image : character or image object usually a nifti image</p>
<p>viz_filename : character for a png output image</p>
<p>title : display a summary title on the png</p>
<p>pull_rank : boolean</p>
<p>resample : None, numeric max or min, resamples image to isotropy</p>
<p>n_to_skip : 10 by default; samples time series every n_to_skip volume</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blind_image_assessment(
    image,
    viz_filename=None,
    title=False,
    pull_rank=False,
    resample=None,
    n_to_skip = 10,
    verbose=False
):
    &#34;&#34;&#34;
    quick blind image assessment and triplanar visualization of an image ... 4D input will be visualized and assessed in 3D.  produces a png and csv where csv contains:

    * reflection error ( estimates asymmetry )

    * brisq ( blind quality assessment )

    * patch eigenvalue ratio ( blind quality assessment )

    * PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)

    * mask volume ( estimates foreground object size )

    * spacing

    * dimension after cropping by mask

    image : character or image object usually a nifti image

    viz_filename : character for a png output image

    title : display a summary title on the png

    pull_rank : boolean

    resample : None, numeric max or min, resamples image to isotropy

    n_to_skip : 10 by default; samples time series every n_to_skip volume

    verbose : boolean

    &#34;&#34;&#34;
    import glob as glob
    from os.path import exists
    import ants
    import matplotlib.pyplot as plt
    from PIL import Image
    from pathlib import Path
    import json
    import re
    from dipy.io.gradients import read_bvals_bvecs
    mystem=&#39;&#39;
    if isinstance(image,list):
        isfilename=isinstance( image[0], str)
        image = image[0]
    else:
        isfilename=isinstance( image, str)
    outdf = pd.DataFrame()
    mymeta = None
    MagneticFieldStrength = None
    image_filename=&#39;&#39;
    if isfilename:
        image_filename = image
        if isinstance(image,list):
            image_filename=image[0]
        json_name = re.sub(&#34;.nii.gz&#34;,&#34;.json&#34;,image_filename)
        if exists( json_name ):
            try:
                with open(json_name, &#39;r&#39;) as fcc_file:
                    mymeta = json.load(fcc_file)
                    if verbose:
                        print(json.dumps(mymeta, indent=4))
                    fcc_file.close()
            except:
                pass
        mystem=Path( image ).stem
        mystem=Path( mystem ).stem
        image_reference = ants.image_read( image )
        image = ants.image_read( image )
    else:
        image_reference = ants.image_clone( image )
    ntimepoints = 1
    bvalueMax=None
    if image_reference.dimension == 4:
        ntimepoints = image_reference.shape[3]
        if &#34;DTI&#34; in image_filename:
            myTSseg = segment_timeseries_by_meanvalue( image_reference )
            image_b0, image_dwi = get_average_dwi_b0( image_reference, fast=True )
            image_b0 = ants.iMath( image_b0, &#39;Normalize&#39; )
            image_dwi = ants.iMath( image_dwi, &#39;Normalize&#39; )
            bval_name = re.sub(&#34;.nii.gz&#34;,&#34;.bval&#34;,image_filename)
            bvec_name = re.sub(&#34;.nii.gz&#34;,&#34;.bvec&#34;,image_filename)
            if exists( bval_name ) and exists( bvec_name ):
                bvals, bvecs = read_bvals_bvecs( bval_name , bvec_name  )
                bvalueMax = bvals.max()
        else:
            image_b0 = ants.get_average_of_timeseries( image_reference ).iMath(&#34;Normalize&#34;)
    else:
        image_compare = ants.smooth_image( image_reference, 3, sigma_in_physical_coordinates=False )
    for jjj in range(0,ntimepoints,n_to_skip):
        modality=&#39;unknown&#39;
        if &#34;rsfMRI&#34; in image_filename:
            modality=&#39;rsfMRI&#39;
        elif &#34;T1w&#34; in image_filename:
            modality=&#39;T1w&#39;
        elif &#34;T2Flair&#34; in image_filename:
            modality=&#39;T2Flair&#39;
        elif &#34;NM2DMT&#34; in image_filename:
            modality=&#39;NM2DMT&#39;
        if image_reference.dimension == 4:
            image = ants.slice_image( image_reference, idx=int(jjj), axis=3 )
            if &#34;DTI&#34; in image_filename:
                if jjj in myTSseg[&#39;highermeans&#39;]:
                    image_compare = ants.image_clone( image_b0 )
                    modality=&#39;DTIb0&#39;
                else:
                    image_compare = ants.image_clone( image_dwi )
                    modality=&#39;DTIdwi&#39;
            else:
                image_compare = ants.image_clone( image_b0 )
        # image = ants.iMath( image, &#39;TruncateIntensity&#39;,0.01,0.995)
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        if resample is not None:
            if resample == &#39;min&#39;:
                if minspc &lt; 1e-12:
                    minspc = np.max(ants.get_spacing(image))
                newspc = np.repeat( minspc, 3 )
            elif resample == &#39;max&#39;:
                newspc = np.repeat( maxspc, 3 )
            else:
                newspc = np.repeat( resample, 3 )
            image = ants.resample_image( image, newspc )
            image_compare = ants.resample_image( image_compare, newspc )
        else:
            # check for spc close to zero
            spc = list(ants.get_spacing(image))
            for spck in range(len(spc)):
                if spc[spck] &lt; 1e-12:
                    spc[spck]=1
            ants.set_spacing( image, spc )
            ants.set_spacing( image_compare, spc )
        # if &#34;NM2DMT&#34; in image_filename or &#34;FIXME&#34; in image_filename or &#34;SPECT&#34; in image_filename or &#34;UNKNOWN&#34; in image_filename:
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        msk = ants.threshold_image( ants.iMath(image,&#39;Normalize&#39;), 0.15, 1.0 )
        # else:
        #    msk = ants.get_mask( image )
        msk = ants.morphology(msk, &#34;close&#34;, 3 )
        bgmsk = msk*0+1-msk
        mskdil = ants.iMath(msk, &#34;MD&#34;, 4 )
        # ants.plot_ortho( image, msk, crop=False )
        nvox = int( msk.sum() )
        spc = ants.get_spacing( image )
        org = ants.get_origin( image )
        if ( nvox &gt; 0 ):
            image = ants.crop_image( image, mskdil ).iMath(&#34;Normalize&#34;)
            msk = ants.crop_image( msk, mskdil ).iMath(&#34;Normalize&#34;)
            bgmsk = ants.crop_image( bgmsk, mskdil ).iMath(&#34;Normalize&#34;)
            image_compare = ants.crop_image( image_compare, mskdil ).iMath(&#34;Normalize&#34;)           
            npatch = int( np.round(  0.1 * nvox ) )
            npatch = np.min(  [512,npatch ] )
            patch_shape = []
            for k in range( 3 ):
                p = int( 32.0 / ants.get_spacing( image  )[k] )
                if p &gt; int( np.round( image.shape[k] * 0.5 ) ):
                    p = int( np.round( image.shape[k] * 0.5 ) )
                patch_shape.append( p )
            if verbose:
                print(image)
                print( patch_shape )
                print( npatch )
            myevr = math.nan # dont want to fail if something odd happens in patch extraction
            try:
                myevr = antspyt1w.patch_eigenvalue_ratio( image, npatch, patch_shape,
                    evdepth = 0.9, mask=msk )
            except:
                pass
            if pull_rank:
                image = ants.rank_intensity(image)
            imagereflect = ants.reflect_image(image, axis=0)
            asym_err = ( image - imagereflect ).abs().mean()
            # estimate noise by center cropping, denoizing and taking magnitude of difference
            nocrop=False
            if image.dimension == 3:
                if image.shape[2] == 1:
                    nocrop=True        
            if maxspc/minspc &gt; 10:
                nocrop=True
            if nocrop:
                mycc = ants.image_clone( image )
            else:
                mycc = antspyt1w.special_crop( image,
                    ants.get_center_of_mass( msk *0 + 1 ), patch_shape )
            myccd = ants.denoise_image( mycc, p=2,r=2,noise_model=&#39;Gaussian&#39; )
            noizlevel = ( mycc - myccd ).abs().mean()
    #        ants.plot_ortho( image, crop=False, filename=viz_filename, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
    #        from brisque import BRISQUE
    #        obj = BRISQUE(url=False)
    #        mybrisq = obj.score( np.array( Image.open( viz_filename )) )
            msk_vol = msk.sum() * np.prod( spc )
            bgstd = image[ bgmsk == 1 ].std()
            fgmean = image[ msk == 1 ].mean()
            bgmean = image[ bgmsk == 1 ].mean()
            snrref = fgmean / bgstd
            cnrref = ( fgmean - bgmean ) / bgstd
            psnrref = antspynet.psnr(  image_compare, image  )
            ssimref = antspynet.ssim(  image_compare, image  )
            if nocrop:
                mymi = math.inf
            else:
                mymi = ants.image_mutual_information( image_compare, image )
        else:
            msk_vol = 0
            myevr = mymi = ssimref = psnrref = cnrref = asym_err = noizlevel = math.nan
            
        mriseries=None
        mrimfg=None
        mrimodel=None
        mriSAR=None
        BandwidthPerPixelPhaseEncode=None
        PixelBandwidth=None
        if mymeta is not None:
            # mriseries=mymeta[&#39;&#39;]
            try:
                mrimfg=mymeta[&#39;Manufacturer&#39;]
            except:
                pass
            try:
                mrimodel=mymeta[&#39;ManufacturersModelName&#39;]
            except:
                pass
            try:
                MagneticFieldStrength=mymeta[&#39;MagneticFieldStrength&#39;]
            except:
                pass
            try:
                PixelBandwidth=mymeta[&#39;PixelBandwidth&#39;]
            except:
                pass
            try:
                BandwidthPerPixelPhaseEncode=mymeta[&#39;BandwidthPerPixelPhaseEncode&#39;]
            except:
                pass
            try:
                mriSAR=mymeta[&#39;SAR&#39;]
            except:
                pass
        ttl=mystem + &#39; &#39;
        ttl=&#39;&#39;
        ttl=ttl + &#34;NZ: &#34; + &#34;{:0.4f}&#34;.format(noizlevel) + &#34; SNR: &#34; + &#34;{:0.4f}&#34;.format(snrref) + &#34; CNR: &#34; + &#34;{:0.4f}&#34;.format(cnrref) + &#34; PS: &#34; + &#34;{:0.4f}&#34;.format(psnrref)+ &#34; SS: &#34; + &#34;{:0.4f}&#34;.format(ssimref) + &#34; EVR: &#34; + &#34;{:0.4f}&#34;.format(myevr)+ &#34; MI: &#34; + &#34;{:0.4f}&#34;.format(mymi)
        if viz_filename is not None and ( jjj == 0 or (jjj % 30 == 0) ) and image.shape[2] &lt; 685:
            viz_filename_use = re.sub( &#34;.png&#34;, &#34;_slice&#34;+str(jjj).zfill(4)+&#34;.png&#34;, viz_filename )
            ants.plot_ortho( image, crop=False, filename=viz_filename_use, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0,  title=ttl, titlefontsize=12, title_dy=-0.02,textfontcolor=&#39;red&#39; )
        df = pd.DataFrame([[ 
            mystem, 
            image_reference.dimension, 
            noizlevel, snrref, cnrref, psnrref, ssimref, mymi, asym_err, myevr, msk_vol, 
            spc[0], spc[1], spc[2],org[0], org[1], org[2], 
            image.shape[0], image.shape[1], image.shape[2], ntimepoints, 
            jjj, modality, mriseries, mrimfg, mrimodel, MagneticFieldStrength, mriSAR, PixelBandwidth, BandwidthPerPixelPhaseEncode, bvalueMax ]], 
            columns=[
                &#39;filename&#39;, 
                &#39;dimensionality&#39;,
                &#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;,&#39;spc1&#39;,&#39;spc2&#39;,&#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;,&#39;dimx&#39;,&#39;dimy&#39;,&#39;dimz&#39;,&#39;dimt&#39;,&#39;slice&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39;, &#39;mriMagneticFieldStrength&#39;, &#39;mriSAR&#39;, &#39;mriPixelBandwidth&#39;, &#39;mriPixelBandwidthPE&#39;, &#39;dti_bvalueMax&#39; ])
        outdf = pd.concat( [outdf, df ], axis=0, ignore_index=False )
        if verbose:
            print( outdf )
    if viz_filename is not None:
        csvfn = re.sub( &#34;png&#34;, &#34;csv&#34;, viz_filename )
        outdf.to_csv( csvfn )
    return outdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.boot_wmh"><code class="name flex">
<span>def <span class="ident">boot_wmh</span></span>(<span>flair, t1, t1seg, mmfromconvexhull=0.0, strict=True, probability_mask=None, prior_probability=None, n_simulations=16, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def boot_wmh( flair, t1, t1seg, mmfromconvexhull = 0.0, strict=True,
        probability_mask=None, prior_probability=None, n_simulations=16,
        verbose=False ) :
    if verbose and prior_probability is None:
        print(&#34;augmented flair&#34;)
    if verbose and prior_probability is not None:
        print(&#34;augmented flair with prior&#34;)
    wmh_sum_aug = 0
    wmh_sum_prior_aug = 0
    augprob = flair * 0.0
    augprob_prior = None
    if prior_probability is not None:
        augprob_prior = flair * 0.0
    for n in range(n_simulations):
        augflair, tx, itx = augment_image( ants.iMath(flair,&#34;Normalize&#34;), 5, 0.01 )
        locwmh = wmh( augflair, t1, t1seg, mmfromconvexhull = mmfromconvexhull,
            strict=strict, probability_mask=None, prior_probability=prior_probability )
        if verbose:
            print( &#34;flair sim: &#34; + str(n) + &#34; vol: &#34; + str( locwmh[&#39;wmh_mass&#39;] )+ &#34; vol-prior: &#34; + str( locwmh[&#39;wmh_mass_prior&#39;] )+ &#34; snr: &#34; + str( locwmh[&#39;wmh_SNR&#39;] ) )
        wmh_sum_aug = wmh_sum_aug + locwmh[&#39;wmh_mass&#39;]
        wmh_sum_prior_aug = wmh_sum_prior_aug + locwmh[&#39;wmh_mass_prior&#39;]
        temp = locwmh[&#39;WMH_probability_map&#39;]
        augprob = augprob + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
        if prior_probability is not None:
            temp = locwmh[&#39;WMH_posterior_probability_map&#39;]
            augprob_prior = augprob_prior + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
    augprob = augprob * (1.0/float( n_simulations ))
    if prior_probability is not None:
        augprob_prior = augprob_prior * (1.0/float( n_simulations ))
    wmh_sum_aug = wmh_sum_aug / float( n_simulations )
    wmh_sum_prior_aug = wmh_sum_prior_aug / float( n_simulations )
    return{
      &#39;flair&#39; : ants.iMath(flair,&#34;Normalize&#34;),
      &#39;WMH_probability_map&#39; : augprob,
      &#39;WMH_posterior_probability_map&#39; : augprob_prior,
      &#39;wmh_mass&#39;: wmh_sum_aug,
      &#39;wmh_mass_prior&#39;: wmh_sum_prior_aug,
      &#39;wmh_evr&#39;: locwmh[&#39;wmh_evr&#39;],
      &#39;wmh_SNR&#39;: locwmh[&#39;wmh_SNR&#39;]  }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bvec_reorientation"><code class="name flex">
<span>def <span class="ident">bvec_reorientation</span></span>(<span>motion_parameters, bvecs, rebase=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bvec_reorientation( motion_parameters, bvecs, rebase=None ):
    if motion_parameters is None:
        return bvecs
    n = len(motion_parameters)
    if n &lt; 1:
        return bvecs
    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs
    dipymoco = np.zeros( [n,3,3] )
    for myidx in range(n):
        if myidx &lt; bvecs.shape[0]:
            dipymoco[myidx,:,:] = np.eye( 3 )
            if motion_parameters[myidx] != &#39;NA&#39;:
                temp = motion_parameters[myidx]
                if len(temp) == 4 :
                    temp1=temp[3] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                elif len(temp) == 2 :
                    temp=temp[1] # FIXME should be composite of index 1 and 3
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                elif len(temp) == 3 :
                    temp1=temp[2] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                else:
                    temp=temp[0]
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                bvecs[myidx,:] = np.dot( Rinv, bvecs[myidx,:] )
                if rebase is not None:
                    # FIXME - should combine these operations
                    bvecs[myidx,:] = np.dot( rebase, bvecs[myidx,:] )
    return bvecs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.clean_tmp_directory"><code class="name flex">
<span>def <span class="ident">clean_tmp_directory</span></span>(<span>age_hours=1.0, use_sudo=False, extensions=['.nii', '.nii.gz'], log_file_path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clean the /tmp directory by removing files and directories older than a certain number of hours.
Optionally uses sudo and can filter files by extensions.</p>
<p>:param age_hours: Age in hours to consider files and directories for deletion.
:param use_sudo: Whether to use sudo for removal commands.
:param extensions: List of file extensions to delete. If None, all files are considered.
:param log_file_path: Path to the log file. If None, a default path will be used based on the OS.</p>
<h1 id="usage">Usage</h1>
<h1 id="example-clean_tmp_directoryage_hours1-use_sudotrue-extensionslog-tmp">Example: clean_tmp_directory(age_hours=1, use_sudo=True, extensions=['.log', '.tmp'])</h1></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_tmp_directory(age_hours=1., use_sudo=False, extensions=[ &#39;.nii&#39;, &#39;.nii.gz&#39; ], log_file_path=None):
    &#34;&#34;&#34;
    Clean the /tmp directory by removing files and directories older than a certain number of hours.
    Optionally uses sudo and can filter files by extensions.

    :param age_hours: Age in hours to consider files and directories for deletion.
    :param use_sudo: Whether to use sudo for removal commands.
    :param extensions: List of file extensions to delete. If None, all files are considered.
    :param log_file_path: Path to the log file. If None, a default path will be used based on the OS.

    # Usage
    # Example: clean_tmp_directory(age_hours=1, use_sudo=True, extensions=[&#39;.log&#39;, &#39;.tmp&#39;])
    &#34;&#34;&#34;
    import os
    import platform
    import subprocess
    from datetime import datetime, timedelta

    if not isinstance(age_hours, float):
        return

    # Determine the tmp directory based on the operating system
    tmp_dir = &#39;/tmp&#39;

    # Set the log file path
    if log_file_path is not None:
        log_file = log_file_path

    current_time = datetime.now()
    for item in os.listdir(tmp_dir):
        try:
            item_path = os.path.join(tmp_dir, item)
            item_stat = os.stat(item_path)

            # Calculate the age of the file/directory
            item_age = current_time - datetime.fromtimestamp(item_stat.st_mtime)
            if item_age &gt; timedelta(hours=age_hours):
                # Check for file extensions if provided
                if extensions is None or any(item.endswith(ext) for ext in extensions):
                    # Construct the removal command
                    rm_command = [&#39;sudo&#39;, &#39;rm&#39;, &#39;-rf&#39;, item_path] if use_sudo else [&#39;rm&#39;, &#39;-rf&#39;, item_path]
                    subprocess.run(rm_command)

                if log_file_path is not None:
                    with open(log_file, &#39;a&#39;) as log:
                        log.write(f&#34;{datetime.now()}: Deleted {item_path}\n&#34;)
        except Exception as e:
            if log_file_path is not None:
                with open(log_file, &#39;a&#39;) as log:
                    log.write(f&#34;{datetime.now()}: Error deleting {item_path}: {e}\n&#34;)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.collect_blind_qc_by_modality"><code class="name flex">
<span>def <span class="ident">collect_blind_qc_by_modality</span></span>(<span>modality_path, set_index_to_fn=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Collects blind QC data from multiple CSV files with the same modality.</p>
<p>Args:</p>
<p>modality_path (str): The path to the folder containing the CSV files.</p>
<p>set_index_to_fn: boolean</p>
<p>Returns:
Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def collect_blind_qc_by_modality( modality_path, set_index_to_fn=True ):
    &#34;&#34;&#34;
    Collects blind QC data from multiple CSV files with the same modality.

    Args:

    modality_path (str): The path to the folder containing the CSV files.

    set_index_to_fn: boolean

    Returns:
    Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.
    &#34;&#34;&#34;
    import glob as glob
    fns = glob.glob( modality_path )
    fns.sort()
    jdf = pd.DataFrame()
    for k in range(len(fns)):
        temp=pd.read_csv(fns[k])
        if not &#39;filename&#39; in temp.keys():
            temp[&#39;filename&#39;]=fns[k]
        jdf=pd.concat( [jdf,temp], axis=0, ignore_index=False )
    if set_index_to_fn:
        jdf.reset_index(drop=True)
        if &#34;Unnamed: 0&#34; in jdf.columns:
            holder=jdf.pop( &#34;Unnamed: 0&#34; )
        jdf.set_index(&#39;filename&#39;)
    return jdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.concat_dewarp"><code class="name flex">
<span>def <span class="ident">concat_dewarp</span></span>(<span>refimg, originalDWI, physSpaceDWI, dwpTx, motion_parameters, motion_correct=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply concatentated motion correction and dewarping transforms to timeseries image.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>refimg</code></strong> :&ensp;<code>an antsImage defining the reference domain (3D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>originalDWI</code></strong> :&ensp;<code>the antsImage in original (not interpolated space) (4D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>physSpaceDWI</code></strong> :&ensp;<code>ants antsImage defining the physical space</code> of <code>the mapping (4D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dwpTx</code></strong> :&ensp;<code>dewarping transform</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_parameters</code></strong> :&ensp;<code>previously computed list</code> of <code>motion parameters</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concat_dewarp(
        refimg,
        originalDWI,
        physSpaceDWI,
        dwpTx,
        motion_parameters,
        motion_correct=True,
        verbose=False ):
    &#34;&#34;&#34;
    Apply concatentated motion correction and dewarping transforms to timeseries image.

    Arguments
    ---------

    refimg : an antsImage defining the reference domain (3D)

    originalDWI : the antsImage in original (not interpolated space) (4D)

    physSpaceDWI : ants antsImage defining the physical space of the mapping (4D)

    dwpTx : dewarping transform

    motion_parameters : previously computed list of motion parameters

    motion_correct : boolean

    verbose : boolean

    &#34;&#34;&#34;
    # apply the dewarping tx to the original dwi and reconstruct again
    # NOTE: refimg must be in the same space for this to work correctly
    # due to the use of ants.list_to_ndimage( originalDWI, dwpimage )
    dwpimage = []
    for myidx in range(originalDWI.shape[3]):
        b0 = ants.slice_image( originalDWI, axis=3, idx=myidx)
        concatx = dwpTx.copy()
        if motion_correct:
            concatx = concatx + motion_parameters[myidx]
        if verbose and myidx == 0:
            print(&#34;dwp parameters&#34;)
            print( dwpTx )
            print(&#34;Motion parameters&#34;)
            print( motion_parameters[myidx] )
            print(&#34;concat parameters&#34;)
            print(concatx)
        warpedb0 = ants.apply_transforms( refimg, b0, concatx,
            interpolator=&#39;nearestNeighbor&#39; )
        dwpimage.append( warpedb0 )
    return ants.list_to_ndimage( physSpaceDWI, dwpimage )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.crop_mcimage"><code class="name flex">
<span>def <span class="ident">crop_mcimage</span></span>(<span>x, mask, padder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>crop a time series (4D) image by a 3D mask</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>raw image</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>mask
: mask for cropping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_mcimage( x, mask, padder=None ):
    &#34;&#34;&#34;
    crop a time series (4D) image by a 3D mask

    Parameters
    -------------

    x : raw image

    mask  : mask for cropping

    &#34;&#34;&#34;
    cropmask = ants.crop_image( mask, mask )
    myorig = list( ants.get_origin(cropmask) )
    myorig.append( ants.get_origin( x )[3] )
    croplist = []
    if len(x.shape) &gt; 3:
        for k in range(x.shape[3]):
            temp = ants.slice_image( x, axis=3, idx=k )
            temp = ants.crop_image( temp, mask )
            if padder is not None:
                temp = ants.pad_image( temp, pad_width=padder )
            croplist.append( temp )
        temp = ants.list_to_ndimage( x, croplist )
        temp.set_origin( myorig )
        return temp
    else:
        return( ants.crop_image( x, mask ) )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dewarp_imageset"><code class="name flex">
<span>def <span class="ident">dewarp_imageset</span></span>(<span>image_list, initial_template=None, iterations=None, padding=0, target_idx=[0], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Dewarp a set of images</p>
<p>Makes simplifying heuristic decisions about how to transform an image set
into an unbiased reference space.
Will handle plenty of decisions
automatically so beware.
Computes an average shape space for the images
and transforms them to that space.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image_list</code></strong> :&ensp;<code>list containing antsImages 2D, 3D</code> or <code>4D</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>initial_template</code></strong> :&ensp;<code>optional</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>iterations</code></strong> :&ensp;<code>number</code> of <code>template building iterations</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>padding</code></strong> :&ensp;<code> will pad the images by an integer amount to limit edge effects</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_idx</code></strong> :&ensp;<code>the target indices for the time series over which we should average;</code></dt>
<dd>a list of integer indices into the last axis of the input images.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>keyword args</code></dt>
<dd>arguments passed to ants registration - these must be set explicitly</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary with the mean image and the list</code> of <code>the transformed images as</code></dt>
<dd>&nbsp;</dd>
<dt><code>well as motion correction parameters for each image in the input list</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dewarp_imageset( image_list, initial_template=None,
    iterations=None, padding=0, target_idx=[0], **kwargs ):
    &#34;&#34;&#34;
    Dewarp a set of images

    Makes simplifying heuristic decisions about how to transform an image set
    into an unbiased reference space.  Will handle plenty of decisions
    automatically so beware.  Computes an average shape space for the images
    and transforms them to that space.

    Arguments
    ---------
    image_list : list containing antsImages 2D, 3D or 4D

    initial_template : optional

    iterations : number of template building iterations

    padding:  will pad the images by an integer amount to limit edge effects

    target_idx : the target indices for the time series over which we should average;
        a list of integer indices into the last axis of the input images.

    kwargs : keyword args
        arguments passed to ants registration - these must be set explicitly

    Returns
    -------
    a dictionary with the mean image and the list of the transformed images as
    well as motion correction parameters for each image in the input list

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    outlist = []
    avglist = []
    if len(image_list[0].shape) &gt; 3:
        imagetype = 3
        for k in range(len(image_list)):
            for j in range(len(target_idx)):
                avglist.append( ants.slice_image( image_list[k], axis=3, idx=target_idx[j] ) )
    else:
        imagetype = 0
        avglist=image_list

    pw=[]
    for k in range(len(avglist[0].shape)):
        pw.append( padding )
    for k in range(len(avglist)):
        avglist[k] = ants.pad_image( avglist[k], pad_width=pw  )

    if initial_template is None:
        initial_template = avglist[0] * 0
        for k in range(len(avglist)):
            initial_template = initial_template + avglist[k]/len(avglist)

    if iterations is None:
        iterations = 2

    btp = ants.build_template(
        initial_template=initial_template,
        image_list=avglist,
        gradient_step=0.5, blending_weight=0.8,
        iterations=iterations, **kwargs )

    # last - warp all images to this frame
    mocoplist = []
    mocofdlist = []
    reglist = []
    for k in range(len(image_list)):
        if imagetype == 3:
            moco0 = ants.motion_correction( image=image_list[k], fixed=btp, type_of_transform=&#39;BOLDRigid&#39; )
            mocoplist.append( moco0[&#39;motion_parameters&#39;] )
            mocofdlist.append( moco0[&#39;FD&#39;] )
            locavg = ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=0 ) * 0.0
            for j in range(len(target_idx)):
                locavg = locavg + ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=target_idx[j] )
            locavg = locavg * 1.0 / len(target_idx)
        else:
            locavg = image_list[k]
        reg = ants.registration( btp, locavg, **kwargs )
        reglist.append( reg )
        if imagetype == 3:
            myishape = image_list[k].shape
            mytslength = myishape[ len(myishape) - 1 ]
            mywarpedlist = []
            for j in range(mytslength):
                locimg = ants.slice_image( image_list[k], axis=3, idx = j )
                mywarped = ants.apply_transforms( btp, locimg,
                    reg[&#39;fwdtransforms&#39;] + moco0[&#39;motion_parameters&#39;][j], imagetype=0 )
                mywarpedlist.append( mywarped )
            mywarped = ants.list_to_ndimage( image_list[k], mywarpedlist )
        else:
            mywarped = ants.apply_transforms( btp, image_list[k], reg[&#39;fwdtransforms&#39;], imagetype=imagetype )
        outlist.append( mywarped )

    return {
        &#39;dewarpedmean&#39;:btp,
        &#39;dewarped&#39;:outlist,
        &#39;deformable_registrations&#39;: reglist,
        &#39;FD&#39;: mocofdlist,
        &#39;motionparameters&#39;: mocoplist }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dict_to_dataframe"><code class="name flex">
<span>def <span class="ident">dict_to_dataframe</span></span>(<span>data_dict, convert_lists=True, convert_arrays=True, convert_images=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a dictionary to a pandas DataFrame, excluding items that cannot be processed by pandas.</p>
<p>:param data_dict: Dictionary to be converted.
:param convert_lists: boolean
:param convert_arrays: boolean
:param convert_images: boolean
:param verbose: boolean
:return: DataFrame representation of the dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dict_to_dataframe(data_dict, convert_lists=True, convert_arrays=True, convert_images=True, verbose=False):
    &#34;&#34;&#34;
    Convert a dictionary to a pandas DataFrame, excluding items that cannot be processed by pandas.

    :param data_dict: Dictionary to be converted.
    :param convert_lists: boolean
    :param convert_arrays: boolean
    :param convert_images: boolean
    :param verbose: boolean
    :return: DataFrame representation of the dictionary.
    &#34;&#34;&#34;
    processed_data = {}
    list_length = None
    def mean_of_list(lst):
        if not lst:  # Check if the list is not empty
            return 0  # Return 0 or appropriate value for an empty list
        all_numeric = all(isinstance(item, (int, float)) for item in lst)
        if all_numeric:
            return sum(lst) / len(lst)
        return None
    
    for key, value in data_dict.items():
        # Check if value is a scalar
        if isinstance(value, (int, float, str, bool)):
            processed_data[key] = [value]
        # Check if value is a list of scalars
        elif isinstance(value, list) and all(isinstance(item, (int, float, str, bool)) for item in value) and convert_lists:
            meanvalue = mean_of_list( value )
            newkey = key+&#34;_mean&#34;
            if verbose:
                print( &#34; Key &#34; + key + &#34; is list with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
            if newkey not in data_dict.keys() and convert_lists:
                processed_data[newkey] = meanvalue
        elif isinstance(value, np.ndarray) and all(isinstance(item, (int, float, str, bool)) for item in value) and convert_arrays:
            meanvalue = value.mean()
            newkey = key+&#34;_mean&#34;
            if verbose:
                print( &#34; Key &#34; + key + &#34; is nparray with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
            if newkey not in data_dict.keys():
                processed_data[newkey] = meanvalue
        elif isinstance(value, ants.ANTsImage) and convert_images:
            meanvalue = value.mean()
            newkey = key+&#34;_mean&#34;
            if newkey not in data_dict.keys():
                if verbose:
                    print( &#34; Key &#34; + key + &#34; is antsimage with mean &#34; + str(meanvalue) + &#34; to &#34; + newkey )
                processed_data[newkey] = meanvalue
            else:
                if verbose:
                    print( &#34; Key &#34; + key + &#34; is antsimage with mean &#34; + str(meanvalue) + &#34; but &#34; + newkey + &#34; already exists&#34; )

    return pd.DataFrame.from_dict(processed_data)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dipy_dti_recon"><code class="name flex">
<span>def <span class="ident">dipy_dti_recon</span></span>(<span>image, bvalsfn, bvecsfn, mask=None, b0_idx=None, mask_dilation=2, mask_closing=5, fit_method='WLS', trim_the_mask=2.0, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>DiPy DTI reconstruction - building on the DiPy basic DTI example</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvalsfn</code></strong> :&ensp;<code>bvalues
obtained by dipy read_bvals_bvecs</code> or <code>the values themselves</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecsfn</code></strong> :&ensp;<code>bvectors obtained by dipy read_bvals_bvecs</code> or <code>the values themselves</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>brain mask for the DWI/DTI reconstruction; if it is not in the same</code></dt>
<dd>space as the image, we will resample directly to the image space.
This
could lead to problems if the inputs are really incorrect.</dd>
<dt><strong><code>b0_idx</code></strong> :&ensp;<code>the indices</code> of <code>the B0; if None, use segment_timeseries_by_bvalue</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask_dilation</code></strong> :&ensp;<code>integer zero</code> or <code>more dilates the brain mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask_closing</code></strong> :&ensp;<code>integer zero</code> or <code>more closes the brain mask</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) &hellip; if None, will not reconstruct DTI.</p>
<dl>
<dt><strong><code>trim_the_mask</code></strong> :&ensp;<code>float &gt;=0 post-hoc method for trimming the mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)</code></dt>
<dd>&nbsp;</dd>
<dt><code>NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)</code></dt>
<dd>&nbsp;</dd>
<dt><code>NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect</code></dt>
<dd>the tailing image volumes.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dipy_dti_recon(
    image,
    bvalsfn,
    bvecsfn,
    mask = None,
    b0_idx = None,
    mask_dilation = 2,
    mask_closing = 5,
    fit_method=&#39;WLS&#39;,
    trim_the_mask=2.0,
    verbose=False ):
    &#34;&#34;&#34;
    DiPy DTI reconstruction - building on the DiPy basic DTI example

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    bvalsfn : bvalues  obtained by dipy read_bvals_bvecs or the values themselves

    bvecsfn : bvectors obtained by dipy read_bvals_bvecs or the values themselves

    mask : brain mask for the DWI/DTI reconstruction; if it is not in the same
        space as the image, we will resample directly to the image space.  This
        could lead to problems if the inputs are really incorrect.

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_bvalue

    mask_dilation : integer zero or more dilates the brain mask

    mask_closing : integer zero or more closes the brain mask

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) ... if None, will not reconstruct DTI.

    trim_the_mask : float &gt;=0 post-hoc method for trimming the mask

    verbose : boolean

    Returns
    -------
    dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)

    NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)

    NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect
        the tailing image volumes.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    if isinstance(bvecsfn, str):
        bvals, bvecs = read_bvals_bvecs( bvalsfn , bvecsfn   )
    else: # assume we already read them
        bvals = bvalsfn.copy()
        bvecs = bvecsfn.copy()

    b0_idx = segment_timeseries_by_bvalue( bvals )[&#39;highermeans&#39;]

    b0 = ants.slice_image( image, axis=3, idx=b0_idx[0] )
    bxtmod=&#39;bold&#39;
    bxtmod=&#39;t2&#39;
    constant_mask=False
    if mask is not None:
        constant_mask=True
        mask = ants.resample_image_to_target( mask, b0, interp_type=&#39;nearestNeighbor&#39;)
    else:
        mask = antspynet.brain_extraction( b0, bxtmod ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    if mask_closing &gt; 0 and not constant_mask :
        mask = ants.morphology( mask, &#34;close&#34;, mask_closing ) # good
    maskdil = ants.iMath( mask, &#34;MD&#34;, mask_dilation )

    if verbose:
        print(&#34;recon dti.TensorModel&#34;,flush=True)

    def justthefit( gtab, fit_method, imagein, maskin ):
        if fit_method is None:
            return None, None, None, None
        maskedimage=[]
        for myidx in range(imagein.shape[3]):
            b0 = ants.slice_image( imagein, axis=3, idx=myidx)
            maskedimage.append( b0 * maskin )
        maskedimage = ants.list_to_ndimage( imagein, maskedimage )
        maskdata = maskedimage.numpy()
        tenmodel = dti.TensorModel(gtab,fit_method=fit_method)
        tenfit = tenmodel.fit(maskdata)
        FA = fractional_anisotropy(tenfit.evals)
        FA[np.isnan(FA)] = 1
        FA = np.clip(FA, 0, 1)
        MD1 = dti.mean_diffusivity(tenfit.evals)
        MD1 = ants.copy_image_info( b0, ants.from_numpy( MD1.astype(np.float32) ) )
        FA = ants.copy_image_info(  b0, ants.from_numpy( FA.astype(np.float32) ) )
        FA, MD1 = impute_fa( FA, MD1 )
        RGB = color_fa(FA.numpy(), tenfit.evecs)
        RGB = ants.from_numpy( RGB.astype(np.float32) )
        RGB0 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=0 ) )
        RGB1 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=1 ) )
        RGB2 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=2 ) )
        RGB = ants.merge_channels( [RGB0,RGB1,RGB2] )
        return tenfit, FA, MD1, RGB

    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, maskdil )
    if verbose:
        print(&#34;recon dti.TensorModel done&#34;,flush=True)

    # change the brain mask based on high FA values
    if trim_the_mask &gt; 0 and fit_method is not None:
        mask = trim_dti_mask( FA, mask, trim_the_mask )
        tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, mask )

    return {
        &#39;tensormodel&#39; : tenfit,
        &#39;MD&#39; : MD1 ,
        &#39;FA&#39; : FA ,
        &#39;RGB&#39; : RGB,
        &#39;dwi_mask&#39;:mask,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
        }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.docsamson"><code class="name flex">
<span>def <span class="ident">docsamson</span></span>(<span>locmod, studycsv, outputdir, projid, sid, dtid, mysep, t1iid=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Processes image file names based on the specified imaging modality and other parameters.</p>
<p>The function selects file names from the provided dictionary <code>studycsv</code> based on the imaging modality.
It supports various modalities like T1w, T2Flair, perf, NM2DMT, rsfMRI, DTI, and configures the filenames accordingly.
The function can optionally print verbose output during processing.</p>
<p>Parameters:
locmod (str): The imaging modality. Options include 'T1w', 'T2Flair', 'perf', 'NM2DMT', 'rsfMRI', 'DTI'.
studycsv (dict): A dictionary with keys corresponding to imaging modalities and values as file names.
outputdir (str): Base directory for output files.
projid (str): Project identifier.
sid (str): Subject identifier.
dtid (str): Data acquisition time identifier.
mysep (str): Separator used in file naming.
t1iid (str, optional): Identifier related to T1-weighted images, used in naming output files when locmod is not 'T1w'.
verbose (bool, optional): If True, prints detailed information during execution.</p>
<p>Returns:
dict: A dictionary with keys 'modality', 'outprefix', and 'images'.
- 'modality' (str): The imaging modality used.
- 'outprefix' (str): The prefix for output file paths.
- 'images' (list): A list of processed image file names.</p>
<p>Notes:
- The function is designed to work within a specific workflow and might require adaptation for general use.</p>
<p>Examples:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; result = docsamson('T1w', studycsv, outputdir, projid, sid, dtid, mysep)
&gt;&gt;&gt; print(result['modality'])
'T1w'
&gt;&gt;&gt; print(result['outprefix'])
'/path/to/output/directory/T1w/some_identifier'
&gt;&gt;&gt; print(result['images'])
['image1.nii', 'image2.nii']
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def docsamson(locmod, studycsv, outputdir, projid, sid, dtid, mysep, t1iid=None, verbose=True):
    &#34;&#34;&#34;
    Processes image file names based on the specified imaging modality and other parameters.

    The function selects file names from the provided dictionary `studycsv` based on the imaging modality.
    It supports various modalities like T1w, T2Flair, perf, NM2DMT, rsfMRI, DTI, and configures the filenames accordingly.
    The function can optionally print verbose output during processing.

    Parameters:
    locmod (str): The imaging modality. Options include &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;perf&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DTI&#39;.
    studycsv (dict): A dictionary with keys corresponding to imaging modalities and values as file names.
    outputdir (str): Base directory for output files.
    projid (str): Project identifier.
    sid (str): Subject identifier.
    dtid (str): Data acquisition time identifier.
    mysep (str): Separator used in file naming.
    t1iid (str, optional): Identifier related to T1-weighted images, used in naming output files when locmod is not &#39;T1w&#39;.
    verbose (bool, optional): If True, prints detailed information during execution.

    Returns:
    dict: A dictionary with keys &#39;modality&#39;, &#39;outprefix&#39;, and &#39;images&#39;.
        - &#39;modality&#39; (str): The imaging modality used.
        - &#39;outprefix&#39; (str): The prefix for output file paths.
        - &#39;images&#39; (list): A list of processed image file names.

    Notes:
    - The function is designed to work within a specific workflow and might require adaptation for general use.

    Examples:
    &gt;&gt;&gt; result = docsamson(&#39;T1w&#39;, studycsv, outputdir, projid, sid, dtid, mysep)
    &gt;&gt;&gt; print(result[&#39;modality&#39;])
    &#39;T1w&#39;
    &gt;&gt;&gt; print(result[&#39;outprefix&#39;])
    &#39;/path/to/output/directory/T1w/some_identifier&#39;
    &gt;&gt;&gt; print(result[&#39;images&#39;])
    [&#39;image1.nii&#39;, &#39;image2.nii&#39;]
    &#34;&#34;&#34;

    import os
    import re

    myimgsInput = []
    myoutputPrefix = None
    imfns = [&#39;filename&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;flairid&#39;]
    
    # Define image file names based on the modality
    if locmod == &#39;T1w&#39;:
        imfns=[&#39;filename&#39;]
    elif locmod == &#39;T2Flair&#39;:
        imfns=[&#39;flairid&#39;]
    elif locmod == &#39;perf&#39;:
        imfns=[&#39;perfid&#39;]
    elif locmod == &#39;NM2DMT&#39;:
        imfns=[]
        for i in range(11):
            imfns.append(&#39;nmid&#39; + str(i))
    elif locmod == &#39;rsfMRI&#39;:
        imfns=[]
        for i in range(4):
            imfns.append(&#39;rsfid&#39; + str(i))
    elif locmod == &#39;DTI&#39;:
        imfns=[]
        for i in range(4):
            imfns.append(&#39;dtid&#39; + str(i))

    # Process each file name
    for i in imfns:
        if verbose:
            print(i + &#34; &#34; + locmod)
        if i in studycsv.keys():
            fni = str(studycsv[i].iloc[0])
            if verbose:
                print(i + &#34; &#34; + fni + &#39; exists &#39; + str(os.path.exists(fni)))
            if os.path.exists(fni):
                myimgsInput.append(fni)
                temp = os.path.basename(fni)
                mysplit = temp.split(mysep)
                iid = re.sub(&#34;.nii.gz&#34;, &#34;&#34;, mysplit[-1])
                iid = re.sub(&#34;.mha&#34;, &#34;&#34;, iid)
                iid = re.sub(&#34;.nii&#34;, &#34;&#34;, iid)
                iid2 = iid
                if locmod != &#39;T1w&#39; and t1iid is not None:
                    iid2 = iid + &#34;_&#34; + t1iid
                else:
                    iid2 = t1iid
                myoutputPrefix = os.path.join(outputdir, projid, sid, dtid, locmod, iid, projid + mysep + sid + mysep + dtid + mysep + locmod + mysep + iid2)
    
    if verbose:
        print(locmod)
        print(myimgsInput)
        print(myoutputPrefix)
    
    return {
        &#39;modality&#39;: locmod,
        &#39;outprefix&#39;: myoutputPrefix,
        &#39;images&#39;: myimgsInput
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.down2iso"><code class="name flex">
<span>def <span class="ident">down2iso</span></span>(<span>x, interpolation='linear', takemin=False)</span>
</code></dt>
<dd>
<div class="desc"><p>will downsample an anisotropic image to an isotropic resolution</p>
<p>x: input image</p>
<p>interpolation: linear or nearestneighbor</p>
<p>takemin : boolean map to min space; otherwise max</p>
<p>return image downsampled to isotropic resolution</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def down2iso( x, interpolation=&#39;linear&#39;, takemin=False ):
    &#34;&#34;&#34;
    will downsample an anisotropic image to an isotropic resolution

    x: input image

    interpolation: linear or nearestneighbor

    takemin : boolean map to min space; otherwise max

    return image downsampled to isotropic resolution
    &#34;&#34;&#34;
    spc = ants.get_spacing( x )
    if takemin:
        newspc = np.asarray(spc).min()
    else:
        newspc = np.asarray(spc).max()
    newspc = np.repeat( newspc, x.dimension )
    if interpolation == &#39;linear&#39;:
        xs = ants.resample_image( x, newspc, interp_type=0)
    else:
        xs = ants.resample_image( x, newspc, interp_type=1)
    return xs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dti_reg"><code class="name flex">
<span>def <span class="ident">dti_reg</span></span>(<span>image, avg_b0, avg_dwi, bvals=None, bvecs=None, b0_idx=None, type_of_transform='Rigid', total_sigma=3.0, fdOffset=2.0, mask_csf=False, output_directory=None, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion - with optional deformation.</p>
<h2 id="arguments">Arguments</h2>
<pre><code>image: antsImage, usually ND where D=4.

avg_b0: Fixed image b0 image

avg_dwi: Fixed dwi same space as b0 image

bvals: bvalues (file or array)

bvecs: bvecs (file or array)

b0_idx: indices of b0

type_of_transform : string
    A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
    See ants registration for details.

fdOffset: offset value to use in framewise displacement calculation

mask_csf: boolean

output_directory : string
    output will be placed in this directory plus a numeric extension.

verbose: boolean

kwargs: keyword args
    extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dti_reg(
    image,
    avg_b0,
    avg_dwi,
    bvals=None,
    bvecs=None,
    b0_idx=None,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=3.0,
    fdOffset=2.0,
    mask_csf=False,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with optional deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        avg_b0: Fixed image b0 image

        avg_dwi: Fixed dwi same space as b0 image

        bvals: bvalues (file or array)

        bvecs: bvecs (file or array)

        b0_idx: indices of b0

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        mask_csf: boolean

        output_directory : string
            output will be placed in this directory plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if bvals is not None and bvecs is not None:
        if isinstance(bvecs, str):
            bvals, bvecs = read_bvals_bvecs( bvals , bvecs  )
        else: # assume we already read them
            bvals = bvals.copy()
            bvecs = bvecs.copy()
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD,
            &#39;bvals&#39;:bvals,
            &#39;bvecs&#39;:bvecs
        }

    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/dti_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]
    # first get a local deformation from slice to local avg space
    # then get a global deformation from avg to ref space
    ab0, adw = get_average_dwi_b0( image )
    mask = ants.get_mask(adw)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)


    if verbose:
        print(&#34;begin global distortion correction&#34;)
    # initrig = tra_initializer(avg_b0, ab0, max_rotation=60, transform=[&#39;rigid&#39;], verbose=verbose)
    if mask_csf:
        bcsf = ants.threshold_image( avg_b0,&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf = ab0 * 0 + 1

    initrig = ants.registration( avg_b0, ab0,&#39;BOLDRigid&#39;,outprefix=ofnG)
    deftx = ants.registration( avg_dwi, adw, &#39;SyNOnly&#39;,
        syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=[50,50,20],
        multivariate_extras=[ [ &#34;CC&#34;, avg_b0, ab0, 1, 2 ]],
        initial_transform=initrig[&#39;fwdtransforms&#39;][0],
        outprefix=ofnG
        )[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;end global distortion correction&#34;)

    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 ) + 1
    for k in range(nTimePoints):
        if verbose and nTimePoints &gt; 0 and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k).zfill(4)+&#34;rig_&#34;
        txprefix2 = ofnL+str(k % 2).zfill(4)+&#34;def_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma, grad_step=0.1,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix2,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        if temp.numpy().var() &gt; 0:
            motion_parameters[k]=deftx+motion_parameters[k]
            img1w = ants.apply_transforms( avg_dwi,
                ants.slice_image(image, axis=idim - 1, idx=k),
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(fixed)

    if verbose:
        print(&#34;Reorient bvecs&#34;)
    if bvecs is not None:
        #    direction = target-&gt;GetDirection().GetTranspose() * img_mov-&gt;GetDirection().GetVnlMatrix();
        rebase = np.dot( np.transpose( avg_b0.direction  ), ab0.direction )
        bvecs = bvec_reorientation( motion_parameters, bvecs, rebase )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( 1.0 )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dti_template"><code class="name flex">
<span>def <span class="ident">dti_template</span></span>(<span>b_image_list=None, w_image_list=None, iterations=5, gradient_step=0.5, mask_csf=False, average_both=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>two channel version of build_template</p>
<p>returns:
avg_b0, avg_dwi</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dti_template(
    b_image_list=None,
    w_image_list=None,
    iterations=5,
    gradient_step=0.5,
    mask_csf=False,
    average_both=True,
    verbose=False
):
    &#34;&#34;&#34;
    two channel version of build_template

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    mydeftx = tempfile.NamedTemporaryFile(delete=False,dir=output_directory).name
    tmp = tempfile.NamedTemporaryFile(delete=False,dir=output_directory,suffix=&#34;.nii.gz&#34;)
    wavgfn = tmp.name
    tmp2 = tempfile.NamedTemporaryFile(delete=False,dir=output_directory)
    comptx = tmp2.name
    weights = np.repeat(1.0 / len(b_image_list), len(b_image_list))
    weights = [x / sum(weights) for x in weights]
    w_initial_template = w_image_list[0]
    b_initial_template = b_image_list[0]
    b_initial_template = ants.iMath(b_initial_template,&#34;Normalize&#34;)
    w_initial_template = ants.iMath(w_initial_template,&#34;Normalize&#34;)
    if mask_csf:
        bcsf0 = ants.threshold_image( b_image_list[0],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
        bcsf1 = ants.threshold_image( b_image_list[1],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf0 = b_image_list[0] * 0 + 1
        bcsf1 = b_image_list[1] * 0 + 1
    bavg = b_initial_template.clone() * bcsf0
    wavg = w_initial_template.clone() * bcsf0
    bcsf = [ bcsf0, bcsf1 ]
    for i in range(iterations):
        for k in range(len(w_image_list)):
            fimg=wavg
            mimg=w_image_list[k] * bcsf[k]
            fimg2=bavg
            mimg2=b_image_list[k] * bcsf[k]
            w1 = ants.registration(
                fimg, mimg, type_of_transform=&#39;antsRegistrationSyNQuick[s]&#39;,
                    multivariate_extras= [ [ &#34;mattes&#34;, fimg2, mimg2, 1, 32 ]],
                    outprefix=mydeftx,
                    verbose=0 )
            txname = ants.apply_transforms(wavg, wavg,
                w1[&#34;fwdtransforms&#34;], compose=comptx )
            if k == 0:
                txavg = ants.image_read(txname) * weights[k]
                wavgnew = ants.apply_transforms( wavg,
                    w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                bavgnew = ants.apply_transforms( wavg,
                    b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
            else:
                txavg = txavg + ants.image_read(txname) * weights[k]
                if i &gt;= (iterations-2) and average_both:
                    wavgnew = wavgnew+ants.apply_transforms( wavg,
                        w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                    bavgnew = bavgnew+ants.apply_transforms( wavg,
                        b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
        if verbose:
            print(&#34;iteration:&#34;,str(i),str(txavg.abs().mean()))
        wscl = (-1.0) * gradient_step
        txavg = txavg * wscl
        ants.image_write( txavg, wavgfn )
        wavg = ants.apply_transforms(wavg, wavgnew, wavgfn).iMath(&#34;Normalize&#34;)
        bavg = ants.apply_transforms(bavg, bavgnew, wavgfn).iMath(&#34;Normalize&#34;)
    import shutil
    shutil.rmtree( output_directory, ignore_errors=True )
    if verbose:
        print(&#34;done&#34;)
    return bavg, wavg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dvars"><code class="name flex">
<span>def <span class="ident">dvars</span></span>(<span>x, mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>dvars on a time series image &hellip; the matrix is normalized to range of 0,1</p>
<p>x: image</p>
<p>mask : mask</p>
<p>indices: indices to use</p>
<p>returns an array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dvars( x,  mask, indices=None ):
    &#34;&#34;&#34;
    dvars on a time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    DVARS = np.zeros( M.shape[0] )
    for i in range(1, M.shape[0] ):
        vecdiff = M[i-1,:] - M[i,:]
        DVARS[i] = np.sqrt( ( vecdiff * vecdiff ).mean() )
    DVARS[0] = DVARS.mean()
    return DVARS</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_closest_peak_tracking"><code class="name flex">
<span>def <span class="ident">dwi_closest_peak_tracking</span></span>(<span>dwi, fa, bvals, bvecs, num_processes=1, mask=None, label_image=None, seed_labels=None, fa_thresh=0.05, seed_density=1, step_size=0.15, peak_indices=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs deterministic tractography from the DWI and returns a tractogram
and path length data frame.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding DWI acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa</code></strong> :&ensp;<code>an antsImage holding FA values</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>bvalues</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>bvectors</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>num_processes</code></strong> :&ensp;<code>number</code> of <code>subprocesses</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>mask within which to do tracking - if None, we will make a mask using the fa_thresh</code></dt>
<dd>and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath("GetLargestComponent")</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_labels</code></strong> :&ensp;<code>list</code> of <code>label numbers from the atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa_thresh</code></strong> :&ensp;<code>0.25 defaults</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_density</code></strong> :&ensp;<code>1 default number</code> of <code>seeds per voxel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>step_size</code></strong> :&ensp;<code>for tracking</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>peak_indices</code></strong> :&ensp;<code>pass these in, if they are previously estimated.
otherwise, will</code></dt>
<dd>compute on the fly (slow)</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding tracts and stateful object.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_closest_peak_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.core.gradients import gradient_table
    from dipy.data import small_sphere
    from dipy.direction import BootDirectionGetter, ClosestPeakDirectionGetter
    from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,
                                    auto_response_ssst)
    from dipy.reconst.shm import CsaOdfModel
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion

    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1


    response, ratio = auto_response_ssst(gtab, dwi_data, roi_radii=10, fa_thr=0.7)
    csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)
    csd_fit = csd_model.fit(dwi_data, mask=dwi_mask)
    csa_model = CsaOdfModel(gtab, sh_order=6)
    gfa = csa_model.fit(dwi_data, mask=dwi_mask).gfa
    stopping_criterion = ThresholdStoppingCriterion(gfa, .25)


    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)

    pmf = csd_fit.odf(small_sphere).clip(min=0)
    if verbose:
        print(&#34;ClosestPeakDirectionGetter begin ...&#34;, flush=True)
    peak_dg = ClosestPeakDirectionGetter.from_pmf(pmf, max_angle=30.,
                                                sphere=small_sphere)
    if verbose:
        print(&#34;local tracking begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(peak_dg, stopping_criterion, seeds,
                                            affine, step_size=.5)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines
          }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_deterministic_tracking"><code class="name flex">
<span>def <span class="ident">dwi_deterministic_tracking</span></span>(<span>dwi, fa, bvals, bvecs, num_processes=1, mask=None, label_image=None, seed_labels=None, fa_thresh=0.05, seed_density=1, step_size=0.15, peak_indices=None, fit_method='WLS', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs deterministic tractography from the DWI and returns a tractogram
and path length data frame.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding DWI acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa</code></strong> :&ensp;<code>an antsImage holding FA values</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>bvalues</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>bvectors</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>num_processes</code></strong> :&ensp;<code>number</code> of <code>subprocesses</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>mask within which to do tracking - if None, we will make a mask using the fa_thresh</code></dt>
<dd>and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath("GetLargestComponent")</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_labels</code></strong> :&ensp;<code>list</code> of <code>label numbers from the atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa_thresh</code></strong> :&ensp;<code>0.25 defaults</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_density</code></strong> :&ensp;<code>1 default number</code> of <code>seeds per voxel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>step_size</code></strong> :&ensp;<code>for tracking</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>peak_indices</code></strong> :&ensp;<code>pass these in, if they are previously estimated.
otherwise, will</code></dt>
<dd>compute on the fly (slow)</dd>
<dt><strong><code>fit_method</code></strong> :&ensp;<code>string one</code> of <code>WLS LS NLLS</code> or <code>restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding tracts and stateful object.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_deterministic_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    bvecs = repair_bvecs( bvecs )
    gtab = gradient_table(bvals, bvecs, atol=2.0 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1
    dti_model = dti.TensorModel(gtab,fit_method=fit_method)
    if verbose:
        print(&#34;begin tracking fit&#34;,flush=True)
    dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while
    evecs_img = dti_fit.evecs
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion
    stopping_criterion = ThresholdStoppingCriterion(fa.numpy(), fa_thresh)
    from dipy.data import get_sphere
    sphere = get_sphere(&#39;symmetric362&#39;)
    from dipy.direction import peaks_from_model
    if peak_indices is None:
        # problems with multi-threading ...
        # see https://github.com/dipy/dipy/issues/2519
        if verbose:
            print(&#34;begin peaks&#34;,flush=True)
        mynump=1
        # if os.getenv(&#34;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#34;):
        #    mynump = os.environ[&#39;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#39;]
        # current_openblas = os.environ.get(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
        # current_mkl = os.environ.get(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)
        # os.environ[&#39;DIPY_OPENBLAS_NUM_THREADS&#39;] = current_openblas
        # os.environ[&#39;DIPY_MKL_NUM_THREADS&#39;] = current_mkl
        # os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = &#39;1&#39;
        # os.environ[&#39;MKL_NUM_THREADS&#39;] = &#39;1&#39;
        peak_indices = peaks_from_model(
            model=dti_model,
            data=dwi_data,
            sphere=sphere,
            relative_peak_threshold=.5,
            min_separation_angle=25,
            mask=dwi_mask,
            npeaks=3, return_odf=False,
            return_sh=False,
            parallel=int(mynump) &gt; 1,
            num_processes=int(mynump)
            )
        if False:
            if &#39;DIPY_OPENBLAS_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
            if &#39;DIPY_MKL_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;MKL_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_MKL_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;MKL_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)

    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(
        peak_indices, stopping_criterion, seeds, affine=affine, step_size=step_size)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines,
          &#39;peak_indices&#39;: peak_indices
          }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_streamline_connectivity"><code class="name flex">
<span>def <span class="ident">dwi_streamline_connectivity</span></span>(<span>streamlines, label_image, label_dataframe, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Summarize network connetivity of the input streamlines between all of the
regions in the label set.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>streamlines</code></strong> :&ensp;<code>streamline object from dipy</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_dataframe</code></strong> :&ensp;<code>pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding summary connection statistics in wide format and matrix format.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_streamline_connectivity(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    labels_to_connect = ulabs[ulabs &gt; 0]
    Ctdf = None
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, not_label = None ):
        pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
        mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
        if not_label is None:
            if ( mylab == target_label ).sum() &gt; 0 :
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            if ( mylab == target_label ).sum() &gt; 0 and ( mylab == not_label ).sum() == 0:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    which = lambda lst:list(np.where(lst)[0])
    myCount = np.zeros( [len(ulabs),len(ulabs)])
    for k in range( len( streamlines ) ):
            sl = streamlines[k]
            mycheck = check_it( sl, labels_to_connect, label_image_np, index=0 )
            if mycheck[&#39;ok&#39;]:
                exclabel=mycheck[&#39;label&#39;]
                lsl = len( sl )-1
                mycheck2 = check_it( sl, labels_to_connect, label_image_np, index=lsl, not_label=exclabel )
                if mycheck2[&#39;ok&#39;]:
                    myCount[ulabs == mycheck[&#39;label&#39;],ulabs == mycheck2[&#39;label&#39;]]+=1
                    ct=ct+1
    Ctdf = label_dataframe.copy()
    for k in range(len(ulabs)):
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
    Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
    return { &#39;connectivity_matrix&#39; :  myCount, &#39;connectivity_wide&#39; : Ctdfw }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_streamline_pairwise_connectivity"><code class="name flex">
<span>def <span class="ident">dwi_streamline_pairwise_connectivity</span></span>(<span>streamlines, label_image, labels_to_connect=[1, None], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return streamlines connecting all of the regions in the label set. Ideal
for just 2 regions.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>streamlines</code></strong> :&ensp;<code>streamline object from dipy</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>labels_to_connect</code></strong> :&ensp;<code>list</code> of <code>2 labels</code> or <code>[label,None]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>the subset</code> of <code>streamlines and a streamline count</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_streamline_pairwise_connectivity( streamlines, label_image, labels_to_connect=[1,None], verbose=False ):
    &#34;&#34;&#34;

    Return streamlines connecting all of the regions in the label set. Ideal
    for just 2 regions.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    labels_to_connect : list of 2 labels or [label,None]

    verbose : boolean

    Returns
    -------
    the subset of streamlines and a streamline count

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    from dipy.tracking.streamline import Streamlines
    keep_streamlines = Streamlines()
    affine = label_image.to_nibabel().affine
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, full=False ):
        if full:
            maxind=sl.shape[0]
            for index in range(maxind):
                pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
                mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
                if mylab == target_label[0] or mylab == target_label[1]:
                    return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
            mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
            if mylab == target_label[0] or mylab == target_label[1]:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    for k in range( len( streamlines ) ):
        sl = streamlines[k]
        mycheck = check_it( sl, labels_to_connect, label_image_np, index=0, full=True )
        if mycheck[&#39;ok&#39;]:
            otherind=1
            if mycheck[&#39;label&#39;] == labels_to_connect[1]:
                otherind=0
            lsl = len( sl )-1
            pt = utils._to_voxel_coordinates(sl[lsl,:], lin_T, offset)
            mylab_end = (label_image_np[ pt[0], pt[1], pt[2] ]).astype(int)
            accept_point = mylab_end == labels_to_connect[otherind]
            if verbose and accept_point:
                print( mylab_end )
            if labels_to_connect[1] is None:
                accept_point = mylab_end != 0
            if accept_point:
                keep_streamlines.append(sl)
                ct=ct+1
    return { &#39;streamlines&#39;: keep_streamlines, &#39;count&#39;: ct }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.enantiomorphic_filling_without_mask"><code class="name flex">
<span>def <span class="ident">enantiomorphic_filling_without_mask</span></span>(<span>image, axis=0, intensity='low')</span>
</code></dt>
<dd>
<div class="desc"><p>Perform an enantiomorphic lesion filling on an image without a lesion mask.</p>
<p>Args:
image (antsImage): The ants image to flip and fill
axis ( int ): the axis along which to reflect the image
intensity ( str ) : low or high</p>
<p>Returns:
ants.ANTsImage: The image after enantiomorphic filling.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enantiomorphic_filling_without_mask( image, axis=0, intensity=&#39;low&#39; ):
    &#34;&#34;&#34;
    Perform an enantiomorphic lesion filling on an image without a lesion mask.

    Args:
    image (antsImage): The ants image to flip and fill
    axis ( int ): the axis along which to reflect the image
    intensity ( str ) : low or high

    Returns:
    ants.ANTsImage: The image after enantiomorphic filling.
    &#34;&#34;&#34;
    imagen = ants.iMath( image, &#39;Normalize&#39; )
    imagen = ants.iMath( imagen, &#34;TruncateIntensity&#34;, 1e-6, 0.98 )
    imagen = ants.iMath( imagen, &#39;Normalize&#39; )
    # Create a mirror image (flipping left and right)
    mirror_image = ants.reflect_image(imagen, axis=0, tx=&#39;SyN&#39; )[&#39;warpedmovout&#39;]

    # Create a symmetric version of the image by averaging the original and the mirror image
    symmetric_image = imagen * 0.5 + mirror_image * 0.5

    # Identify potential lesion areas by finding differences between the original and symmetric image
    difference_image = image - symmetric_image
    diffseg = ants.threshold_image(difference_image, &#34;Otsu&#34;, 3 )
    if intensity == &#39;low&#39;:
        likely_lesion = ants.threshold_image( diffseg, 1,  1)
    else:
        likely_lesion = ants.threshold_image( diffseg, 3,  3)
    likely_lesion = ants.smooth_image( likely_lesion, 3.0 ).iMath(&#34;Normalize&#34;)
    lesionneg = ( imagen*0+1.0 ) - likely_lesion
    filled_image = ants.image_clone(imagen)    
    filled_image = imagen * lesionneg + mirror_image * likely_lesion

    return filled_image, diffseg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.filter_image_files"><code class="name flex">
<span>def <span class="ident">filter_image_files</span></span>(<span>image_paths, criteria='largest')</span>
</code></dt>
<dd>
<div class="desc"><p>Filters a list of image file paths based on specified criteria and returns
the path of the image that best matches that criteria (smallest, largest, or brightest).</p>
<p>Args:
image_paths (list): A list of file paths to the images.
criteria (str): Criteria for selecting the image ('smallest', 'largest', 'brightest').</p>
<p>Returns:
str: The file path of the selected image, or None if no valid images are found.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_image_files(image_paths, criteria=&#39;largest&#39;):
    &#34;&#34;&#34;
    Filters a list of image file paths based on specified criteria and returns 
    the path of the image that best matches that criteria (smallest, largest, or brightest).

    Args:
    image_paths (list): A list of file paths to the images.
    criteria (str): Criteria for selecting the image (&#39;smallest&#39;, &#39;largest&#39;, &#39;brightest&#39;).

    Returns:
    str: The file path of the selected image, or None if no valid images are found.
    &#34;&#34;&#34;
    import numpy as np
    if not image_paths:
        return None

    selected_image_path = None
    if criteria == &#39;smallest&#39; or criteria == &#39;largest&#39;:
        extreme_volume = None

        for path in image_paths:
            try:
                image = ants.image_read(path)
                volume = np.prod(image.shape)

                if criteria == &#39;largest&#39;:
                    if extreme_volume is None or volume &gt; extreme_volume:
                        extreme_volume = volume
                        selected_image_path = path
                elif criteria == &#39;smallest&#39;:
                    if extreme_volume is None or volume &lt; extreme_volume:
                        extreme_volume = volume
                        selected_image_path = path

            except Exception as e:
                print(f&#34;Error processing image {path}: {e}&#34;)

    elif criteria == &#39;brightest&#39;:
        max_brightness = None

        for path in image_paths:
            try:
                image = ants.image_read(path)
                brightness = np.mean(image.numpy())

                if max_brightness is None or brightness &gt; max_brightness:
                    max_brightness = brightness
                    selected_image_path = path

            except Exception as e:
                print(f&#34;Error processing image {path}: {e}&#34;)

    else:
        raise ValueError(&#34;Criteria must be &#39;smallest&#39;, &#39;largest&#39;, or &#39;brightest&#39;.&#34;)

    return selected_image_path</code></pre>
</details>
</dd>
<dt id="antspymm.mm.foreground_background_snr"><code class="name flex">
<span>def <span class="ident">foreground_background_snr</span></span>(<span>x, background_dilation=10, erode_foreground=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_dilation</code></strong> :&ensp;<code>integer - amount to dilate foreground mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>erode_foreground</code></strong> :&ensp;<code>boolean - 2nd option which erodes the initial</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>foregound mask
to create a new foreground mask.
the background
mask is the initial mask minus the eroded mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def foreground_background_snr( x, background_dilation=10,
        erode_foreground=False):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    erode_foreground : boolean - 2nd option which erodes the initial
    foregound mask  to create a new foreground mask.  the background
    mask is the initial mask minus the eroded mask.

    &#34;&#34;&#34;
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xmask = ants.threshold_image( xbc, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmask, &#34;MD&#34;, background_dilation ) - xmask
    fgmask = xmask
    if erode_foreground:
        fgmask = ants.iMath( xmask, &#34;ME&#34;, background_dilation )
        xbkgmask = xmask - fgmask
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.generate_mm_dataframe"><code class="name flex">
<span>def <span class="ident">generate_mm_dataframe</span></span>(<span>projectID, subjectID, date, imageUniqueID, modality, source_image_directory, output_image_directory, t1_filename, flair_filename=[], rsf_filenames=[], dti_filenames=[], nm_filenames=[], perf_filename=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a DataFrame for medical imaging data with extensive validation of input parameters.</p>
<p>This function creates a DataFrame containing information about medical imaging files,
ensuring that filenames match expected patterns for their modalities and that all
required images exist. It also validates the number of filenames provided for specific
modalities like rsfMRI, DTI, and NM.</p>
<p>Parameters:
- projectID (str): Project identifier.
- subjectID (str): Subject identifier.
- date (str): Date of the imaging study.
- imageUniqueID (str): Unique image identifier.
- modality (str): Modality of the imaging study.
- source_image_directory (str): Directory of the source images.
- output_image_directory (str): Directory for output images.
- t1_filename (str): Filename of the T1-weighted image.
- flair_filename (list): List of filenames for FLAIR images.
- rsf_filenames (list): List of filenames for rsfMRI images.
- dti_filenames (list): List of filenames for DTI images.
- nm_filenames (list): List of filenames for NM images.
- perf_filename (list): List of filenames for perfusion images.</p>
<p>Returns:
- pandas.DataFrame: A DataFrame containing the validated imaging study information.</p>
<p>Raises:
- ValueError: If any validation checks fail or if the number of columns does not match the data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_mm_dataframe(
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename=[],
        rsf_filenames=[],
        dti_filenames=[],
        nm_filenames=[],
        perf_filename=[]
):
    &#34;&#34;&#34;
    Generate a DataFrame for medical imaging data with extensive validation of input parameters.

    This function creates a DataFrame containing information about medical imaging files,
    ensuring that filenames match expected patterns for their modalities and that all
    required images exist. It also validates the number of filenames provided for specific
    modalities like rsfMRI, DTI, and NM.

    Parameters:
    - projectID (str): Project identifier.
    - subjectID (str): Subject identifier.
    - date (str): Date of the imaging study.
    - imageUniqueID (str): Unique image identifier.
    - modality (str): Modality of the imaging study.
    - source_image_directory (str): Directory of the source images.
    - output_image_directory (str): Directory for output images.
    - t1_filename (str): Filename of the T1-weighted image.
    - flair_filename (list): List of filenames for FLAIR images.
    - rsf_filenames (list): List of filenames for rsfMRI images.
    - dti_filenames (list): List of filenames for DTI images.
    - nm_filenames (list): List of filenames for NM images.
    - perf_filename (list): List of filenames for perfusion images.

    Returns:
    - pandas.DataFrame: A DataFrame containing the validated imaging study information.

    Raises:
    - ValueError: If any validation checks fail or if the number of columns does not match the data.
    &#34;&#34;&#34;
    def check_pd_construction(data, columns):
        # Check if the length of columns matches the length of data in each row
        if all(len(row) == len(columns) for row in data):
            return True
        else:
            return False
    from os.path import exists
    valid_modalities = get_valid_modalities()
    if not isinstance(t1_filename, str):
        raise ValueError(&#34;t1_filename is not a string&#34;)
    if not exists(t1_filename):
        raise ValueError(&#34;t1_filename does not exist&#34;)
    if modality not in valid_modalities:
        raise ValueError(&#39;modality &#39; + str(modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))
    # if not exists( output_image_directory ):
    #    raise ValueError(&#34;output_image_directory does not exist&#34;)
    if not exists( source_image_directory ):
        raise ValueError(&#34;source_image_directory does not exist&#34;)
    if len( rsf_filenames ) &gt; 2:
        raise ValueError(&#34;len( rsf_filenames ) &gt; 2&#34;)
    if len( dti_filenames ) &gt; 3:
        raise ValueError(&#34;len( dti_filenames ) &gt; 3&#34;)
    if len( nm_filenames ) &gt; 11:
        raise ValueError(&#34;len( nm_filenames ) &gt; 11&#34;)
    if len( rsf_filenames ) &lt; 2:
        for k in range(len(rsf_filenames),2):
            rsf_filenames.append(None)
    if len( dti_filenames ) &lt; 3:
        for k in range(len(dti_filenames),3):
            dti_filenames.append(None)
    if len( nm_filenames ) &lt; 10:
        for k in range(len(nm_filenames),10):
            nm_filenames.append(None)
    # check modality names
    if not &#34;T1w&#34; in t1_filename:
        raise ValueError(&#34;T1w is not in t1 filename &#34; + t1_filename)
    if flair_filename is not None:
        if isinstance(flair_filename,list):
            if (len(flair_filename) == 0):
                flair_filename=None
            else:
                print(&#34;Take first entry from flair_filename list&#34;)
                flair_filename=flair_filename[0]
    if flair_filename is not None and not &#34;lair&#34; in flair_filename:
            raise ValueError(&#34;flair is not flair filename &#34; + flair_filename)
    ## perfusion
    if perf_filename is not None:
        if isinstance(perf_filename,list):
            if (len(perf_filename) == 0):
                perf_filename=None
            else:
                print(&#34;Take first entry from perf_filename list&#34;)
                perf_filename=perf_filename[0]
    if perf_filename is not None and not &#34;perf&#34; in perf_filename:
            raise ValueError(&#34;perf_filename is not perf filename &#34; + perf_filename)
    
    for k in nm_filenames:
        if k is not None:
            if not &#34;NM&#34; in k:
                raise ValueError(&#34;NM is not flair filename &#34; + k)
    for k in dti_filenames:
        if k is not None:
            if not &#34;DTI&#34; in k and not &#34;dwi&#34; in k:
                raise ValueError(&#34;DTI/DWI is not dti filename &#34; + k)
    for k in rsf_filenames:
        if k is not None:
            if not &#34;fMRI&#34; in k and not &#34;func&#34; in k:
                raise ValueError(&#34;rsfMRI/func is not rsfmri filename &#34; + k)
    if perf_filename is not None:
        if not &#34;perf&#34; in perf_filename:
                raise ValueError(&#34;perf_filename is not a valid perfusion (perf) filename &#34; + k)
    allfns = [t1_filename] + [flair_filename] + nm_filenames + dti_filenames + rsf_filenames + [perf_filename]
    for k in allfns:
        if k is not None:
            if not isinstance(k, str):
                raise ValueError(str(k) + &#34; is not a string&#34;)
            if not exists( k ):
                raise ValueError( &#34;image &#34; + k + &#34; does not exist&#34;)
    coredata = [
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename, 
        perf_filename]
    mydata0 = coredata +  rsf_filenames + dti_filenames
    mydata = mydata0 + nm_filenames
    corecols = [
        &#39;projectID&#39;,
        &#39;subjectID&#39;,
        &#39;date&#39;,
        &#39;imageID&#39;,
        &#39;modality&#39;,
        &#39;sourcedir&#39;,
        &#39;outputdir&#39;,
        &#39;filename&#39;,
        &#39;flairid&#39;,
        &#39;perfid&#39;]
    mycols0 = corecols + [
        &#39;rsfid1&#39;, &#39;rsfid2&#39;,
        &#39;dtid1&#39;, &#39;dtid2&#39;,&#39;dtid3&#39;]
    nmext = [
        &#39;nmid1&#39;, &#39;nmid2&#39; &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;,
        &#39;nmid6&#39;, &#39;nmid7&#39;,&#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;nmid11&#39;
    ]
    mycols = mycols0 + nmext
    if not check_pd_construction( [mydata], mycols ) :
        raise ValueError( &#34;Error in generate_mm_dataframe: len( mycols ) != len( mydata ) which indicates a bad input parameter to this function.&#34; )
    studycsv = pd.DataFrame([ mydata ], columns=mycols)
    return studycsv</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_average_dwi_b0"><code class="name flex">
<span>def <span class="ident">get_average_dwi_b0</span></span>(<span>x, fixed_b0=None, fixed_dwi=None, fast=False)</span>
</code></dt>
<dd>
<div class="desc"><p>automatically generates the average b0 and dwi and outputs both;
maps dwi to b0 space at end.</p>
<p>x : input image</p>
<p>fixed_b0 : alernative reference space</p>
<p>fixed_dwi : alernative reference space</p>
<p>fast : boolean</p>
<p>returns:
avg_b0, avg_dwi</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_dwi_b0( x, fixed_b0=None, fixed_dwi=None, fast=False ):
    &#34;&#34;&#34;
    automatically generates the average b0 and dwi and outputs both;
    maps dwi to b0 space at end.

    x : input image

    fixed_b0 : alernative reference space

    fixed_dwi : alernative reference space

    fast : boolean

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    temp = segment_timeseries_by_meanvalue( x )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]
    if ( fixed_b0 is None and fixed_dwi is None ) or fast:
        xavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        fixed_b0_use = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        fixed_dwi_use = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
    else:
        temp_b0 = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        temp_dwi = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
        xavg = fixed_b0 * 0.0
        bavg = fixed_b0 * 0.0
        tempreg = ants.registration( fixed_b0, temp_b0,&#39;BOLDRigid&#39;)
        fixed_b0_use = tempreg[&#39;warpedmovout&#39;]
        fixed_dwi_use = ants.apply_transforms( fixed_b0, temp_dwi, tempreg[&#39;fwdtransforms&#39;] )
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        if not fast:
            if not myidx in b0_idx:
                xavg = xavg + ants.registration(fixed_dwi_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
            else:
                bavg = bavg + ants.registration(fixed_b0_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
        else:
            if not myidx in b0_idx:
                xavg = xavg + b0
            else:
                bavg = bavg + b0
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    xavg = ants.iMath( xavg, &#39;Normalize&#39; )
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    avgb0=ants.n4_bias_field_correction(bavg)
    avgdwi=ants.n4_bias_field_correction(xavg)
    avgdwi=ants.registration( avgb0, avgdwi, &#39;Rigid&#39; )[&#39;warpedmovout&#39;]
    return avgb0, avgdwi</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_average_rsf"><code class="name flex">
<span>def <span class="ident">get_average_rsf</span></span>(<span>x, min_t=10, max_t=35)</span>
</code></dt>
<dd>
<div class="desc"><p>automatically generates the average bold image with quick registration</p>
<p>returns:
avg_bold</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_rsf( x, min_t=10, max_t=35 ):
    &#34;&#34;&#34;
    automatically generates the average bold image with quick registration

    returns:
        avg_bold
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
    oavg = ants.slice_image( x, axis=3, idx=0 )
    if x.shape[3] &lt;= min_t:
        min_t=0
    if x.shape[3] &lt;= max_t:
        max_t=x.shape[3]
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    oavg = ants.image_clone( bavg )
    bavg = oavg * 0.0
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    return bavg
    # return ants.n4_bias_field_correction(bavg, mask=ants.get_mask( bavg ) )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>name=None, force_download=False, version=23, target_extension='.csv')</span>
</code></dt>
<dd>
<div class="desc"><p>Get ANTsPyMM data filename</p>
<p>The first time this is called, it will download data to ~/.antspymm.
After, it will just read data from disk.
The ~/.antspymm may need to
be periodically deleted in order to ensure data is current.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>name of data tag to retrieve
Options:
- 'all'</dd>
<dt><strong><code>force_download</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>version</code></strong> :&ensp;<code><a title="antspymm.mm.version" href="#antspymm.mm.version">version()</a></code> of <code>data to download (integer)</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>filepath of selected data</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
&gt;&gt;&gt; antspymm.get_data()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data( name=None, force_download=False, version=23, target_extension=&#39;.csv&#39; ):
    &#34;&#34;&#34;
    Get ANTsPyMM data filename

    The first time this is called, it will download data to ~/.antspymm.
    After, it will just read data from disk.  The ~/.antspymm may need to
    be periodically deleted in order to ensure data is current.

    Arguments
    ---------
    name : string
        name of data tag to retrieve
        Options:
            - &#39;all&#39;

    force_download: boolean

    version: version of data to download (integer)

    Returns
    -------
    string
        filepath of selected data

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.get_data()
    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/16912366/versions/&#34; + str(version)
        target_file_name = &#34;16912366.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )


    files = []
    for fname in os.listdir(DATA_PATH):
        if ( fname.endswith(target_extension) ) :
            fname = os.path.join(DATA_PATH, fname)
            files.append(fname)

    if len( files ) == 0 :
        download_data( version = version )
        for fname in os.listdir(DATA_PATH):
            if ( fname.endswith(target_extension) ) :
                fname = os.path.join(DATA_PATH, fname)
                files.append(fname)

    if name == &#39;all&#39;:
        return files

    datapath = None

    for fname in os.listdir(DATA_PATH):
        mystem = (Path(fname).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        if ( name == mystem and fname.endswith(target_extension) ) :
            datapath = os.path.join(DATA_PATH, fname)

    return datapath</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_dti"><code class="name flex">
<span>def <span class="ident">get_dti</span></span>(<span>reference_image, tensormodel, upper_triangular=True, return_image=False)</span>
</code></dt>
<dd>
<div class="desc"><p>extract DTI data from a dipy tensormodel</p>
<p>reference_image : antsImage defining physical space (3D)</p>
<p>tensormodel : from dipy e.g. the variable myoutx['dtrecon_LR_dewarp']['tensormodel'] if myoutx is produced my joint_dti_recon</p>
<p>upper_triangular: boolean otherwise use lower triangular coding</p>
<p>return_image : boolean return the ANTsImage form of DTI otherwise return an array</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>either an ANTsImage (dim=X.Y.Z with 6 component voxels, upper triangular form)</code></dt>
<dd>or a 5D NumPy array (dim=X.Y.Z.3.3)</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>DiPy returns lower triangular form but ANTs expects upper triangular.
Here, we default to the ANTs standard but could generalize in the future
because not much here depends on ANTs standards of tensor data.
ANTs xx,xy,xz,yy,yz,zz
DiPy Dxx, Dxy, Dyy, Dxz, Dyz, Dzz</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dti( reference_image, tensormodel, upper_triangular=True, return_image=False ):
    &#34;&#34;&#34;
    extract DTI data from a dipy tensormodel

    reference_image : antsImage defining physical space (3D)

    tensormodel : from dipy e.g. the variable myoutx[&#39;dtrecon_LR_dewarp&#39;][&#39;tensormodel&#39;] if myoutx is produced my joint_dti_recon

    upper_triangular: boolean otherwise use lower triangular coding

    return_image : boolean return the ANTsImage form of DTI otherwise return an array

    Returns
    -------
    either an ANTsImage (dim=X.Y.Z with 6 component voxels, upper triangular form)
        or a 5D NumPy array (dim=X.Y.Z.3.3)

    Notes
    -----
    DiPy returns lower triangular form but ANTs expects upper triangular.
        Here, we default to the ANTs standard but could generalize in the future 
        because not much here depends on ANTs standards of tensor data.
        ANTs xx,xy,xz,yy,yz,zz
        DiPy Dxx, Dxy, Dyy, Dxz, Dyz, Dzz

    &#34;&#34;&#34;
    # make the DTI - see 
    # https://dipy.org/documentation/1.7.0/examples_built/07_reconstruction/reconst_dti/#sphx-glr-examples-built-07-reconstruction-reconst-dti-py
    # By default, in DIPY, values are ordered as (Dxx, Dxy, Dyy, Dxz, Dyz, Dzz)
    # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
    reoind = np.array([0,1,3,2,4,5]) # arrays are faster than lists
    import dipy.reconst.dti as dti
    dtiut = dti.lower_triangular(tensormodel.quadratic_form)
    it = np.ndindex( reference_image.shape )
    yyind=2
    xzind=3
    if upper_triangular:
        yyind=3
        xzind=2
        for i in it: # convert to upper triangular
            dtiut[i] = dtiut[i][ reoind ] # do we care if this is doing extra work?
    if return_image:
        dtiAnts = ants.from_numpy(dtiut,has_components=True)
        ants.copy_image_info( reference_image, dtiAnts )
        return dtiAnts
    # copy these data into a tensor 
    dtinp = np.zeros(reference_image.shape + (3,3), dtype=float)  
    dtix = np.zeros((3,3), dtype=float)  
    it = np.ndindex( reference_image.shape )
    for i in it:
        dtivec = dtiut[i] # in ANTs - we have: [xx,xy,xz,yy,yz,zz]
        dtix[0,0]=dtivec[0]
        dtix[1,1]=dtivec[yyind] # 2 for LT
        dtix[2,2]=dtivec[5] 
        dtix[0,1]=dtix[1,0]=dtivec[1]
        dtix[0,2]=dtix[2,0]=dtivec[xzind] # 3 for LT
        dtix[1,2]=dtix[2,1]=dtivec[4]
        dtinp[i]=dtix
    return dtinp</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_models"><code class="name flex">
<span>def <span class="ident">get_models</span></span>(<span>version=3, force_download=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Get ANTsPyMM data models</p>
<p>force_download: boolean</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_models( version=3, force_download=True ):
    &#34;&#34;&#34;
    Get ANTsPyMM data models

    force_download: boolean

    Returns
    -------
    None

    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/21718412/versions/&#34;+str(version)
        target_file_name = &#34;21718412.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_names_from_data_frame"><code class="name flex">
<span>def <span class="ident">get_names_from_data_frame</span></span>(<span>x, demogIn, exclusions=None)</span>
</code></dt>
<dd>
<div class="desc"><p>data = {'Name':['Tom', 'nick', 'krish', 'jack'], 'Age':[20, 21, 19, 18]}
antspymm.get_names_from_data_frame( ['e'], df )
antspymm.get_names_from_data_frame( ['a','e'], df )
antspymm.get_names_from_data_frame( ['e'], df, exclusions='N' )</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_names_from_data_frame(x, demogIn, exclusions=None):
    &#34;&#34;&#34;
    data = {&#39;Name&#39;:[&#39;Tom&#39;, &#39;nick&#39;, &#39;krish&#39;, &#39;jack&#39;], &#39;Age&#39;:[20, 21, 19, 18]}
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;a&#39;,&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df, exclusions=&#39;N&#39; )
    &#34;&#34;&#34;
    # Check if x is a string and convert it to a list
    if isinstance(x, str):
        x = [x]
    def get_unique( qq ):
        unique = []
        for number in qq:
            if number in unique:
                continue
            else:
                unique.append(number)
        return unique
    outnames = list(demogIn.columns[demogIn.columns.str.contains(x[0])])
    if len(x) &gt; 1:
        for y in x[1:]:
            outnames = [i for i in outnames if y in i]
    outnames = get_unique( outnames )
    if exclusions is not None:
        toexclude = [name for name in outnames if exclusions[0] in name ]
        if len(exclusions) &gt; 1:
            for zz in exclusions[1:]:
                toexclude.extend([name for name in outnames if zz in name ])
        if len(toexclude) &gt; 0:
            outnames = [name for name in outnames if name not in toexclude]
    return outnames</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_valid_modalities"><code class="name flex">
<span>def <span class="ident">get_valid_modalities</span></span>(<span>long=False, asString=False, qc=False)</span>
</code></dt>
<dd>
<div class="desc"><p>return a list of valid modality identifiers used in NRG modality designation
and that can be processed by this package.</p>
<p>long - return the long version</p>
<p>asString - concat list to string</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_valid_modalities( long=False, asString=False, qc=False ):
    &#34;&#34;&#34;
    return a list of valid modality identifiers used in NRG modality designation
    and that can be processed by this package.

    long - return the long version

    asString - concat list to string
    &#34;&#34;&#34;
    if long:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;, &#34;rsfMRILR&#34;, &#34;rsfMRIRL&#34;, &#34;DTI&#34;, &#34;DTI_LR&#34;,&#34;DTI_RL&#34;,  &#34;DTILR&#34;,&#34;DTIRL&#34;,&#34;T2Flair&#34;, &#34;dwi&#34;, &#34;dwi_ap&#34;, &#34;dwi_pa&#34;, &#34;func&#34;, &#34;func_ap&#34;, &#34;func_pa&#34;, &#34;perf&#34;]
    elif qc:
        mymod = [ &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39;, &#39;DTI&#39;, &#39;DTIdwi&#39;,&#39;DTIb0&#39;, &#39;rsfMRI&#39;, &#34;perf&#34; ]
    else:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;DTI&#34;,&#34;T2Flair&#34;, &#34;rsfMRI&#34;, &#34;perf&#34; ]
    if not asString:
        return mymod
    else:
        mymodchar=&#34;&#34;
        for x in mymod:
            mymodchar = mymodchar + &#34; &#34; + str(x)
        return mymodchar</code></pre>
</details>
</dd>
<dt id="antspymm.mm.hierarchical_modality_summary"><code class="name flex">
<span>def <span class="ident">hierarchical_modality_summary</span></span>(<span>target_image, hier, transformlist, modality_name, return_keys=['Mean', 'Volume'], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Use output of antspyt1w.hierarchical to summarize a modality</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>target_image</code></strong> :&ensp;<code>the image to summarize - should be brain extracted</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>hier</code></strong> :&ensp;<code>dictionary holding antspyt1w.hierarchical output</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>transformlist</code></strong> :&ensp;<code>spatial transformations mapping from T1 to this modality (e.g. from ants.registration)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>modality_name</code></strong> :&ensp;<code>adds the modality name to the data frame columns</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>return_keys = ["Mean","Volume"] keys to return</p>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data frame holding summary statistics in wide format</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hierarchical_modality_summary(
    target_image,
    hier,
    transformlist,
    modality_name,
    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;],
    verbose = False ):
    &#34;&#34;&#34;

    Use output of antspyt1w.hierarchical to summarize a modality

    Arguments
    ---------

    target_image : the image to summarize - should be brain extracted

    hier : dictionary holding antspyt1w.hierarchical output

    transformlist : spatial transformations mapping from T1 to this modality (e.g. from ants.registration)

    modality_name : adds the modality name to the data frame columns

    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;] keys to return

    verbose : boolean

    Returns
    -------
    data frame holding summary statistics in wide format

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    dfout = pd.DataFrame()
    def myhelper( target_image, seg, mytx, mapname, modname, mydf, extra=&#39;&#39;, verbose=False ):
        if verbose:
            print( mapname )
        target_image_mask = ants.image_clone( target_image ) * 0.0
        target_image_mask[ target_image != 0 ] = 1
        cortmapped = ants.apply_transforms(
            target_image,
            seg,
            mytx, interpolator=&#39;nearestNeighbor&#39; ) * target_image_mask
        mapped = antspyt1w.map_intensity_to_dataframe(
            mapname,
            target_image,
            cortmapped )
        mapped.iloc[:,1] = modname + &#39;_&#39; + extra + mapped.iloc[:,1]
        mappedw = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            { &#39;x&#39; : mapped},
            col_names = return_keys )
        if verbose:
            print( mappedw.keys() )
        if mydf.shape[0] &gt; 0:
            mydf = pd.concat( [ mydf, mappedw], axis=1, ignore_index=False )
        else:
            mydf = mappedw
        return mydf
    if hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], transformlist,
            &#34;dkt&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose )
    if hier[&#39;deep_cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;deep_cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;deep_&#39;, verbose=verbose )
    if hier[&#39;cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    if hier[&#39;bf&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;bf&#39;], transformlist,
            &#34;nbm3CH13&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    # if hier[&#39;mtl&#39;] is not None:
    #    dfout = myhelper( target_image, hier[&#39;mtl&#39;], reg,
    #        &#34;mtl_description&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    return dfout</code></pre>
</details>
</dd>
<dt id="antspymm.mm.highest_quality_repeat"><code class="name flex">
<span>def <span class="ident">highest_quality_repeat</span></span>(<span>mxdfin, idvar, visitvar, qualityvar)</span>
</code></dt>
<dd>
<div class="desc"><p>This function returns a subset of the input dataframe that retains only the rows
that correspond to the highest quality observation for each combination of ID and visit.</p>
<h2 id="parameters">Parameters:</h2>
<p>mxdfin: pandas.DataFrame
The input dataframe.
idvar: str
The name of the column that contains the ID variable.
visitvar: str
The name of the column that contains the visit variable.
qualityvar: str
The name of the column that contains the quality variable.</p>
<h2 id="returns">Returns:</h2>
<p>pandas.DataFrame
A subset of the input dataframe that retains only the rows that correspond
to the highest quality observation for each combination of ID and visit.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def highest_quality_repeat(mxdfin, idvar, visitvar, qualityvar):
    &#34;&#34;&#34;
    This function returns a subset of the input dataframe that retains only the rows
    that correspond to the highest quality observation for each combination of ID and visit.

    Parameters:
    ----------
    mxdfin: pandas.DataFrame
        The input dataframe.
    idvar: str
        The name of the column that contains the ID variable.
    visitvar: str
        The name of the column that contains the visit variable.
    qualityvar: str
        The name of the column that contains the quality variable.

    Returns:
    -------
    pandas.DataFrame
        A subset of the input dataframe that retains only the rows that correspond
        to the highest quality observation for each combination of ID and visit.
    &#34;&#34;&#34;
    if visitvar not in mxdfin.columns:
        raise ValueError(&#34;visitvar not in dataframe&#34;)
    if idvar not in mxdfin.columns:
        raise ValueError(&#34;idvar not in dataframe&#34;)
    if qualityvar not in mxdfin.columns:
        raise ValueError(&#34;qualityvar not in dataframe&#34;)

    mxdfin[qualityvar] = mxdfin[qualityvar].astype(float)

    vizzes = mxdfin[visitvar].unique()
    uids = mxdfin[idvar].unique()
    useit = np.zeros(mxdfin.shape[0], dtype=bool)

    for u in uids:
        losel = mxdfin[idvar] == u
        vizzesloc = mxdfin[losel][visitvar].unique()

        for v in vizzesloc:
            losel = (mxdfin[idvar] == u) &amp; (mxdfin[visitvar] == v)
            mysnr = mxdfin.loc[losel, qualityvar]
            myw = np.where(losel)[0]

            if len(myw) &gt; 1:
                if any(~np.isnan(mysnr)):
                    useit[myw[np.argmax(mysnr)]] = True
                else:
                    useit[myw] = True
            else:
                useit[myw] = True

    return mxdfin[useit]</code></pre>
</details>
</dd>
<dt id="antspymm.mm.image_write_with_thumbnail"><code class="name flex">
<span>def <span class="ident">image_write_with_thumbnail</span></span>(<span>x, fn, y=None, thumb=True)</span>
</code></dt>
<dd>
<div class="desc"><p>will write the image and (optionally) a png thumbnail with (optional) overlay/underlay</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_write_with_thumbnail( x,  fn, y=None, thumb=True ):
    &#34;&#34;&#34;
    will write the image and (optionally) a png thumbnail with (optional) overlay/underlay
    &#34;&#34;&#34;
    ants.image_write( x, fn )
    if not thumb or x.components &gt; 1:
        return
    thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_3dthumb.png&#34;,fn)
    if thumb and x.dimension == 3:
        if y is None:
            try:
                ants.plot_ortho( x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            try:
                ants.plot_ortho( y, x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
    if thumb and x.dimension == 4:
        thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_4dthumb.png&#34;,fn)
        nslices = x.shape[3]
        sl = np.round( nslices * 0.5 )
        if sl &gt; nslices:
            sl = nslices-1
        xview = ants.slice_image( x, axis=3, idx=int(sl) )
        if y is None:
            try:
                ants.plot_ortho( xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            if y.dimension == 3:
                try:
                    ants.plot_ortho(y, xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
                except:
                    pass
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.impute_fa"><code class="name flex">
<span>def <span class="ident">impute_fa</span></span>(<span>fa, md)</span>
</code></dt>
<dd>
<div class="desc"><p>impute bad values in dti, fa, md</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def impute_fa( fa, md ):
    &#34;&#34;&#34;
    impute bad values in dti, fa, md
    &#34;&#34;&#34;
    def imputeit( x, fa ):
        badfa=ants.threshold_image(fa,1,1)
        if badfa.max() == 1:
            temp=ants.image_clone(x)
            temp[badfa==1]=0
            temp=ants.iMath(temp,&#39;GD&#39;,2)
            x[ badfa==1 ]=temp[badfa==1]
        return x
    md=imputeit( md, fa )
    fa=imputeit( ants.image_clone(fa), fa )
    return fa, md</code></pre>
</details>
</dd>
<dt id="antspymm.mm.joint_dti_recon"><code class="name flex">
<span>def <span class="ident">joint_dti_recon</span></span>(<span>img_LR, bval_LR, bvec_LR, jhu_atlas, jhu_labels, reference_B0, reference_DWI, srmodel=None, img_RL=None, bval_RL=None, bvec_RL=None, t1w=None, brain_mask=None, motion_correct=None, dewarp_modality='FA', denoise=False, fit_method='WLS', impute=False, censor=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>pass in subject data and 1mm JHU atlas/labels</li>
<li>perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)</li>
<li>dewarp the images using dewarp_modality or T1w</li>
<li>apply dewarping to the original data
===&gt; may want to apply SR at this step</li>
<li>reconstruct DTI again</li>
<li>label images and do registration</li>
<li>return relevant outputs</li>
</ol>
<p>NOTE: RL images are optional; should pass t1w in this case.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>img_LR</code></strong> :&ensp;<code>an antsImage holding B0 and DWI LR acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bval_LR</code></strong> :&ensp;<code>bvalue filename LR</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvec_LR</code></strong> :&ensp;<code>bvector filename LR</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>jhu_atlas</code></strong> :&ensp;<code>atlas FA image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>jhu_labels</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>reference_B0</code></strong> :&ensp;<code>the "target" B0 image space</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>reference_DWI</code></strong> :&ensp;<code>the "target" DW image space</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>optional h5 (tensorflow) model</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>img_RL</code></strong> :&ensp;<code>an antsImage holding B0 and DWI RL acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bval_RL</code></strong> :&ensp;<code>bvalue filename RL</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvec_RL</code></strong> :&ensp;<code>bvector filename RL</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1w</code></strong> :&ensp;<code>antsimage t1w neuroimage (brain-extracted)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>brain_mask</code></strong> :&ensp;<code>mask for the DWI - just 3D - provided brain mask should be in reference_B0 space</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_correct</code></strong> :&ensp;<code>None Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dewarp_modality</code></strong> :&ensp;<code>string average_dwi, average_b0, MD</code> or <code>FA</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fit_method</code></strong> :&ensp;<code>string one</code> of <code>WLS LS NLLS</code> or <code>restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>impute</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>censor</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the mean_fa, its summary statistics via JHU labels,</code></dt>
<dd>the JHU registration, the JHU labels, the dewarping dictionary and the
dti reconstruction dictionaries.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def joint_dti_recon(
    img_LR,
    bval_LR,
    bvec_LR,
    jhu_atlas,
    jhu_labels,
    reference_B0,
    reference_DWI,
    srmodel = None,
    img_RL = None,
    bval_RL = None,
    bvec_RL = None,
    t1w = None,
    brain_mask = None,
    motion_correct = None,
    dewarp_modality = &#39;FA&#39;,
    denoise=False,
    fit_method=&#39;WLS&#39;,
    impute = False,
    censor = True,
    verbose = False ):
    &#34;&#34;&#34;
    1. pass in subject data and 1mm JHU atlas/labels
    2. perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)
    3. dewarp the images using dewarp_modality or T1w
    4. apply dewarping to the original data
        ===&gt; may want to apply SR at this step
    5. reconstruct DTI again
    6. label images and do registration
    7. return relevant outputs

    NOTE: RL images are optional; should pass t1w in this case.

    Arguments
    ---------

    img_LR : an antsImage holding B0 and DWI LR acquisition

    bval_LR : bvalue filename LR

    bvec_LR : bvector filename LR

    jhu_atlas : atlas FA image

    jhu_labels : atlas labels

    reference_B0 : the &#34;target&#34; B0 image space

    reference_DWI : the &#34;target&#34; DW image space

    srmodel : optional h5 (tensorflow) model

    img_RL : an antsImage holding B0 and DWI RL acquisition

    bval_RL : bvalue filename RL

    bvec_RL : bvector filename RL

    t1w : antsimage t1w neuroimage (brain-extracted)

    brain_mask : mask for the DWI - just 3D - provided brain mask should be in reference_B0 space

    motion_correct : None Rigid or SyN

    dewarp_modality : string average_dwi, average_b0, MD or FA

    denoise: boolean

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    impute : boolean

    censor : boolean

    verbose : boolean

    Returns
    -------
    dictionary holding the mean_fa, its summary statistics via JHU labels,
        the JHU registration, the JHU labels, the dewarping dictionary and the
        dti reconstruction dictionaries.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;Recon DTI on OR images ...&#34;)

    def fix_dwi_shape( img, bvalfn, bvecfn ):
        if isinstance(bvecfn, str):
            bvals, bvecs = read_bvals_bvecs( bvalfn , bvecfn   )
        else:
            bvals = bvalfn
            bvecs = bvecfn
        if bvecs.shape[0] &lt; img.shape[3]:
            imgout = ants.from_numpy( img[:,:,:,0:bvecs.shape[0]] )
            imgout = ants.copy_image_info( img, imgout )
            return( imgout )
        else:
            return( img )

    img_LR = fix_dwi_shape( img_LR, bval_LR, bvec_LR )
    if denoise :
        img_LR = mc_denoise( img_LR )
    if img_RL is not None:
        img_RL = fix_dwi_shape( img_RL, bval_RL, bvec_RL )
        if denoise :
            img_RL = mc_denoise( img_RL )

    if brain_mask is not None:
        maskInRightSpace = ants.image_physical_space_consistency( brain_mask, reference_B0 )
        if not maskInRightSpace :
            raise ValueError(&#39;not maskInRightSpace ... provided brain mask should be in reference_B0 space&#39;)

    if img_RL is not None :
        if verbose:
            print(&#34;img_RL correction&#34;)
        reg_RL = dti_reg(
            img_RL,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_RL,
            bvecs=bvec_RL,
            type_of_transform=motion_correct,
            verbose=True )
    else:
        reg_RL=None


    if verbose:
        print(&#34;img_LR correction&#34;)
    reg_LR = dti_reg(
            img_LR,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_LR,
            bvecs=bvec_LR,
            type_of_transform=motion_correct,
            verbose=True )

    ts_LR_avg = None
    ts_RL_avg = None
    reg_its = [100,50,10]
    img_LRdwp = ants.image_clone( reg_LR[ &#39;motion_corrected&#39; ] )
    if img_RL is not None:
        img_RLdwp = ants.image_clone( reg_RL[ &#39;motion_corrected&#39; ] )
        if srmodel is not None:
            if verbose:
                print(&#34;convert img_RL_dwp to img_RL_dwp_SR&#34;)
            img_RLdwp = super_res_mcimage( img_RLdwp, srmodel, isotropic=True,
                        verbose=verbose )
    if srmodel is not None:
        reg_its = [100] + reg_its
        if verbose:
            print(&#34;convert img_LR_dwp to img_LR_dwp_SR&#34;)
        img_LRdwp = super_res_mcimage( img_LRdwp, srmodel, isotropic=True,
                verbose=verbose )
    if verbose:
        print(&#34;recon after distortion correction&#34;, flush=True)

    if impute:
        img_LRdwp=impute_dwi( img_LRdwp, verbose=True )
    elif censor:
        img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;] = censor_dwi( img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;], verbose=True )
    if impute and img_RL is not None:
        img_RLdwp=impute_dwi( img_RLdwp, verbose=True )
    elif censor and img_RL is not None:
        img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;] = censor_dwi( img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;], verbose=True )

    if img_RL is not None:
        img_LRdwp, bval_LR, bvec_LR = merge_dwi_data(
            img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;],
            img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;]
        )
    else:
        bval_LR=reg_LR[&#39;bvals&#39;]
        bvec_LR=reg_LR[&#39;bvecs&#39;]

    if verbose:
        print(&#34;final recon&#34;, flush=True)
        print(img_LRdwp)
    recon_LR_dewarp = dipy_dti_recon(
            img_LRdwp, bval_LR, bvec_LR,
            mask = brain_mask,
            fit_method=fit_method,
            mask_dilation=0, verbose=True )
    if verbose:
        print(&#34;recon done&#34;, flush=True)

    if img_RL is not None:
        fdjoin = [ reg_LR[&#39;FD&#39;],
                   reg_RL[&#39;FD&#39;] ]
        framewise_displacement=np.concatenate( fdjoin )
    else:
        framewise_displacement=reg_LR[&#39;FD&#39;]

    motion_count = ( framewise_displacement &gt; 1.5  ).sum()
    reconFA = recon_LR_dewarp[&#39;FA&#39;]
    reconMD = recon_LR_dewarp[&#39;MD&#39;]

    if verbose:
        print(&#34;JHU reg&#34;,flush=True)

    OR_FA2JHUreg = ants.registration( reconFA, jhu_atlas,
        type_of_transform = &#39;SyN&#39;, syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=reg_its, verbose=False )
    OR_FA_jhulabels = ants.apply_transforms( reconFA, jhu_labels,
        OR_FA2JHUreg[&#39;fwdtransforms&#39;], interpolator=&#39;genericLabel&#39;)

    df_FA_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;FA_JHU_labels_edited&#39;,
        reconFA,
        OR_FA_jhulabels)
    df_FA_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_FA_JHU_ORRL&#39; : df_FA_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    df_MD_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;MD_JHU_labels_edited&#39;,
        reconMD,
        OR_FA_jhulabels)
    df_MD_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_MD_JHU_ORRL&#39; : df_MD_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    temp = segment_timeseries_by_meanvalue( img_LRdwp )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]

    nonbrainmask = ants.iMath( recon_LR_dewarp[&#39;dwi_mask&#39;], &#34;MD&#34;,2) - recon_LR_dewarp[&#39;dwi_mask&#39;]
    fgmask = ants.threshold_image( reconFA, 0.5 , 1.0).iMath(&#34;GetLargestComponent&#34;)
    bgmask = ants.threshold_image( reconFA, 1e-4 , 0.1)
    fa_SNR = 0.0
    fa_SNR = mask_snr( reconFA, bgmask, fgmask, bias_correct=False )
    fa_evr = antspyt1w.patch_eigenvalue_ratio( reconFA, 512, [16,16,16], evdepth = 0.9, mask=recon_LR_dewarp[&#39;dwi_mask&#39;] )

    dti_itself = get_dti( reconFA, recon_LR_dewarp[&#39;tensormodel&#39;], return_image=True )
    return convert_np_in_dict( {
        &#39;dti&#39;: dti_itself,
        &#39;recon_fa&#39;:reconFA,
        &#39;recon_fa_summary&#39;:df_FA_JHU_ORRL_bfwide,
        &#39;recon_md&#39;:reconMD,
        &#39;recon_md_summary&#39;:df_MD_JHU_ORRL_bfwide,
        &#39;jhu_labels&#39;:OR_FA_jhulabels,
        &#39;jhu_registration&#39;:OR_FA2JHUreg,
        &#39;reg_LR&#39;:reg_LR,
        &#39;reg_RL&#39;:reg_RL,
        &#39;dtrecon_LR_dewarp&#39;:recon_LR_dewarp,
        &#39;dwi_LR_dewarped&#39;:img_LRdwp,
        &#39;bval_LR&#39;:bval_LR,
        &#39;bvec_LR&#39;:bvec_LR,
        &#39;bval_RL&#39;:bval_RL,
        &#39;bvec_RL&#39;:bvec_RL,
        &#39;b0avg&#39;: reference_B0,
        &#39;dwiavg&#39;: reference_DWI,
        &#39;framewise_displacement&#39;:framewise_displacement,
        &#39;high_motion_count&#39;: motion_count,
        &#39;tsnr_b0&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;tsnr_dwi&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;dvars_b0&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;dvars_dwi&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;ssnr_b0&#39;: slice_snr( img_LRdwp, bgmask , fgmask, b0_idx),
        &#39;ssnr_dwi&#39;: slice_snr( img_LRdwp, bgmask, fgmask, non_b0_idx),
        &#39;fa_evr&#39;: fa_evr,
        &#39;fa_SNR&#39;: fa_SNR
    } )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.loop_timeseries_censoring"><code class="name flex">
<span>def <span class="ident">loop_timeseries_censoring</span></span>(<span>x, threshold=0.5, mask=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Censor high leverage volumes from a time series using Local Outlier Probabilities (LoOP).</p>
<p>Parameters:
x (ANTsImage): A 4D time series image.
threshold (float): Threshold for determining high leverage volumes based on LoOP scores.
mask (antsImage): restricts to a ROI
verbose (bool)</p>
<p>Returns:
tuple: A tuple containing the censored time series (ANTsImage) and the indices of the high leverage volumes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def loop_timeseries_censoring(x, threshold=0.5, mask=None, verbose=False):
    &#34;&#34;&#34;
    Censor high leverage volumes from a time series using Local Outlier Probabilities (LoOP).

    Parameters:
    x (ANTsImage): A 4D time series image.
    threshold (float): Threshold for determining high leverage volumes based on LoOP scores.
    mask (antsImage): restricts to a ROI
    verbose (bool)

    Returns:
    tuple: A tuple containing the censored time series (ANTsImage) and the indices of the high leverage volumes.
    &#34;&#34;&#34;
    import warnings
    if x.shape[3] &lt; 20: # just a guess at what we need here ...
        warnings.warn(&#34;Warning: the time dimension is &lt; 20 - too few samples for loop. just return the original data.&#34;)
        return x, []
    if mask is None:
        flattened_series = flatten_time_series(x.numpy())
    else:
        flattened_series = ants.timeseries_to_matrix( x, mask )
    loop_scores = calculate_loop_scores(flattened_series)
    high_leverage_volumes = np.where(loop_scores &gt; threshold)[0]
    if verbose:
        print(&#34;LOOP High Leverage Volumes:&#34;, high_leverage_volumes)
    new_asl = remove_volumes_from_timeseries(x, high_leverage_volumes)
    return new_asl, high_leverage_volumes</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mask_snr"><code class="name flex">
<span>def <span class="ident">mask_snr</span></span>(<span>x, background_mask, foreground_mask, bias_correct=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image using
a user-defined foreground and background mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_mask</code></strong> :&ensp;<code>binary antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>foreground_mask</code></strong> :&ensp;<code>binary antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bias_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mask_snr( x, background_mask, foreground_mask, bias_correct=True ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image using
    a user-defined foreground and background mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_mask : binary antsImage

    foreground_mask : binary antsImage

    bias_correct : boolean

    &#34;&#34;&#34;
    import numpy as np
    if foreground_mask.sum() &lt;= 1 or background_mask.sum() &lt;= 1:
        return 0
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    if bias_correct:
        xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    signal = (xbc[ foreground_mask == 1] ).mean()
    noise = (xbc[ background_mask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.match_modalities"><code class="name flex">
<span>def <span class="ident">match_modalities</span></span>(<span>qc_dataframe, unique_identifier='filename', outlier_column='ol_loop', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the best multiple modality dataset at each time point</p>
<p>:param qc_dataframe: quality control data frame with
:param unique_identifier : the unique NRG filename for each image
:param outlier_column: outlierness score used to identify the best image (pair) at a given date
:param verbose: boolean
:return: filtered matched modality data frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match_modalities( qc_dataframe, unique_identifier=&#39;filename&#39;, outlier_column=&#39;ol_loop&#39;,  verbose=False ):
    &#34;&#34;&#34;
    Find the best multiple modality dataset at each time point

    :param qc_dataframe: quality control data frame with
    :param unique_identifier : the unique NRG filename for each image
    :param outlier_column: outlierness score used to identify the best image (pair) at a given date
    :param verbose: boolean
    :return: filtered matched modality data frame
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    qc_dataframe[&#39;filename&#39;]=qc_dataframe[&#39;filename&#39;].astype(str)
    qc_dataframe[&#39;ol_loop&#39;]=qc_dataframe[&#39;ol_loop&#39;].astype(float)
    qc_dataframe[&#39;ol_lof&#39;]=qc_dataframe[&#39;ol_lof&#39;].astype(float)
    qc_dataframe[&#39;ol_lof_decision&#39;]=qc_dataframe[&#39;ol_lof_decision&#39;].astype(float)
    mmdf = best_mmm( qc_dataframe, &#39;T1w&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    fldf = best_mmm( qc_dataframe, &#39;T2Flair&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    nmdf = best_mmm( qc_dataframe, &#39;NM2DMT&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    rsdf = best_mmm( qc_dataframe, &#39;rsfMRI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    dtdf = best_mmm( qc_dataframe, &#39;DTI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    mmdf[&#39;flairid&#39;] = None
    mmdf[&#39;flairfn&#39;] = None
    mmdf[&#39;flairloop&#39;] = None
    mmdf[&#39;flairlof&#39;] = None
    mmdf[&#39;dtid1&#39;] = None
    mmdf[&#39;dtfn1&#39;] = None
    mmdf[&#39;dtntimepoints1&#39;] = 0
    mmdf[&#39;dtloop1&#39;] = math.nan
    mmdf[&#39;dtlof1&#39;] = math.nan
    mmdf[&#39;dtid2&#39;] = None
    mmdf[&#39;dtfn2&#39;] = None
    mmdf[&#39;dtntimepoints2&#39;] = 0
    mmdf[&#39;dtloop2&#39;] = math.nan
    mmdf[&#39;dtlof2&#39;] = math.nan
    mmdf[&#39;rsfid1&#39;] = None
    mmdf[&#39;rsffn1&#39;] = None
    mmdf[&#39;rsfntimepoints1&#39;] = 0
    mmdf[&#39;rsfloop1&#39;] = math.nan
    mmdf[&#39;rsflof1&#39;] = math.nan
    mmdf[&#39;rsfid2&#39;] = None
    mmdf[&#39;rsffn2&#39;] = None
    mmdf[&#39;rsfntimepoints2&#39;] = 0
    mmdf[&#39;rsfloop2&#39;] = math.nan
    mmdf[&#39;rsflof2&#39;] = math.nan
    for k in range(1,11):
        myid=&#39;nmid&#39;+str(k)
        mmdf[myid] = None
        myid=&#39;nmfn&#39;+str(k)
        mmdf[myid] = None
        myid=&#39;nmloop&#39;+str(k)
        mmdf[myid] = math.nan
        myid=&#39;nmlof&#39;+str(k)
        mmdf[myid] = math.nan
    if verbose:
        print( mmdf.shape )
    for k in range(mmdf.shape[0]):
        if verbose:
            if k % 100 == 0:
                progger = str( k ) # np.round( k / mmdf.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        if dtdf is not None:
            locsel = (dtdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k])
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = dtdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = dtdf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = dtdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = float(dtdf[&#39;ol_lof_decision&#39;][locsel].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints1&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = dtdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = float(locdf[&#39;ol_lof_decision&#39;][locsel].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints1&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[0])
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn2&#34;)] = locdf[unique_identifier].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof2&#34;)] = float(locdf[&#39;ol_lof_decision&#39;][locsel].values[1])
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtntimepoints2&#34;)] = float(dtdf[&#39;dimt&#39;][locsel].values[1])
        if rsdf is not None:
            locsel = (rsdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k])
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = rsdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = rsdf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = rsdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = float(rsdf[&#39;ol_lof_decision&#39;].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints1&#34;)] = float(rsdf[&#39;dimt&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = rsdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[0])
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints1&#34;)] = float(locdf[&#39;dimt&#39;][locsel].values[0])
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn2&#34;)] = locdf[unique_identifier].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof2&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[1])
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfntimepoints2&#34;)] = float(locdf[&#39;dimt&#39;][locsel].values[1])

        if fldf is not None:
            locsel = fldf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = fldf[&#39;imageID&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = fldf[unique_identifier][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = fldf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = float(fldf[&#39;ol_lof_decision&#39;][locsel].values[0])
            elif sum(locsel) &gt; 1:
                locdf = fldf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = locdf[unique_identifier].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = float(locdf[&#39;ol_lof_decision&#39;].values[0])

        if nmdf is not None:
            locsel = nmdf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() &gt; 0:
                locdf = nmdf[locsel]
                for i in range(np.min( [10,locdf.shape[0]])):
                    nmid = &#34;nmid&#34;+str(i+1)
                    mmdf.loc[k,nmid] = locdf[&#39;imageID&#39;].iloc[i]
                    nmfn = &#34;nmfn&#34;+str(i+1)
                    mmdf.loc[k,nmfn] = locdf[&#39;imageID&#39;].iloc[i]
                    nmloop = &#34;nmloop&#34;+str(i+1)
                    mmdf.loc[k,nmloop] = locdf[outlier_column].iloc[i]
                    nmloop = &#34;nmlof&#34;+str(i+1)
                    mmdf.loc[k,nmloop] = float(locdf[&#39;ol_lof_decision&#39;].iloc[i])

    mmdf[&#39;rsf_total_timepoints&#39;]=mmdf[&#39;rsfntimepoints1&#39;]+mmdf[&#39;rsfntimepoints2&#39;]
    mmdf[&#39;dt_total_timepoints&#39;]=mmdf[&#39;dtntimepoints1&#39;]+mmdf[&#39;dtntimepoints2&#39;]
    return mmdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_denoise"><code class="name flex">
<span>def <span class="ident">mc_denoise</span></span>(<span>x, ratio=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>ants denoising for timeseries (4D)</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage 4D</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ratio</code></strong> :&ensp;<code>weight between 1 and 0 - lower weights bring result closer to initial image</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>denoised time series</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_denoise( x, ratio = 0.5 ):
    &#34;&#34;&#34;
    ants denoising for timeseries (4D)

    Arguments
    ---------
    x : an antsImage 4D

    ratio : weight between 1 and 0 - lower weights bring result closer to initial image

    Returns
    -------
    denoised time series

    &#34;&#34;&#34;
    dwpimage = []
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        dnzb0 = ants.denoise_image( b0, p=1,r=1,noise_model=&#39;Gaussian&#39; )
        dwpimage.append( dnzb0 * ratio + b0 * (1.0-ratio) )
    return ants.list_to_ndimage( x, dwpimage )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_reg"><code class="name flex">
<span>def <span class="ident">mc_reg</span></span>(<span>image, fixed=None, type_of_transform='Rigid', mask=None, total_sigma=3.0, fdOffset=2.0, output_directory=None, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion - with deformation.</p>
<h2 id="arguments">Arguments</h2>
<pre><code>image: antsImage, usually ND where D=4.

fixed: Fixed image to register all timepoints to.  If not provided,
    mean image is used.

type_of_transform : string
    A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
    See ants registration for details.

fdOffset: offset value to use in framewise displacement calculation

output_directory : string
    output will be named with this prefix plus a numeric extension.

verbose: boolean

kwargs: keyword args
    extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
&gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data('ch2'))
&gt;&gt;&gt; mytx = ants.motion_correction( fi )
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_reg(
    image,
    fixed=None,
    type_of_transform=&#34;Rigid&#34;,
    mask=None,
    total_sigma=3.0,
    fdOffset=2.0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        fixed: Fixed image to register all timepoints to.  If not provided,
            mean image is used.

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        output_directory : string
            output will be named with this prefix plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data(&#39;ch2&#39;))
    &gt;&gt;&gt; mytx = ants.motion_correction( fi )
    &#34;&#34;&#34;
    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/mc_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)

    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    if fixed is None:
        fixed = ants.get_average_of_timeseries( image )
    if mask is None:
        mask = ants.get_mask(fixed)
    FD = np.zeros(nTimePoints)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = 0
    for k in range(nTimePoints):
        mycount = round(k / nTimePoints * 100)
        if verbose and mycount == counter:
            counter = counter + 10
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;Rigid&#39;,
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myreg[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
            img1w = ants.apply_transforms( fixed,
                ants.slice_image(image, axis=idim - 1, idx=k),
                myreg[&#34;fwdtransforms&#34;] )
            motion_corrected.append(img1w)
        else:
            motion_parameters.append(&#34;NA&#34;)
            motion_corrected.append(temp)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(image, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_resample_image_to_target"><code class="name flex">
<span>def <span class="ident">mc_resample_image_to_target</span></span>(<span>x, y, interp_type='linear')</span>
</code></dt>
<dd>
<div class="desc"><p>multichannel version of resample_image_to_target</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_resample_image_to_target( x , y, interp_type=&#39;linear&#39; ):
    &#34;&#34;&#34;
    multichannel version of resample_image_to_target
    &#34;&#34;&#34;
    xx=ants.split_channels( x )
    yy=ants.split_channels( y )[0]
    newl=[]
    for k in range(len(xx)):
        newl.append(  ants.resample_image_to_target( xx[k], yy, interp_type=interp_type ) )
    return ants.merge_channels( newl )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_dwi_data"><code class="name flex">
<span>def <span class="ident">merge_dwi_data</span></span>(<span>img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL)</span>
</code></dt>
<dd>
<div class="desc"><p>merge motion and distortion corrected data if possible</p>
<p>img_LRdwp : image</p>
<p>bval_LR : array</p>
<p>bvec_LR : array</p>
<p>img_RLdwp : image</p>
<p>bval_RL : array</p>
<p>bvec_RL : array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_dwi_data( img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL ):
    &#34;&#34;&#34;
    merge motion and distortion corrected data if possible

    img_LRdwp : image

    bval_LR : array

    bvec_LR : array

    img_RLdwp : image

    bval_RL : array

    bvec_RL : array

    &#34;&#34;&#34;
    import warnings
    insamespace = ants.image_physical_space_consistency( img_LRdwp, img_RLdwp )
    if not insamespace :
        warnings.warn(&#39;not insamespace ... corrected image pair should occupy the same physical space; returning only the 1st set and wont join these data.&#39;)
        return img_LRdwp, bval_LR, bvec_LR
    
    bval_LR = np.concatenate([bval_LR,bval_RL])
    bvec_LR = np.concatenate([bvec_LR,bvec_RL])
    # concatenate the images
    mimg=[]
    for kk in range( img_LRdwp.shape[3] ):
            mimg.append( ants.slice_image( img_LRdwp, axis=3, idx=kk ) )
    for kk in range( img_RLdwp.shape[3] ):
            mimg.append( ants.slice_image( img_RLdwp, axis=3, idx=kk ) )
    img_LRdwp = ants.list_to_ndimage( img_LRdwp, mimg )
    return img_LRdwp, bval_LR, bvec_LR</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_mm_dataframe"><code class="name flex">
<span>def <span class="ident">merge_mm_dataframe</span></span>(<span>hierdf, mmdf, mm_suffix)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_mm_dataframe(hierdf, mmdf, mm_suffix):
    try:
        hierdf = hierdf.merge(mmdf, on=[&#39;sid&#39;, &#39;visitdate&#39;, &#39;t1imageuid&#39;], suffixes=(&#34;&#34;,mm_suffix),how=&#39;left&#39;)
        return hierdf
    except KeyError:
        return hierdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_timeseries_data"><code class="name flex">
<span>def <span class="ident">merge_timeseries_data</span></span>(<span>img_LR, img_RL, allow_resample=True)</span>
</code></dt>
<dd>
<div class="desc"><p>merge time series data into space of reference_image</p>
<p>img_LR : image</p>
<p>img_RL : image</p>
<p>allow_resample : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_timeseries_data( img_LR, img_RL, allow_resample=True ):
    &#34;&#34;&#34;
    merge time series data into space of reference_image

    img_LR : image

    img_RL : image

    allow_resample : boolean

    &#34;&#34;&#34;
    # concatenate the images into the reference space
    mimg=[]
    for kk in range( img_LR.shape[3] ):
        temp = ants.slice_image( img_LR, axis=3, idx=kk )
        mimg.append( temp )
    for kk in range( img_RL.shape[3] ):
        temp = ants.slice_image( img_RL, axis=3, idx=kk )
        if kk == 0:
            insamespace = ants.image_physical_space_consistency( temp, mimg[0] )
        if allow_resample and not insamespace :
            temp = ants.resample_image_to_target( temp, mimg[0] )
        mimg.append( temp )
    return ants.list_to_ndimage( img_LR, mimg )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_wides_to_study_dataframe"><code class="name flex">
<span>def <span class="ident">merge_wides_to_study_dataframe</span></span>(<span>sdf, processing_dir, separator='-', sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False, progress=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>extend a study data frame with wide outputs</p>
<p>sdf : the input study dataframe from antspymm QC output</p>
<p>processing_dir:
the directory location of the processed data </p>
<p>separator : string usually '-' or '_'</p>
<p>sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>report_missing : boolean combined with verbose will report missing modalities</p>
<p>progress : integer reports percent progress modulo progress value </p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_wides_to_study_dataframe( sdf, processing_dir, separator=&#39;-&#39;, sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False,
progress=False, verbose=False ):
    &#34;&#34;&#34;
    extend a study data frame with wide outputs

    sdf : the input study dataframe from antspymm QC output

    processing_dir:  the directory location of the processed data 

    separator : string usually &#39;-&#39; or &#39;_&#39;

    sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas

    date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas

    id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas

    report_missing : boolean combined with verbose will report missing modalities

    progress : integer reports percent progress modulo progress value 

    verbose : boolean
    &#34;&#34;&#34;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in sdf.keys():
            raise ValueError(&#39;sdf is missing column &#39; +musthavecols[k] + &#39; in merge_wides_to_study_dataframe&#39; )
    possible_iids = [ &#39;imageID&#39;, &#39;imageID&#39;, &#39;imageID&#39;, &#39;flairid&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;nmid1&#39;, &#39;nmid2&#39;, &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;, &#39;nmid6&#39;, &#39;nmid7&#39;, &#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;perfid&#39; ]
    modality_ids = [ &#39;T1wHierarchical&#39;, &#39;T1wHierarchicalSR&#39;, &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;DTI&#39;, &#39;DTI&#39;, &#39;rsfMRI&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;perf&#39;]
    alldf=pd.DataFrame()
    for myk in sdf.index:
        if progress &gt; 0 and int(myk) % int(progress) == 0:
            print( str( round( myk/sdf.shape[0]*100.0)) + &#34;%...&#34;, end=&#39;&#39;, flush=True)
        if verbose:
            print( &#34;DOROW &#34; + str(myk) + &#39; of &#39; + str( sdf.shape[0] ) )
        csvrow = sdf.loc[sdf.index == myk].dropna(axis=1)
        ct=-1
        for iidkey in possible_iids:
            ct=ct+1
            mod_name = modality_ids[ct]
            if iidkey in csvrow.keys():
                if id_is_int:
                    iid = str( int( csvrow[iidkey].iloc[0] ) )
                else:
                    iid = str( csvrow[iidkey].iloc[0] )
                if verbose:
                    print( &#34;iidkey &#34; + iidkey + &#34; modality &#34; + mod_name + &#39; iid &#39;+ iid )
                pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
                if sid_is_int:
                    sid=str(int(csvrow[&#39;subjectID&#39;].iloc[0] ))
                else:
                    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
                if date_is_int:
                    dt=str(int(csvrow[&#39;date&#39;].iloc[0]))
                else:
                    dt=str(csvrow[&#39;date&#39;].iloc[0])
                if id_is_int:
                    t1iid=str(int(csvrow[&#39;imageID&#39;].iloc[0]))
                else:
                    t1iid=str(csvrow[&#39;imageID&#39;].iloc[0])
                if t1iid != iid:
                    iidj=iid+&#34;_&#34;+t1iid
                else:
                    iidj=iid
                rootid = pid +separator+ sid +separator+dt+separator+mod_name+separator+iidj
                myext = rootid +separator+&#39;mmwide.csv&#39;
                nrgwidefn=os.path.join( processing_dir, pid, sid, dt, mod_name, iid, myext )
                moddersub = mod_name
                is_t1=False
                if mod_name == &#39;T1wHierarchical&#39;:
                    is_t1=True
                    moddersub=&#39;T1Hier&#39;
                elif mod_name == &#39;T1wHierarchicalSR&#39;:
                    is_t1=True
                    moddersub=&#39;T1HSR&#39;
                if exists( nrgwidefn ):
                    if verbose:
                        print( nrgwidefn + &#34; exists&#34;)
                    mm=read_mm_csv( nrgwidefn, colprefix=moddersub+&#39;_&#39;, is_t1=is_t1, separator=separator, verbose=verbose )
                    if mm is not None:
                        if mod_name == &#39;T1wHierarchical&#39;:
                            a=list( csvrow.keys() )
                            b=list( mm.keys() )
                            abintersect=list(set(b).intersection( set(a) ) )
                            if len( abintersect  ) &gt; 0 :
                                for qq in abintersect:
                                    mm.pop( qq )
                        # mm.index=csvrow.index
                        uidname = mod_name + &#39;_mmwide_filename&#39;
                        mm[ uidname ] = rootid
                        csvrow=pd.concat( [csvrow,mm], axis=1, ignore_index=False )
                else:
                    if verbose and report_missing:
                        print( nrgwidefn + &#34; absent&#34;)
        if alldf.shape[0] == 0:
            alldf = csvrow.copy()
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
        else:
            csvrow=csvrow.loc[:,~csvrow.columns.duplicated()]
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
            alldf = pd.concat( [alldf, csvrow], axis=0, ignore_index=True )
    return alldf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.middle_slice_snr"><code class="name flex">
<span>def <span class="ident">middle_slice_snr</span></span>(<span>x, background_dilation=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_dilation</code></strong> :&ensp;<code>integer - amount to dilate foreground mask</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def middle_slice_snr( x, background_dilation=5 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    &#34;&#34;&#34;
    xshp = x.shape
    xmidslice = ants.slice_image( x, 2, int( xshp[2]/2 )  )
    xmidslice = ants.iMath( xmidslice - xmidslice.min(), &#34;Normalize&#34; )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslicemask = ants.threshold_image( xmidslice, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmidslicemask, &#34;MD&#34;, background_dilation ) - xmidslicemask
    signal = (xmidslice[ xmidslicemask == 1] ).mean()
    noise = (xmidslice[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm"><code class="name flex">
<span>def <span class="ident">mm</span></span>(<span>t1_image, hier, rsf_image=[], flair_image=None, nm_image_list=None, dw_image=[], bvals=[], bvecs=[], perfusion_image=None, srmodel=None, do_tractography=False, do_kk=False, do_normalization=None, group_template=None, group_transform=None, target_range=[0, 1], dti_motion_correct='Rigid', dti_denoise=False, perfusion_trim=10, perfusion_m0_image=None, perfusion_m0=None, rsf_upsampling=3.0, test_run=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Multiple modality processing and normalization</p>
<p>aggregates modality-specific processing under one roof.
see individual
modality specific functions for details.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>t1_image</code></strong> :&ensp;<code>raw t1 image</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>hier
: output of antspyt1w.hierarchical ( see read hierarchical )</p>
<dl>
<dt><strong><code>rsf_image</code></strong> :&ensp;<code>list</code> of <code>resting state fmri</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>flair_image</code></strong> :&ensp;<code>flair</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nm_image_list</code></strong> :&ensp;<code>list</code> of <code><a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> images</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dw_image</code></strong> :&ensp;<code>list</code> of <code>diffusion weighted images</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>list</code> of <code>bvals file names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>list</code> of <code>bvecs file names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_image</code></strong> :&ensp;<code>single perfusion image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>optional srmodel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_tractography</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_kk</code></strong> :&ensp;<code>boolean to control whether we compute kelly kapowski thickness image (slow)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_normalization</code></strong> :&ensp;<code>template transformation if available</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>group_template</code></strong> :&ensp;<code>optional reference template corresponding to the group_transform</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>group_transform</code></strong> :&ensp;<code>optional transforms corresponding to the group_template</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>dti_motion_correct</code></strong> :&ensp;<code>None Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_trim</code></strong> :&ensp;<code>optional integer number</code> of <code>time volumes to exclude from the front</code> of <code>the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_m0_image</code></strong> :&ensp;<code>optional antsImage m0 associated with the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_m0</code></strong> :&ensp;<code>optional list containing indices</code> of <code>the m0 in the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>rsf_upsampling</code></strong> :&ensp;<code>optional upsampling parameter value in mm; if set to zero, no upsampling is done</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>test_run</code></strong> :&ensp;<code>boolean </code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm(
    t1_image,
    hier,
    rsf_image=[],
    flair_image=None,
    nm_image_list=None,
    dw_image=[], bvals=[], bvecs=[],
    perfusion_image=None,
    srmodel=None,
    do_tractography = False,
    do_kk = False,
    do_normalization = None,
    group_template = None,
    group_transform = None,
    target_range = [0,1],
    dti_motion_correct = &#39;Rigid&#39;,
    dti_denoise = False,
    perfusion_trim=10,
    perfusion_m0_image=None,
    perfusion_m0=None,
    rsf_upsampling=3.0,
    test_run = False,
    verbose = False ):
    &#34;&#34;&#34;
    Multiple modality processing and normalization

    aggregates modality-specific processing under one roof.  see individual
    modality specific functions for details.

    Parameters
    -------------

    t1_image : raw t1 image

    hier  : output of antspyt1w.hierarchical ( see read hierarchical )

    rsf_image : list of resting state fmri

    flair_image : flair

    nm_image_list : list of neuromelanin images

    dw_image : list of diffusion weighted images

    bvals : list of bvals file names

    bvecs : list of bvecs file names

    perfusion_image : single perfusion image

    srmodel : optional srmodel

    do_tractography : boolean

    do_kk : boolean to control whether we compute kelly kapowski thickness image (slow)

    do_normalization : template transformation if available

    group_template : optional reference template corresponding to the group_transform

    group_transform : optional transforms corresponding to the group_template

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.
    
    dti_motion_correct : None Rigid or SyN

    dti_denoise : boolean

    perfusion_trim : optional integer number of time volumes to exclude from the front of the perfusion time series

    perfusion_m0_image : optional antsImage m0 associated with the perfusion time series

    perfusion_m0 : optional list containing indices of the m0 in the perfusion time series

    rsf_upsampling : optional upsampling parameter value in mm; if set to zero, no upsampling is done

    test_run : boolean 

    verbose : boolean

    &#34;&#34;&#34;
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_path_mm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    mycsvfn = ex_path + &#34;FA_JHU_labels_edited.csv&#34;
    citcsvfn = ex_path + &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad.csv&#34;
    dktcsvfn = ex_path + &#34;dkt.csv&#34;
    cnxcsvfn = ex_path + &#34;dkt_cortex_cit_deep_brain.csv&#34;
    JHU_atlasfn = ex_path + &#39;JHU-ICBM-FA-1mm.nii.gz&#39; # Read in JHU atlas
    JHU_labelsfn = ex_path + &#39;JHU-ICBM-labels-1mm.nii.gz&#39; # Read in JHU labels
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( mycsvfn ) or not exists( citcsvfn ) or not exists( cnxcsvfn ) or not exists( dktcsvfn ) or not exists( JHU_atlasfn ) or not exists( JHU_labelsfn ) or not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        raise ValueError(&#39;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#39;)
    mycsv = pd.read_csv(  mycsvfn )
    citcsv = pd.read_csv(  os.path.expanduser( citcsvfn ) )
    dktcsv = pd.read_csv(  os.path.expanduser( dktcsvfn ) )
    cnxcsv = pd.read_csv(  os.path.expanduser( cnxcsvfn ) )
    JHU_atlas = mm_read( JHU_atlasfn ) # Read in JHU atlas
    JHU_labels = mm_read( JHU_labelsfn ) # Read in JHU labels
    template = mm_read( templatefn ) # Read in template
    if group_template is None:
        group_template = template
        group_transform = do_normalization[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;Using group template:&#34;)
        print( group_template )
    #####################
    #  T1 hierarchical  #
    #####################
    t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
    t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    output_dict = {
        &#39;kk&#39;: None,
        &#39;rsf&#39;: None,
        &#39;flair&#39; : None,
        &#39;NM&#39; : None,
        &#39;DTI&#39; : None,
        &#39;FA_summ&#39; : None,
        &#39;MD_summ&#39; : None,
        &#39;tractography&#39; : None,
        &#39;tractography_connectivity&#39; : None,
        &#39;perf&#39; : None,
    }
    normalization_dict = {
        &#39;kk_norm&#39;: None,
        &#39;NM_norm&#39; : None,
        &#39;DTI_norm&#39;: None,
        &#39;FA_norm&#39; : None,
        &#39;MD_norm&#39; : None,
        &#39;perf_norm&#39; : None,
        &#39;alff_norm&#39; : None,
        &#39;falff_norm&#39; : None,
        &#39;CinguloopercularTaskControl_norm&#39; : None,
        &#39;DefaultMode_norm&#39; : None,
        &#39;MemoryRetrieval_norm&#39; : None,
        &#39;VentralAttention_norm&#39; : None,
        &#39;Visual_norm&#39; : None,
        &#39;FrontoparietalTaskControl_norm&#39; : None,
        &#39;Salience_norm&#39; : None,
        &#39;Subcortical_norm&#39; : None,
        &#39;DorsalAttention_norm&#39; : None
    }
    if test_run:
        return output_dict, normalization_dict

    if do_kk:
        if verbose:
            print(&#39;kk&#39;)
        output_dict[&#39;kk&#39;] = antspyt1w.kelly_kapowski_thickness( hier[&#39;brain_n4_dnz&#39;],
            labels=hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], iterations=45 )
    if  perfusion_image is not None:
        if perfusion_image.shape[3] &gt; 1: # FIXME - better heuristic?
            output_dict[&#39;perf&#39;] = bold_perfusion(
                perfusion_image,
                t1_image,
                hier[&#39;brain_n4_dnz&#39;],
                t1atropos,
                hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] + hier[&#39;cit168lab&#39;],
                n_to_trim = perfusion_trim,
                m0_image = perfusion_m0_image,
                m0_indices = perfusion_m0,
                verbose=verbose )
    ################################## do the rsf .....
    if len(rsf_image) &gt; 0:
        my_motion_tx = &#39;Rigid&#39;
        rsf_image = [i for i in rsf_image if i is not None]
        if verbose:
            print(&#39;rsf length &#39; + str( len( rsf_image ) ) )
        if len( rsf_image ) &gt;= 2: # assume 2 is the largest possible value
            rsf_image1 = rsf_image[0]
            rsf_image2 = rsf_image[1]
            # build a template then join the images
            if verbose:
                print(&#34;initial average for rsf&#34;)
            rsfavg1, hlinds = loop_timeseries_censoring( rsf_image1, 0.1 )
            rsfavg1=get_average_rsf(rsfavg1)
            rsfavg2, hlinds = loop_timeseries_censoring( rsf_image2, 0.1 )
            rsfavg2=get_average_rsf(rsfavg2)
            if verbose:
                print(&#34;template average for rsf&#34;)
            init_temp = ants.image_clone( rsfavg1 )
            if rsf_image1.shape[3] &lt; rsf_image2.shape[3]:
                init_temp = ants.image_clone( rsfavg2 )
            boldTemplate = ants.build_template(
                initial_template = init_temp,
                image_list=[rsfavg1,rsfavg2],
                iterations=5, verbose=False )
            if verbose:
                print(&#34;join the 2 rsf&#34;)
            if rsf_image1.shape[3] &gt; 10 and rsf_image2.shape[3] &gt; 10:
                leadvols = list(range(8))
                rsf_image2 = remove_volumes_from_timeseries( rsf_image2, leadvols )
                rsf_image = merge_timeseries_data( rsf_image1, rsf_image2 )
            elif rsf_image1.shape[3] &gt; rsf_image2.shape[3]:
                rsf_image = rsf_image1
            else:
                rsf_image = rsf_image2
        elif len( rsf_image ) == 1:
            rsf_image = rsf_image[0]
            boldTemplate, hlinds = loop_timeseries_censoring( rsf_image, 0.1 )
            boldTemplate = get_average_rsf(boldTemplate)
        if rsf_image.shape[3] &gt; 10: # FIXME - better heuristic?
            rsfprolist = [] # FIXMERSF
            # Create the parameter DataFrame
            df = pd.DataFrame({
                &#34;num&#34;: [134, 122, 129],
                &#34;loop&#34;: [0.50, 0.25, 0.50],
                &#34;cens&#34;: [True, True, True],
                &#34;HM&#34;: [1.0, 5.0, 0.5],
                &#34;ff&#34;: [&#34;tight&#34;, &#34;tight&#34;, &#34;tight&#34;],
                &#34;CC&#34;: [5, 5, 0.8],
                &#34;imp&#34;: [True, True, True],
                &#34;up&#34;: [rsf_upsampling, rsf_upsampling, rsf_upsampling],
                &#34;coords&#34;: [False,False,False]
            }, index=[0, 1, 2])
            for p in range(df.shape[0]):
                if verbose:
                    print(&#34;rsf parameters&#34;)
                    print( df.iloc[p] )
                if df[&#39;ff&#39;].iloc[p] == &#39;broad&#39;:
                    f=[ 0.008, 0.15 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;tight&#39;:
                    f=[ 0.03, 0.08 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;mid&#39;:
                    f=[ 0.01, 0.1 ]
                elif df[&#39;ff&#39;].iloc[p] == &#39;mid2&#39;:
                    f=[ 0.01, 0.08 ]
                else:
                    raise ValueError(&#34;we do not recognize this parameter choice for frequency filtering: &#34; + df[&#39;ff&#39;].iloc[p] )
                HM = df[&#39;HM&#39;].iloc[p]
                CC = df[&#39;CC&#39;].iloc[p]
                loop= df[&#39;loop&#39;].iloc[p]
                cens =df[&#39;cens&#39;].iloc[p]
                imp = df[&#39;imp&#39;].iloc[p]
                rsf0 = resting_state_fmri_networks(
                                            rsf_image,
                                            boldTemplate,
                                            hier[&#39;brain_n4_dnz&#39;],
                                            t1atropos,
                                            f=f,
                                            FD_threshold=HM, 
                                            spa = None, 
                                            spt = None, 
                                            nc = CC,
                                            outlier_threshold=loop,
                                            ica_components = 0,
                                            impute = imp,
                                            censor = cens,
                                            despike = 2.5,
                                            motion_as_nuisance = True,
                                            upsample=df[&#39;up&#39;].iloc[p],
                                            clean_tmp=0.66,
                                            paramset=df[&#39;num&#39;].iloc[p],
                                            powers=df[&#39;coords&#39;].iloc[p],
                                            verbose=verbose ) # default
                rsfprolist.append( rsf0 )
            output_dict[&#39;rsf&#39;] = rsfprolist
            if False:  # this is the old parameter search stuff
                # Initialize the parameters DataFrame
                # first - no censoring - just explore compcor
                df = pd.DataFrame()
                cens=False
                HM=1.0 # best by PTBP
                hmsearch = [0.5, 1.0, 5.0 ]
                loopsearch = [ 0.25, 0.5, 0.75, 1.0 ]
                loop = 1.0
                CCsearch = [ 5, 0.80 ]
                defaultf = [ 0.008, 0.15 ]
                freqsearch = [&#39;broad&#39;,&#39;mid&#39;,&#39;tight&#39;] # 
                # for debuggin
                # rsf_image = remove_volumes_from_timeseries( rsf_image, list(range(80,2000))) 
                docens=True                     # explore censoring
                for ff in freqsearch:
                    for CC in CCsearch:
                        local_df = pd.DataFrame({&#34;loop&#34;: [loop], &#34;cens&#34;: [cens], &#34;HM&#34;: [HM], &#34;ff&#34;: [ff], &#34;CC&#34;: [CC]})
                        if verbose:
                            print( local_df )
                        if df.shape[0] == 0:
                            df = local_df
                        else:
                            df = pd.concat([df, local_df], ignore_index=True)
                        f = defaultf
                        if ff == &#39;mid&#39;:
                            f = [0.01,0.1]
                        elif ff == &#39;tight&#39;:
                            f = [0.03,0.08]
                        rsf0 = resting_state_fmri_networks(
                            rsf_image, boldTemplate, hier[&#39;brain_n4_dnz&#39;], t1atropos,
                            f=f,
                            FD_threshold=HM,
                            spa = None, spt = None, 
                            nc = CC, 
                            outlier_threshold=loop,
                            ica_components = 0,
                            impute = False,
                            censor = cens,
                            despike = 2.5,
                            motion_as_nuisance = True,
                            upsample=False,
                            clean_tmp=0.66,
                            verbose=verbose ) # default
                        rsfprolist.append( rsf0 )

                # test impact of censoring
                if docens:
                    cens = True
                    for loop in loopsearch:
                        for HM in hmsearch:
                            for ff in freqsearch:
                                for CC in CCsearch:
                                    local_df = pd.DataFrame({&#34;loop&#34;: [loop], &#34;cens&#34;: [cens], &#34;HM&#34;: [HM], &#34;ff&#34;: [ff], &#34;CC&#34;: [CC]})
                                    if verbose:
                                        print( local_df )
                                    df = pd.concat([df, local_df], ignore_index=True)
                                    f = defaultf
                                    if ff == &#39;mid&#39;:
                                        f = [0.01,0.1]
                                    elif ff == &#39;tight&#39;:
                                        f = [0.03,0.08]
                                    rsf0 = resting_state_fmri_networks(
                                            rsf_image,
                                            boldTemplate,
                                            hier[&#39;brain_n4_dnz&#39;],
                                            t1atropos,
                                            f=f,
                                            FD_threshold=HM, 
                                            spa = None, 
                                            spt = None, 
                                            nc = CC,
                                            outlier_threshold=loop,
                                            ica_components = 0,
                                            impute = False,
                                            censor = cens,
                                            despike = 2.5,
                                            motion_as_nuisance = True,
                                            upsample=False,
                                            clean_tmp=0.66,
                                            verbose=verbose ) # default
                                    rsfprolist.append( rsf0 )
                output_dict[&#39;rsf&#39;] = rsfprolist
    if nm_image_list is not None:
        if verbose:
            print(&#39;nm&#39;)
        if srmodel is None:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], verbose=verbose )
        else:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], srmodel=srmodel, target_range=target_range, verbose=verbose  )
################################## do the dti .....
    if len(dw_image) &gt; 0 :
        if verbose:
            print(&#39;dti-x&#39;)
        if len( dw_image ) == 1: # use T1 for distortion correction and brain extraction
            if verbose:
                print(&#34;We have only one DTI: &#34; + str(len(dw_image)))
            dw_image = dw_image[0]
            btpB0,btpDW=get_average_dwi_b0(dw_image)
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            btpDW = ants.apply_transforms( btpDW, btpDW,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            btpB0 = ants.apply_transforms( btpB0, btpB0,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;nearestNeighbor&#39;)
            # dwimask = ants.iMath(dwimask,&#39;MD&#39;,1)
            t12dwi = ants.apply_transforms( btpDW, hier[&#39;brain_n4_dnz&#39;], tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;linear&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image,
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                motion_correct=dti_motion_correct, # set to False if using input from qsiprep
                denoise=dti_denoise,
                verbose = verbose)
        else :  # use phase encoding acquisitions for distortion correction and T1 for brain extraction
            if verbose:
                print(&#34;We have both DTI_LR and DTI_RL: &#34; + str(len(dw_image)))
            a1b,a1w=get_average_dwi_b0(dw_image[0])
            a2b,a2w=get_average_dwi_b0(dw_image[1],fixed_b0=a1b,fixed_dwi=a1w)
            btpB0, btpDW = dti_template(
                b_image_list=[a1b,a2b],
                w_image_list=[a1w,a2w],
                iterations=7, verbose=verbose )
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image[0],
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                img_RL=dw_image[1],
                bval_RL=bvals[1],
                bvec_RL=bvecs[1],
                motion_correct=&#39;SyN&#39;, # set to False if using input from qsiprep
                denoise=True,
                verbose = verbose)
        mydti = output_dict[&#39;DTI&#39;]
        # summarize dwi with T1 outputs
        # first - register ....
        reg = ants.registration( mydti[&#39;recon_fa&#39;], hier[&#39;brain_n4_dnz&#39;], &#39;SyNBold&#39;, total_sigma=1.0 )
        ##################################################
        output_dict[&#39;FA_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_fa&#39;],
            hier=hier,
            modality_name=&#39;fa&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        ##################################################
        output_dict[&#39;MD_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_md&#39;],
            hier=hier,
            modality_name=&#39;md&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        # these inputs should come from nicely processed data
        dktmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        citmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;cit168lab&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        dktmapped[ citmapped &gt; 0]=0
        mask = ants.threshold_image( mydti[&#39;recon_fa&#39;], 0.01, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
        if do_tractography: # dwi_deterministic_tracking dwi_closest_peak_tracking
            output_dict[&#39;tractography&#39;] = dwi_deterministic_tracking(
                mydti[&#39;dwi_LR_dewarped&#39;],
                mydti[&#39;recon_fa&#39;],
                mydti[&#39;bval_LR&#39;],
                mydti[&#39;bvec_LR&#39;],
                seed_density = 1,
                mask=mask,
                verbose = verbose )
            mystr = output_dict[&#39;tractography&#39;]
            output_dict[&#39;tractography_connectivity&#39;] = dwi_streamline_connectivity( mystr[&#39;streamlines&#39;], dktmapped+citmapped, cnxcsv, verbose=verbose )
    ################################## do the flair .....
    if flair_image is not None:
        if verbose:
            print(&#39;flair&#39;)
        wmhprior = None
        priorfn = ex_path_mm + &#39;CIT168_wmhprior_700um_pad_adni.nii.gz&#39;
        if ( exists( priorfn ) ):
            wmhprior = ants.image_read( priorfn )
            wmhprior = ants.apply_transforms( t1_image, wmhprior, do_normalization[&#39;invtransforms&#39;] )
        output_dict[&#39;flair&#39;] = boot_wmh( flair_image, t1_image, t1atropos,
            prior_probability=wmhprior, verbose=verbose )
    #################################################################
    ### NOTES: deforming to a common space and writing out images ###
    ### images we want come from: DTI, NM, rsf, thickness ###########
    #################################################################
    if do_normalization is not None:
        if verbose:
            print(&#39;normalization&#39;)
        # might reconsider this template space - cropped and/or higher res?
        # template = ants.resample_image( template, [1,1,1], use_voxels=False )
        # t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;], &#34;antsRegistrationSyNQuickRepro[s]&#34;)
        t1reg = do_normalization
        if do_kk:
            normalization_dict[&#39;kk_norm&#39;] = ants.apply_transforms( group_template, output_dict[&#39;kk&#39;][&#39;thickness_image&#39;], group_transform )
        if output_dict[&#39;DTI&#39;] is not None:
            mydti = output_dict[&#39;DTI&#39;]
            dtirig = ants.registration( hier[&#39;brain_n4_dnz&#39;], mydti[&#39;recon_fa&#39;], &#39;Rigid&#39; )
            normalization_dict[&#39;MD_norm&#39;] = ants.apply_transforms( group_template, mydti[&#39;recon_md&#39;],group_transform+dtirig[&#39;fwdtransforms&#39;] )
            normalization_dict[&#39;FA_norm&#39;] = ants.apply_transforms( group_template, mydti[&#39;recon_fa&#39;],group_transform+dtirig[&#39;fwdtransforms&#39;] )
            output_directory = tempfile.mkdtemp()
            do_dti_norm=False
            if do_dti_norm:
                comptx = ants.apply_transforms( group_template, group_template, group_transform+dtirig[&#39;fwdtransforms&#39;], compose = output_directory + &#39;/xxx&#39; )
                tspc=[2.,2.,2.]
                if srmodel is not None:
                    tspc=[1.,1.,1.]
                group_template2mm = ants.resample_image( group_template, tspc  )
                normalization_dict[&#39;DTI_norm&#39;] = transform_and_reorient_dti( group_template2mm, mydti[&#39;dti&#39;], comptx, py_based=True, verbose=True )
            import shutil
            shutil.rmtree(output_directory, ignore_errors=True )
        if output_dict[&#39;rsf&#39;] is not None:
            if False:
                rsfpro = output_dict[&#39;rsf&#39;] # FIXME
                rsfrig = ants.registration( hier[&#39;brain_n4_dnz&#39;], rsfpro[&#39;meanBold&#39;], &#39;Rigid&#39; )
                for netid in get_antsimage_keys( rsfpro ):
                    rsfkey = netid + &#34;_norm&#34;
                    normalization_dict[rsfkey] = ants.apply_transforms(
                        group_template, rsfpro[netid],
                        group_transform+rsfrig[&#39;fwdtransforms&#39;] )
        if output_dict[&#39;perf&#39;] is not None: # zizzer
            comptx = group_transform + output_dict[&#39;perf&#39;][&#39;t1reg&#39;][&#39;invtransforms&#39;]
            normalization_dict[&#39;perf_norm&#39;] = ants.apply_transforms( group_template,
                output_dict[&#39;perf&#39;][&#39;perfusion&#39;], comptx,
                whichtoinvert=[False,False,True,False] )
            normalization_dict[&#39;cbf_norm&#39;] = ants.apply_transforms( group_template,
                output_dict[&#39;perf&#39;][&#39;cbf&#39;], comptx,
                whichtoinvert=[False,False,True,False] )
        if nm_image_list is not None:
            nmpro = output_dict[&#39;NM&#39;]
            nmrig = nmpro[&#39;t1_to_NM_transform&#39;] # this is an inverse tx
            normalization_dict[&#39;NM_norm&#39;] = ants.apply_transforms( group_template, nmpro[&#39;NM_avg&#39;], group_transform+nmrig,
                whichtoinvert=[False,False,True])

    if verbose:
        print(&#39;mm done&#39;)
    return output_dict, normalization_dict</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_csv"><code class="name flex">
<span>def <span class="ident">mm_csv</span></span>(<span>studycsv, mysep='-', srmodel_T1=False, srmodel_NM=False, srmodel_DTI=False, dti_motion_correct='SyN', dti_denoise=True, nrg_modality_list=None, normalization_template=None, normalization_template_output=None, normalization_template_transform_type='antsRegistrationSyNRepro[s]', normalization_template_spacing=None, enantiomorphic=False, perfusion_trim=10, perfusion_m0_image=None, perfusion_m0=None, rsf_upsampling=3.0)</span>
</code></dt>
<dd>
<div class="desc"><p>too dangerous to document &hellip; use with care.</p>
<p>processes multiple modality MRI specifically:</p>
<ul>
<li>T1w</li>
<li>T2Flair</li>
<li>DTI, DTI_LR, DTI_RL</li>
<li>rsfMRI, rsfMRI_LR, rsfMRI_RL</li>
<li>NM2DMT (neuromelanin)</li>
</ul>
<p>other modalities may be added later &hellip;</p>
<p>"trust me, i know what i'm doing" - sledgehammer</p>
<p>convert to pynb via:
p2j mm.py -o</p>
<p>convert the ipynb to html via:
jupyter nbconvert ANTsPyMM/tests/mm.ipynb &ndash;execute &ndash;to html</p>
<p>this function does not assume NRG format for the input data ....</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>studycsv</code></strong> :&ensp;<code>must have columns:</code></dt>
<dd>
<ul>
<li>subjectID</li>
<li>date or session</li>
<li>imageID</li>
<li>modality</li>
<li>sourcedir</li>
<li>outputdir</li>
<li>filename (path to the t1 image)
other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
rsf=resting state fmri, flair=T2Flair.
none of these are required. only
t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
see antspymm.generate_mm_dataframe</li>
</ul>
</dd>
<dt><strong><code>sourcedir</code></strong> :&ensp;<code>a study specific folder containing individual subject folders</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>outputdir</code></strong> :&ensp;<code>a study specific folder where individual output subject folders will go</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>the raw image filename (full path)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_T1</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 2 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_NM</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_DTI</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_motion_correct</code></strong> :&ensp;<code>None, Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nrg_modality_list</code></strong> :&ensp;<code>optional; defaults to None; use to focus on a given modality</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>normalization_template</code></strong> :&ensp;<code>optional; defaults to None; if present, all images will</code></dt>
<dd>be deformed into this space and the deformation will be stored with an extension
related to this variable.
this should be a brain extracted T1w image.</dd>
<dt><strong><code>normalization_template_output</code></strong> :&ensp;<code>optional string; defaults to None; naming for the</code></dt>
<dd>normalization_template outputs which will be in the T1w directory.</dd>
<dt><strong><code>normalization_template_transform_type</code></strong> :&ensp;<code>optional string transform type passed to ants.registration</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>normalization_template_spacing</code></strong> :&ensp;<code>3-tuple controlling the resolution at which registration is computed</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>enantiomorphic</code></strong> :&ensp;<code>boolean (WIP)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_trim</code></strong> :&ensp;<code>optional integer number</code> of <code>time volumes to exclude from the front</code> of <code>the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_m0_image</code></strong> :&ensp;<code>optional m0 antsImage associated with the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>perfusion_m0</code></strong> :&ensp;<code>optional list containing indices</code> of <code>the m0 in the perfusion time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>rsf_upsampling</code></strong> :&ensp;<code>optional upsampling parameter value in mm; if set to zero, no upsampling is done</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>writes output to disk and produces figures</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_csv(
    studycsv,   # pandas data frame
    mysep = &#39;-&#39;, # or &#34;_&#34; for BIDS
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    dti_motion_correct = &#39;SyN&#39;,
    dti_denoise = True,
    nrg_modality_list = None,
    normalization_template = None,
    normalization_template_output = None,
    normalization_template_transform_type = &#34;antsRegistrationSyNRepro[s]&#34;,
    normalization_template_spacing=None,
    enantiomorphic=False,
    perfusion_trim = 10,
    perfusion_m0_image = None,
    perfusion_m0 = None,
    rsf_upsampling = 3.0
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function does not assume NRG format for the input data ....

    Parameters
    -------------

    studycsv : must have columns:
        - subjectID
        - date or session
        - imageID
        - modality
        - sourcedir
        - outputdir
        - filename (path to the t1 image)
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
        see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    outputdir : a study specific folder where individual output subject folders will go

    filename : the raw image filename (full path)

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    dti_motion_correct : None, Rigid or SyN

    dti_denoise : boolean

    nrg_modality_list : optional; defaults to None; use to focus on a given modality

    normalization_template : optional; defaults to None; if present, all images will
        be deformed into this space and the deformation will be stored with an extension
        related to this variable.  this should be a brain extracted T1w image.

    normalization_template_output : optional string; defaults to None; naming for the 
        normalization_template outputs which will be in the T1w directory.

    normalization_template_transform_type : optional string transform type passed to ants.registration

    normalization_template_spacing : 3-tuple controlling the resolution at which registration is computed 
    
    enantiomorphic: boolean (WIP)

    perfusion_trim : optional integer number of time volumes to exclude from the front of the perfusion time series

    perfusion_m0_image : optional m0 antsImage associated with the perfusion time series

    perfusion_m0 : optional list containing indices of the m0 in the perfusion time series

    rsf_upsampling : optional upsampling parameter value in mm; if set to zero, no upsampling is done

    Returns
    ---------

    writes output to disk and produces figures

    &#34;&#34;&#34;
    import traceback
    visualize = True
    verbose = True
    if verbose:
        print( version() )
    if nrg_modality_list is None:
        nrg_modality_list = get_valid_modalities()
    if studycsv.shape[0] &lt; 1:
        raise ValueError(&#39;studycsv has no rows&#39;)
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studycsv.keys():
            raise ValueError(&#39;studycsv is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = mysep ):
        return x + separator + &#39;mmwide.csv&#39;
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studycsv
    # musthavecols = [&#39;projectID&#39;,&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    projid = str(studycsv[&#39;projectID&#39;].iloc[0])
    sid = str(studycsv[&#39;subjectID&#39;].iloc[0])
    dtid = str(studycsv[&#39;date&#39;].iloc[0])
    iid = str(studycsv[&#39;imageID&#39;].iloc[0])
    t1iidUse=iid
    modality = str(studycsv[&#39;modality&#39;].iloc[0])
    sourcedir = str(studycsv[&#39;sourcedir&#39;].iloc[0])
    outputdir = str(studycsv[&#39;outputdir&#39;].iloc[0])
    filename = str(studycsv[&#39;filename&#39;].iloc[0])
    if not exists(filename):
            raise ValueError(&#39;mm_nrg cannot find filename &#39; + filename + &#39; in mm_csv&#39; )

    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1fn = filename
    if not exists( t1fn ):
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + t1fn )
    t1 = mm_read( t1fn, modality=&#39;T1w&#39; )
    minspc = np.min(ants.get_spacing(t1))
    minshape = np.min(t1.shape)
    if minspc &lt; 1e-16:
        warnings.warn(&#39;minimum spacing in T1w is too small - cannot process. &#39; + str(minspc) )
        return
    if minshape &lt; 32:
        warnings.warn(&#39;minimum shape in T1w is too small - cannot process. &#39; + str(minshape) )
        return

    if enantiomorphic:
        t1 = enantiomorphic_filling_without_mask( t1, axis=0 )[0]
    hierfn = outputdir + &#34;/&#34;  + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchical&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchical&#34; + mysep + iid + mysep
    hierfnSR = outputdir + &#34;/&#34; + projid + &#34;/&#34;  + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchicalSR&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchicalSR&#34; + mysep + iid + mysep
    hierfntest = hierfn + &#39;cerebellum.csv&#39;
    if verbose:
        print( hierfntest )
    regout = re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn) + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    groupTx = None
    # make the T1w directory
    os.makedirs( os.path.dirname(re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn)), exist_ok=True  )
    if normalization_template_output is not None:
        normout = re.sub(&#34;T1wHierarchical&#34;,&#34;T1w&#34;,hierfn) +  normalization_template_output
        templateNormTx = {
            &#39;fwdtransforms&#39;: [ normout+&#39;1Warp.nii.gz&#39;, normout+&#39;0GenericAffine.mat&#39;],
            &#39;invtransforms&#39;: [ normout+&#39;0GenericAffine.mat&#39;, normout+&#39;1InverseWarp.nii.gz&#39;]  }
        groupTx = templateNormTx[&#39;fwdtransforms&#39;]
    if verbose:
        print( &#34;-&lt;REGISTRATION EXISTENCE&gt;-: \n&#34; + 
              &#34;NAMING: &#34; + regout+&#39;0GenericAffine.mat&#39; + &#34; \n &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) and exists( templateTx[&#39;fwdtransforms&#39;][0]) and exists( templateTx[&#39;fwdtransforms&#39;][1]) and exists( templateTx[&#39;invtransforms&#39;][0]) and exists( templateTx[&#39;invtransforms&#39;][1])
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if t1wide[&#39;resnetGrade&#39;].iloc[0] &lt; 0.35:
        rgrade = str( t1wide[&#39;resnetGrade&#39;].iloc[0] )
        warnings.warn(&#39;T1w quality check indicates failure: &#39; + rgrade + &#34; will not process.&#34; )
        return

    if srmodel_T1 is not False :
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]

    if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
        if verbose:
            print(&#39;start t1 registration&#39;)
        ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
        templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
        template = mm_read( templatefn )
        template = ants.resample_image( template, [1,1,1], use_voxels=False )
        t1reg = ants.registration( template, 
            hier[&#39;brain_n4_dnz&#39;],
            &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
        myjac = ants.create_jacobian_determinant_image( template,
            t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
        image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
        if visualize:
            ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
            ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )

    if normalization_template_output is not None and normalization_template is not None:
        if verbose:
            print(&#34;begin group template registration&#34;)
        if not exists( normout+&#39;0GenericAffine.mat&#39; ):
            if normalization_template_spacing is not None:
                normalization_template_rr=ants.resample_image(normalization_template,normalization_template_spacing)
            else:
                normalization_template_rr=normalization_template
            greg = ants.registration( 
                normalization_template_rr, 
                hier[&#39;brain_n4_dnz&#39;],
                normalization_template_transform_type,
                outprefix = normout, verbose=False )
            myjac = ants.create_jacobian_determinant_image( template,
                    greg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
            image_write_with_thumbnail( myjac, normout + &#34;logjacobian.nii.gz&#34;, thumb=False )
            if verbose:
                print(&#34;end group template registration&#34;)
        else:
            if verbose:
                print(&#34;group template registration already done&#34;)

    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    for overmodX in nrg_modality_list:
        # define 1. input images 2. output prefix
        mydoc = docsamson( overmodX, studycsv=studycsv, outputdir=outputdir, projid=projid, sid=sid, dtid=dtid, mysep=mysep,t1iid=t1iidUse )
        myimgsr = mydoc[&#39;images&#39;]
        mymm = mydoc[&#39;outprefix&#39;]
        mymod = mydoc[&#39;modality&#39;]
        if verbose:
            print( mydoc )
        if len(myimgsr) &gt; 0:
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodX )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodX == &#39;NM2DMT&#39;:
                subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                if verbose:
                    print(&#34;subjectpropath is&#34;)
                    print(subjectpropath)
                    os.makedirs( subjectpropath, exist_ok=True  )
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    try:
                        tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            group_template = normalization_template,
                            group_transform = groupTx,
                            test_run=test_run,
                            verbose=True )
                    except Exception as e:
                        error_info = traceback.format_exc()
                        print(error_info)
                        visualize=False
                        dowrite=False
                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                        pass
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount=0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                        if verbose:
                            print(&#34;subjectpropath is&#34;)
                            print(subjectpropath)
                        os.makedirs( subjectpropath, exist_ok=True  )
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            srmodel=None,
                                            do_tractography=False,
                                            do_kk=True,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3 and np.min(img.shape) &gt; 15:
                                dowrite=True
                                try:
                                    tabPro, normPro = mm( t1, hier,
                                        flair_image = img,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        group_template = normalization_template,
                                        group_transform = groupTx,
                                        test_run=test_run,
                                        verbose=True )
                                except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 or 1 in img2.shape:
                                        img2 = None
                                if 1 in img.shape:
                                    warnings.warn( &#39;rsfMRI image shape suggests it is an incorrectly converted mosaic image - will not process.&#39;)
                                    dowrite=False
                                    tabPro={&#39;rsf&#39;:None}
                                    normPro={&#39;rsf&#39;:None}
                                else:
                                    dowrite=True
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            rsf_image=[img,img2],
                                            srmodel=None,
                                            do_tractography=False,
                                            do_kk=False,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            rsf_upsampling = rsf_upsampling,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        tabPro={&#39;rsf&#39;:None}
                                        normPro={&#39;rsf&#39;:None}
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    for tpro in tabPro[&#39;rsf&#39;]: # FIXMERSF
                                        maxslice = np.min( [21, tpro[&#39;meanBold&#39;].shape[2] ] )
                                        tproprefix = mymm+mysep+str(tpro[&#39;paramset&#39;])+mysep
                                        ants.plot( tpro[&#39;meanBold&#39;],
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=tproprefix+&#34;meanBOLD.png&#34; )
                                        ants.plot( tpro[&#39;meanBold&#39;], ants.iMath(tpro[&#39;alff&#39;],&#34;Normalize&#34;),
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=tproprefix+&#34;boldALFF.png&#34; )
                                        ants.plot( tpro[&#39;meanBold&#39;], ants.iMath(tpro[&#39;falff&#39;],&#34;Normalize&#34;),
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=tproprefix+&#34;boldfALFF.png&#34; )
                                        dfn=tpro[&#39;dfnname&#39;]
                                        ants.plot( tpro[&#39;meanBold&#39;], tpro[dfn],
                                            axis=2, nslices=maxslice, ncol=7, crop=True, title=dfn, filename=tproprefix+&#34;boldDefaultMode.png&#34; )
                            if ( mymod == &#39;perf&#39; ) and ishapelen == 4:
                                dowrite=True
                                try:
                                    tabPro, normPro = mm( t1, hier,
                                        perfusion_image=img,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        group_template = normalization_template,
                                        group_transform = groupTx,
                                        test_run=test_run,
                                        perfusion_trim=perfusion_trim,
                                        perfusion_m0_image=perfusion_m0_image,
                                        perfusion_m0=perfusion_m0,
                                        verbose=True )
                                except Exception as e:
                                        error_info = traceback.format_exc()
                                        print(error_info)
                                        visualize=False
                                        dowrite=False
                                        tabPro={&#39;perf&#39;:None}
                                        print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                        pass
                                if tabPro[&#39;perf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;perf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;perfusion&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;perfusion image&#39;, filename=mymm+mysep+&#34;perfusion.png&#34; )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;cbf&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;CBF image&#39;, filename=mymm+mysep+&#34;cbf.png&#34; )
                                    ants.plot( tabPro[&#39;perf&#39;][&#39;m0&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;M0 image&#39;, filename=mymm+mysep+&#34;m0.png&#34; )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                missing_dti_data=False # bval, bvec or images
                                if len( myimgsr ) == 2:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if exists( dtilrfn ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                elif len( myimgsr ) == 3:  # find DTI_RL
                                    print(&#34;DTI trinity&#34;)
                                    dtilrfn = myimgsr[myimgcount+1]
                                    dtilrfn2 = myimgsr[myimgcount+2]
                                    if exists( dtilrfn ) and exists( dtilrfn2 ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        bvalfnRL2 = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn2 )
                                        bvecfnRL2 = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn2 )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgRL2 = ants.image_read( dtilrfn2 )
                                        bvals, bvecs = read_bvals_bvecs( bvalfnRL , bvecfnRL  )
                                        print( bvals.max() )
                                        bvals2, bvecs2 = read_bvals_bvecs( bvalfnRL2 , bvecfnRL2  )
                                        print( bvals2.max() )
                                        temp = merge_dwi_data( imgRL, bvals, bvecs, imgRL2, bvals2, bvecs2  )
                                        imgList.append( temp[0] )
                                        bvalfnList.append( mymm+mysep+&#39;joined.bval&#39; )
                                        bvecfnList.append( mymm+mysep+&#39;joined.bvec&#39; )
                                        write_bvals_bvecs( temp[1], temp[2], mymm+mysep+&#39;joined&#39; )
                                        bvalsX, bvecsX = read_bvals_bvecs( bvalfnRL2 , bvecfnRL2  )
                                        print( bvalsX.max() )
                                # check existence of all files expected ...
                                for dtiex in bvalfnList+bvecfnList+myimgsr:
                                    if not exists(dtiex):
                                        print(&#39;mm_csv: missing dti data &#39; + dtiex )
                                        missing_dti_data=True
                                        dowrite=False
                                if not missing_dti_data:
                                    dowrite=True
                                    srmodel_DTI_mdl=None
                                    if srmodel_DTI is not False:
                                        temp = ants.get_spacing(img)
                                        dtspc=[temp[0],temp[1],temp[2]]
                                        bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                        mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                        if isinstance( srmodel_DTI, str ):
                                            srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                            mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                        if exists( mdlfn ):
                                            if verbose:
                                                print(mdlfn)
                                            srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                        else:
                                            print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                    try:
                                        tabPro, normPro = mm( t1, hier,
                                            dw_image=imgList,
                                            bvals = bvalfnList,
                                            bvecs = bvecfnList,
                                            srmodel=srmodel_DTI_mdl,
                                            do_tractography=not test_run,
                                            do_kk=False,
                                            do_normalization=templateTx,
                                            group_template = normalization_template,
                                            group_transform = groupTx,
                                            dti_motion_correct = dti_motion_correct,
                                            dti_denoise = dti_denoise,
                                            test_run=test_run,
                                            verbose=True )
                                    except Exception as e:
                                            error_info = traceback.format_exc()
                                            print(error_info)
                                            visualize=False
                                            dowrite=False
                                            tabPro={&#39;DTI&#39;:None}
                                            print(f&#34;antspymmerror occurred while processing {overmodX}: {e}&#34;)
                                            pass
                                    mydti = tabPro[&#39;DTI&#39;]
                                    if visualize and tabPro[&#39;DTI&#39;] is not None:
                                        maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                        ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                        ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                        ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None and normPro[mykey].components == 1:
                                        if visualize and False:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_nrg"><code class="name flex">
<span>def <span class="ident">mm_nrg</span></span>(<span>studyid, sourcedir='/Users/stnava/data/PPMI/MV/example_s3_b/images/PPMI/', sourcedatafoldername='images', processDir='processed', mysep='-', srmodel_T1=False, srmodel_NM=False, srmodel_DTI=False, visualize=True, nrg_modality_list=['T1w', 'NM2DMT', 'DTI', 'T2Flair', 'rsfMRI'], verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>too dangerous to document &hellip; use with care.</p>
<p>processes multiple modality MRI specifically:</p>
<ul>
<li>T1w</li>
<li>T2Flair</li>
<li>DTI, DTI_LR, DTI_RL</li>
<li>rsfMRI, rsfMRI_LR, rsfMRI_RL</li>
<li>NM2DMT (neuromelanin)</li>
</ul>
<p>other modalities may be added later &hellip;</p>
<p>"trust me, i know what i'm doing" - sledgehammer</p>
<p>convert to pynb via:
p2j mm.py -o</p>
<p>convert the ipynb to html via:
jupyter nbconvert ANTsPyMM/tests/mm.ipynb &ndash;execute &ndash;to html</p>
<p>this function assumes NRG format for the input data ....
we also assume that t1w hierarchical (if already done) was written
via its standardized write function.
NRG = <a href="https://github.com/stnava/biomedicalDataOrganization">https://github.com/stnava/biomedicalDataOrganization</a></p>
<p>this function is verbose</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>studyid</code></strong> :&ensp;<code>must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID</code></dt>
<dd>other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
rsf=resting state fmri, flair=T2Flair.
none of these are required. only
t1 is required.
rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
see antspymm.generate_mm_dataframe</dd>
<dt><strong><code>sourcedir</code></strong> :&ensp;<code>a study specific folder containing individual subject folders</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>sourcedatafoldername</code></strong> :&ensp;<code>root for source data e.g. "images"</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>processDir : where output will go - parallel to sourcedatafoldername e.g.
"processed"</p>
<dl>
<dt><strong><code>mysep</code></strong> :&ensp;<code>define a character separator for filename components</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_T1</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 2 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_NM</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_DTI</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>visualize</code></strong> :&ensp;<code>True - will plot some results to png</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nrg_modality_list</code></strong> :&ensp;<code>list</code> of <code>permissible modalities - always include [T1w] as base</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>writes output to disk and potentially produces figures that may be</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>captured in a ipynb / html file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_nrg(
    studyid,   # pandas data frame
    sourcedir = os.path.expanduser( &#34;~/data/PPMI/MV/example_s3_b/images/PPMI/&#34; ),
    sourcedatafoldername = &#39;images&#39;, # root for source data
    processDir = &#34;processed&#34;, # where output will go - parallel to sourcedatafoldername
    mysep = &#39;-&#39;, # define a separator for filename components
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    visualize = True,
    nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;DTI&#34;,&#34;T2Flair&#34;, &#34;rsfMRI&#34; ],
    verbose = True
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function assumes NRG format for the input data ....
    we also assume that t1w hierarchical (if already done) was written
    via its standardized write function.
    NRG = https://github.com/stnava/biomedicalDataOrganization

    this function is verbose

    Parameters
    -------------

    studyid : must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required.  rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.  see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    sourcedatafoldername : root for source data e.g. &#34;images&#34;

    processDir : where output will go - parallel to sourcedatafoldername e.g.
        &#34;processed&#34;

    mysep : define a character separator for filename components

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    visualize : True - will plot some results to png

    nrg_modality_list : list of permissible modalities - always include [T1w] as base

    verbose : boolean

    Returns
    ---------

    writes output to disk and potentially produces figures that may be
    captured in a ipynb / html file.

    &#34;&#34;&#34;
    studyid = studyid.dropna(axis=1)
    if studyid.shape[0] &lt; 1:
        raise ValueError(&#39;studyid has no rows&#39;)
    musthavecols = [&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studyid.keys():
            raise ValueError(&#39;studyid is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = &#39;-&#39; ):
        return x + separator + &#39;mmwide.csv&#39;
    if nrg_modality_list[0] != &#39;T1w&#39;:
        nrg_modality_list.insert(0, &#34;T1w&#34; )
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studyid
    sid = str(studyid[&#39;subjectID&#39;].iloc[0])
    dtid = str(studyid[&#39;date&#39;].iloc[0])
    iid = str(studyid[&#39;imageID&#39;].iloc[0])
    subjectrootpath = os.path.join(sourcedir,sid, dtid)
    if verbose:
        print(&#34;subjectrootpath: &#34;+ subjectrootpath )
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, iid, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + iid + &#39; @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    hierfn0 = re.sub( sourcedatafoldername, processDir, t1fn)
    hierfn0 = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfn0)
    hierfn = re.sub( &#34;T1w&#34;, &#34;T1wHierarchical&#34;, hierfn0)
    hierfn = hierfn + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    regout = hierfn0 + mysep + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;-&lt;REGISTRATION EXISTENCE&gt;-: \n&#34; + 
              &#34;NAMING: &#34; + regout+&#39;0GenericAffine.mat&#39; + &#34; \n &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfnSR = re.sub( sourcedatafoldername, processDir, t1fn)
        hierfnSR = re.sub( &#34;T1w&#34;, &#34;T1wHierarchicalSR&#34;, hierfnSR)
        hierfnSR = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfnSR)
        hierfnSR = hierfnSR + mysep
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    nimages = len(myimgsInput)
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.&#34;)
    for overmodX in nrg_modality_list:
        counter=counter+1
        if counter &gt; (len(nrg_modality_list)+1):
            print(&#34;This is weird. &#34; + str(counter))
            return
        if overmodX == &#39;T1w&#39;:
            iidOtherMod = iid
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        elif overmodX == &#39;NM2DMT&#39; and (&#39;nmid1&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;nmid1&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            for nmnum in range(2,11):
                locnmnum = &#39;nmid&#39;+str(nmnum)
                if locnmnum in studyid.keys() :
                    iidOtherMod = str( int(studyid[locnmnum].iloc[0]) )
                    mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
                    myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;rsfMRI&#39; in overmodX and ( ( &#39;rsfid1&#39; in studyid.keys() ) or (&#39;rsfid2&#39; in studyid.keys() ) ):
            myimgsr = []
            if  &#39;rsfid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;rsfid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;DTI&#39; in overmodX and (  &#39;dtid1&#39; in studyid.keys() or  &#39;dtid2&#39; in studyid.keys() ):
            myimgsr = []
            if  &#39;dtid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;dtid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;T2Flair&#39; in overmodX and (&#39;flairid&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;flairid&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        if verbose:
            print( &#34;overmod &#34; + overmodX + &#34; &#34; + iidOtherMod )
            print(f&#34;modality search path: {mod_search_path}&#34;)
        myimgsr.sort()
        if len(myimgsr) &gt; 0:
            overmodXx = str(overmodX)
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodXx )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodXx == &#39;NM2DMT&#39;:
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                subjectpropath = os.path.dirname( myimgsr2[0] )
                subjectpropath = re.sub( sourcedatafoldername, processDir,subjectpropath )
                if verbose:
                    print( &#34;subjectpropath &#34; + subjectpropath )
                mysplit = subjectpropath.split( &#34;/&#34; )
                os.makedirs( subjectpropath, exist_ok=True  )
                mysplitCount = len( mysplit )
                project = mysplit[mysplitCount-5]
                subject = mysplit[mysplitCount-4]
                date = mysplit[mysplitCount-3]
                modality = mysplit[mysplitCount-2]
                uider = mysplit[mysplitCount-1]
                identifier = mysep.join([project, subject, date, modality ])
                identifier = identifier + &#34;_&#34; + iid
                mymm = subjectpropath + &#34;/&#34; + identifier
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount = 0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( myimg )
                        subjectpropath = re.sub( sourcedatafoldername, processDir, subjectpropath )
                        mysplit = subjectpropath.split(&#34;/&#34;)
                        mysplitCount = len( mysplit )
                        project = mysplit[mysplitCount-5]
                        date = mysplit[mysplitCount-4]
                        subject = mysplit[mysplitCount-3]
                        mymod = mysplit[mysplitCount-2] # FIXME system dependent
                        uid = mysplit[mysplitCount-1] # unique image id
                        os.makedirs( subjectpropath, exist_ok=True  )
                        if mymod == &#39;T1w&#39;:
                            identifier = mysep.join([project, date, subject, mymod, uid])
                        else:  # add the T1 unique id since that drives a lot of the analysis
                            identifier = mysep.join([project, date, subject, mymod, uid ])
                            identifier = identifier + &#34;_&#34; + iid
                        mymm = subjectpropath + &#34;/&#34; + identifier
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print(identifier)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    dfn=tabPro[&#39;rsf&#39;][&#39;dfnname&#39;]
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][dfn],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                dowrite=True
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if len( dtilrfn ) == 1:
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                srmodel_DTI_mdl=None
                                if srmodel_DTI is not False:
                                    temp = ants.get_spacing(img)
                                    dtspc=[temp[0],temp[1],temp[2]]
                                    bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                    if isinstance( srmodel_DTI, str ):
                                        srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                        mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                    if exists( mdlfn ):
                                        if verbose:
                                            print(mdlfn)
                                        srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                    else:
                                        print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                tabPro, normPro = mm( t1, hier,
                                    dw_image=imgList,
                                    bvals = bvalfnList,
                                    bvecs = bvecfnList,
                                    srmodel=srmodel_DTI_mdl,
                                    do_tractography=not test_run,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                mydti = tabPro[&#39;DTI&#39;]
                                if visualize:
                                    maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                    ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                    ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                    ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep, verbose=True )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize and normPro[mykey].components == 1 and False:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_read"><code class="name flex">
<span>def <span class="ident">mm_read</span></span>(<span>x, standardize_intensity=False, modality='')</span>
</code></dt>
<dd>
<div class="desc"><p>read an image from a filename - same as ants.image_read (for now)</p>
<p>standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one</p>
<p>modality : not used</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_read( x, standardize_intensity=False, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - same as ants.image_read (for now)

    standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one

    modality : not used
    &#34;&#34;&#34;
    if x is None:
        raise ValueError( &#34; None passed to function antspymm.mm_read.&#34; )
    if not isinstance(x,str):
        raise ValueError( &#34; Non-string passed to function antspymm.mm_read.&#34; )
    if not os.path.exists( x ):
        raise ValueError( &#34; file &#34; + fni + &#34; does not exist.&#34; )
    img = ants.image_read( x, reorient=False )
    if standardize_intensity:
        img[img&lt;0.0]=0.0
        img=ants.iMath(img,&#39;Normalize&#39;)
    if modality == &#34;T1w&#34; and img.dimension == 4:
        print(&#34;WARNING: input image is 4D - we attempt a hack fix that works in some odd cases of PPMI data - please check this image: &#34; + x, flush=True )
        i1=ants.slice_image(img,3,0)
        i2=ants.slice_image(img,3,1)
        kk=np.concatenate( [i1.numpy(),i2.numpy()], axis=2 )
        kk=ants.from_numpy(kk)
        img=ants.copy_image_info(i1,kk)
    return img</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_read_to_3d"><code class="name flex">
<span>def <span class="ident">mm_read_to_3d</span></span>(<span>x, slice=None, modality='')</span>
</code></dt>
<dd>
<div class="desc"><p>read an image from a filename - and return as 3d or None if that is not possible</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_read_to_3d( x, slice=None, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - and return as 3d or None if that is not possible
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if img.dimension &lt; 3:
        return None
    elif img.dimension == 4:
        nslices = img.shape[3]
        if slice is None:
            sl = np.round( nslices * 0.5 )
        else:
            sl = slice
        if sl &gt; nslices:
            sl = nslices-1
        return ants.slice_image( img, axis=3, idx=int(sl) )
    elif img.dimension == 3:
        return img
    return None</code></pre>
</details>
</dd>
<dt id="antspymm.mm.neuromelanin"><code class="name flex">
<span>def <span class="ident">neuromelanin</span></span>(<span>list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8, bias_correct=True, denoise=None, srmodel=None, target_range=[0, 1], poly_order='hist', normalize_nm=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs the averaged and registered neuromelanin image, and neuromelanin labels</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>list_nm_image</code></strong> :&ensp;<code>list</code> of <code>ANTsImages</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>list of neuromenlanin repeat images</p>
<dl>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 brain image</p>
<dl>
<dt><strong><code>t1_head</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 head image</p>
<dl>
<dt><strong><code>t1lab</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>t1 labels that will be propagated to the NM</p>
<dl>
<dt><strong><code>brain_stem_dilation</code></strong> :&ensp;<code>integer default 8</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>dilates the brain stem mask to better match coverage of NM</p>
<dl>
<dt><strong><code>bias_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>denoise</code></strong> :&ensp;<code>None</code> or <code>integer</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>None -- this is a work in progress feature, probably not optimal</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>poly_order</code></strong> :&ensp;<code>if not None, will fit a global regression model to map</code></dt>
<dd>intensity back to original histogram space; if 'hist' will match
by histogram matching - ants.histogram_match_image</dd>
<dt><strong><code>normalize_nm</code></strong> :&ensp;<code>boolean - WIP not validated</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Averaged and registered <a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> image and <a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> labels and wide csv</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def neuromelanin( list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8,
    bias_correct=True,
    denoise=None,
    srmodel=None,
    target_range=[0,1],
    poly_order=&#39;hist&#39;,
    normalize_nm = False,
    verbose=False ) :

  &#34;&#34;&#34;
  Outputs the averaged and registered neuromelanin image, and neuromelanin labels

  Arguments
  ---------
  list_nm_image : list of ANTsImages
    list of neuromenlanin repeat images

  t1 : ANTsImage
    input 3-D T1 brain image

  t1_head : ANTsImage
    input 3-D T1 head image

  t1lab : ANTsImage
    t1 labels that will be propagated to the NM

  brain_stem_dilation : integer default 8
    dilates the brain stem mask to better match coverage of NM

  bias_correct : boolean

  denoise : None or integer

  srmodel : None -- this is a work in progress feature, probably not optimal

  target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

  poly_order : if not None, will fit a global regression model to map
      intensity back to original histogram space; if &#39;hist&#39; will match
      by histogram matching - ants.histogram_match_image

  normalize_nm : boolean - WIP not validated

  verbose : boolean

  Returns
  ---------
  Averaged and registered neuromelanin image and neuromelanin labels and wide csv

  &#34;&#34;&#34;

  fnt=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni.nii.gz&#34; )
  fntNM=os.path.expanduser(&#34;~/.antspymm/CIT168_T1w_700um_pad_adni_NM_norm_avg.nii.gz&#34; )
  fntbst=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni_brainstem.nii.gz&#34;)
  fnslab=os.path.expanduser(&#34;~/.antspyt1w/CIT168_MT_Slab_adni.nii.gz&#34;)
  fntseg=os.path.expanduser(&#34;~/.antspyt1w/det_atlas_25_pad_LR_adni.nii.gz&#34;)

  template = mm_read( fnt )
  templateNM = ants.iMath( mm_read( fntNM ), &#34;Normalize&#34; )
  templatebstem = mm_read( fntbst ).threshold_image( 1, 1000 )
  # reg = ants.registration( t1, template, &#39;antsRegistrationSyNQuickRepro[s]&#39; )
  reg = ants.registration( t1, template, &#39;SyN&#39; )
  # map NM avg to t1 for neuromelanin processing
  nmavg2t1 = ants.apply_transforms( t1, templateNM,
    reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39; )
  slab2t1 = ants.threshold_image( nmavg2t1, &#34;Otsu&#34;, 2 ).threshold_image(1,2).iMath(&#34;MD&#34;,1).iMath(&#34;FillHoles&#34;)
  # map brain stem and slab to t1 for neuromelanin processing
  bstem2t1 = ants.apply_transforms( t1, templatebstem,
    reg[&#39;fwdtransforms&#39;],
    interpolator=&#39;nearestNeighbor&#39; ).iMath(&#34;MD&#34;,1)
  slab2t1B = ants.apply_transforms( t1, mm_read( fnslab ),
    reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39;)
  bstem2t1 = ants.crop_image( bstem2t1, slab2t1 )
  cropper = ants.decrop_image( bstem2t1, slab2t1 ).iMath(&#34;MD&#34;,brain_stem_dilation)

  # Average images in image_list
  nm_avg = list_nm_images[0]*0.0
  for k in range(len( list_nm_images )):
    if denoise is not None:
        list_nm_images[k] = ants.denoise_image( list_nm_images[k],
            shrink_factor=1,
            p=denoise,
            r=denoise+1,
            noise_model=&#39;Gaussian&#39; )
    if bias_correct :
        n4mask = ants.threshold_image( ants.iMath(list_nm_images[k], &#34;Normalize&#34; ), 0.05, 1 )
        list_nm_images[k] = ants.n4_bias_field_correction( list_nm_images[k], mask=n4mask )
    nm_avg = nm_avg + ants.resample_image_to_target( list_nm_images[k], nm_avg ) / len( list_nm_images )

  if verbose:
      print(&#34;Register each nm image in list_nm_images to the averaged nm image (avg)&#34;)
  nm_avg_new = nm_avg * 0.0
  txlist = []
  for k in range(len( list_nm_images )):
    if verbose:
        print(str(k) + &#34; of &#34; + str(len( list_nm_images ) ) )
    current_image = ants.registration( list_nm_images[k], nm_avg,
        type_of_transform = &#39;Rigid&#39; )
    txlist.append( current_image[&#39;fwdtransforms&#39;][0] )
    current_image = current_image[&#39;warpedfixout&#39;]
    nm_avg_new = nm_avg_new + current_image / len( list_nm_images )
  nm_avg = nm_avg_new

  if verbose:
      print(&#34;do slab registration to map anatomy to NM space&#34;)
  t1c = ants.crop_image( t1_head, slab2t1 ).iMath(&#34;Normalize&#34;) # old way
  nmavg2t1c = ants.crop_image( nmavg2t1, slab2t1 ).iMath(&#34;Normalize&#34;)
  # slabreg = ants.registration( nm_avg, nmavg2t1c, &#39;Rigid&#39; )
  slabreg = tra_initializer( nm_avg, t1c, verbose=verbose )
  if False:
      slabregT1 = tra_initializer( nm_avg, t1c, verbose=verbose  )
      miNM = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg0[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      miT1 = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg1[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      if miT1 &lt; miNM:
        slabreg = slabregT1
  labels2nm = ants.apply_transforms( nm_avg, t1lab, slabreg[&#39;fwdtransforms&#39;],
    interpolator = &#39;genericLabel&#39; )
  cropper2nm = ants.apply_transforms( nm_avg, cropper, slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
  nm_avg_cropped = ants.crop_image( nm_avg, cropper2nm )

  if verbose:
      print(&#34;now map these labels to each individual nm&#34;)
  crop_mask_list = []
  crop_nm_list = []
  for k in range(len( list_nm_images )):
      concattx = []
      concattx.append( txlist[k] )
      concattx.append( slabreg[&#39;fwdtransforms&#39;][0] )
      cropmask = ants.apply_transforms( list_nm_images[k], cropper,
        concattx, interpolator = &#39;nearestNeighbor&#39; )
      crop_mask_list.append( cropmask )
      temp = ants.crop_image( list_nm_images[k], cropmask )
      crop_nm_list.append( temp )

  if srmodel is not None:
      if verbose:
          print( &#34; start sr &#34; + str(len( crop_nm_list )) )
      for k in range(len( crop_nm_list )):
          if verbose:
              print( &#34; do sr &#34; + str(k) )
              print( crop_nm_list[k] )
          temp = antspynet.apply_super_resolution_model_to_image(
                crop_nm_list[k], srmodel, target_range=target_range,
                regression_order=None )
          if poly_order is not None:
              bilin = ants.resample_image_to_target( crop_nm_list[k], temp )
              if poly_order == &#39;hist&#39;:
                  temp = ants.histogram_match_image( temp, bilin )
              else:
                  temp = antspynet.regression_match_image( temp, bilin, poly_order = poly_order )
          crop_nm_list[k] = temp

  nm_avg_cropped = crop_nm_list[0]*0.0
  if verbose:
      print( &#34;cropped average&#34; )
      print( nm_avg_cropped )
  for k in range(len( crop_nm_list )):
      nm_avg_cropped = nm_avg_cropped + ants.apply_transforms( nm_avg_cropped,
        crop_nm_list[k], txlist[k] ) / len( crop_nm_list )
  for loop in range( 3 ):
      nm_avg_cropped_new = nm_avg_cropped * 0.0
      for k in range(len( crop_nm_list )):
            myreg = ants.registration(
                ants.iMath(nm_avg_cropped,&#34;Normalize&#34;),
                ants.iMath(crop_nm_list[k],&#34;Normalize&#34;),
                &#39;BOLDRigid&#39; )
            warpednext = ants.apply_transforms(
                nm_avg_cropped_new,
                crop_nm_list[k],
                myreg[&#39;fwdtransforms&#39;] )
            nm_avg_cropped_new = nm_avg_cropped_new + warpednext
      nm_avg_cropped = nm_avg_cropped_new / len( crop_nm_list )

  slabregUpdated = tra_initializer( nm_avg_cropped, t1c, compreg=slabreg,verbose=verbose  )
  tempOrig = ants.apply_transforms( nm_avg_cropped_new, t1c, slabreg[&#39;fwdtransforms&#39;] )
  tempUpdate = ants.apply_transforms( nm_avg_cropped_new, t1c, slabregUpdated[&#39;fwdtransforms&#39;] )
  miUpdate = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempUpdate,&#34;Normalize&#34;) )
  miOrig = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempOrig,&#34;Normalize&#34;) )
  if miUpdate &lt; miOrig :
      slabreg = slabregUpdated

  if normalize_nm:
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;TruncateIntensity&#34;,0.05,0.95)
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )

  labels2nm = ants.apply_transforms( nm_avg_cropped, t1lab,
        slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )

  # fix the reference region - keep top two parts
  def get_biggest_part( x, labeln ):
      temp33 = ants.threshold_image( x, labeln, labeln ).iMath(&#34;GetLargestComponent&#34;)
      x[ x == labeln] = 0
      x[ temp33 == 1 ] = labeln

  get_biggest_part( labels2nm, 33 )
  get_biggest_part( labels2nm, 34 )

  if verbose:
      print( &#34;map summary measurements to wide format&#34; )
  nmdf = antspyt1w.map_intensity_to_dataframe(
          &#39;CIT168_Reinf_Learn_v1_label_descriptions_pad&#39;,
          nm_avg_cropped,
          labels2nm)
  if verbose:
      print( &#34;merge to wide format&#34; )
  nmdf_wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;NM&#39; : nmdf},
              col_names = [&#39;Mean&#39;] )
  if verbose:
      print( &#34;nm done&#34; )

  rr_mask = ants.mask_image( labels2nm, labels2nm, [33,34] , binarize=True )
  sn_mask = ants.mask_image( labels2nm, labels2nm, [7,9,23,25] , binarize=True )
  nmavgsnr = mask_snr( nm_avg_cropped, rr_mask, sn_mask, bias_correct = False )

  snavg = nm_avg_cropped[ sn_mask == 1].mean()
  rravg = nm_avg_cropped[ rr_mask == 1].mean()
  snstd = nm_avg_cropped[ sn_mask == 1].std()
  rrstd = nm_avg_cropped[ rr_mask == 1].std()
  snvol = np.prod( ants.get_spacing(sn_mask) ) * sn_mask.sum()

  # get the mean voxel position of the SN
  if snvol &gt; 0:
      sn_z = ants.transform_physical_point_to_index( sn_mask, ants.get_center_of_mass(sn_mask ))[2]
      sn_z = sn_z/sn_mask.shape[2] # around 0.5 would be nice
  else:
      sn_z = math.nan

  nm_evr = antspyt1w.patch_eigenvalue_ratio( nm_avg, 512, [6,6,6], evdepth = 0.9, mask=cropper2nm )

  return{
      &#39;NM_avg&#39; : nm_avg,
      &#39;NM_avg_cropped&#39; : nm_avg_cropped,
      &#39;NM_labels&#39;: labels2nm,
      &#39;NM_cropped&#39;: crop_nm_list,
      &#39;NM_midbrainROI&#39;: cropper2nm,
      &#39;NM_dataframe&#39;: nmdf,
      &#39;NM_dataframe_wide&#39;: nmdf_wide,
      &#39;t1_to_NM&#39;: slabreg[&#39;warpedmovout&#39;],
      &#39;t1_to_NM_transform&#39; : slabreg[&#39;fwdtransforms&#39;],
      &#39;NM_avg_signaltonoise&#39; : nmavgsnr,
      &#39;NM_avg_substantianigra&#39; : snavg,
      &#39;NM_std_substantianigra&#39; : snstd,
      &#39;NM_volume_substantianigra&#39; : snvol,
      &#39;NM_avg_refregion&#39; : rravg,
      &#39;NM_std_refregion&#39; : rrstd,
      &#39;NM_min&#39; : nm_avg_cropped.min(),
      &#39;NM_max&#39; : nm_avg_cropped.max(),
      &#39;NM_mean&#39; : nm_avg_cropped.numpy().mean(),
      &#39;NM_sd&#39; : np.std( nm_avg_cropped.numpy() ),
      &#39;NM_q0pt05&#39; : np.quantile( nm_avg_cropped.numpy(), 0.05 ),
      &#39;NM_q0pt10&#39; : np.quantile( nm_avg_cropped.numpy(), 0.10 ),
      &#39;NM_q0pt90&#39; : np.quantile( nm_avg_cropped.numpy(), 0.90 ),
      &#39;NM_q0pt95&#39; : np.quantile( nm_avg_cropped.numpy(), 0.95 ),
      &#39;NM_substantianigra_z_coordinate&#39; : sn_z,
      &#39;NM_evr&#39; : nm_evr,
      &#39;NM_count&#39;: len( list_nm_images )
       }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_ee"><code class="name flex">
<span>def <span class="ident">novelty_detection_ee</span></span>(<span>df_train, df_test, contamination=0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Elliptic Envelope.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)</p>
</li>
</ul>
<p>Returns:</p>
<p>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_ee(df_train, df_test, contamination=0.05):
    &#34;&#34;&#34;
    This function performs novelty detection using Elliptic Envelope.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    import pandas as pd
    from sklearn.covariance import EllipticEnvelope
    # Fit the model on the training data
    clf = EllipticEnvelope(contamination=contamination,support_fraction=1)
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_lof"><code class="name flex">
<span>def <span class="ident">novelty_detection_lof</span></span>(<span>df_train, df_test, n_neighbors=20)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Local Outlier Factor (LOF).</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>n_neighbors (int): number of neighbors used to compute the LOF (default: 20)</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_lof(df_train, df_test, n_neighbors=20):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOF (default: 20)

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, algorithm=&#39;auto&#39;,contamination=&#39;auto&#39;, novelty=True)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_loop"><code class="name flex">
<span>def <span class="ident">novelty_detection_loop</span></span>(<span>df_train, df_test, n_neighbors=20, distance_metric='minkowski')</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Local Outlier Factor (LOF).</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)</p>
</li>
<li>
<p>distance_metric : default minkowski</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_loop(df_train, df_test, n_neighbors=20, distance_metric=&#39;minkowski&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)

    - distance_metric : default minkowski

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    data = np.vstack( [scaler.transform(df_test),scaler.transform(df_train)])
    neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=distance_metric)
    neigh.fit(data)
    d, idx = neigh.kneighbors(data, return_distance=True)
    m = loop.LocalOutlierProbability(distance_matrix=d, neighbor_matrix=idx, n_neighbors=n_neighbors).fit()
    return m.local_outlier_probabilities[range(df_test.shape[0])]</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_quantile"><code class="name flex">
<span>def <span class="ident">novelty_detection_quantile</span></span>(<span>df_train, df_test)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using quantiles for each column.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>quantiles for the test sample at each column where values range in [0,1]
and higher values mean the column is closer to the edge of the distribution</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_quantile(df_train, df_test):
    &#34;&#34;&#34;
    This function performs novelty detection using quantiles for each column.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    Returns:

    - quantiles for the test sample at each column where values range in [0,1]
        and higher values mean the column is closer to the edge of the distribution

    &#34;&#34;&#34;
    myqs = df_test.copy()
    n = df_train.shape[0]
    df_trainkeys = df_train.keys()
    for k in range( df_train.shape[1] ):
        mykey = df_trainkeys[k]
        temp = (myqs[mykey][0] &gt;  df_train[mykey]).sum() / n
        myqs[mykey] = abs( temp - 0.5 ) / 0.5
    return myqs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_svm"><code class="name flex">
<span>def <span class="ident">novelty_detection_svm</span></span>(<span>df_train, df_test, nu=0.05, kernel='rbf')</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using One-Class SVM.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)</p>
</li>
<li>
<p>kernel (str): kernel type used in the SVM algorithm (default: 'rbf')</p>
</li>
</ul>
<p>Returns:</p>
<p>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_svm(df_train, df_test, nu=0.05, kernel=&#39;rbf&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using One-Class SVM.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)

    - kernel (str): kernel type used in the SVM algorithm (default: &#39;rbf&#39;)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    from sklearn.svm import OneClassSVM
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = OneClassSVM(nu=nu, kernel=kernel)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_2_bids"><code class="name flex">
<span>def <span class="ident">nrg_2_bids</span></span>(<span>nrg_filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert an NRG filename to BIDS path/filename.</p>
<p>Parameters:
nrg_filename (str): The NRG filename to convert.</p>
<p>Returns:
str: The BIDS path/filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_2_bids( nrg_filename ):
    &#34;&#34;&#34;
    Convert an NRG filename to BIDS path/filename.

    Parameters:
    nrg_filename (str): The NRG filename to convert.

    Returns:
    str: The BIDS path/filename.
    &#34;&#34;&#34;

    # Split the NRG filename into its components
    nrg_dirname, nrg_basename = os.path.split(nrg_filename)
    nrg_suffix = &#39;.&#39; + nrg_basename.split(&#39;.&#39;,1)[-1]
    nrg_basename = nrg_basename.replace(nrg_suffix, &#39;&#39;) # remove ext
    nrg_parts = nrg_basename.split(&#39;-&#39;)
    nrg_subject_id = nrg_parts[1]
    nrg_modality = nrg_parts[3]
    nrg_repeat= nrg_parts[4]

    # Build the BIDS path/filename
    bids_dirname = os.path.join(nrg_dirname, &#39;bids&#39;)
    bids_subject = f&#39;sub-{nrg_subject_id}&#39;
    bids_session = f&#39;ses-{nrg_repeat}&#39;

    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))

    if nrg_modality == &#39;T1w&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;T1w&#39;

    if nrg_modality == &#39;T2Flair&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;flair&#39;

    if nrg_modality == &#39;NM2DMT&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;nm2dmt&#39;

    if nrg_modality == &#39;DTI&#39; or nrg_modality == &#39;DTI_RL&#39; or nrg_modality == &#39;DTI_LR&#39; :
        bids_modality_folder = &#39;dwi&#39;
        bids_modality_filename = &#39;dwi&#39;

    if nrg_modality == &#39;rsfMRI&#39; or nrg_modality == &#39;rsfMRI_RL&#39; or nrg_modality == &#39;rsfMRI_LR&#39; :
        bids_modality_folder = &#39;func&#39;
        bids_modality_filename = &#39;func&#39;

    if nrg_modality == &#39;perf&#39;  :
        bids_modality_folder = &#39;perf&#39;
        bids_modality_filename = &#39;perf&#39;

    bids_suffix = nrg_suffix[1:]
    bids_filename = f&#39;{bids_subject}_{bids_session}_{bids_modality_filename}.{bids_suffix}&#39;

    # Return bids filepath/filename
    return os.path.join(bids_dirname, bids_subject, bids_session, bids_modality_folder, bids_filename)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_filelist_to_dataframe"><code class="name flex">
<span>def <span class="ident">nrg_filelist_to_dataframe</span></span>(<span>filename_list, myseparator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>convert a list of files in nrg format to a dataframe</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>filename_list</code></strong> :&ensp;<code>globbed list</code> of <code>files</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>myseparator</code></strong> :&ensp;<code>string separator between nrg parts</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas data frame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_filelist_to_dataframe( filename_list, myseparator=&#34;-&#34; ):
    &#34;&#34;&#34;
    convert a list of files in nrg format to a dataframe

    Arguments
    ---------
    filename_list : globbed list of files

    myseparator : string separator between nrg parts

    Returns
    -------

    df : pandas data frame

    &#34;&#34;&#34;
    def getmtime(x):
        x= dt.datetime.fromtimestamp(os.path.getmtime(x)).strftime(&#34;%Y-%m-%d %H:%M:%d&#34;)
        return x
    df=pd.DataFrame(columns=[&#39;filename&#39;,&#39;file_last_mod_t&#39;,&#39;else&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;uid&#39;])
    df.set_index(&#39;filename&#39;)
    df[&#39;filename&#39;] = pd.Series([file for file in filename_list ])
    # I applied a time modified file to df[&#39;file_last_mod_t&#39;] by getmtime function
    df[&#39;file_last_mod_t&#39;] = df[&#39;filename&#39;].apply(lambda x: getmtime(x))
    for k in range(df.shape[0]):
        locfn=df[&#39;filename&#39;].iloc[k]
        splitter=os.path.basename(locfn).split( myseparator )
        df[&#39;sid&#39;].iloc[k]=splitter[1]
        df[&#39;visitdate&#39;].iloc[k]=splitter[2]
        df[&#39;modality&#39;].iloc[k]=splitter[3]
        temp = os.path.splitext(splitter[4])[0]
        df[&#39;uid&#39;].iloc[k]=os.path.splitext(temp)[0]
    return df</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_format_path"><code class="name flex">
<span>def <span class="ident">nrg_format_path</span></span>(<span>projectID, subjectID, date, modality, imageID, separator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>create the NRG path on disk given the project, subject id, date, modality and image id</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>projectID</code></strong> :&ensp;<code>string for the project e.g. PPMI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>subjectID</code></strong> :&ensp;<code>string uniquely identifying the subject e.g. 0001</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>date</code></strong> :&ensp;<code>string for the date usually 20550228 ie YYYYMMDD format</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>modality</code></strong> :&ensp;<code>string should be one</code> of <code>T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>imageID</code></strong> :&ensp;<code>string uniquely identifying the specific image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>separator</code></strong> :&ensp;<code>default to -</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>the path where one would write the image on disk</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_format_path( projectID, subjectID, date, modality, imageID, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    create the NRG path on disk given the project, subject id, date, modality and image id

    Arguments
    ---------

    projectID : string for the project e.g. PPMI

    subjectID : string uniquely identifying the subject e.g. 0001

    date : string for the date usually 20550228 ie YYYYMMDD format

    modality : string should be one of T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)

    imageID : string uniquely identifying the specific image

    separator : default to -

    Returns
    -------
    the path where one would write the image on disk

    &#34;&#34;&#34;
    thedirectory = os.path.join( str(projectID), str(subjectID), str(date), str(modality), str(imageID) )
    thefilename = str(projectID) + separator + str(subjectID) + separator + str(date) + separator + str(modality) + separator + str(imageID)
    return os.path.join( thedirectory, thefilename )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.outlierness_by_modality"><code class="name flex">
<span>def <span class="ident">outlierness_by_modality</span></span>(<span>qcdf, uid='filename', outlier_columns=['noise', 'snr', 'cnr', 'psnr', 'ssim', 'mi', 'reflection_err', 'EVR', 'msk_vol'], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.
LOF appears to be more conservative.
This function will impute missing columns with the mean.</p>
<p>Args:
- qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
- uid: (str) Unique identifier for a subject. Default is 'filename'.
- outlier_columns: (list) List of columns containing outlier information. Default is ['noise', 'snr', 'cnr', 'psnr', 'ssim', 'mi', 'reflection_err', 'EVR', 'msk_vol'].
- verbose: (bool) If True, prints information for each modality. Default is False.</p>
<p>Returns:
- qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the 'ol_loop' and 'ol_lof' column.
Higher values near 1 are more outlying.</p>
<p>Raises:
- ValueError: If uid is not present in the dataframe.</p>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = pd.read_csv('data.csv')
&gt;&gt;&gt; outlierness_by_modality(df)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def outlierness_by_modality( qcdf, uid=&#39;filename&#39;, outlier_columns = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;], verbose=False ):
    &#34;&#34;&#34;
    Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.  LOF appears to be more conservative.  This function will impute missing columns with the mean.

    Args:
    - qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
    - uid: (str) Unique identifier for a subject. Default is &#39;filename&#39;.
    - outlier_columns: (list) List of columns containing outlier information. Default is [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;].
    - verbose: (bool) If True, prints information for each modality. Default is False.

    Returns:
    - qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the &#39;ol_loop&#39; and &#39;ol_lof&#39; column.  Higher values near 1 are more outlying.

    Raises:
    - ValueError: If uid is not present in the dataframe.

    Example:
    &gt;&gt;&gt; df = pd.read_csv(&#39;data.csv&#39;)
    &gt;&gt;&gt; outlierness_by_modality(df)
    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import LocalOutlierFactor
    qcdfout = qcdf.copy()
    pd.set_option(&#39;future.no_silent_downcasting&#39;, True)
    qcdfout.replace([np.inf, -np.inf], np.nan, inplace=True)
    if uid not in qcdfout.keys():
        raise ValueError( str(uid) + &#34; not in dataframe&#34;)
    if &#39;ol_loop&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_loop&#39;]=math.nan
    if &#39;ol_lof&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_lof&#39;]=math.nan
    didit=False
    for mod in get_valid_modalities( qc=True ):
        didit=True
        lof = LocalOutlierFactor()
        locsel = qcdfout[&#34;modality&#34;] == mod
        rr = qcdfout[locsel][outlier_columns]
        column_means = rr.mean()
        rr.fillna(column_means, inplace=True)
        if rr.shape[0] &gt; 1:
            if verbose:
                print(&#34;calc: &#34; + mod + &#34; outlierness &#34; )
            myneigh = np.min( [24, int(np.round(rr.shape[0]*0.5)) ] )
            temp = antspyt1w.loop_outlierness(rr.astype(float), standardize=True, extent=3, n_neighbors=myneigh, cluster_labels=None)
            qcdfout.loc[locsel,&#39;ol_loop&#39;]=temp.astype(&#39;float64&#39;)
            yhat = lof.fit_predict(rr)
            temp = lof.negative_outlier_factor_*(-1.0)
            temp = temp - temp.min()
            yhat[ yhat == 1] = 0
            yhat[ yhat == -1] = 1 # these are outliers
            qcdfout.loc[locsel,&#39;ol_lof_decision&#39;]=yhat
            qcdfout.loc[locsel,&#39;ol_lof&#39;]=temp/temp.max()
    if verbose:
        print( didit )
    return qcdfout</code></pre>
</details>
</dd>
<dt id="antspymm.mm.parse_nrg_filename"><code class="name flex">
<span>def <span class="ident">parse_nrg_filename</span></span>(<span>x, separator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>split a NRG filename into its named parts</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_nrg_filename( x, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    split a NRG filename into its named parts
    &#34;&#34;&#34;
    temp = x.split( separator )
    if len(temp) != 5:
        raise ValueError(x + &#34; not a valid NRG filename&#34;)
    return {
        &#39;project&#39;:temp[0],
        &#39;subjectID&#39;:temp[1],
        &#39;date&#39;:temp[2],
        &#39;modality&#39;:temp[3],
        &#39;imageID&#39;:temp[4]
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.quantile_snr"><code class="name flex">
<span>def <span class="ident">quantile_snr</span></span>(<span>x, lowest_quantile=0.01, low_quantile=0.1, high_quantile=0.5, highest_quantile=0.95)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>lowest_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>low_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>high_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>highest_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantile_snr( x,
    lowest_quantile=0.01,
    low_quantile=0.1,
    high_quantile=0.5,
    highest_quantile=0.95 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    lowest_quantile : float value &lt; 1 and &gt; 0

    low_quantile : float value &lt; 1 and &gt; 0

    high_quantile : float value &lt; 1 and &gt; 0

    highest_quantile : float value &lt; 1 and &gt; 0

    &#34;&#34;&#34;
    import numpy as np
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    y = xbc.numpy()
    ylowest = np.quantile( y[y&gt;0], lowest_quantile )
    ylo = np.quantile( y[y&gt;0], low_quantile )
    yhi = np.quantile( y[y&gt;0], high_quantile )
    yhiest = np.quantile( y[y&gt;0], highest_quantile )
    xbkgmask = ants.threshold_image( xbc, ylowest, ylo )
    fgmask = ants.threshold_image( xbc, yhi, yhiest )
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.quick_viz_mm_nrg"><code class="name flex">
<span>def <span class="ident">quick_viz_mm_nrg</span></span>(<span>sourcedir, projectid, sid, dtid, extract_brain=True, slice_factor=0.55, show_it=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>This function creates visualizations of brain images for a specific subject in a project using ANTsPy.</p>
<p>Args:</p>
<p>sourcedir (str): Root folder.</p>
<p>projectid (str): Project name.</p>
<p>sid (str): Subject unique id.</p>
<p>dtid (str): Date.</p>
<p>extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.</p>
<p>slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.</p>
<p>show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.</p>
<p>verbose (bool): If True, information will be printed while running the function. Default is True.</p>
<p>Returns:
vizlist (list): List of image visualizations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quick_viz_mm_nrg(
    sourcedir, # root folder
    projectid, # project name
    sid , # subject unique id
    dtid, # date
    extract_brain=True,
    slice_factor = 0.55,
    show_it = None, # output path
    verbose = True
):
    &#34;&#34;&#34;
    This function creates visualizations of brain images for a specific subject in a project using ANTsPy.

    Args:

    sourcedir (str): Root folder.
    
    projectid (str): Project name.
    
    sid (str): Subject unique id.
    
    dtid (str): Date.
    
    extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.
    
    slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.
    
    show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.
    
    verbose (bool): If True, information will be printed while running the function. Default is True.

    Returns:
    vizlist (list): List of image visualizations.

    &#34;&#34;&#34;
    iid=&#39;*&#39;
    import glob as glob
    from os.path import exists
    import ants
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    subjectrootpath = os.path.join(sourcedir, projectid, sid, dtid)
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, &#34;*&#34;, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;quick_viz_mm_nrg cannot find the T1w @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    nimages = len(myimgsInput)
    vizlist=[]
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.  will visualize T1 NM rsfMRI DTIB0 DTIDWI FLAIR&#34;)
    # nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;rsfMRI_LR&#34;,&#34;rsfMRI_RL&#34;,&#34;DTI&#34;,&#34;DTI_LR&#34;, &#34;T2Flair&#34; ],
    nrg_modality_list = [ &#39;T1w&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DWI1&#39;, &#39;DWI2&#39;, &#39;T2Flair&#39; ]
    for nrgNum in [0,1,2,3,4,5]:
        overmodX = nrg_modality_list[nrgNum]
        if overmodX == &#39;T1w&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, iid, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) == 0:
                if verbose:
                    print(&#34;No t1 images: &#34; + sid + dtid )
                return None
            myimgsr.sort()
            myimgsr=myimgsr[0]
            vimg=ants.image_read( myimgsr )
        elif overmodX == &#39;DWI1&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;DWI2&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[len(myimgsr)-1]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;NM2DMT&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr0=myimgsr[0]
                vimg=ants.image_read( myimgsr0 )
                for k in range(1,len(myimgsr)):
                    temp = ants.image_read( myimgsr[k])
                    vimg=vimg+ants.resample_image_to_target(temp,vimg)
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;rsfMRI&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;rsfMRI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=mm_read_to_3d( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        else :
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        if True:
            if extract_brain and overmodX == &#39;T1w&#39;:
                vimg = vimg * antspyt1w.brain_extraction(vimg)
            if verbose:
                print(f&#34;modality search path: {myimgsr}&#34; + &#34; num: &#34; + str(nrgNum))
            if len( vimg.shape ) == 4 and ( overmodX == &#34;DWI2&#34;  ):
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttdw
            elif len( vimg.shape ) == 4 and overmodX == &#34;DWI1&#34;:
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttb0
            elif len( vimg.shape ) == 4 :
                vimg=ants.get_average_of_timeseries(vimg)
            msk=ants.get_mask(vimg)
            vimg=ants.crop_image(vimg,msk)
            if overmodX == &#39;T1w&#39;:
                refimg=ants.image_clone( vimg )
                noizimg = ants.add_noise_to_image( refimg*0, &#39;additivegaussian&#39;, [100,1] )
                vizlist.append( vimg )
            else:
                vimg = ants.resample_image_to_target( vimg, refimg )
                vimg = ants.iMath( vimg, &#39;TruncateIntensity&#39;,0.01,0.98)
                vizlist.append( ants.iMath( vimg, &#39;Normalize&#39; ) * 255 )

    listlen = len( vizlist )
    vizlist = np.asarray( vizlist )
    if show_it is not None:
        filenameout=None
        if verbose:
            print( show_it )
        for a in [0,1,2]:
            n=int(np.round( refimg.shape[a] * slice_factor ))
            slices=np.repeat( int(n), listlen  )
            if isinstance(show_it,str):
                filenameout=show_it+&#39;_ax&#39;+str(int(a))+&#39;_sl&#39;+str(n)+&#39;.png&#39;
                if verbose:
                    print( filenameout )
            ants.plot_grid(vizlist.reshape(2,3), slices.reshape(2,3), title=&#39;MM Subject &#39; + sid + &#39; &#39; + dtid, rfacecolor=&#39;white&#39;, axes=a, filename=filenameout )
    if verbose:
        print(&#34;viz complete.&#34;)
    return vizlist</code></pre>
</details>
</dd>
<dt id="antspymm.mm.read_mm_csv"><code class="name flex">
<span>def <span class="ident">read_mm_csv</span></span>(<span>x, is_t1=False, colprefix=None, separator='-', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_mm_csv( x, is_t1=False, colprefix=None, separator=&#39;-&#39;, verbose=False ):
    splitter=os.path.basename(x).split( separator )
    lensplit = len( splitter )-1
    temp = os.path.basename(x)
    temp = os.path.splitext(temp)[0]
    temp = re.sub(separator+&#39;mmwide&#39;,&#39;&#39;,temp)
    idcols = [&#39;u_hier_id&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;mmimageuid&#39;,&#39;t1imageuid&#39;]
    df = pd.DataFrame( columns = idcols, index=range(1) )
    valstoadd = [temp] + splitter[1:(lensplit-1)]
    if is_t1:
        valstoadd = valstoadd + [splitter[(lensplit-1)],splitter[(lensplit-1)]]
    else:
        split2=splitter[(lensplit-1)].split( &#34;_&#34; )
        if len(split2) == 1:
            split2.append( split2[0] )
        if len(valstoadd) == 3:
            valstoadd = valstoadd + [split2[0]] + [math.nan] + [split2[1]]
        else:
            valstoadd = valstoadd + [split2[0],split2[1]]
    if verbose:
        print( valstoadd )
    df.iloc[0] = valstoadd
    if verbose:
        print( &#34;read xdf: &#34; + x )
    xdf = pd.read_csv( x )
    df.reset_index()
    xdf.reset_index(drop=True)
    if &#34;Unnamed: 0&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 0&#34; )
    if &#34;Unnamed: 1&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 1&#34; )
    if &#34;u_hier_id.1&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id.1&#34; )
    if &#34;u_hier_id&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id&#34; )
    if not is_t1:
        if &#39;resnetGrade&#39; in xdf.columns:
            index_no = xdf.columns.get_loc(&#39;resnetGrade&#39;)
            xdf = xdf.drop( xdf.columns[range(index_no+1)] , axis=1)

    if xdf.shape[0] == 2:
        xdfcols = xdf.columns
        xdf = xdf.iloc[1]
        ddnum = xdf.to_numpy()
        ddnum = ddnum.reshape([1,ddnum.shape[0]])
        newcolnames = xdf.index.to_list()
        if len(newcolnames) != ddnum.shape[1]:
            print(&#34;Cannot Merge : Shape MisMatch &#34; + str( len(newcolnames) ) + &#34; &#34; + str(ddnum.shape[1]))
        else:
            xdf = pd.DataFrame(ddnum, columns=xdfcols )
    if xdf.shape[1] == 0:
        return None
    if colprefix is not None:
        xdf.columns=colprefix + xdf.columns
    return pd.concat( [df,xdf], axis=1, ignore_index=False )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.remove_elements_from_numpy_array"><code class="name flex">
<span>def <span class="ident">remove_elements_from_numpy_array</span></span>(<span>original_array, indices_to_remove)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove specified elements or rows from a numpy array.</p>
<p>Parameters:
original_array (numpy.ndarray): A numpy array from which elements or rows are to be removed.
indices_to_remove (list or numpy.ndarray): Indices of elements or rows to be removed.</p>
<p>Returns:
numpy.ndarray: A new numpy array with the specified elements or rows removed. If the input array is None,
the function returns None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_elements_from_numpy_array(original_array, indices_to_remove):
    &#34;&#34;&#34;
    Remove specified elements or rows from a numpy array.

    Parameters:
    original_array (numpy.ndarray): A numpy array from which elements or rows are to be removed.
    indices_to_remove (list or numpy.ndarray): Indices of elements or rows to be removed.

    Returns:
    numpy.ndarray: A new numpy array with the specified elements or rows removed. If the input array is None,
                   the function returns None.
    &#34;&#34;&#34;

    if original_array is None:
        return None

    if original_array.ndim == 1:
        # Remove elements from a 1D array
        return np.delete(original_array, indices_to_remove)
    elif original_array.ndim == 2:
        # Remove rows from a 2D array
        return np.delete(original_array, indices_to_remove, axis=0)
    else:
        raise ValueError(&#34;original_array must be either 1D or 2D.&#34;)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.remove_volumes_from_timeseries"><code class="name flex">
<span>def <span class="ident">remove_volumes_from_timeseries</span></span>(<span>time_series, volumes_to_remove)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove specified volumes from a time series.</p>
<p>:param time_series: ANTsImage representing the time series (4D image).
:param volumes_to_remove: List of volume indices to remove.
:return: ANTsImage with specified volumes removed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_volumes_from_timeseries(time_series, volumes_to_remove):
    &#34;&#34;&#34;
    Remove specified volumes from a time series.

    :param time_series: ANTsImage representing the time series (4D image).
    :param volumes_to_remove: List of volume indices to remove.
    :return: ANTsImage with specified volumes removed.
    &#34;&#34;&#34;
    if not isinstance(time_series, ants.ANTsImage):
        raise ValueError(&#34;time_series must be an ANTsImage.&#34;)

    if time_series.dimension != 4:
        raise ValueError(&#34;time_series must be a 4D image.&#34;)

    # Create a boolean index for volumes to keep
    volumes_to_keep = [i for i in range(time_series.shape[3]) if i not in volumes_to_remove]

    # Select the volumes to keep
    filtered_time_series = ants.from_numpy( time_series[..., volumes_to_keep] )

    return ants.copy_image_info( time_series, filtered_time_series )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.resting_state_fmri_networks"><code class="name flex">
<span>def <span class="ident">resting_state_fmri_networks</span></span>(<span>fmri, fmri_template, t1, t1segmentation, f=[0.03, 0.08], FD_threshold=5.0, spa=None, spt=None, nc=5, outlier_threshold=0.25, ica_components=0, impute=True, censor=True, despike=2.5, motion_as_nuisance=True, powers=False, upsample=3.0, clean_tmp=None, paramset='unset', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute resting state network correlation maps based on the J Power labels.
This will output a map for each of the major network systems.
This function
will by optionally upsample data to 2mm during the registration process if data
is below that resolution.</p>
<p>registration - despike - anatomy - smooth - nuisance - bandpass - regress.nuisance - censor - falff - correlations</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>fmri</code></strong> :&ensp;<code>BOLD fmri antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fmri_template</code></strong> :&ensp;<code>reference space for BOLD</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 brain image (brain extracted)</p>
<dl>
<dt><strong><code>t1segmentation</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>t1 segmentation - a six tissue segmentation image in T1 space</p>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>band pass limits for frequency filtering; we use high-pass here as per Shirer 2015</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>spa</code></strong> :&ensp;<code>gaussian smoothing for spatial component (physical coordinates)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>spt</code></strong> :&ensp;<code>gaussian smoothing for temporal component</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>nc
: number of components for compcor filtering; if less than 1 we estimate on the fly based on explained variance; 10 wrt Shirer 2015 5 from csf and 5 from wm</p>
<dl>
<dt><strong><code>ica_components</code></strong> :&ensp;<code>integer if greater than 0 then include ica components</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>impute</code></strong> :&ensp;<code>boolean if True, then use imputation in f/ALFF, PerAF calculation</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>censor</code></strong> :&ensp;<code>boolean if True, then use censoring (censoring)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>despike</code></strong> :&ensp;<code>if this is greater than zero will run voxel-wise despiking in the 3dDespike (afni) sense; after motion-correction</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_as_nuisance</code></strong> :&ensp;<code>boolean will add motion and first derivative</code> of <code>motion as nuisance</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>powers</code></strong> :&ensp;<code>boolean if True use Powers nodes otherwise 2023 Yeo 500 homotopic nodes (10.1016/j.neuroimage.2023.120010)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>upsample</code></strong> :&ensp;<code>float optionally isotropically upsample data to upsample (the parameter value) in mm during the registration process if data is below that resolution; if the input spacing is less than that provided by the user, the data will simply be resampled to isotropic resolution</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>clean_tmp : will automatically try to clean the tmp directory - not recommended but can be used in distributed computing systems to help prevent failures due to accumulation of tmp files when doing large-scale processing.
if this is set, the float value clean_tmp will be interpreted as the age in hours of files to be cleaned.</p>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary containing the derived network maps</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="references">References</h2>
<p>10.1162/netn_a_00071 "Methods that included global signal regression were the most consistently effective de-noising strategies."</p>
<p>10.1016/j.neuroimage.2019.116157 "frontal and default model networks are most reliable whereas subcortical neteworks are least reliable"
"the most comprehensive studies of pipeline effects on edge-level reliability have been done by shirer (2015) and Parkes (2018)" "slice timing correction has minimal impact" "use of low-pass or narrow filter (discarding
high frequency information) reduced both reliability and signal-noise separation"</p>
<p>10.1016/j.neuroimage.2017.12.073: Our results indicate that (1) simple linear regression of regional fMRI time series against head motion parameters and WM/CSF signals (with or without expansion terms) is not sufficient to remove head motion artefacts; (2) aCompCor pipelines may only be viable in low-motion data; (3) volume censoring performs well at minimising motion-related artefact but a major benefit of this approach derives from the exclusion of high-motion individuals; (4) while not as effective as volume censoring, ICA-AROMA performed well across our benchmarks for relatively low cost in terms of data loss; (5) the addition of global signal regression improved the performance of nearly all pipelines on most benchmarks, but exacerbated the distance-dependence of correlations between motion and functional connec- tivity; and (6) group comparisons in functional connectivity between healthy controls and schizophrenia patients are highly dependent on preprocessing strategy. We offer some recommendations for best practice and outline simple analyses to facilitate transparent reporting of the degree to which a given set of findings may be affected by motion-related artefact.</p>
<p>10.1016/j.dcn.2022.101087 : We found that: 1) the most efficacious pipeline for both noise removal and information recovery included censoring, GSR, bandpass filtering, and head motion parameter (HMP) regression, 2) ICA-AROMA performed similarly to HMP regression and did not obviate the need for censoring, 3) GSR had a minimal impact on connectome fingerprinting but improved ISC, and 4) the strictest censoring approaches reduced motion correlated edges but negatively impacted identifiability.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resting_state_fmri_networks( fmri, fmri_template, t1, t1segmentation,
    f=[0.03, 0.08],
    FD_threshold=5.0,
    spa = None,
    spt = None,
    nc = 5,
    outlier_threshold=0.250,
    ica_components = 0,
    impute = True,
    censor = True,
    despike = 2.5,
    motion_as_nuisance = True,
    powers = False,
    upsample = 3.0,
    clean_tmp = None,
    paramset=&#39;unset&#39;,
    verbose=False ):
  &#34;&#34;&#34;
  Compute resting state network correlation maps based on the J Power labels.
  This will output a map for each of the major network systems.  This function 
  will by optionally upsample data to 2mm during the registration process if data 
  is below that resolution.

  registration - despike - anatomy - smooth - nuisance - bandpass - regress.nuisance - censor - falff - correlations

  Arguments
  ---------
  fmri : BOLD fmri antsImage

  fmri_template : reference space for BOLD

  t1 : ANTsImage
    input 3-D T1 brain image (brain extracted)

  t1segmentation : ANTsImage
    t1 segmentation - a six tissue segmentation image in T1 space

  f : band pass limits for frequency filtering; we use high-pass here as per Shirer 2015

  spa : gaussian smoothing for spatial component (physical coordinates)

  spt : gaussian smoothing for temporal component

  nc  : number of components for compcor filtering; if less than 1 we estimate on the fly based on explained variance; 10 wrt Shirer 2015 5 from csf and 5 from wm

  ica_components : integer if greater than 0 then include ica components

  impute : boolean if True, then use imputation in f/ALFF, PerAF calculation

  censor : boolean if True, then use censoring (censoring)

  despike : if this is greater than zero will run voxel-wise despiking in the 3dDespike (afni) sense; after motion-correction

  motion_as_nuisance: boolean will add motion and first derivative of motion as nuisance

  powers : boolean if True use Powers nodes otherwise 2023 Yeo 500 homotopic nodes (10.1016/j.neuroimage.2023.120010)

  upsample : float optionally isotropically upsample data to upsample (the parameter value) in mm during the registration process if data is below that resolution; if the input spacing is less than that provided by the user, the data will simply be resampled to isotropic resolution

  clean_tmp : will automatically try to clean the tmp directory - not recommended but can be used in distributed computing systems to help prevent failures due to accumulation of tmp files when doing large-scale processing.  if this is set, the float value clean_tmp will be interpreted as the age in hours of files to be cleaned.

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  References
  ---------

  10.1162/netn_a_00071 &#34;Methods that included global signal regression were the most consistently effective de-noising strategies.&#34;

  10.1016/j.neuroimage.2019.116157 &#34;frontal and default model networks are most reliable whereas subcortical neteworks are least reliable&#34;  &#34;the most comprehensive studies of pipeline effects on edge-level reliability have been done by shirer (2015) and Parkes (2018)&#34; &#34;slice timing correction has minimal impact&#34; &#34;use of low-pass or narrow filter (discarding  high frequency information) reduced both reliability and signal-noise separation&#34;

  10.1016/j.neuroimage.2017.12.073: Our results indicate that (1) simple linear regression of regional fMRI time series against head motion parameters and WM/CSF signals (with or without expansion terms) is not sufficient to remove head motion artefacts; (2) aCompCor pipelines may only be viable in low-motion data; (3) volume censoring performs well at minimising motion-related artefact but a major benefit of this approach derives from the exclusion of high-motion individuals; (4) while not as effective as volume censoring, ICA-AROMA performed well across our benchmarks for relatively low cost in terms of data loss; (5) the addition of global signal regression improved the performance of nearly all pipelines on most benchmarks, but exacerbated the distance-dependence of correlations between motion and functional connec- tivity; and (6) group comparisons in functional connectivity between healthy controls and schizophrenia patients are highly dependent on preprocessing strategy. We offer some recommendations for best practice and outline simple analyses to facilitate transparent reporting of the degree to which a given set of findings may be affected by motion-related artefact.

  10.1016/j.dcn.2022.101087 : We found that: 1) the most efficacious pipeline for both noise removal and information recovery included censoring, GSR, bandpass filtering, and head motion parameter (HMP) regression, 2) ICA-AROMA performed similarly to HMP regression and did not obviate the need for censoring, 3) GSR had a minimal impact on connectome fingerprinting but improved ISC, and 4) the strictest censoring approaches reduced motion correlated edges but negatively impacted identifiability.

  &#34;&#34;&#34;

  import warnings

  if clean_tmp is not None:
    clean_tmp_directory( age_hours = clean_tmp )

  if nc &gt; 1:
    nc = int(nc)
  else:
    nc=float(nc)

  type_of_transform=&#39;Rigid&#39; # , # should probably not change this
  remove_it=True
  output_directory = tempfile.mkdtemp()
  output_directory_w = output_directory + &#34;/ts_t1_reg/&#34;
  os.makedirs(output_directory_w,exist_ok=True)
  ofnt1tx = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;t1_deformation&#39;,dir=output_directory_w).name

  import numpy as np
# Assuming core and utils are modules or packages with necessary functions

  if upsample &gt; 0.0:
      spc = ants.get_spacing( fmri )
      minspc = upsample
      if min(spc[0:3]) &lt; minspc:
          minspc = min(spc[0:3])
      newspc = [minspc,minspc,minspc]
      fmri_template = ants.resample_image( fmri_template, newspc, interp_type=0 )

  def temporal_derivative_same_shape(array):
    &#34;&#34;&#34;
    Compute the temporal derivative of a 2D numpy array along the 0th axis (time)
    and ensure the output has the same shape as the input.

    :param array: 2D numpy array with time as the 0th axis.
    :return: 2D numpy array of the temporal derivative with the same shape as input.
    &#34;&#34;&#34;
    derivative = np.diff(array, axis=0)
    
    # Append a row to maintain the same shape
    # You can choose to append a row of zeros or the last row of the derivative
    # Here, a row of zeros is appended
    zeros_row = np.zeros((1, array.shape[1]))
    return np.vstack((zeros_row, derivative ))

  def compute_tSTD(M, quantile, x=0, axis=0):
    stdM = np.std(M, axis=axis)
    # set bad values to x
    stdM[stdM == 0] = x
    stdM[np.isnan(stdM)] = x
    tt = round(quantile * 100)
    threshold_std = np.percentile(stdM, tt)
    return {&#39;tSTD&#39;: stdM, &#39;threshold_std&#39;: threshold_std}

  def get_compcor_matrix(boldImage, mask, quantile):
    &#34;&#34;&#34;
    Compute the compcor matrix.

    :param boldImage: The bold image.
    :param mask: The mask to apply, if None, it will be computed.
    :param quantile: Quantile for computing threshold in tSTD.
    :return: The compor matrix.
    &#34;&#34;&#34;
    if mask is None:
        temp = ants.slice_image(boldImage, axis=boldImage.dimension - 1, idx=0)
        mask = ants.get_mask(temp)

    imagematrix = ants.timeseries_to_matrix(boldImage, mask)
    temp = compute_tSTD(imagematrix, quantile, 0)
    tsnrmask = ants.make_image(mask, temp[&#39;tSTD&#39;])
    tsnrmask = ants.threshold_image(tsnrmask, temp[&#39;threshold_std&#39;], temp[&#39;tSTD&#39;].max())
    M = ants.timeseries_to_matrix(boldImage, tsnrmask)
    return M


  from sklearn.decomposition import FastICA
  def find_indices(lst, value):
    return [index for index, element in enumerate(lst) if element &gt; value]

  def mean_of_list(lst):
    if not lst:  # Check if the list is not empty
        return 0  # Return 0 or appropriate value for an empty list
    return sum(lst) / len(lst)
  fmrispc = list( ants.get_spacing( fmri ) )
  if spa is None:
    spa = mean_of_list( fmrispc[0:3] ) * 1.0
  if spt is None:
    spt = fmrispc[3] * 0.5
      
  import numpy as np
  import pandas as pd
  import re
  import math
  # point data resources
  A = np.zeros((1,1))
  dfnname=&#39;DefaultMode&#39;
  if powers:
      powers_areal_mni_itk = pd.read_csv( get_data(&#39;powers_mni_itk&#39;, target_extension=&#34;.csv&#34;)) # power coordinates
      coords=&#39;powers&#39;
  else:
      powers_areal_mni_itk = pd.read_csv( get_data(&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;, target_extension=&#34;.csv&#34;)) # yeo 2023 coordinates
      coords=&#39;yeo_17_500_2023&#39;
  fmri = ants.iMath( fmri, &#39;Normalize&#39; )
  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;FillHoles&#34;)
  if verbose:
      print(&#34;Begin rsfmri motion correction&#34;)
  debug=False
  if debug:
      ants.image_write( fmri_template, &#39;/tmp/fmri_template.nii.gz&#39; )
      ants.image_write( fmri, &#39;/tmp/fmri.nii.gz&#39; )
      print(&#34;debug wrote fmri and fmri_template&#34;)
  # mot-co
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=type_of_transform,
    total_sigma=0.5,
    fdOffset=2.0,
    trim = 8,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5],
    return_numpy_motion_parameters=True )
  
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)
      print(&#34;=== next anatomically based mapping ===&#34;)

  despiking_count = np.zeros( corrmo[&#39;motion_corrected&#39;].shape[3] )
  if despike &gt; 0.0:
      corrmo[&#39;motion_corrected&#39;], despiking_count = despike_time_series_afni( corrmo[&#39;motion_corrected&#39;], c1=despike )

  despiking_count_summary = despiking_count.sum() / np.prod( corrmo[&#39;motion_corrected&#39;].shape )
  high_motion_count=(corrmo[&#39;FD&#39;] &gt; FD_threshold ).sum()
  high_motion_pct=high_motion_count / fmri.shape[3]

  # filter mask based on TSNR
  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,2)
  bmask = bmask * tsnrmask

  # anatomical mapping
  und = fmri_template * bmask
  t1reg = ants.registration( und, t1,
    &#34;SyNBold&#34;, outprefix=ofnt1tx )
  if verbose:
    print(&#34;t1 2 bold done&#34;)
  gmseg = ants.threshold_image( t1segmentation, 2, 2 )
  gmseg = gmseg + ants.threshold_image( t1segmentation, 4, 4 )
  gmseg = ants.threshold_image( gmseg, 1, 4 )
  gmseg = ants.iMath( gmseg, &#39;MD&#39;, 1 ) # FIXMERSF
  gmseg = ants.apply_transforms( und, gmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; ) * bmask
  csfAndWM = ( ants.threshold_image( t1segmentation, 1, 1 ) +
               ants.threshold_image( t1segmentation, 3, 3 ) ).morphology(&#34;erode&#34;,1)
  csfAndWM = ants.apply_transforms( und, csfAndWM,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  csf = ants.threshold_image( t1segmentation, 1, 1 )
  csf = ants.apply_transforms( und, csf, t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  wm = ants.threshold_image( t1segmentation, 3, 3 ).morphology(&#34;erode&#34;,1)
  wm = ants.apply_transforms( und, wm, t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask
  if powers:
    ch2 = mm_read( ants.get_ants_data( &#34;ch2&#34; ) )
  else:
    ch2 = mm_read( get_data( &#34;PPMI_template0_brain&#34;, target_extension=&#39;.nii.gz&#39; ) )
  treg = ants.registration( 
    # this is to make the impact of resolution consistent
    ants.resample_image(t1, [1.0,1.0,1.0], interp_type=0), 
    ch2, &#34;antsRegistrationSyNQuickRepro[s]&#34; )
  if powers:
    concatx2 = treg[&#39;invtransforms&#39;] + t1reg[&#39;invtransforms&#39;]
    pts2bold = ants.apply_transforms_to_points( 3, powers_areal_mni_itk, concatx2,
        whichtoinvert = ( True, False, True, False ) )
    locations = pts2bold.iloc[:,:3].values
    ptImg = ants.make_points_image( locations, bmask, radius = 2 )
  else:
    concatx2 = t1reg[&#39;fwdtransforms&#39;] + treg[&#39;fwdtransforms&#39;]    
    rsfsegfn = get_data(&#39;ppmi_template_500Parcels_Yeo2011_17Networks_2023_homotopic&#39;, target_extension=&#34;.nii.gz&#34;)
    rsfsegimg = ants.image_read( rsfsegfn )
    ptImg = ants.apply_transforms( und, rsfsegimg, concatx2, interpolator=&#39;nearestNeighbor&#39; ) * bmask
    pts2bold = powers_areal_mni_itk
    # ants.plot( und, ptImg, crop=True, axis=2 )

  # optional smoothing
  tr = ants.get_spacing( corrmo[&#39;motion_corrected&#39;] )[3]
  smth = ( spa, spa, spa, spt ) # this is for sigmaInPhysicalCoordinates = TRUE
  simg = ants.smooth_image( corrmo[&#39;motion_corrected&#39;], smth, sigma_in_physical_coordinates = True )

  # collect censoring indices
  hlinds = find_indices( corrmo[&#39;FD&#39;], FD_threshold )
  if verbose:
    print(&#34;high motion indices&#34;)
    print( hlinds )
  if outlier_threshold &lt; 1.0 and outlier_threshold &gt; 0.0:
    fmrimotcorr, hlinds2 = loop_timeseries_censoring( corrmo[&#39;motion_corrected&#39;], 
      threshold=outlier_threshold, verbose=verbose )
    hlinds.extend( hlinds2 )
    del fmrimotcorr
  hlinds = list(set(hlinds)) # make unique

  # nuisance
  globalmat = ants.timeseries_to_matrix( corrmo[&#39;motion_corrected&#39;], bmask )
  globalsignal = np.nanmean( globalmat, axis = 1 )
  del globalmat
  compcorquantile=0.50
  nc_wm=nc_csf=nc
  if nc &lt; 1:
    globalmat = get_compcor_matrix( corrmo[&#39;motion_corrected&#39;], wm, compcorquantile )
    nc_wm = int(estimate_optimal_pca_components( data=globalmat, variance_threshold=nc))
    globalmat = get_compcor_matrix( corrmo[&#39;motion_corrected&#39;], csf, compcorquantile )
    nc_csf = int(estimate_optimal_pca_components( data=globalmat, variance_threshold=nc))
    del globalmat
  if verbose:
    print(&#34;include compcor components as nuisance: csf &#34; + str(nc_csf) + &#34; wm &#34; + str(nc_wm))
  mycompcor_csf = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc_csf, quantile=compcorquantile, mask = csf,
    filter_type=&#39;polynomial&#39;, degree=2 )
  mycompcor_wm = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc_wm, quantile=compcorquantile, mask = wm,
    filter_type=&#39;polynomial&#39;, degree=2 )
  nuisance = np.c_[ mycompcor_csf[ &#39;components&#39; ], mycompcor_wm[ &#39;components&#39; ] ]

  if motion_as_nuisance:
      if verbose:
          print(&#34;include motion as nuisance&#34;)
          print( corrmo[&#39;motion_parameters&#39;].shape )
      deriv = temporal_derivative_same_shape( corrmo[&#39;motion_parameters&#39;]  )
      nuisance = np.c_[ nuisance, corrmo[&#39;motion_parameters&#39;], deriv ]

  if ica_components &gt; 0:
    if verbose:
        print(&#34;include ica components as nuisance: &#34; + str(ica_components))
    ica = FastICA(n_components=ica_components, max_iter=10000, tol=0.001, random_state=42 )
    globalmat = ants.timeseries_to_matrix( corrmo[&#39;motion_corrected&#39;], csfAndWM )
    nuisance_ica = ica.fit_transform(globalmat)  # Reconstruct signals
    nuisance = np.c_[ nuisance, nuisance_ica ]
    del globalmat

  # concat all nuisance data
  # nuisance = np.c_[ nuisance, mycompcor[&#39;basis&#39;] ]
  # nuisance = np.c_[ nuisance, corrmo[&#39;FD&#39;] ]
  nuisance = np.c_[ nuisance, globalsignal ]

  if impute:
    simgimp = impute_timeseries( simg, hlinds, method=&#39;linear&#39;)
  else:
    simgimp = simg

  # falff/alff stuff  def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
  myfalff=alff_image( simgimp, bmask, flo=f[0], fhi=f[1], nuisance=nuisance  )

  # bandpass any data collected before here -- if bandpass requested
  if f[0] &gt; 0 and f[1] &lt; 1.0:
    if verbose:
        print( &#34;bandpass: &#34; + str(f[0]) + &#34; &lt;=&gt; &#34; + str( f[1] ) )
    nuisance = ants.bandpass_filter_matrix( nuisance, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
    globalmat = ants.timeseries_to_matrix( simg, bmask )
    globalmat = ants.bandpass_filter_matrix( globalmat, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
    simg = ants.matrix_to_timeseries( simg, globalmat, bmask )

  if verbose:
    print(&#34;now regress nuisance&#34;)


  if len( hlinds ) &gt; 0 :
    if censor:
        nuisance = remove_elements_from_numpy_array( nuisance, hlinds  )
        simg = remove_volumes_from_timeseries( simg, hlinds )

  gmmat = ants.timeseries_to_matrix( simg, bmask )
  gmmat = ants.regress_components( gmmat, nuisance )
  simg = ants.matrix_to_timeseries(simg, gmmat, bmask)


  # structure the output data
  outdict = {}
  outdict[&#39;paramset&#39;] = paramset
  outdict[&#39;upsampling&#39;] = upsample
  outdict[&#39;coords&#39;] = coords
  outdict[&#39;dfnname&#39;]=dfnname
  outdict[&#39;meanBold&#39;] = und

  # add correlation matrix that captures each node pair
  # some of the spheres overlap so extract separately from each ROI
  if powers:
    nPoints = int(pts2bold[&#39;ROI&#39;].max())
    pointrange = list(range(int(nPoints)))
  else:
    nPoints = int(ptImg.max())
    pointrange = list(range(int(nPoints)))
  nVolumes = simg.shape[3]
  meanROI = np.zeros([nVolumes, nPoints])
  roiNames = []
  if debug:
      ptImgAll = und * 0.
  for i in pointrange:
    # specify name for matrix entries that&#39;s links back to ROI number and network; e.g., ROI1_Uncertain
    netLabel = re.sub( &#34; &#34;, &#34;&#34;, pts2bold.loc[i,&#39;SystemName&#39;])
    netLabel = re.sub( &#34;-&#34;, &#34;&#34;, netLabel )
    netLabel = re.sub( &#34;/&#34;, &#34;&#34;, netLabel )
    roiLabel = &#34;ROI&#34; + str(pts2bold.loc[i,&#39;ROI&#39;]) + &#39;_&#39; + netLabel
    roiNames.append( roiLabel )
    if powers:
        ptImage = ants.make_points_image(pts2bold.iloc[[i],:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    else:
        #print(&#34;Doing &#34; + pts2bold.loc[i,&#39;SystemName&#39;] + &#34; at &#34; + str(i) )
        #ptImage = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==pts2bold.loc[i,&#39;SystemName&#39;]],binarize=True)
        ptImage=ants.threshold_image( ptImg, pts2bold.loc[i,&#39;ROI&#39;], pts2bold.loc[i,&#39;ROI&#39;] )
    if debug:
      ptImgAll = ptImgAll + ptImage
    if ptImage.sum() &gt; 0 :
        meanROI[:,i] = ants.timeseries_to_matrix( simg, ptImage).mean(axis=1)

  if debug:
      ants.image_write( simg, &#39;/tmp/simg.nii.gz&#39; )
      ants.image_write( ptImgAll, &#39;/tmp/ptImgAll.nii.gz&#39; )
      ants.image_write( und, &#39;/tmp/und.nii.gz&#39; )
      ants.image_write( und, &#39;/tmp/und.nii.gz&#39; )

  # get full correlation matrix
  corMat = np.corrcoef(meanROI, rowvar=False)
  outputMat = pd.DataFrame(corMat)
  outputMat.columns = roiNames
  outputMat[&#39;ROIs&#39;] = roiNames
  # add to dictionary
  outdict[&#39;fullCorrMat&#39;] = outputMat

  networks = powers_areal_mni_itk[&#39;SystemName&#39;].unique()
  # this is just for human readability - reminds us of which we choose by default
  if powers:
    netnames = [&#39;Cingulo-opercular Task Control&#39;, &#39;Default Mode&#39;,
                    &#39;Memory Retrieval&#39;, &#39;Ventral Attention&#39;, &#39;Visual&#39;,
                    &#39;Fronto-parietal Task Control&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
                    &#39;Dorsal Attention&#39;]
    numofnets = [3,5,6,7,8,9,10,11,13]
  else:
    netnames = networks
    numofnets = list(range(len(netnames)))
 
  ct = 0
  for mynet in numofnets:
    netname = re.sub( &#34; &#34;, &#34;&#34;, networks[mynet] )
    netname = re.sub( &#34;-&#34;, &#34;&#34;, netname )
    ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[mynet] )[0]
    if powers:
        dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    else:
        dfnImg = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==networks[mynet]],binarize=True)
    if dfnImg.max() &gt;= 1:
        if verbose:
            print(&#34;DO: &#34; + coords + &#34; &#34; + netname )
        dfnmat = ants.timeseries_to_matrix( simg, ants.threshold_image( dfnImg, 1, dfnImg.max() ) )
        dfnsignal = np.nanmean( dfnmat, axis = 1 )
        nan_count_dfn = np.count_nonzero( np.isnan( dfnsignal) )
        if nan_count_dfn &gt; 0 :
            warnings.warn( &#34; mynet &#34; + netnames[ mynet ] + &#34; vs &#34; +  &#34; mean-signal has nans &#34; + str( nan_count_dfn ) ) 
        gmmatDFNCorr = np.zeros( gmmat.shape[1] )
        if nan_count_dfn == 0:
            for k in range( gmmat.shape[1] ):
                nan_count_gm = np.count_nonzero( np.isnan( gmmat[:,k]) )
                if debug and False:
                    print( str( k ) +  &#34; nans gm &#34; + str(nan_count_gm)  )
                if nan_count_gm == 0:
                    gmmatDFNCorr[ k ] = pearsonr( dfnsignal, gmmat[:,k] )[0]
        corrImg = ants.make_image( bmask, gmmatDFNCorr  )
        outdict[ netname ] = corrImg * gmseg
    else:
        outdict[ netname ] = None
    ct = ct + 1

  A = np.zeros( ( len( numofnets ) , len( numofnets ) ) )
  A_wide = np.zeros( ( 1, len( numofnets ) * len( numofnets ) ) )
  newnames=[]
  newnames_wide=[]
  ct = 0
  for i in range( len( numofnets ) ):
      netnamei = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[i]] )
      netnamei = re.sub( &#34;-&#34;, &#34;&#34;, netnamei )
      newnames.append( netnamei  )
      ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[numofnets[i]] )[0]
      if powers:
          dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
      else:
          dfnImg = ants.mask_image( ptImg, ptImg, level=pts2bold[&#39;ROI&#39;][pts2bold[&#39;SystemName&#39;]==networks[numofnets[i]]],binarize=True)
      for j in range( len( numofnets ) ):
          netnamej = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[j]] )
          netnamej = re.sub( &#34;-&#34;, &#34;&#34;, netnamej )
          newnames_wide.append( netnamei + &#34;_2_&#34; + netnamej )
          A[i,j] = 0
          if dfnImg is not None and netnamej is not None:
            subbit = dfnImg == 1
            if subbit is not None:
                if subbit.sum() &gt; 0 and netnamej in outdict:
                    A[i,j] = outdict[ netnamej ][ subbit ].mean()
          A_wide[0,ct] = A[i,j]
          ct=ct+1

  A = pd.DataFrame( A )
  A.columns = newnames
  A[&#39;networks&#39;]=newnames
  A_wide = pd.DataFrame( A_wide )
  A_wide.columns = newnames_wide
  outdict[&#39;corr&#39;] = A
  outdict[&#39;corr_wide&#39;] = A_wide
  outdict[&#39;fmri_template&#39;] = fmri_template
  outdict[&#39;brainmask&#39;] = bmask
  outdict[&#39;gmmask&#39;] = gmseg
  outdict[&#39;alff&#39;] = myfalff[&#39;alff&#39;]
  outdict[&#39;falff&#39;] = myfalff[&#39;falff&#39;]
  # add global mean and standard deviation for post-hoc z-scoring
  outdict[&#39;alff_mean&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).mean()
  outdict[&#39;alff_sd&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).std()
  outdict[&#39;falff_mean&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).mean()
  outdict[&#39;falff_sd&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).std()

  perafimg = PerAF( simgimp, bmask )
  for k in pointrange:
    anatname=( pts2bold[&#39;AAL&#39;][k] )
    if isinstance(anatname, str):
        anatname = re.sub(&#34;_&#34;,&#34;&#34;,anatname)
    else:
        anatname=&#39;Unk&#39;
    if powers:
        kk = f&#34;{k:0&gt;3}&#34;+&#34;_&#34;
    else:
        kk = f&#34;{k % int(nPoints/2):0&gt;3}&#34;+&#34;_&#34;
    fname=&#39;falffPoint&#39;+kk+anatname
    aname=&#39;alffPoint&#39;+kk+anatname
    pname=&#39;perafPoint&#39;+kk+anatname
    localsel = ptImg == k
    if localsel.sum() &gt; 0 : # check if non-empty
        outdict[fname]=(outdict[&#39;falff&#39;][localsel]).mean()
        outdict[aname]=(outdict[&#39;alff&#39;][localsel]).mean()
        outdict[pname]=(perafimg[localsel]).mean()
    else:
        outdict[fname]=math.nan
        outdict[aname]=math.nan
        outdict[pname]=math.nan

  rsfNuisance = pd.DataFrame( nuisance )
  if remove_it:
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )

  if not powers:
    dfnsum=outdict[&#39;DefaultA&#39;]+outdict[&#39;DefaultB&#39;]+outdict[&#39;DefaultC&#39;]
    outdict[&#39;DefaultMode&#39;]=dfnsum
    dfnsum=outdict[&#39;VisCent&#39;]+outdict[&#39;VisPeri&#39;]
    outdict[&#39;Visual&#39;]=dfnsum

  nonbrainmask = ants.iMath( bmask, &#34;MD&#34;,2) - bmask
  trimmask = ants.iMath( bmask, &#34;ME&#34;,2)
  edgemask = ants.iMath( bmask, &#34;ME&#34;,1) - trimmask
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;PerAF&#39;] = perafimg
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;ssnr&#39;] = slice_snr( corrmo[&#39;motion_corrected&#39;], csfAndWM, gmseg )
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;bandpass_freq_0&#39;]=f[0]
  outdict[&#39;bandpass_freq_1&#39;]=f[1]
  outdict[&#39;censor&#39;]=int(censor)
  outdict[&#39;spatial_smoothing&#39;]=spa
  outdict[&#39;outlier_threshold&#39;]=outlier_threshold
  outdict[&#39;FD_threshold&#39;]=outlier_threshold
  outdict[&#39;high_motion_count&#39;] = high_motion_count
  outdict[&#39;high_motion_pct&#39;] = high_motion_pct
  outdict[&#39;despiking_count_summary&#39;] = despiking_count_summary
  outdict[&#39;FD_max&#39;] = corrmo[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = corrmo[&#39;FD&#39;].mean()
  outdict[&#39;FD_sd&#39;] = corrmo[&#39;FD&#39;].std()
  outdict[&#39;bold_evr&#39;] =  antspyt1w.patch_eigenvalue_ratio( und, 512, [16,16,16], evdepth = 0.9, mask = bmask )
  outdict[&#39;n_outliers&#39;] = len(hlinds)
  outdict[&#39;nc_wm&#39;] = int(nc_wm)
  outdict[&#39;nc_csf&#39;] = int(nc_csf)
  outdict[&#39;minutes_original_data&#39;] = ( tr * fmri.shape[3] ) / 60.0 # minutes of useful data
  outdict[&#39;minutes_censored_data&#39;] = ( tr * simg.shape[3] ) / 60.0 # minutes of useful data
  return convert_np_in_dict( outdict )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.score_fmri_censoring"><code class="name flex">
<span>def <span class="ident">score_fmri_censoring</span></span>(<span>cbfts, csf_seg, gm_seg, wm_seg)</span>
</code></dt>
<dd>
<div class="desc"><p>Process CBF time series to remove high-leverage points.
Derived from the SCORE algorithm by Sudipto Dolui et. al.</p>
<p>Parameters:
cbfts (ANTsImage): 4D ANTsImage of CBF time series.
csf_seg (ANTsImage): CSF binary map.
gm_seg (ANTsImage): Gray matter binary map.
wm_seg (ANTsImage): WM binary map.</p>
<p>Returns:
ANTsImage: Processed CBF time series.
ndarray: Index of removed volumes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score_fmri_censoring(cbfts, csf_seg, gm_seg, wm_seg ):
    &#34;&#34;&#34;
    Process CBF time series to remove high-leverage points.
    Derived from the SCORE algorithm by Sudipto Dolui et. al.

    Parameters:
    cbfts (ANTsImage): 4D ANTsImage of CBF time series.
    csf_seg (ANTsImage): CSF binary map.
    gm_seg (ANTsImage): Gray matter binary map.
    wm_seg (ANTsImage): WM binary map.

    Returns:
    ANTsImage: Processed CBF time series.
    ndarray: Index of removed volumes.
    &#34;&#34;&#34;
    
    n_gm_voxels = np.sum(gm_seg.numpy()) - 1
    n_wm_voxels = np.sum(wm_seg.numpy()) - 1
    n_csf_voxels = np.sum(csf_seg.numpy()) - 1
    mask1img = gm_seg + wm_seg + csf_seg
    mask1 = (mask1img==1).numpy()
    
    cbfts_np = cbfts.numpy()
    gmbool = (gm_seg==1).numpy()
    csfbool = (csf_seg==1).numpy()
    wmbool = (wm_seg==1).numpy()
    gm_cbf_ts = ants.timeseries_to_matrix( cbfts, gm_seg )
    gm_cbf_ts = np.squeeze(np.mean(gm_cbf_ts, axis=1))
    
    median_gm_cbf = np.median(gm_cbf_ts)
    mad_gm_cbf = np.median(np.abs(gm_cbf_ts - median_gm_cbf)) / 0.675
    indx = np.abs(gm_cbf_ts - median_gm_cbf) &gt; (2.5 * mad_gm_cbf)
    
    # the spatial mean
    spatmeannp = np.mean(cbfts_np[:, :, :, ~indx], axis=3)
    spatmean = ants.from_numpy( spatmeannp )
    V = (
        n_gm_voxels * np.var(spatmeannp[gmbool])
        + n_wm_voxels * np.var(spatmeannp[wmbool])
        + n_csf_voxels * np.var(spatmeannp[csfbool])
    )
    V1 = math.inf
    ct=0
    while V &lt; V1:
        ct=ct+1
        V1 = V
        CC = np.zeros(cbfts_np.shape[3])
        for s in range(cbfts_np.shape[3]):
            if indx[s]:
                continue
            tmp1 = ants.from_numpy( cbfts_np[:, :, :, s] )
            CC[s] = ants.image_similarity( spatmean, tmp1, metric_type=&#39;Correlation&#39;, fixed_mask=mask1img )
        inx = np.argmin(CC)
        indx[inx] = True
        spatmeannp = np.mean(cbfts_np[:, :, :, ~indx], axis=3)
        spatmean = ants.from_numpy( spatmeannp )
        V = (
          n_gm_voxels * np.var(spatmeannp[gmbool]) + 
          n_wm_voxels * np.var(spatmeannp[wmbool]) + 
          n_csf_voxels * np.var(spatmeannp[csfbool])
        )
    cbfts_recon = cbfts_np[:, :, :, ~indx]
    cbfts_recon = np.nan_to_num(cbfts_recon)
    cbfts_recon_ants = ants.from_numpy(cbfts_recon)
    cbfts_recon_ants = ants.copy_image_info(cbfts, cbfts_recon_ants)
    return cbfts_recon_ants, indx</code></pre>
</details>
</dd>
<dt id="antspymm.mm.segment_timeseries_by_meanvalue"><code class="name flex">
<span>def <span class="ident">segment_timeseries_by_meanvalue</span></span>(<span>image, quantile=0.995)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify indices of a time series where we assume there is a different mean
intensity over the volumes.
The indices of volumes with higher and lower
intensities is returned.
Can be used to automatically identify B0 volumes
in DWI timeseries.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>quantile</code></strong> :&ensp;<code>a quantile for splitting the indices</code> of <code>the volume - should be greater than 0.5</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the two sets</code> of <code>indices</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def segment_timeseries_by_meanvalue( image, quantile = 0.995 ):
    &#34;&#34;&#34;
    Identify indices of a time series where we assume there is a different mean
    intensity over the volumes.  The indices of volumes with higher and lower
    intensities is returned.  Can be used to automatically identify B0 volumes
    in DWI timeseries.

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    quantile : a quantile for splitting the indices of the volume - should be greater than 0.5

    Returns
    -------
    dictionary holding the two sets of indices

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    ishape = image.shape
    lastdim = len(ishape)-1
    meanvalues = list()
    for x in range(ishape[lastdim]):
        meanvalues.append(  ants.slice_image( image, axis=lastdim, idx=x ).mean() )
    myhiq = np.quantile( meanvalues, quantile )
    myloq = np.quantile( meanvalues, 1.0 - quantile )
    lowerindices = list()
    higherindices = list()
    for x in range(len(meanvalues)):
        hiabs = abs( meanvalues[x] - myhiq )
        loabs = abs( meanvalues[x] - myloq )
        if hiabs &lt; loabs:
            higherindices.append(x)
        else:
            lowerindices.append(x)

    return {
    &#39;lowermeans&#39;:lowerindices,
    &#39;highermeans&#39;:higherindices }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.slice_snr"><code class="name flex">
<span>def <span class="ident">slice_snr</span></span>(<span>x, background_mask, foreground_mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>slice-wise SNR on a time series image</p>
<p>x: image</p>
<p>background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask</p>
<p>foreground_mask : mask - maybe cortex or WM or brain mask</p>
<p>indices: indices to use</p>
<p>returns an array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_snr( x,  background_mask, foreground_mask, indices=None ):
    &#34;&#34;&#34;
    slice-wise SNR on a time series image

    x: image

    background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask

    foreground_mask : mask - maybe cortex or WM or brain mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    xuse=ants.iMath(x,&#34;Normalize&#34;)
    MB = ants.timeseries_to_matrix( xuse, background_mask )
    MF = ants.timeseries_to_matrix( xuse, foreground_mask )
    if indices is not None:
        MB=MB[indices,:]
        MF=MF[indices,:]
    ssnr = np.zeros( MB.shape[0] )
    for i in range( MB.shape[0] ):
        ssnr[i]=MF[i,:].mean()/MB[i,:].std()
    ssnr[np.isnan(ssnr)] = 0
    return ssnr</code></pre>
</details>
</dd>
<dt id="antspymm.mm.study_dataframe_from_matched_dataframe"><code class="name flex">
<span>def <span class="ident">study_dataframe_from_matched_dataframe</span></span>(<span>matched_dataframe, rootdir, outputdir, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv</p>
<p>matched_dataframe : output of antspymm.match_modalities</p>
<p>rootdir : location for the input data root folder (in e.g. NRG format)</p>
<p>outputdir : location for the output data</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def study_dataframe_from_matched_dataframe( matched_dataframe, rootdir, outputdir, verbose=False ):
    &#34;&#34;&#34;
    converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv

    matched_dataframe : output of antspymm.match_modalities

    rootdir : location for the input data root folder (in e.g. NRG format)

    outputdir : location for the output data

    verbose : boolean
    &#34;&#34;&#34;
    iext=&#39;.nii.gz&#39;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in matched_dataframe.keys():
            raise ValueError(&#39;matched_dataframe is missing column &#39; +musthavecols[k] + &#39; in study_dataframe_from_qc_dataframe&#39; )
    csvrow=matched_dataframe.dropna(axis=1)
    pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
    dt=str(csvrow[&#39;date&#39;].iloc[0])
    iid=str(csvrow[&#39;imageID&#39;].iloc[0])
    nrgt1fn=os.path.join( rootdir, pid, sid, dt, &#39;T1w&#39;, iid, str(csvrow[&#39;filename&#39;].iloc[0]+iext) )
    if not exists( nrgt1fn ):
        raise ValueError(&#34;T1 &#34; + nrgt1fn + &#34; does not exist in study_dataframe_from_qc_dataframe&#34;)
    flList=[]
    dtList=[]
    rsfList=[]
    nmList=[]
    if &#39;flairfn&#39; in csvrow.keys():
        flid=str(int(csvrow[&#39;flairid&#39;].iloc[0]))
        nrgt2fn=os.path.join( rootdir, pid, sid, dt, &#39;T2Flair&#39;, flid, str(csvrow[&#39;flairfn&#39;].iloc[0]+iext) )
        if exists( nrgt2fn ):
            flList.append( nrgt2fn )
    if &#39;dtfn1&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid1&#39;].iloc[0]))
        dtfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn1&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn1 ):
            dtList.append( dtfn1 )
    if &#39;dtfn2&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid2&#39;].iloc[0]))
        dtfn2=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn2&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn2 ):
            dtList.append( dtfn2 )
    if &#39;dtfn3&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid3&#39;].iloc[0]))
        dtfn3=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn3&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn3 ):
            dtList.append( dtfn3 )
    if &#39;rsffn1&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid1&#39;].iloc[0]))
        rsfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn1&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn1 ):
            rsfList.append( rsfn1 )
    if &#39;rsffn2&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid2&#39;].iloc[0]))
        rsfn2=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn2&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn2 ):
            rsfList.append( rsfn2 )
    for j in range(11):
        keyname=&#34;nmfn&#34;+str(j)
        keynameid=&#34;nmid&#34;+str(j)
        if keyname in csvrow.keys() and keynameid in csvrow.keys():
            nmid=str(int(csvrow[keynameid].iloc[0]))
            nmsearchpath=os.path.join( rootdir, pid, sid, dt, &#39;NM2DMT&#39;, nmid, &#34;*&#34;+nmid+iext)
            nmfn=glob.glob( nmsearchpath )
            nmfn=nmfn[0]
            if exists( nmfn ):
                nmList.append( nmfn )
    if verbose:
        print(&#34;assembled the image lists mapping to ....&#34;)
        print(nrgt1fn)
        print(&#34;NM&#34;)
        print(nmList)
        print(&#34;FLAIR&#34;)
        print(flList)
        print(&#34;DTI&#34;)
        print(dtList)
        print(&#34;rsfMRI&#34;)
        print(rsfList)
    studycsv = generate_mm_dataframe(
        pid,
        sid,
        dt,
        iid, # the T1 id
        &#39;T1w&#39;,
        rootdir,
        outputdir,
        t1_filename=nrgt1fn,
        flair_filename=flList,
        dti_filenames=dtList,
        rsf_filenames=rsfList,
        nm_filenames=nmList)
    return studycsv.dropna(axis=1)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.super_res_mcimage"><code class="name flex">
<span>def <span class="ident">super_res_mcimage</span></span>(<span>image, srmodel, truncation=[0.0001, 0.995], poly_order='hist', target_range=[0, 1], isotropic=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Super resolution on a timeseries or multi-channel image</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>a tensorflow fully convolutional model</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>truncation</code></strong> :&ensp;<code> quantiles at which we truncate intensities to limit impact</code> of <code>outliers e.g. [0.005,0.995]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>poly_order</code></strong> :&ensp;<code>if not None, will fit a global regression model to map</code></dt>
<dd>intensity back to original histogram space; if 'hist' will match
by histogram matching - ants.histogram_match_image</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>isotropic</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>super resolution <a title="antspymm.mm.version" href="#antspymm.mm.version">version()</a></code> of <code>the image</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def super_res_mcimage( image,
    srmodel,
    truncation=[0.0001,0.995],
    poly_order=&#39;hist&#39;,
    target_range=[0,1],
    isotropic = False,
    verbose=False ):
    &#34;&#34;&#34;
    Super resolution on a timeseries or multi-channel image

    Arguments
    ---------
    image : an antsImage

    srmodel : a tensorflow fully convolutional model

    truncation :  quantiles at which we truncate intensities to limit impact of outliers e.g. [0.005,0.995]

    poly_order : if not None, will fit a global regression model to map
        intensity back to original histogram space; if &#39;hist&#39; will match
        by histogram matching - ants.histogram_match_image

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

    isotropic : boolean

    verbose : boolean

    Returns
    -------
    super resolution version of the image

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    mcsr = list()
    for k in range(nTimePoints):
        if verbose and (( k % 5 ) == 0 ):
            mycount = round(k / nTimePoints * 100)
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image( image, axis=idim - 1, idx=k )
        temp = ants.iMath( temp, &#34;TruncateIntensity&#34;, truncation[0], truncation[1] )
        mysr = antspynet.apply_super_resolution_model_to_image( temp, srmodel,
            target_range = target_range )
        if poly_order is not None:
            bilin = ants.resample_image_to_target( temp, mysr )
            if poly_order == &#39;hist&#39;:
                mysr = ants.histogram_match_image( mysr, bilin )
            else:
                mysr = antspynet.regression_match_image( mysr, bilin, poly_order = poly_order )
        if isotropic:
            mysr = down2iso( mysr )
        if k == 0:
            upshape = list()
            for j in range(len(ishape)-1):
                upshape.append( mysr.shape[j] )
            upshape.append( ishape[ idim-1 ] )
            if verbose:
                print(&#34;SR will be of voxel size:&#34; + str(upshape) )
        mcsr.append( mysr )

    upshape = list()
    for j in range(len(ishape)-1):
        upshape.append( mysr.shape[j] )
    upshape.append( ishape[ idim-1 ] )
    if verbose:
        print(&#34;SR will be of voxel size:&#34; + str(upshape) )

    imageup = ants.resample_image( image, upshape, use_voxels = True )
    if verbose:
        print(&#34;Done&#34;)

    return ants.list_to_ndimage( imageup, mcsr )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.t1_based_dwi_brain_extraction"><code class="name flex">
<span>def <span class="ident">t1_based_dwi_brain_extraction</span></span>(<span>t1w_head, t1w, dwi, b0_idx=None, transform='Rigid', deform=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Map a t1-based brain extraction to b0 and return a mask and average b0</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>t1w_head</code></strong> :&ensp;<code>an antsImage</code> of <code>the hole head</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1w</code></strong> :&ensp;<code>an antsImage probably but not necessarily T1-weighted</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>b0_idx</code></strong> :&ensp;<code>the indices</code> of <code>the B0; if None, use segment_timeseries_by_meanvalue to guess</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>string Rigid</code> or <code>other ants.registration tx type</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>deform</code></strong> :&ensp;<code>follow up transform with deformation</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the avg_b0 and its mask</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def t1_based_dwi_brain_extraction(
    t1w_head,
    t1w,
    dwi,
    b0_idx = None,
    transform=&#39;Rigid&#39;,
    deform=None,
    verbose=False
):
    &#34;&#34;&#34;
    Map a t1-based brain extraction to b0 and return a mask and average b0

    Arguments
    ---------
    t1w_head : an antsImage of the hole head

    t1w : an antsImage probably but not necessarily T1-weighted

    dwi : an antsImage holding B0 and DWI

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    transform : string Rigid or other ants.registration tx type

    deform : follow up transform with deformation

    Returns
    -------
    dictionary holding the avg_b0 and its mask

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    t1w_use = ants.iMath( t1w, &#34;Normalize&#34; )
    t1bxt = ants.threshold_image( t1w_use, 0.05, 1 ).iMath(&#34;FillHoles&#34;)
    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    # first get the average b0
    if len( b0_idx ) &gt; 1:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] ).iMath(&#34;Normalize&#34;)
        for n in range(1,len(b0_idx)):
            temp = ants.slice_image( dwi, axis=3, idx=b0_idx[n] )
            reg = ants.registration( b0_avg, temp, &#39;Rigid&#39; )
            b0_avg = b0_avg + ants.iMath( reg[&#39;warpedmovout&#39;], &#34;Normalize&#34;)
    else:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] )
    b0_avg = ants.iMath(b0_avg,&#34;Normalize&#34;)
    reg = tra_initializer( b0_avg, t1w, n_simulations=12,   verbose=verbose )
    if deform is not None:
        reg = ants.registration( b0_avg, t1w,
            &#39;SyNOnly&#39;,
            total_sigma=0.5,
            initial_transform=reg[&#39;fwdtransforms&#39;][0],
            verbose=False )
    outmsk = ants.apply_transforms( b0_avg, t1bxt, reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39;).threshold_image( 0.5, 1.0 )
    return  {
    &#39;b0_avg&#39;:b0_avg,
    &#39;b0_mask&#39;:outmsk }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.threaded_bind_wide_mm_csvs"><code class="name flex">
<span>def <span class="ident">threaded_bind_wide_mm_csvs</span></span>(<span>mm_wide_csvs, n_workers)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def threaded_bind_wide_mm_csvs( mm_wide_csvs, n_workers ):
    from concurrent.futures import as_completed
    from concurrent import futures
    import concurrent.futures
    def chunks(l, n):
        &#34;&#34;&#34;Yield n number of sequential chunks from l.&#34;&#34;&#34;
        d, r = divmod(len(l), n)
        for i in range(n):
            si = (d+1)*(i if i &lt; r else r) + d*(0 if i &lt; r else i - r)
            yield l[si:si+(d+1 if i &lt; r else d)]
    import numpy as np
    newx = list( chunks( mm_wide_csvs, n_workers ) )
    import pandas as pd
    alldf = pd.DataFrame()
    alldfavg = pd.DataFrame()
    with futures.ThreadPoolExecutor(max_workers=n_workers) as executor:
        to_do = []
        for group in range(len(newx)) :
            future = executor.submit(bind_wide_mm_csvs, newx[group] )
            to_do.append(future)
        results = []
        for future in futures.as_completed(to_do):
            res0, res1 = future.result()
            alldf=pd.concat(  [alldf, res0 ], axis=0, ignore_index=False )
            alldfavg=pd.concat(  [alldfavg, res1 ], axis=0, ignore_index=False )
    return alldf, alldfavg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.timeseries_reg"><code class="name flex">
<span>def <span class="ident">timeseries_reg</span></span>(<span>image, avg_b0, type_of_transform='Rigid', total_sigma=1.0, fdOffset=2.0, trim=0, output_directory=None, return_numpy_motion_parameters=False, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion.</p>
<h2 id="arguments">Arguments</h2>
<p>image: antsImage, usually ND where D=4.</p>
<dl>
<dt><strong><code>avg_b0</code></strong> :&ensp;<code>Fixed image b0 image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>type_of_transform</code></strong> :&ensp;<code>string</code></dt>
<dd>A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
See ants registration for details.</dd>
<dt><strong><code>fdOffset</code></strong> :&ensp;<code>offset value to use in framewise displacement calculation</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>trim</code></strong> :&ensp;<code>integer - trim this many images off the front</code> of <code>the time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>output_directory</code></strong> :&ensp;<code>string</code></dt>
<dd>output will be placed in this directory plus a numeric extension.</dd>
<dt><strong><code>return_numpy_motion_parameters</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>keyword args</code></dt>
<dd>extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timeseries_reg(
    image,
    avg_b0,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=1.0,
    fdOffset=2.0,
    trim = 0,
    output_directory=None,
    return_numpy_motion_parameters=False,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion.

    Arguments
    ---------
    image: antsImage, usually ND where D=4.

    avg_b0: Fixed image b0 image

    type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

    fdOffset: offset value to use in framewise displacement calculation

    trim : integer - trim this many images off the front of the time series

    output_directory : string
            output will be placed in this directory plus a numeric extension.

    return_numpy_motion_parameters : boolean

    verbose: boolean

    kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD
        }

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/ts_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(&#39;bold motcorr with &#39; + type_of_transform)
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    # get a local deformation from slice to local avg space
    motion_parameters = list()
    motion_corrected = list()
    mask = ants.get_mask( avg_b0 )
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 ) + 1
    for k in range( nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k % 2).zfill(4)+&#34;_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if temp.numpy().var() &gt; 0:
            img1w = ants.apply_transforms( avg_b0,
                temp,
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(avg_b0)

    motion_parameters = motion_parameters[trim:len(motion_parameters)]
    if return_numpy_motion_parameters:
        motion_parameters = read_ants_transforms_to_numpy( motion_parameters )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( ants.get_spacing(image)[3] )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected[trim:len(motion_corrected)]),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD[trim:len(FD)]
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.tra_initializer"><code class="name flex">
<span>def <span class="ident">tra_initializer</span></span>(<span>fixed, moving, n_simulations=32, max_rotation=30, transform=['rigid'], compreg=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>multi-start multi-transform registration solution - based on ants.registration</p>
<p>fixed: fixed image</p>
<p>moving: moving image</p>
<p>n_simulations : number of simulations</p>
<p>max_rotation : maximum rotation angle</p>
<p>transform : list of transforms to loop through</p>
<p>compreg : registration results against which to compare</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tra_initializer( fixed, moving, n_simulations=32, max_rotation=30,
    transform=[&#39;rigid&#39;], compreg=None, verbose=False ):
    &#34;&#34;&#34;
    multi-start multi-transform registration solution - based on ants.registration

    fixed: fixed image

    moving: moving image

    n_simulations : number of simulations

    max_rotation : maximum rotation angle

    transform : list of transforms to loop through

    compreg : registration results against which to compare

    verbose : boolean

    &#34;&#34;&#34;
    if True:
        output_directory = tempfile.mkdtemp()
        output_directory_w = output_directory + &#34;/tra_reg/&#34;
        os.makedirs(output_directory_w,exist_ok=True)
        bestmi = math.inf
        bestvar = 0.0
        myorig = list(ants.get_origin( fixed ))
        mymax = 0;
        for k in range(len( myorig ) ):
            if abs(myorig[k]) &gt; mymax:
                mymax = abs(myorig[k])
        maxtrans = mymax * 0.05
        if compreg is None:
            bestreg=ants.registration( fixed,moving,&#39;Translation&#39;,
                outprefix=output_directory_w+&#34;trans&#34;)
            initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        else :
            bestreg=compreg
            initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        for mytx in transform:
            regtx = &#39;Rigid&#39;
            with tempfile.NamedTemporaryFile(suffix=&#39;.h5&#39;) as tp:
                if mytx == &#39;translation&#39;:
                    regtx = &#39;Translation&#39;
                    rRotGenerator = ants.contrib.RandomTranslate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                elif mytx == &#39;affine&#39;:
                    regtx = &#39;Affine&#39;
                    rRotGenerator = ants.contrib.RandomRotate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                else:
                    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rotation*(-1.0), max_rotation ), reference=fixed )
                for k in range(n_simulations):
                    simtx = ants.compose_ants_transforms( [rRotGenerator.transform(), initx] )
                    ants.write_transform( simtx, tp.name )
                    if k &gt; 0:
                        reg = ants.registration( fixed, moving, regtx,
                            initial_transform=tp.name,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    else:
                        reg = ants.registration( fixed, moving,
                            regtx,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    mymi = math.inf
                    temp = reg[&#39;warpedmovout&#39;]
                    myvar = temp.numpy().var()
                    if verbose:
                        print( str(k) + &#34; : &#34; + regtx  + &#34; : &#34; + mytx + &#34; _var_ &#34; + str( myvar ) )
                    if myvar &gt; 0 :
                        mymi = ants.image_mutual_information( fixed, temp )
                        if mymi &lt; bestmi:
                            if verbose:
                                print( &#34;mi @ &#34; + str(k) + &#34; : &#34; + str(mymi), flush=True)
                            bestmi = mymi
                            bestreg = reg
                            bestvar = myvar
        if bestvar == 0.0 and compreg is not None:
            return compreg        
        return bestreg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.trim_dti_mask"><code class="name flex">
<span>def <span class="ident">trim_dti_mask</span></span>(<span>fa, mask, param=4.0)</span>
</code></dt>
<dd>
<div class="desc"><p>trim the dti mask to get rid of bright fa rim</p>
<p>this function erodes the famask by param amount then segments the rim into
bright and less bright parts.
the bright parts are trimmed from the mask
and the remaining edges are cleaned up a bit with closing.</p>
<p>param: closing radius unit is in physical space</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_dti_mask( fa, mask, param=4.0 ):
    &#34;&#34;&#34;
    trim the dti mask to get rid of bright fa rim

    this function erodes the famask by param amount then segments the rim into
    bright and less bright parts.  the bright parts are trimmed from the mask
    and the remaining edges are cleaned up a bit with closing.

    param: closing radius unit is in physical space
    &#34;&#34;&#34;
    spacing = ants.get_spacing(mask)
    spacing_product = np.prod( spacing )
    spcmin = min( spacing )
    paramVox = int(np.round( param / spcmin ))
    trim_mask = ants.image_clone( mask )
    trim_mask = ants.iMath( trim_mask, &#34;FillHoles&#34; )
    edgemask = trim_mask - ants.iMath( trim_mask, &#34;ME&#34;, paramVox )
    maxk=4
    edgemask = ants.threshold_image( fa * edgemask, &#34;Otsu&#34;, maxk )
    edgemask = ants.threshold_image( edgemask, maxk-1, maxk )
    trim_mask[edgemask &gt;= 1 ]=0
    trim_mask = ants.iMath(trim_mask,&#34;ME&#34;,paramVox-1)
    trim_mask = ants.iMath(trim_mask,&#39;GetLargestComponent&#39;)
    trim_mask = ants.iMath(trim_mask,&#34;MD&#34;,paramVox-1)
    return trim_mask</code></pre>
</details>
</dd>
<dt id="antspymm.mm.tsnr"><code class="name flex">
<span>def <span class="ident">tsnr</span></span>(<span>x, mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>3D temporal snr image from a 4D time series image &hellip; the matrix is normalized to range of 0,1</p>
<p>x: image</p>
<p>mask : mask</p>
<p>indices: indices to use</p>
<p>returns a 3D image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tsnr( x, mask, indices=None ):
    &#34;&#34;&#34;
    3D temporal snr image from a 4D time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns a 3D image
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    stdM = np.std(M, axis=0 )
    stdM[np.isnan(stdM)] = 0
    tt = round( 0.975*100 )
    threshold_std = np.percentile( stdM, tt )
    tsnrimage = ants.make_image( mask, stdM )
    return tsnrimage</code></pre>
</details>
</dd>
<dt id="antspymm.mm.validate_nrg_file_format"><code class="name flex">
<span>def <span class="ident">validate_nrg_file_format</span></span>(<span>path, separator)</span>
</code></dt>
<dd>
<div class="desc"><p>is your path nrg-etic?
Validates if a given path conforms to the NRG file format, taking into account known extensions
and the expected directory structure.</p>
<dl>
<dt>:param path: The file path to validate.</dt>
<dt>:param separator: The separator used in the filename and directory structure.</dt>
<dt>:return: A tuple (bool, str) indicating whether the path is valid and a message explaining the validation result.</dt>
<dd>
<p>example</p>
</dd>
</dl>
<p>ntfn='/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses-1/rsfMRI_RL/000/ANTsLIMBIC_sub08C105120Yr_ses-1_rsfMRI_RL_000.nii.gz'
ntfngood='/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses_1/rsfMRI_RL/000/ANTsLIMBIC-sub08C105120Yr-ses_1-rsfMRI_RL-000.nii.gz'</p>
<p>validate_nrg_detailed(ntfngood, '-')
print( validate_nrg_detailed(ntfn, '-') )
print( validate_nrg_detailed(ntfn, '_') )</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_nrg_file_format(path, separator):
    &#34;&#34;&#34;
    is your path nrg-etic?
    Validates if a given path conforms to the NRG file format, taking into account known extensions
    and the expected directory structure.

    :param path: The file path to validate.
    :param separator: The separator used in the filename and directory structure.
    :return: A tuple (bool, str) indicating whether the path is valid and a message explaining the validation result.

    : example

    ntfn=&#39;/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses-1/rsfMRI_RL/000/ANTsLIMBIC_sub08C105120Yr_ses-1_rsfMRI_RL_000.nii.gz&#39;
    ntfngood=&#39;/Users/ntustison/Data/Stone/LIMBIC/NRG/ANTsLIMBIC/sub08C105120Yr/ses_1/rsfMRI_RL/000/ANTsLIMBIC-sub08C105120Yr-ses_1-rsfMRI_RL-000.nii.gz&#39;

    validate_nrg_detailed(ntfngood, &#39;-&#39;)
    print( validate_nrg_detailed(ntfn, &#39;-&#39;) )
    print( validate_nrg_detailed(ntfn, &#39;_&#39;) )

    &#34;&#34;&#34;
    import re    

    def normalize_path(path):
        &#34;&#34;&#34;
        Replace multiple repeated &#39;/&#39; with just a single &#39;/&#39;
        
        :param path: The file path to normalize.
        :return: The normalized file path with single &#39;/&#39;.
        &#34;&#34;&#34;
        normalized_path = re.sub(r&#39;/+&#39;, &#39;/&#39;, path)
        return normalized_path

    def strip_known_extension(filename, known_extensions):
        &#34;&#34;&#34;
        Strips a known extension from the filename.

        :param filename: The filename from which to strip the extension.
        :param known_extensions: A list of known extensions to strip from the filename.
        :return: The filename with the known extension stripped off, if found.
        &#34;&#34;&#34;
        for ext in known_extensions:
            if filename.endswith(ext):
                # Strip the extension and return the modified filename
                return filename[:-len(ext)]
        # If no known extension is found, return the original filename
        return filename

    import warnings
    if normalize_path( path ) != path:
        path = normalize_path( path )
        warnings.warn(&#34;Probably had multiple repeated slashes eg /// in the file path.  this might cause issues. clean up with re.sub(r&#39;/+&#39;, &#39;/&#39;, path)&#34;)

    known_extensions = [&#34;.nii.gz&#34;, &#34;.nii&#34;, &#34;.mhd&#34;, &#34;.nrrd&#34;, &#34;.mha&#34;, &#34;.json&#34;, &#34;.bval&#34;, &#34;.bvec&#34;]
    known_extensions2 = [ext.lstrip(&#39;.&#39;) for ext in known_extensions]
    def get_extension(filename, known_extensions ):
        # List of known extensions in priority order
        for ext in known_extensions:
            if filename.endswith(ext):
                return ext.strip(&#39;.&#39;)
        return &#34;Invalid extension&#34;
    
    parts = path.split(&#39;/&#39;)
    if len(parts) &lt; 7:  # Checking for minimum path structure
        return False, &#34;Path structure is incomplete. Expected at least 7 components, found {}.&#34;.format(len(parts))
    
    # Extract directory components and filename
    directory_components = parts[1:-1]  # Exclude the root &#39;/&#39; and filename
    filename = parts[-1]
    filename_without_extension = strip_known_extension( filename, known_extensions )
    file_extension = get_extension( filename, known_extensions )
    
    # Validating file extension
    if file_extension not in known_extensions2:
        print( file_extension )
        return False, &#34;Invalid file extension: {}. Expected &#39;nii.gz&#39; or &#39;json&#39;.&#34;.format(file_extension)
    
    # Splitting the filename to validate individual parts
    filename_parts = filename_without_extension.split(separator)
    if len(filename_parts) != 5:  # Expecting 5 parts based on the NRG format
        print( filename_parts )
        return False, &#34;Filename does not have exactly 5 parts separated by &#39;{}&#39;. Found {} parts.&#34;.format(separator, len(filename_parts))
    
    # Reconstruct expected filename from directory components
    expected_filename_parts = directory_components[-5:]
    expected_filename = separator.join(expected_filename_parts)
    if filename_without_extension != expected_filename:
        print( filename_without_extension )
        print(&#34;--- vs expected ---&#34;)
        print( expected_filename )
        return False, &#34;Filename structure does not match directory structure. Expected filename: {}.&#34;.format(expected_filename)
    
    # Validate directory structure against NRG format
    study_name, subject_id, session, modality = directory_components[-4:-1] + [directory_components[-1].split(&#39;/&#39;)[0]]
    if not all([study_name, subject_id, session, modality]):
        return False, &#34;Directory structure does not follow NRG format. Ensure StudyName, SubjectID, Session (ses_x), and Modality are correctly specified.&#34;
    
    # If all checks pass
    return True, &#34;The path conforms to the NRG format.&#34;</code></pre>
</details>
</dd>
<dt id="antspymm.mm.version"><code class="name flex">
<span>def <span class="ident">version</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>report versions of this package and primary dependencies</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary with package name and versions</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
&gt;&gt;&gt; antspymm.version()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def version( ):
    &#34;&#34;&#34;
    report versions of this package and primary dependencies

    Arguments
    ---------
    None

    Returns
    -------
    a dictionary with package name and versions

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.version()
    &#34;&#34;&#34;
    import pkg_resources
    return {
              &#39;tensorflow&#39;: pkg_resources.require(&#34;tensorflow&#34;)[0].version,
              &#39;antspyx&#39;: pkg_resources.require(&#34;antspyx&#34;)[0].version,
              &#39;antspynet&#39;: pkg_resources.require(&#34;antspynet&#34;)[0].version,
              &#39;antspyt1w&#39;: pkg_resources.require(&#34;antspyt1w&#34;)[0].version,
              &#39;antspymm&#39;: pkg_resources.require(&#34;antspymm&#34;)[0].version
              }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.wmh"><code class="name flex">
<span>def <span class="ident">wmh</span></span>(<span>flair, t1, t1seg, mmfromconvexhull=3.0, strict=True, probability_mask=None, prior_probability=None, model='sysu', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs the WMH probability mask and a summary single measurement</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>flair</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>input 3-D FLAIR brain image (not skull-stripped).</dd>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>input 3-D T1 brain image (not skull-stripped).</dd>
<dt><strong><code>t1seg</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>T1 segmentation image</dd>
<dt><strong><code>mmfromconvexhull</code></strong> :&ensp;<code>float</code></dt>
<dd>restrict WMH to regions that are WM or mmfromconvexhull mm away from the
convex hull of the cerebrum.
we choose a default value based on
Figure 4 from:
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf</a></dd>
<dt><strong><code>strict</code></strong> :&ensp;<code>boolean - if True, only use convex hull distance</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>probability_mask</code></strong> :&ensp;<code>None - use to compute wmh just once - then this function</code></dt>
<dd>just does refinement and summary</dd>
<dt><strong><code>prior_probability</code></strong> :&ensp;<code>optional prior probability image in space</code> of <code>the input t1</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>either sysu</code> or <code>hyper</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>WMH probability map and a summary single measurement which is the sum</code> of <code>the WMH map</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wmh( flair, t1, t1seg,
    mmfromconvexhull = 3.0,
    strict=True,
    probability_mask=None,
    prior_probability=None,
    model=&#39;sysu&#39;,
    verbose=False ) :
    &#34;&#34;&#34;
    Outputs the WMH probability mask and a summary single measurement

    Arguments
    ---------
    flair : ANTsImage
        input 3-D FLAIR brain image (not skull-stripped).

    t1 : ANTsImage
        input 3-D T1 brain image (not skull-stripped).

    t1seg : ANTsImage
        T1 segmentation image

    mmfromconvexhull : float
        restrict WMH to regions that are WM or mmfromconvexhull mm away from the
        convex hull of the cerebrum.   we choose a default value based on
        Figure 4 from:
        https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf

    strict: boolean - if True, only use convex hull distance

    probability_mask : None - use to compute wmh just once - then this function
        just does refinement and summary

    prior_probability : optional prior probability image in space of the input t1

    model : either sysu or hyper

    verbose : boolean

    Returns
    ---------
    WMH probability map and a summary single measurement which is the sum of the WMH map

    &#34;&#34;&#34;
    import numpy as np
    import math
    t1_2_flair_reg = ants.registration(flair, t1, type_of_transform = &#39;Rigid&#39;) # Register T1 to Flair
    if probability_mask is None and model == &#39;sysu&#39;:
        if verbose:
            print(&#39;sysu&#39;)
        probability_mask = antspynet.sysu_media_wmh_segmentation( flair )
    elif probability_mask is None and model == &#39;hyper&#39;:
        if verbose:
            print(&#39;hyper&#39;)
        probability_mask = antspynet.hypermapp3r_segmentation( t1_2_flair_reg[&#39;warpedmovout&#39;], flair )
    # t1_2_flair_reg = tra_initializer( flair, t1, n_simulations=4, max_rotation=5, transform=[&#39;rigid&#39;], verbose=False )
    prior_probability_flair = None
    if prior_probability is not None:
        prior_probability_flair = ants.apply_transforms( flair, prior_probability,
            t1_2_flair_reg[&#39;fwdtransforms&#39;] )
    wmseg_mask = ants.threshold_image( t1seg,
        low_thresh = 3, high_thresh = 3).iMath(&#34;FillHoles&#34;)
    wmseg_mask_use = ants.image_clone( wmseg_mask )
    distmask = None
    if mmfromconvexhull &gt; 0:
            convexhull = ants.threshold_image( t1seg, 1, 4 )
            spc2vox = np.prod( ants.get_spacing( t1seg ) )
            voxdist = 0.0
            myspc = ants.get_spacing( t1seg )
            for k in range( t1seg.dimension ):
                voxdist = voxdist + myspc[k] * myspc[k]
            voxdist = math.sqrt( voxdist )
            nmorph = round( 2.0 / voxdist )
            convexhull = ants.morphology( convexhull, &#34;close&#34;, nmorph ).iMath(&#34;FillHoles&#34;)
            dist = ants.iMath( convexhull, &#34;MaurerDistance&#34; ) * -1.0
            distmask = ants.threshold_image( dist, mmfromconvexhull, 1.e80 )
            wmseg_mask = wmseg_mask + distmask
            if strict:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 2, 2 )
            else:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 1, 2 )
    ##############################################################################
    wmseg_2_flair = ants.apply_transforms(flair, wmseg_mask_use,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    seg_2_flair = ants.apply_transforms(flair, t1seg,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    csfmask = ants.threshold_image(seg_2_flair,1,1)
    flairsnr = mask_snr( flair, csfmask, wmseg_2_flair, bias_correct = False )
    probability_mask_WM = wmseg_2_flair * probability_mask # Remove WMH signal outside of WM
    wmh_sum = np.prod( ants.get_spacing( flair ) ) * probability_mask_WM.sum()
    wmh_sum_prior = math.nan
    probability_mask_posterior = None
    if prior_probability_flair is not None:
        probability_mask_posterior = prior_probability_flair * probability_mask # use prior
        wmh_sum_prior = np.prod( ants.get_spacing(flair) ) * probability_mask_posterior.sum()
    if math.isnan( wmh_sum ):
        wmh_sum=0
    if math.isnan( wmh_sum_prior ):
        wmh_sum_prior=0
    flair_evr = antspyt1w.patch_eigenvalue_ratio( flair, 512, [16,16,16], evdepth = 0.9, mask=wmseg_2_flair )
    return{
        &#39;WMH_probability_map_raw&#39;: probability_mask,
        &#39;WMH_probability_map&#39; : probability_mask_WM,
        &#39;WMH_posterior_probability_map&#39; : probability_mask_posterior,
        &#39;wmh_mass&#39;: wmh_sum,
        &#39;wmh_mass_prior&#39;: wmh_sum_prior,
        &#39;wmh_evr&#39; : flair_evr,
        &#39;wmh_SNR&#39; : flairsnr,
        &#39;convexhull_mask&#39;: distmask }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.write_bvals_bvecs"><code class="name flex">
<span>def <span class="ident">write_bvals_bvecs</span></span>(<span>bvals, bvecs, prefix)</span>
</code></dt>
<dd>
<div class="desc"><p>Write FSL FDT bvals and bvecs files</p>
<p>adapted from dipy.external code</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bvals</code></strong> :&ensp;<code>(N,) sequence</code></dt>
<dd>&nbsp;</dd>
<dt>Vector with diffusion gradient strength (one per diffusion</dt>
<dt>acquisition, N=no of acquisitions)</dt>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>(N, 3) array-like</code></dt>
<dd>&nbsp;</dd>
<dt>diffusion gradient directions</dt>
<dt><strong><code>prefix</code></strong> :&ensp;<code>string</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>path to write FDT bvals, bvecs text files
None results in current working directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_bvals_bvecs(bvals, bvecs, prefix ):
    &#39;&#39;&#39; Write FSL FDT bvals and bvecs files

    adapted from dipy.external code

    Parameters
    -------------
    bvals : (N,) sequence
       Vector with diffusion gradient strength (one per diffusion
       acquisition, N=no of acquisitions)
    bvecs : (N, 3) array-like
       diffusion gradient directions
    prefix : string
       path to write FDT bvals, bvecs text files
       None results in current working directory.
    &#39;&#39;&#39;
    _VAL_FMT = &#39;   %e&#39;
    bvals = tuple(bvals)
    bvecs = np.asarray(bvecs)
    bvecs[np.isnan(bvecs)] = 0
    N = len(bvals)
    fname = prefix + &#39;.bval&#39;
    fmt = _VAL_FMT * N + &#39;\n&#39;
    myfile = open(fname, &#39;wt&#39;)
    myfile.write(fmt % bvals)
    myfile.close()
    fname = prefix + &#39;.bvec&#39;
    bvf = open(fname, &#39;wt&#39;)
    for dim_vals in bvecs.T:
        bvf.write(fmt % tuple(dim_vals))
    bvf.close()</code></pre>
</details>
</dd>
<dt id="antspymm.mm.write_mm"><code class="name flex">
<span>def <span class="ident">write_mm</span></span>(<span>output_prefix, mm, mm_norm=None, t1wide=None, separator='_', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>write the tabular and normalization output of the mm function</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>output_prefix</code></strong> :&ensp;<code>prefix for file outputs - modality specific postfix will be added</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>mm
: output of mm function for modality-space processing should be a dictionary with
dictionary entries for each modality.</p>
<dl>
<dt><strong><code>mm_norm</code></strong> :&ensp;<code>output</code> of <code><a title="antspymm.mm.mm" href="#antspymm.mm.mm">mm()</a> function for normalized processing</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1wide</code></strong> :&ensp;<code>wide output data frame from t1 hierarchical</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>separator</code></strong> :&ensp;<code>string</code> or <code>character separator for filenames</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>both csv and image files written to disk.
the primary outputs will be</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>output_prefix + separator + 'mmwide.csv' and *norm.nii.gz images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_mm( output_prefix, mm, mm_norm=None, t1wide=None, separator=&#39;_&#39;, verbose=False ):
    &#34;&#34;&#34;
    write the tabular and normalization output of the mm function

    Parameters
    -------------

    output_prefix : prefix for file outputs - modality specific postfix will be added

    mm  : output of mm function for modality-space processing should be a dictionary with 
        dictionary entries for each modality.

    mm_norm : output of mm function for normalized processing

    t1wide : wide output data frame from t1 hierarchical

    separator : string or character separator for filenames

    verbose : boolean

    Returns
    ---------

    both csv and image files written to disk.  the primary outputs will be
    output_prefix + separator + &#39;mmwide.csv&#39; and *norm.nii.gz images

    &#34;&#34;&#34;
    from dipy.io.streamline import save_tractogram
    if mm_norm is not None:
        for mykey in mm_norm:
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            if mm_norm[mykey] is not None:
                image_write_with_thumbnail( mm_norm[mykey], tempfn )
    thkderk = None
    if t1wide is not None:
        thkderk = t1wide.iloc[: , 1:]
    kkderk = None
    if &#39;kk&#39; in mm:
        if mm[&#39;kk&#39;] is not None:
            kkderk = mm[&#39;kk&#39;][&#39;thickness_dataframe&#39;].iloc[: , 1:]
            mykey=&#39;thickness_image&#39;
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( mm[&#39;kk&#39;][mykey], tempfn )
    nmderk = None
    if &#39;NM&#39; in mm:
        if mm[&#39;NM&#39;] is not None:
            nmderk = mm[&#39;NM&#39;][&#39;NM_dataframe_wide&#39;].iloc[: , 1:]
            for mykey in get_antsimage_keys( mm[&#39;NM&#39;] ):
                tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
                image_write_with_thumbnail( mm[&#39;NM&#39;][mykey], tempfn, thumb=False )

    faderk = mdderk = fat1derk = mdt1derk = None

    if &#39;DTI&#39; in mm:
        if mm[&#39;DTI&#39;] is not None:
            mydti = mm[&#39;DTI&#39;]
            myop = output_prefix + separator
            ants.image_write( mydti[&#39;dti&#39;],  myop + &#39;dti.nii.gz&#39; )
            write_bvals_bvecs( mydti[&#39;bval_LR&#39;], mydti[&#39;bvec_LR&#39;], myop + &#39;reoriented&#39; )
            image_write_with_thumbnail( mydti[&#39;dwi_LR_dewarped&#39;],  myop + &#39;dwi.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;dtrecon_LR_dewarp&#39;][&#39;RGB&#39;] ,  myop + &#39;DTIRGB.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;jhu_labels&#39;],  myop+&#39;dtijhulabels.nii.gz&#39;, mydti[&#39;recon_fa&#39;] )
            image_write_with_thumbnail( mydti[&#39;recon_fa&#39;],  myop+&#39;dtifa.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;recon_md&#39;],  myop+&#39;dtimd.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;b0avg&#39;],  myop+&#39;b0avg.nii.gz&#39; )
            image_write_with_thumbnail( mydti[&#39;dwiavg&#39;],  myop+&#39;dwiavg.nii.gz&#39; )
            faderk = mm[&#39;DTI&#39;][&#39;recon_fa_summary&#39;].iloc[: , 1:]
            mdderk = mm[&#39;DTI&#39;][&#39;recon_md_summary&#39;].iloc[: , 1:]
            fat1derk = mm[&#39;FA_summ&#39;].iloc[: , 1:]
            mdt1derk = mm[&#39;MD_summ&#39;].iloc[: , 1:]
    if &#39;tractography&#39; in mm:
        if mm[&#39;tractography&#39;] is not None:
            ofn = output_prefix + separator + &#39;tractogram.trk&#39;
            save_tractogram( mm[&#39;tractography&#39;][&#39;tractogram&#39;], ofn )
    cnxderk = None
    if &#39;tractography_connectivity&#39; in mm:
        if mm[&#39;tractography_connectivity&#39;] is not None:
            cnxderk = mm[&#39;tractography_connectivity&#39;][&#39;connectivity_wide&#39;].iloc[: , 1:] # NOTE: connectivity_wide is not much tested
            ofn = output_prefix + separator + &#39;dtistreamlineconn.csv&#39;
            pd.DataFrame(mm[&#39;tractography_connectivity&#39;][&#39;connectivity_matrix&#39;]).to_csv( ofn )

    dlist = [
        thkderk,
        kkderk,
        nmderk,
        faderk,
        mdderk,
        fat1derk,
        mdt1derk,
        cnxderk
        ]
    is_all_none = all(element is None for element in dlist)
    if is_all_none:
        mm_wide = pd.DataFrame({&#39;u_hier_id&#39;: [output_prefix] })
    else:
        mm_wide = pd.concat( dlist, axis=1, ignore_index=False )

    mm_wide = mm_wide.copy()
    if &#39;NM&#39; in mm:
        if mm[&#39;NM&#39;] is not None:
            nmwide = dict_to_dataframe( mm[&#39;NM&#39;] )
            if mm_wide.shape[0] &gt; 0 and nmwide.shape[0] &gt; 0:
                nmwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, nmwide ], axis=1, ignore_index=False )
    if &#39;flair&#39; in mm:
        if mm[&#39;flair&#39;] is not None:
            myop = output_prefix + separator + &#39;wmh.nii.gz&#39;
            pngfnb = output_prefix + separator + &#39;wmh_seg.png&#39;
            ants.plot( mm[&#39;flair&#39;][&#39;flair&#39;], mm[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;], axis=2, nslices=21, ncol=7, filename=pngfnb, crop=True )
            if mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;] is not None:
                image_write_with_thumbnail( mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;], myop, thumb=False )
            flwide = dict_to_dataframe( mm[&#39;flair&#39;] )
            if mm_wide.shape[0] &gt; 0 and flwide.shape[0] &gt; 0:
                flwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, flwide ], axis=1, ignore_index=False )
    if &#39;rsf&#39; in mm:
        if mm[&#39;rsf&#39;] is not None:
            fcnxpro=99
            rsfdata = mm[&#39;rsf&#39;]
            if not isinstance( rsfdata, list ):
                rsfdata = [ rsfdata ]
            for rsfpro in rsfdata:
                fcnxpro=str( rsfpro[&#39;paramset&#39;]  )
                pronum = &#39;fcnxpro&#39;+str(fcnxpro)+&#34;_&#34;
                if verbose:
                    print(&#34;Collect rsf data &#34; + pronum)
                new_rsf_wide = dict_to_dataframe( rsfpro )
                new_rsf_wide = pd.concat( [new_rsf_wide, rsfpro[&#39;corr_wide&#39;] ], axis=1, ignore_index=False )
                new_rsf_wide = new_rsf_wide.add_prefix( pronum )
                new_rsf_wide.set_index( mm_wide.index, inplace=True )
                ofn = output_prefix + separator + pronum + &#39;.csv&#39;
                new_rsf_wide.to_csv( ofn )
                mm_wide = pd.concat( [mm_wide, new_rsf_wide ], axis=1, ignore_index=False )
                for mykey in get_antsimage_keys( rsfpro ):
                    myop = output_prefix + separator + pronum + mykey + &#39;.nii.gz&#39;
                    image_write_with_thumbnail( rsfpro[mykey], myop, thumb=True )
                ofn = output_prefix + separator + pronum + &#39;rsfcorr.csv&#39;
                rsfpro[&#39;corr&#39;].to_csv( ofn )
                # apply same principle to new correlation matrix, doesn&#39;t need to be incorporated with mm_wide
                ofn2 = output_prefix + separator + pronum + &#39;nodescorr.csv&#39;
                rsfpro[&#39;fullCorrMat&#39;].to_csv( ofn2 )
    if &#39;DTI&#39; in mm:
        if mm[&#39;DTI&#39;] is not None:
            mydti = mm[&#39;DTI&#39;]
            mm_wide[&#39;dti_tsnr_b0_mean&#39;] =  mydti[&#39;tsnr_b0&#39;].mean()
            mm_wide[&#39;dti_tsnr_dwi_mean&#39;] =  mydti[&#39;tsnr_dwi&#39;].mean()
            mm_wide[&#39;dti_dvars_b0_mean&#39;] =  mydti[&#39;dvars_b0&#39;].mean()
            mm_wide[&#39;dti_dvars_dwi_mean&#39;] =  mydti[&#39;dvars_dwi&#39;].mean()
            mm_wide[&#39;dti_ssnr_b0_mean&#39;] =  mydti[&#39;ssnr_b0&#39;].mean()
            mm_wide[&#39;dti_ssnr_dwi_mean&#39;] =  mydti[&#39;ssnr_dwi&#39;].mean()
            mm_wide[&#39;dti_fa_evr&#39;] =  mydti[&#39;fa_evr&#39;]
            mm_wide[&#39;dti_fa_SNR&#39;] =  mydti[&#39;fa_SNR&#39;]
            if mydti[&#39;framewise_displacement&#39;] is not None:
                mm_wide[&#39;dti_high_motion_count&#39;] =  mydti[&#39;high_motion_count&#39;]
                mm_wide[&#39;dti_FD_mean&#39;] = mydti[&#39;framewise_displacement&#39;].mean()
                mm_wide[&#39;dti_FD_max&#39;] = mydti[&#39;framewise_displacement&#39;].max()
                mm_wide[&#39;dti_FD_sd&#39;] = mydti[&#39;framewise_displacement&#39;].std()
                fdfn = output_prefix + separator + &#39;_fd.csv&#39;
            else:
                mm_wide[&#39;dti_FD_mean&#39;] = mm_wide[&#39;dti_FD_max&#39;] = mm_wide[&#39;dti_FD_sd&#39;] = &#39;NA&#39;

    if &#39;perf&#39; in mm:
        if mm[&#39;perf&#39;] is not None:
            perfpro = mm[&#39;perf&#39;]
            prwide = dict_to_dataframe( perfpro )
            if mm_wide.shape[0] &gt; 0 and prwide.shape[0] &gt; 0:
                prwide.set_index( mm_wide.index, inplace=True )
            mm_wide = pd.concat( [mm_wide, prwide ], axis=1, ignore_index=False )
            if &#39;perf_dataframe&#39; in perfpro.keys():
                pderk = perfpro[&#39;perf_dataframe&#39;].iloc[: , 1:]
                pderk.set_index( mm_wide.index, inplace=True )
                mm_wide = pd.concat( [ mm_wide, pderk ], axis=1, ignore_index=False )
            else:
                print(&#34;FIXME - perfusion dataframe&#34;)
            for mykey in get_antsimage_keys( mm[&#39;perf&#39;] ):
                tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
                image_write_with_thumbnail( mm[&#39;perf&#39;][mykey], tempfn, thumb=False )

    mmwidefn = output_prefix + separator + &#39;mmwide.csv&#39;
    mm_wide.to_csv( mmwidefn )
    if verbose:
        print( output_prefix + &#34; write_mm done.&#34; )
    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="antspymm" href="index.html">antspymm</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="antspymm.mm.aggregate_antspymm_results" href="#antspymm.mm.aggregate_antspymm_results">aggregate_antspymm_results</a></code></li>
<li><code><a title="antspymm.mm.aggregate_antspymm_results_sdf" href="#antspymm.mm.aggregate_antspymm_results_sdf">aggregate_antspymm_results_sdf</a></code></li>
<li><code><a title="antspymm.mm.alff_image" href="#antspymm.mm.alff_image">alff_image</a></code></li>
<li><code><a title="antspymm.mm.alffmap" href="#antspymm.mm.alffmap">alffmap</a></code></li>
<li><code><a title="antspymm.mm.assemble_modality_specific_dataframes" href="#antspymm.mm.assemble_modality_specific_dataframes">assemble_modality_specific_dataframes</a></code></li>
<li><code><a title="antspymm.mm.augment_image" href="#antspymm.mm.augment_image">augment_image</a></code></li>
<li><code><a title="antspymm.mm.average_blind_qc_by_modality" href="#antspymm.mm.average_blind_qc_by_modality">average_blind_qc_by_modality</a></code></li>
<li><code><a title="antspymm.mm.average_mm_df" href="#antspymm.mm.average_mm_df">average_mm_df</a></code></li>
<li><code><a title="antspymm.mm.best_mmm" href="#antspymm.mm.best_mmm">best_mmm</a></code></li>
<li><code><a title="antspymm.mm.bids_2_nrg" href="#antspymm.mm.bids_2_nrg">bids_2_nrg</a></code></li>
<li><code><a title="antspymm.mm.bind_wide_mm_csvs" href="#antspymm.mm.bind_wide_mm_csvs">bind_wide_mm_csvs</a></code></li>
<li><code><a title="antspymm.mm.blind_image_assessment" href="#antspymm.mm.blind_image_assessment">blind_image_assessment</a></code></li>
<li><code><a title="antspymm.mm.boot_wmh" href="#antspymm.mm.boot_wmh">boot_wmh</a></code></li>
<li><code><a title="antspymm.mm.bvec_reorientation" href="#antspymm.mm.bvec_reorientation">bvec_reorientation</a></code></li>
<li><code><a title="antspymm.mm.clean_tmp_directory" href="#antspymm.mm.clean_tmp_directory">clean_tmp_directory</a></code></li>
<li><code><a title="antspymm.mm.collect_blind_qc_by_modality" href="#antspymm.mm.collect_blind_qc_by_modality">collect_blind_qc_by_modality</a></code></li>
<li><code><a title="antspymm.mm.concat_dewarp" href="#antspymm.mm.concat_dewarp">concat_dewarp</a></code></li>
<li><code><a title="antspymm.mm.crop_mcimage" href="#antspymm.mm.crop_mcimage">crop_mcimage</a></code></li>
<li><code><a title="antspymm.mm.dewarp_imageset" href="#antspymm.mm.dewarp_imageset">dewarp_imageset</a></code></li>
<li><code><a title="antspymm.mm.dict_to_dataframe" href="#antspymm.mm.dict_to_dataframe">dict_to_dataframe</a></code></li>
<li><code><a title="antspymm.mm.dipy_dti_recon" href="#antspymm.mm.dipy_dti_recon">dipy_dti_recon</a></code></li>
<li><code><a title="antspymm.mm.docsamson" href="#antspymm.mm.docsamson">docsamson</a></code></li>
<li><code><a title="antspymm.mm.down2iso" href="#antspymm.mm.down2iso">down2iso</a></code></li>
<li><code><a title="antspymm.mm.dti_reg" href="#antspymm.mm.dti_reg">dti_reg</a></code></li>
<li><code><a title="antspymm.mm.dti_template" href="#antspymm.mm.dti_template">dti_template</a></code></li>
<li><code><a title="antspymm.mm.dvars" href="#antspymm.mm.dvars">dvars</a></code></li>
<li><code><a title="antspymm.mm.dwi_closest_peak_tracking" href="#antspymm.mm.dwi_closest_peak_tracking">dwi_closest_peak_tracking</a></code></li>
<li><code><a title="antspymm.mm.dwi_deterministic_tracking" href="#antspymm.mm.dwi_deterministic_tracking">dwi_deterministic_tracking</a></code></li>
<li><code><a title="antspymm.mm.dwi_streamline_connectivity" href="#antspymm.mm.dwi_streamline_connectivity">dwi_streamline_connectivity</a></code></li>
<li><code><a title="antspymm.mm.dwi_streamline_pairwise_connectivity" href="#antspymm.mm.dwi_streamline_pairwise_connectivity">dwi_streamline_pairwise_connectivity</a></code></li>
<li><code><a title="antspymm.mm.enantiomorphic_filling_without_mask" href="#antspymm.mm.enantiomorphic_filling_without_mask">enantiomorphic_filling_without_mask</a></code></li>
<li><code><a title="antspymm.mm.filter_image_files" href="#antspymm.mm.filter_image_files">filter_image_files</a></code></li>
<li><code><a title="antspymm.mm.foreground_background_snr" href="#antspymm.mm.foreground_background_snr">foreground_background_snr</a></code></li>
<li><code><a title="antspymm.mm.generate_mm_dataframe" href="#antspymm.mm.generate_mm_dataframe">generate_mm_dataframe</a></code></li>
<li><code><a title="antspymm.mm.get_average_dwi_b0" href="#antspymm.mm.get_average_dwi_b0">get_average_dwi_b0</a></code></li>
<li><code><a title="antspymm.mm.get_average_rsf" href="#antspymm.mm.get_average_rsf">get_average_rsf</a></code></li>
<li><code><a title="antspymm.mm.get_data" href="#antspymm.mm.get_data">get_data</a></code></li>
<li><code><a title="antspymm.mm.get_dti" href="#antspymm.mm.get_dti">get_dti</a></code></li>
<li><code><a title="antspymm.mm.get_models" href="#antspymm.mm.get_models">get_models</a></code></li>
<li><code><a title="antspymm.mm.get_names_from_data_frame" href="#antspymm.mm.get_names_from_data_frame">get_names_from_data_frame</a></code></li>
<li><code><a title="antspymm.mm.get_valid_modalities" href="#antspymm.mm.get_valid_modalities">get_valid_modalities</a></code></li>
<li><code><a title="antspymm.mm.hierarchical_modality_summary" href="#antspymm.mm.hierarchical_modality_summary">hierarchical_modality_summary</a></code></li>
<li><code><a title="antspymm.mm.highest_quality_repeat" href="#antspymm.mm.highest_quality_repeat">highest_quality_repeat</a></code></li>
<li><code><a title="antspymm.mm.image_write_with_thumbnail" href="#antspymm.mm.image_write_with_thumbnail">image_write_with_thumbnail</a></code></li>
<li><code><a title="antspymm.mm.impute_fa" href="#antspymm.mm.impute_fa">impute_fa</a></code></li>
<li><code><a title="antspymm.mm.joint_dti_recon" href="#antspymm.mm.joint_dti_recon">joint_dti_recon</a></code></li>
<li><code><a title="antspymm.mm.loop_timeseries_censoring" href="#antspymm.mm.loop_timeseries_censoring">loop_timeseries_censoring</a></code></li>
<li><code><a title="antspymm.mm.mask_snr" href="#antspymm.mm.mask_snr">mask_snr</a></code></li>
<li><code><a title="antspymm.mm.match_modalities" href="#antspymm.mm.match_modalities">match_modalities</a></code></li>
<li><code><a title="antspymm.mm.mc_denoise" href="#antspymm.mm.mc_denoise">mc_denoise</a></code></li>
<li><code><a title="antspymm.mm.mc_reg" href="#antspymm.mm.mc_reg">mc_reg</a></code></li>
<li><code><a title="antspymm.mm.mc_resample_image_to_target" href="#antspymm.mm.mc_resample_image_to_target">mc_resample_image_to_target</a></code></li>
<li><code><a title="antspymm.mm.merge_dwi_data" href="#antspymm.mm.merge_dwi_data">merge_dwi_data</a></code></li>
<li><code><a title="antspymm.mm.merge_mm_dataframe" href="#antspymm.mm.merge_mm_dataframe">merge_mm_dataframe</a></code></li>
<li><code><a title="antspymm.mm.merge_timeseries_data" href="#antspymm.mm.merge_timeseries_data">merge_timeseries_data</a></code></li>
<li><code><a title="antspymm.mm.merge_wides_to_study_dataframe" href="#antspymm.mm.merge_wides_to_study_dataframe">merge_wides_to_study_dataframe</a></code></li>
<li><code><a title="antspymm.mm.middle_slice_snr" href="#antspymm.mm.middle_slice_snr">middle_slice_snr</a></code></li>
<li><code><a title="antspymm.mm.mm" href="#antspymm.mm.mm">mm</a></code></li>
<li><code><a title="antspymm.mm.mm_csv" href="#antspymm.mm.mm_csv">mm_csv</a></code></li>
<li><code><a title="antspymm.mm.mm_nrg" href="#antspymm.mm.mm_nrg">mm_nrg</a></code></li>
<li><code><a title="antspymm.mm.mm_read" href="#antspymm.mm.mm_read">mm_read</a></code></li>
<li><code><a title="antspymm.mm.mm_read_to_3d" href="#antspymm.mm.mm_read_to_3d">mm_read_to_3d</a></code></li>
<li><code><a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_ee" href="#antspymm.mm.novelty_detection_ee">novelty_detection_ee</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_lof" href="#antspymm.mm.novelty_detection_lof">novelty_detection_lof</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_loop" href="#antspymm.mm.novelty_detection_loop">novelty_detection_loop</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_quantile" href="#antspymm.mm.novelty_detection_quantile">novelty_detection_quantile</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_svm" href="#antspymm.mm.novelty_detection_svm">novelty_detection_svm</a></code></li>
<li><code><a title="antspymm.mm.nrg_2_bids" href="#antspymm.mm.nrg_2_bids">nrg_2_bids</a></code></li>
<li><code><a title="antspymm.mm.nrg_filelist_to_dataframe" href="#antspymm.mm.nrg_filelist_to_dataframe">nrg_filelist_to_dataframe</a></code></li>
<li><code><a title="antspymm.mm.nrg_format_path" href="#antspymm.mm.nrg_format_path">nrg_format_path</a></code></li>
<li><code><a title="antspymm.mm.outlierness_by_modality" href="#antspymm.mm.outlierness_by_modality">outlierness_by_modality</a></code></li>
<li><code><a title="antspymm.mm.parse_nrg_filename" href="#antspymm.mm.parse_nrg_filename">parse_nrg_filename</a></code></li>
<li><code><a title="antspymm.mm.quantile_snr" href="#antspymm.mm.quantile_snr">quantile_snr</a></code></li>
<li><code><a title="antspymm.mm.quick_viz_mm_nrg" href="#antspymm.mm.quick_viz_mm_nrg">quick_viz_mm_nrg</a></code></li>
<li><code><a title="antspymm.mm.read_mm_csv" href="#antspymm.mm.read_mm_csv">read_mm_csv</a></code></li>
<li><code><a title="antspymm.mm.remove_elements_from_numpy_array" href="#antspymm.mm.remove_elements_from_numpy_array">remove_elements_from_numpy_array</a></code></li>
<li><code><a title="antspymm.mm.remove_volumes_from_timeseries" href="#antspymm.mm.remove_volumes_from_timeseries">remove_volumes_from_timeseries</a></code></li>
<li><code><a title="antspymm.mm.resting_state_fmri_networks" href="#antspymm.mm.resting_state_fmri_networks">resting_state_fmri_networks</a></code></li>
<li><code><a title="antspymm.mm.score_fmri_censoring" href="#antspymm.mm.score_fmri_censoring">score_fmri_censoring</a></code></li>
<li><code><a title="antspymm.mm.segment_timeseries_by_meanvalue" href="#antspymm.mm.segment_timeseries_by_meanvalue">segment_timeseries_by_meanvalue</a></code></li>
<li><code><a title="antspymm.mm.slice_snr" href="#antspymm.mm.slice_snr">slice_snr</a></code></li>
<li><code><a title="antspymm.mm.study_dataframe_from_matched_dataframe" href="#antspymm.mm.study_dataframe_from_matched_dataframe">study_dataframe_from_matched_dataframe</a></code></li>
<li><code><a title="antspymm.mm.super_res_mcimage" href="#antspymm.mm.super_res_mcimage">super_res_mcimage</a></code></li>
<li><code><a title="antspymm.mm.t1_based_dwi_brain_extraction" href="#antspymm.mm.t1_based_dwi_brain_extraction">t1_based_dwi_brain_extraction</a></code></li>
<li><code><a title="antspymm.mm.threaded_bind_wide_mm_csvs" href="#antspymm.mm.threaded_bind_wide_mm_csvs">threaded_bind_wide_mm_csvs</a></code></li>
<li><code><a title="antspymm.mm.timeseries_reg" href="#antspymm.mm.timeseries_reg">timeseries_reg</a></code></li>
<li><code><a title="antspymm.mm.tra_initializer" href="#antspymm.mm.tra_initializer">tra_initializer</a></code></li>
<li><code><a title="antspymm.mm.trim_dti_mask" href="#antspymm.mm.trim_dti_mask">trim_dti_mask</a></code></li>
<li><code><a title="antspymm.mm.tsnr" href="#antspymm.mm.tsnr">tsnr</a></code></li>
<li><code><a title="antspymm.mm.validate_nrg_file_format" href="#antspymm.mm.validate_nrg_file_format">validate_nrg_file_format</a></code></li>
<li><code><a title="antspymm.mm.version" href="#antspymm.mm.version">version</a></code></li>
<li><code><a title="antspymm.mm.wmh" href="#antspymm.mm.wmh">wmh</a></code></li>
<li><code><a title="antspymm.mm.write_bvals_bvecs" href="#antspymm.mm.write_bvals_bvecs">write_bvals_bvecs</a></code></li>
<li><code><a title="antspymm.mm.write_mm" href="#antspymm.mm.write_mm">write_mm</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>