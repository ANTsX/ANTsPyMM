<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>antspymm.mm API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>antspymm.mm</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">__all__ = [&#39;version&#39;,
    &#39;mm_read&#39;,
    &#39;mm_read_to_3d&#39;,
    &#39;image_write_with_thumbnail&#39;,
    &#39;nrg_format_path&#39;,
    &#39;highest_quality_repeat&#39;,
    &#39;match_modalities&#39;,
    &#39;mc_resample_image_to_target&#39;,
    &#39;nrg_filelist_to_dataframe&#39;,
    &#39;merge_timeseries_data&#39;,
    &#39;timeseries_reg&#39;,
    &#39;merge_dwi_data&#39;,
    &#39;outlierness_by_modality&#39;,
    &#39;bvec_reorientation&#39;,
    &#39;dti_reg&#39;,
    &#39;mc_reg&#39;,
    &#39;get_data&#39;,
    &#39;get_models&#39;,
    &#39;get_valid_modalities&#39;,
    &#39;dewarp_imageset&#39;,
    &#39;super_res_mcimage&#39;,
    &#39;segment_timeseries_by_meanvalue&#39;,
    &#39;get_average_rsf&#39;,
    &#39;get_average_dwi_b0&#39;,
    &#39;dti_template&#39;,
    &#39;t1_based_dwi_brain_extraction&#39;,
    &#39;mc_denoise&#39;,
    &#39;tsnr&#39;,
    &#39;dvars&#39;,
    &#39;slice_snr&#39;,
    &#39;impute_fa&#39;,
    &#39;trim_dti_mask&#39;,
    &#39;dipy_dti_recon&#39;,
    &#39;concat_dewarp&#39;,
    &#39;joint_dti_recon&#39;,
    &#39;middle_slice_snr&#39;,
    &#39;foreground_background_snr&#39;,
    &#39;quantile_snr&#39;,
    &#39;mask_snr&#39;,
    &#39;dwi_deterministic_tracking&#39;,
    &#39;dwi_closest_peak_tracking&#39;,
    &#39;dwi_streamline_pairwise_connectivity&#39;,
    &#39;dwi_streamline_connectivity&#39;,
    &#39;hierarchical_modality_summary&#39;,
    &#39;tra_initializer&#39;,
    &#39;neuromelanin&#39;,
    &#39;resting_state_fmri_networks&#39;,
    &#39;write_bvals_bvecs&#39;,
    &#39;crop_mcimage&#39;,
    &#39;mm&#39;,
    &#39;write_mm&#39;,
    &#39;mm_nrg&#39;,
    &#39;mm_csv&#39;,
    &#39;collect_blind_qc_by_modality&#39;,
    &#39;alffmap&#39;,
    &#39;alff_image&#39;,
    &#39;down2iso&#39;,
    &#39;read_mm_csv&#39;,
    &#39;assemble_modality_specific_dataframes&#39;,
    &#39;bind_wide_mm_csvs&#39;,
    &#39;merge_mm_dataframe&#39;,
    &#39;augment_image&#39;,
    &#39;boot_wmh&#39;,
    &#39;threaded_bind_wide_mm_csvs&#39;,
    &#39;get_names_from_data_frame&#39;,
    &#39;average_mm_df&#39;,
    &#39;quick_viz_mm_nrg&#39;,
    &#39;blind_image_assessment&#39;,
    &#39;average_blind_qc_by_modality&#39;,
    &#39;best_mmm&#39;,
    &#39;nrg_2_bids&#39;,
    &#39;bids_2_nrg&#39;,
    &#39;parse_nrg_filename&#39;,
    &#39;novelty_detection_svm&#39;,
    &#39;novelty_detection_ee&#39;,
    &#39;novelty_detection_lof&#39;,
    &#39;novelty_detection_loop&#39;,
    &#39;novelty_detection_quantile&#39;,
    &#39;generate_mm_dataframe&#39;,
    &#39;study_dataframe_from_matched_dataframe&#39;,
    &#39;merge_wides_to_study_dataframe&#39;,
    &#39;wmh&#39;]

from pathlib import Path
from pathlib import PurePath
import os
import pandas as pd
import math
import os.path
from os import path
import pickle
import sys
import numpy as np
import random
import functools
from operator import mul
from scipy.sparse.linalg import svds
from scipy.stats import pearsonr
import re
import datetime as dt
from collections import Counter
import tempfile


from dipy.core.histeq import histeq
import dipy.reconst.dti as dti
from dipy.core.gradients import (gradient_table, gradient_table_from_gradient_strength_bvecs)
from dipy.io.gradients import read_bvals_bvecs
from dipy.segment.mask import median_otsu
from dipy.reconst.dti import fractional_anisotropy, color_fa
import nibabel as nib

import ants
import antspynet
import antspyt1w
import siq
import tensorflow as tf

from multiprocessing import Pool
import glob as glob

DATA_PATH = os.path.expanduser(&#39;~/.antspymm/&#39;)

def version( ):
    &#34;&#34;&#34;
    report versions of this package and primary dependencies

    Arguments
    ---------
    None

    Returns
    -------
    a dictionary with package name and versions

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.version()
    &#34;&#34;&#34;
    import pkg_resources
    return {
              &#39;tensorflow&#39;: pkg_resources.require(&#34;tensorflow&#34;)[0].version,
              &#39;antspyx&#39;: pkg_resources.require(&#34;antspyx&#34;)[0].version,
              &#39;antspynet&#39;: pkg_resources.require(&#34;antspynet&#34;)[0].version,
              &#39;antspyt1w&#39;: pkg_resources.require(&#34;antspyt1w&#34;)[0].version,
              &#39;antspymm&#39;: pkg_resources.require(&#34;antspymm&#34;)[0].version
              }

def get_valid_modalities( long=False, asString=False, qc=False ):
    &#34;&#34;&#34;
    return a list of valid modality identifiers used in NRG modality designation
    and that can be processed by this package.

    long - return the long version

    asString - concat list to string
    &#34;&#34;&#34;
    if long:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;, &#34;DTI&#34;, &#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;T2Flair&#34;, &#34;dwi&#34;, &#34;func&#34; ]
    elif qc:
        mymod = [ &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;,&#39;DTIdwi&#39;,&#39;DTIb0&#39;]
    else:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;DTI&#34;,&#34;T2Flair&#34; ]
    if not asString:
        return mymod
    else:
        mymodchar=&#34;&#34;
        for x in mymod:
            mymodchar = mymodchar + &#34; &#34; + str(x)
        return mymodchar

def generate_mm_dataframe(
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename=[],
        rsf_filenames=[],
        dti_filenames=[],
        nm_filenames=[]
):
    from os.path import exists
    valid_modalities = get_valid_modalities()
    if not isinstance(t1_filename, str):
        raise ValueError(&#34;t1_filename is not a string&#34;)
    if not exists(t1_filename):
        raise ValueError(&#34;t1_filename does not exist&#34;)
    if modality not in valid_modalities:
        raise ValueError(&#39;modality &#39; + str(modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))
    # if not exists( output_image_directory ):
    #    raise ValueError(&#34;output_image_directory does not exist&#34;)
    if not exists( source_image_directory ):
        raise ValueError(&#34;source_image_directory does not exist&#34;)
    if len( rsf_filenames ) &lt; 2:
        for k in range(len(rsf_filenames),2):
            rsf_filenames.append(None)
    if len( dti_filenames ) &lt; 2:
        for k in range(len(dti_filenames),2):
            dti_filenames.append(None)
    if len( nm_filenames ) &lt; 10:
        for k in range(len(nm_filenames),10):
            nm_filenames.append(None)
    # check modality names
    if not &#34;T1w&#34; in t1_filename:
        raise ValueError(&#34;T1w is not in t1 filename &#34; + t1_filename)
    if flair_filename is not None:
        if isinstance(flair_filename,list):
            if (len(flair_filename) == 0):
                flair_filename=None
            else:
                print(&#34;Take first entry from flair_filename list&#34;)
                flair_filename=flair_filename[0]
    if flair_filename is not None and not &#34;lair&#34; in flair_filename:
            raise ValueError(&#34;flair is not flair filename &#34; + flair_filename)
    for k in nm_filenames:
        if k is not None:
            if not &#34;NM&#34; in k:
                raise ValueError(&#34;NM is not flair filename &#34; + k)
    for k in dti_filenames:
        if k is not None:
            if not &#34;DTI&#34; in k and not &#34;dwi&#34; in k:
                raise ValueError(&#34;DTI/DWI is not dti filename &#34; + k)
    for k in rsf_filenames:
        if k is not None:
            if not &#34;fMRI&#34; in k and not &#34;func&#34; in k:
                raise ValueError(&#34;rsfMRI/func is not rsfmri filename &#34; + k)
    allfns = [t1_filename] + [flair_filename] + nm_filenames + dti_filenames + rsf_filenames
    for k in allfns:
        if k is not None:
            if not isinstance(k, str):
                raise ValueError(str(k) + &#34; is not a string&#34;)
            if not exists( k ):
                raise ValueError( &#34;image &#34; + k + &#34; does not exist&#34;)
    coredata = [
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename]
    mydata0 = coredata +  rsf_filenames + dti_filenames
    mydata = mydata0 + nm_filenames
    corecols = [
        &#39;projectID&#39;,
        &#39;subjectID&#39;,
        &#39;date&#39;,
        &#39;imageID&#39;,
        &#39;modality&#39;,
        &#39;sourcedir&#39;,
        &#39;outputdir&#39;,
        &#39;filename&#39;,
        &#39;flairid&#39;]
    mycols0 = corecols + [
        &#39;rsfid1&#39;, &#39;rsfid2&#39;,
        &#39;dtid1&#39;, &#39;dtid2&#39;]
    nmext = [
        &#39;nmid1&#39;, &#39;nmid2&#39; &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;,
        &#39;nmid6&#39;, &#39;nmid7&#39;,&#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;nmid11&#39;
    ]
    mycols = mycols0 + nmext
    print(len(mydata0))
    print(len(nm_filenames))
    print(len(mycols0))
    print(len(nmext))
    studycsv = pd.DataFrame([ mydata ],
        columns=mycols)
    return studycsv

def parse_nrg_filename( x, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    split a NRG filename into its named parts
    &#34;&#34;&#34;
    temp = x.split( separator )
    if len(temp) != 5:
        raise ValueError(x + &#34; not a valid NRG filename&#34;)
    return {
        &#39;project&#39;:temp[0],
        &#39;subjectID&#39;:temp[1],
        &#39;date&#39;:temp[2],
        &#39;modality&#39;:temp[3],
        &#39;imageID&#39;:temp[4]
    }



def nrg_2_bids( nrg_filename ):
    &#34;&#34;&#34;
    Convert an NRG filename to BIDS path/filename.

    Parameters:
    nrg_filename (str): The NRG filename to convert.

    Returns:
    str: The BIDS path/filename.
    &#34;&#34;&#34;

    # Split the NRG filename into its components
    nrg_dirname, nrg_basename = os.path.split(nrg_filename)
    nrg_suffix = &#39;.&#39; + nrg_basename.split(&#39;.&#39;,1)[-1]
    nrg_basename = nrg_basename.replace(nrg_suffix, &#39;&#39;) # remove ext
    nrg_parts = nrg_basename.split(&#39;-&#39;)
    nrg_subject_id = nrg_parts[1]
    nrg_modality = nrg_parts[3]
    nrg_repeat= nrg_parts[4]

    # Build the BIDS path/filename
    bids_dirname = os.path.join(nrg_dirname, &#39;bids&#39;)
    bids_subject = f&#39;sub-{nrg_subject_id}&#39;
    bids_session = f&#39;ses-{nrg_repeat}&#39;

    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))

    if nrg_modality == &#39;T1w&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;T1w&#39;

    if nrg_modality == &#39;T2Flair&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;flair&#39;

    if nrg_modality == &#39;NM2DMT&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;nm2dmt&#39;

    if nrg_modality == &#39;DTI&#39; or nrg_modality == &#39;DTI_RL&#39; or nrg_modality == &#39;DTI_LR&#39; :
        bids_modality_folder = &#39;dwi&#39;
        bids_modality_filename = &#39;dwi&#39;

    if nrg_modality == &#39;rsfMRI&#39; or nrg_modality == &#39;rsfMRI_RL&#39; or nrg_modality == &#39;rsfMRI_LR&#39; :
        bids_modality_folder = &#39;func&#39;
        bids_modality_filename = &#39;func&#39;

    bids_suffix = nrg_suffix[1:]
    bids_filename = f&#39;{bids_subject}_{bids_session}_{bids_modality_filename}.{bids_suffix}&#39;

    # Return bids filepath/filename
    return os.path.join(bids_dirname, bids_subject, bids_session, bids_modality_folder, bids_filename)


def bids_2_nrg( bids_filename, project_name, date, nrg_modality=None ):
    &#34;&#34;&#34;
    Convert a BIDS filename to NRG path/filename.

    Parameters:
    bids_filename (str): The BIDS filename to convert
    project_name (str) : Name of project (i.e. PPMI)
    date (str) : Date of image acquisition


    Returns:
    str: The NRG path/filename.
    &#34;&#34;&#34;

    bids_dirname, bids_basename = os.path.split(bids_filename)
    bids_suffix = &#39;.&#39;+ bids_basename.split(&#39;.&#39;,1)[-1]
    bids_basename = bids_basename.replace(bids_suffix, &#39;&#39;) # remove ext
    bids_parts = bids_basename.split(&#39;_&#39;)
    nrg_subject_id = bids_parts[0].replace(&#39;sub-&#39;,&#39;&#39;)
    nrg_image_id = bids_parts[1].replace(&#39;ses-&#39;, &#39;&#39;)
    bids_modality = bids_parts[2]
    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality: &#34; + get_valid_modalities(asString=True))

    if bids_modality == &#39;anat&#39; and nrg_modality is None :
        nrg_modality = &#39;T1w&#39;

    if bids_modality == &#39;dwi&#39; and nrg_modality is None  :
        nrg_modality = &#39;DTI&#39;

    if bids_modality == &#39;func&#39; and nrg_modality is None  :
        nrg_modality = &#39;rsfMRI&#39;

    nrg_suffix = bids_suffix[1:]
    nrg_filename = f&#39;{project_name}-{nrg_subject_id}-{date}-{nrg_modality}-{nrg_image_id}.{nrg_suffix}&#39;

    return os.path.join(project_name, nrg_subject_id, date, nrg_modality, nrg_image_id,nrg_filename)

def collect_blind_qc_by_modality( modality_path, set_index_to_fn=True ):
    &#34;&#34;&#34;
    Collects blind QC data from multiple CSV files with the same modality.

    Args:

    modality_path (str): The path to the folder containing the CSV files.

    set_index_to_fn: boolean

    Returns:
    Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.
    &#34;&#34;&#34;
    import glob as glob
    fns = glob.glob( modality_path )
    fns.sort()
    jdf = pd.DataFrame()
    for k in range(len(fns)):
        temp=pd.read_csv(fns[k])
        if not &#39;fn&#39; in temp.keys():
            temp[&#39;fn&#39;]=fns[k]
        jdf=pd.concat( [jdf,temp])
    if set_index_to_fn:
        jdf.reset_index(drop=True)
        if &#34;Unnamed: 0&#34; in jdf.columns:
            holder=jdf.pop( &#34;Unnamed: 0&#34; )
        jdf.set_index(&#39;fn&#39;)
    return jdf


def outlierness_by_modality( qcdf, uid=&#39;fn&#39;, outlier_columns = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;], verbose=False ):
    &#34;&#34;&#34;
    Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.  LOF appears to be more conservative.  This function will impute missing columns with the mean.

    Args:
    - qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
    - uid: (str) Unique identifier for a subject. Default is &#39;fn&#39;.
    - outlier_columns: (list) List of columns containing outlier information. Default is [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;].
    - verbose: (bool) If True, prints information for each modality. Default is False.

    Returns:
    - qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the &#39;ol_loop&#39; and &#39;ol_lof&#39; column.  Higher values near 1 are more outlying.

    Raises:
    - ValueError: If uid is not present in the dataframe.

    Example:
    &gt;&gt;&gt; df = pd.read_csv(&#39;data.csv&#39;)
    &gt;&gt;&gt; outlierness_by_modality(df)
    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import LocalOutlierFactor
    qcdfout = qcdf.copy()
    if uid not in qcdfout.keys():
        raise ValueError(uid + &#34; not in dataframe&#34;)
    if &#39;ol_loop&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_loop&#39;]=math.nan
    if &#39;ol_lof&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_lof&#39;]=math.nan
    for mod in get_valid_modalities( qc=True ):
        lof = LocalOutlierFactor()
        locsel = qcdfout[&#34;modality&#34;] == mod
        rr = qcdfout[locsel][outlier_columns]
        with pd.option_context(&#39;mode.use_inf_as_na&#39;, True):
            for myolcol in outlier_columns:
                rr[myolcol].fillna(rr[myolcol].mean(), inplace=True)
        if rr.shape[0] &gt; 1:
            if verbose:
                print(mod)
            myneigh = np.min( [24, int(np.round(rr.shape[0]*0.5)) ] )
            temp = antspyt1w.loop_outlierness(rr.astype(float), standardize=True, extent=3, n_neighbors=myneigh, cluster_labels=None)
            qcdfout.loc[locsel,&#39;ol_loop&#39;]=temp
            yhat = lof.fit_predict(rr)
            temp = lof.negative_outlier_factor_*(-1.0)
            temp = temp - temp.min()
            yhat[ yhat == 1] = 0
            yhat[ yhat == -1] = 1 # these are outliers
            qcdfout.loc[locsel,&#39;ol_lof_decision&#39;]=yhat
            qcdfout.loc[locsel,&#39;ol_lof&#39;]=temp/temp.max()
    return qcdfout


def nrg_format_path( projectID, subjectID, date, modality, imageID, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    create the NRG path on disk given the project, subject id, date, modality and image id

    Arguments
    ---------

    projectID : string for the project e.g. PPMI

    subjectID : string uniquely identifying the subject e.g. 0001

    date : string for the date usually 20550228 ie YYYYMMDD format

    modality : string should be one of T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)

    imageID : string uniquely identifying the specific image

    separator : default to -

    Returns
    -------
    the path where one would write the image on disk

    &#34;&#34;&#34;
    thedirectory = os.path.join( str(projectID), str(subjectID), str(date), str(modality), str(imageID) )
    thefilename = str(projectID) + separator + str(subjectID) + separator + str(date) + separator + str(modality) + separator + str(imageID)
    return os.path.join( thedirectory, thefilename )


def study_dataframe_from_matched_dataframe( matched_dataframe, rootdir, outputdir, verbose=False ):
    &#34;&#34;&#34;
    converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv

    matched_dataframe : output of antspymm.match_modalities

    rootdir : location for the input data root folder (in e.g. NRG format)

    outputdir : location for the output data

    verbose : boolean
    &#34;&#34;&#34;
    iext=&#39;.nii.gz&#39;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;fn&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in matched_dataframe.keys():
            raise ValueError(&#39;matched_dataframe is missing column &#39; +musthavecols[k] + &#39; in study_dataframe_from_qc_dataframe&#39; )
    csvrow=matched_dataframe.dropna(axis=1)
    pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
    dt=str(csvrow[&#39;date&#39;].iloc[0])
    iid=str(csvrow[&#39;imageID&#39;].iloc[0])
    nrgt1fn=os.path.join( rootdir, pid, sid, dt, &#39;T1w&#39;, iid, str(csvrow[&#39;fn&#39;].iloc[0]+iext) )
    if not exists( nrgt1fn ):
        raise ValueError(&#34;T1 &#34; + nrgt1fn + &#34; does not exist in study_dataframe_from_qc_dataframe&#34;)
    flList=[]
    dtList=[]
    rsfList=[]
    nmList=[]
    if &#39;flairfn&#39; in csvrow.keys():
        flid=str(int(csvrow[&#39;flairid&#39;].iloc[0]))
        nrgt2fn=os.path.join( rootdir, pid, sid, dt, &#39;T2Flair&#39;, flid, str(csvrow[&#39;flairfn&#39;].iloc[0]+iext) )
        if exists( nrgt2fn ):
            flList.append( nrgt2fn )
    if &#39;dtfn1&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid1&#39;].iloc[0]))
        dtfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn1&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn1 ):
            dtList.append( dtfn1 )
    if &#39;dtfn2&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid2&#39;].iloc[0]))
        dtfn2=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn2&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn2 ):
            dtList.append( dtfn2 )
    if &#39;rsffn1&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid1&#39;].iloc[0]))
        rsfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn1&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn1 ):
            rsfList.append( rsfn1 )
    if &#39;rsffn2&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid2&#39;].iloc[0]))
        rsfn2=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn2&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn2 ):
            rsfList.append( rsfn2 )
    for j in range(11):
        keyname=&#34;nmfn&#34;+str(j)
        keynameid=&#34;nmid&#34;+str(j)
        if keyname in csvrow.keys() and keynameid in csvrow.keys():
            nmid=str(int(csvrow[keynameid].iloc[0]))
            nmsearchpath=os.path.join( rootdir, pid, sid, dt, &#39;NM2DMT&#39;, nmid, &#34;*&#34;+nmid+iext)
            nmfn=glob.glob( nmsearchpath )
            nmfn=nmfn[0]
            if exists( nmfn ):
                nmList.append( nmfn )
    if verbose:
        print(&#34;assembled the image lists mapping to ....&#34;)
        print(nrgt1fn)
        print(&#34;NM&#34;)
        print(nmList)
        print(&#34;FLAIR&#34;)
        print(flList)
        print(&#34;DTI&#34;)
        print(dtList)
        print(&#34;rsfMRI&#34;)
        print(rsfList)
    studycsv = generate_mm_dataframe(
        pid,
        sid,
        dt,
        iid, # the T1 id
        &#39;T1w&#39;,
        rootdir,
        outputdir,
        t1_filename=nrgt1fn,
        flair_filename=flList,
        dti_filenames=dtList,
        rsf_filenames=rsfList,
        nm_filenames=nmList)
    return studycsv.dropna(axis=1)

def highest_quality_repeat(mxdfin, idvar, visitvar, qualityvar):
    &#34;&#34;&#34;
    This function returns a subset of the input dataframe that retains only the rows
    that correspond to the highest quality observation for each combination of ID and visit.

    Parameters:
    ----------
    mxdfin: pandas.DataFrame
        The input dataframe.
    idvar: str
        The name of the column that contains the ID variable.
    visitvar: str
        The name of the column that contains the visit variable.
    qualityvar: str
        The name of the column that contains the quality variable.

    Returns:
    -------
    pandas.DataFrame
        A subset of the input dataframe that retains only the rows that correspond
        to the highest quality observation for each combination of ID and visit.
    &#34;&#34;&#34;
    if visitvar not in mxdfin.columns:
        raise ValueError(&#34;visitvar not in dataframe&#34;)
    if idvar not in mxdfin.columns:
        raise ValueError(&#34;idvar not in dataframe&#34;)
    if qualityvar not in mxdfin.columns:
        raise ValueError(&#34;qualityvar not in dataframe&#34;)

    vizzes = mxdfin[visitvar].unique()
    uids = mxdfin[idvar].unique()
    useit = np.zeros(mxdfin.shape[0], dtype=bool)

    for u in uids:
        losel = mxdfin[idvar] == u
        vizzesloc = mxdfin[losel][visitvar].unique()

        for v in vizzesloc:
            losel = (mxdfin[idvar] == u) &amp; (mxdfin[visitvar] == v)
            mysnr = mxdfin.loc[losel, qualityvar]
            myw = np.where(losel)[0]

            if len(myw) &gt; 1:
                if any(~np.isnan(mysnr)):
                    useit[myw[np.argmax(mysnr)]] = True
                else:
                    useit[myw] = True
            else:
                useit[myw] = True

    return mxdfin[useit]


def match_modalities( qc_dataframe, unique_identifier=&#39;fn&#39;, outlier_column=&#39;ol_loop&#39;,  verbose=False ):
    &#34;&#34;&#34;
    Find the best multiple modality dataset at each time point

    :param qc_dataframe: quality control data frame with
    :param unique_identifier : the unique NRG filename for each image
    :param outlier_column: outlierness score used to identify the best image (pair) at a given date
    :param verbose: boolean
    :return: filtered matched modality data frame
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    mmdf = best_mmm( qc_dataframe, &#39;T1w&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    fldf = best_mmm( qc_dataframe, &#39;T2Flair&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    nmdf = best_mmm( qc_dataframe, &#39;NM2DMT&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    rsdf = best_mmm( qc_dataframe, &#39;rsfMRI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    dtdf = best_mmm( qc_dataframe, &#39;DTI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    mmdf[&#39;flairid&#39;] = np.nan
    mmdf[&#39;flairfn&#39;] = np.nan
    mmdf[&#39;flairloop&#39;] = np.nan
    mmdf[&#39;flairlof&#39;] = np.nan
    mmdf[&#39;dtid1&#39;] = np.nan
    mmdf[&#39;dtfn1&#39;] = np.nan
    mmdf[&#39;dtloop1&#39;] = np.nan
    mmdf[&#39;dtlof1&#39;] = np.nan
    mmdf[&#39;dtid2&#39;] = np.nan
    mmdf[&#39;dtfn2&#39;] = np.nan
    mmdf[&#39;dtloop2&#39;] = np.nan
    mmdf[&#39;dtlof2&#39;] = np.nan
    mmdf[&#39;rsfid1&#39;] = np.nan
    mmdf[&#39;rsffn1&#39;] = np.nan
    mmdf[&#39;rsfloop1&#39;] = np.nan
    mmdf[&#39;rsflof1&#39;] = np.nan
    mmdf[&#39;rsfid2&#39;] = np.nan
    mmdf[&#39;rsffn2&#39;] = np.nan
    mmdf[&#39;rsfloop2&#39;] = np.nan
    mmdf[&#39;rsflof2&#39;] = np.nan
    for k in range(1,11):
        myid=&#39;nmid&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmfn&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmloop&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmlof&#39;+str(k)
        mmdf[myid] = np.nan
    if verbose:
        print( mmdf.shape )
    for k in range(mmdf.shape[0]):
        if verbose:
            if k % 100 == 0:
                progger = str( k ) # np.round( k / mmdf.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        if dtdf is not None:
            locsel = (dtdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k]) &amp; (dtdf[outlier_column] &lt; 0.5)
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = dtdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = dtdf[&#34;fn&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = dtdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = dtdf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = dtdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = locdf[&#39;ol_lof_decision&#39;][locsel].values[0]
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn2&#34;)] = locdf[&#34;fn&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof2&#34;)] = locdf[&#39;ol_lof_decision&#39;][locsel].values[1]
        if rsdf is not None:
            locsel = (rsdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k]) &amp; (rsdf[outlier_column] &lt; 0.5)
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = rsdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = rsdf[&#34;fn&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = rsdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = rsdf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = rsdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[0]
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn2&#34;)] = locdf[&#34;fn&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof2&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[1]

        if fldf is not None:
            locsel = fldf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = fldf[&#39;imageID&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = fldf[&#39;fn&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = fldf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = fldf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = fldf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[0]

        if nmdf is not None:
            locsel = nmdf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() &gt; 0:
                locdf = nmdf[locsel]
                for i in range(np.min( [10,locdf.shape[0]])):
                    nmid = &#34;nmid&#34;+str(i+1)
                    mmdf[nmid].iloc[k] = locdf[&#39;imageID&#39;].iloc[i]
                    nmfn = &#34;nmfn&#34;+str(i+1)
                    mmdf[nmfn].iloc[k] = locdf[&#39;imageID&#39;].iloc[i]
                    nmloop = &#34;nmloop&#34;+str(i+1)
                    mmdf[nmloop].iloc[k] = locdf[outlier_column].iloc[i]
                    nmloop = &#34;nmlof&#34;+str(i+1)
                    mmdf[nmloop].iloc[k] = locdf[&#39;ol_lof_decision&#39;].iloc[i]

    return mmdf

def best_mmm( mmdf, wmod, mysep=&#39;-&#39;, outlier_column=&#39;ol_loop&#39;, verbose=False):
    &#34;&#34;&#34;
    Selects the best repeats per modality.

    Args:
    wmod (str): the modality of the image ( &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39; &#39;rsfMRI&#39;, &#39;DTI&#39;)

    mysep (str, optional): the separator used in the image file names. Defaults to &#39;-&#39;.

    outlier_name : column name for outlier score

    verbose (bool, optional): default True

    Returns:

    list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.

    &#34;&#34;&#34;
    msel = mmdf[&#39;modality&#39;] == wmod
    if wmod == &#39;rsfMRI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;rsfMRI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_RL&#39;
        msel = msel1 | msel2
        msel = msel | msel3
    if wmod == &#39;DTI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;DTI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;DTI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;DTI_RL&#39;
        msel4 = mmdf[&#39;modality&#39;] == &#39;DTIdwi&#39;
        msel = msel1 | msel2 | msel3 | msel4
    if sum(msel) == 0:
        return {&#39;raw&#39;: None, &#39;filt&#39;: None}
    uids = list(mmdf[&#39;fn&#39;][msel])
    metasub = mmdf[msel]

    if verbose:
        print(f&#34;{wmod} {(metasub.shape[0])} pre&#34;)

    metasub[&#39;subjectID&#39;]=math.nan
    metasub[&#39;date&#39;]=math.nan
    metasub[&#39;subjectIDdate&#39;]=math.nan
    metasub[&#39;imageID&#39;]=math.nan
    for k in range(len(uids)):
        temp = uids[k].split( mysep )
        metasub[&#39;subjectID&#39;].iloc[k] = temp[1]
        metasub[&#39;date&#39;].iloc[k] = temp[2]
        metasub[&#39;subjectIDdate&#39;].iloc[k] = temp[1] + mysep + temp[2]
        metasub[&#39;imageID&#39;].iloc[k] = temp[4]

    metasub[&#39;negol&#39;] = metasub[outlier_column].max() - metasub[outlier_column]
    if &#39;date&#39; not in metasub.keys():
        metasub[&#39;date&#39;]=&#39;NA&#39;
    metasubq = highest_quality_repeat(metasub, &#39;fn&#39;, &#39;date&#39;, &#39;negol&#39;)

    if verbose:
        print(f&#34;{wmod} {metasubq.shape[0]} post&#34;)

    return {&#39;raw&#39;: metasub, &#39;filt&#39;: metasubq}

def mm_read( x, standardize_intensity=False, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - same as ants.image_read (for now)

    standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one

    modality : not used
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if standardize_intensity:
        img[img&lt;0.0]=0.0
        img=ants.iMath(img,&#39;Normalize&#39;)
    if modality == &#34;T1w&#34; and img.dimension == 4:
        print(&#34;WARNING: input image is 4D - we attempt a hack fix that works in some odd cases of PPMI data - please check this image: &#34; + x, flush=True )
        i1=ants.slice_image(img,3,0)
        i2=ants.slice_image(img,3,1)
        kk=np.concatenate( [i1.numpy(),i2.numpy()], axis=2 )
        kk=ants.from_numpy(kk)
        img=ants.copy_image_info(i1,kk)
    return img

def mm_read_to_3d( x, slice=None, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - and return as 3d or None if that is not possible
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if img.dimension &lt; 3:
        return None
    elif img.dimension == 4:
        nslices = img.shape[3]
        if slice is None:
            sl = np.round( nslices * 0.5 )
        else:
            sl = slice
        if sl &gt; nslices:
            sl = nslices-1
        return ants.slice_image( img, axis=3, idx=int(sl) )
    elif img.dimension == 3:
        return img
    return None

def image_write_with_thumbnail( x,  fn, y=None, thumb=True ):
    &#34;&#34;&#34;
    will write the image and (optionally) a png thumbnail with (optional) overlay/underlay
    &#34;&#34;&#34;
    ants.image_write( x, fn )
    if not thumb or x.components &gt; 1:
        return
    thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_3dthumb.png&#34;,fn)
    if thumb and x.dimension == 3:
        if y is None:
            try:
                ants.plot_ortho( x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            try:
                ants.plot_ortho( y, x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
    if thumb and x.dimension == 4:
        thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_4dthumb.png&#34;,fn)
        nslices = x.shape[3]
        sl = np.round( nslices * 0.5 )
        if sl &gt; nslices:
            sl = nslices-1
        xview = ants.slice_image( x, axis=3, idx=int(sl) )
        if y is None:
            try:
                ants.plot_ortho( xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            if y.dimension == 3:
                try:
                    ants.plot_ortho(y, xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
                except:
                    pass
    return


def mc_resample_image_to_target( x , y, interp_type=&#39;linear&#39; ):
    &#34;&#34;&#34;
    multichannel version of resample_image_to_target
    &#34;&#34;&#34;
    xx=ants.split_channels( x )
    yy=ants.split_channels( y )[0]
    newl=[]
    for k in range(len(xx)):
        newl.append(  ants.resample_image_to_target( xx[k], yy, interp_type=interp_type ) )
    return ants.merge_channels( newl )

def nrg_filelist_to_dataframe( filename_list, myseparator=&#34;-&#34; ):
    &#34;&#34;&#34;
    convert a list of files in nrg format to a dataframe

    Arguments
    ---------
    filename_list : globbed list of files

    myseparator : string separator between nrg parts

    Returns
    -------

    df : pandas data frame

    &#34;&#34;&#34;
    def getmtime(x):
        x= dt.datetime.fromtimestamp(os.path.getmtime(x)).strftime(&#34;%Y-%m-%d %H:%M:%d&#34;)
        return x
    df=pd.DataFrame(columns=[&#39;filename&#39;,&#39;file_last_mod_t&#39;,&#39;else&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;uid&#39;])
    df.set_index(&#39;filename&#39;)
    df[&#39;filename&#39;] = pd.Series([file for file in filename_list ])
    # I applied a time modified file to df[&#39;file_last_mod_t&#39;] by getmtime function
    df[&#39;file_last_mod_t&#39;] = df[&#39;filename&#39;].apply(lambda x: getmtime(x))
    for k in range(df.shape[0]):
        locfn=df[&#39;filename&#39;].iloc[k]
        splitter=os.path.basename(locfn).split( myseparator )
        df[&#39;sid&#39;].iloc[k]=splitter[1]
        df[&#39;visitdate&#39;].iloc[k]=splitter[2]
        df[&#39;modality&#39;].iloc[k]=splitter[3]
        temp = os.path.splitext(splitter[4])[0]
        df[&#39;uid&#39;].iloc[k]=os.path.splitext(temp)[0]
    return df


def merge_timeseries_data( img_LR, img_RL, allow_resample=True ):
    &#34;&#34;&#34;
    merge time series data into space of reference_image

    img_LR : image

    img_RL : image

    allow_resample : boolean

    &#34;&#34;&#34;
    # concatenate the images into the reference space
    mimg=[]
    for kk in range( img_LR.shape[3] ):
        temp = ants.slice_image( img_LR, axis=3, idx=kk )
        mimg.append( temp )
    for kk in range( img_RL.shape[3] ):
        temp = ants.slice_image( img_RL, axis=3, idx=kk )
        if kk == 0:
            insamespace = ants.image_physical_space_consistency( temp, mimg[0] )
        if allow_resample and not insamespace :
            temp = ants.resample_image_to_target( temp, mimg[0] )
        mimg.append( temp )
    return ants.list_to_ndimage( img_LR, mimg )


def timeseries_reg(
    image,
    avg_b0,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=1.0,
    fdOffset=2.0,
    trim = 0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
    image: antsImage, usually ND where D=4.

    avg_b0: Fixed image b0 image

    type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

    fdOffset: offset value to use in framewise displacement calculation

    trim : integer - trim this many images off the front of the time series

    output_directory : string
            output will be placed in this directory plus a numeric extension.

    verbose: boolean

    kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD
        }

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/ts_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(&#39;bold motcorr with &#39; + type_of_transform)
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    # get a local deformation from slice to local avg space
    motion_parameters = list()
    motion_corrected = list()
    mask = ants.get_mask( avg_b0 )
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 )
    for k in range( nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.n4_bias_field_correction( temp )
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k % 2).zfill(4)+&#34;_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if temp.numpy().var() &gt; 0:
            img1w = ants.apply_transforms( avg_b0,
                temp,
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(avg_b0)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( ants.get_spacing(image)[3] )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected[trim:len(motion_corrected)]),
        &#34;motion_parameters&#34;: motion_parameters[trim:len(motion_parameters)],
        &#34;FD&#34;: FD[trim:len(FD)]
    }


def merge_dwi_data( img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL ):
    &#34;&#34;&#34;
    merge motion and distortion corrected data if possible

    img_LRdwp : image

    bval_LR : array

    bvec_LR : array

    img_RLdwp : image

    bval_RL : array

    bvec_RL : array

    &#34;&#34;&#34;
    insamespace = ants.image_physical_space_consistency( img_LRdwp, img_RLdwp )
    if not insamespace :
        raise ValueError(&#39;not insamespace ... corrected image pair should occupy the same physical space&#39;)

    bval_LR = np.concatenate([bval_LR,bval_RL])
    bvec_LR = np.concatenate([bvec_LR,bvec_RL])
    # concatenate the images
    mimg=[]
    for kk in range( img_LRdwp.shape[3] ):
            mimg.append( ants.slice_image( img_LRdwp, axis=3, idx=kk ) )
    for kk in range( img_RLdwp.shape[3] ):
            mimg.append( ants.slice_image( img_RLdwp, axis=3, idx=kk ) )
    img_LRdwp = ants.list_to_ndimage( img_LRdwp, mimg )
    return img_LRdwp, bval_LR, bvec_LR

def bvec_reorientation( motion_parameters, bvecs ):
    if motion_parameters is None:
        return bvecs
    n = len(motion_parameters)
    if n &lt; 1:
        return bvecs
    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs
    dipymoco = np.zeros( [n,3,3] )
    for myidx in range(n):
        if myidx &lt; bvecs.shape[0]:
            dipymoco[myidx,:,:] = np.eye( 3 )
            if motion_parameters[myidx] != &#39;NA&#39;:
                temp = motion_parameters[myidx]
                if len(temp) == 4 :
                    temp1=temp[3] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                elif len(temp) == 2 :
                    temp=temp[1] # FIXME should be composite of index 1 and 3
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                elif len(temp) == 3 :
                    temp1=temp[2] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                else:
                    temp=temp[0]
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                bvecs[myidx,:] = np.dot( Rinv, bvecs[myidx,:] )
    return bvecs


def dti_reg(
    image,
    avg_b0,
    avg_dwi,
    bvals=None,
    bvecs=None,
    b0_idx=None,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=3.0,
    fdOffset=2.0,
    mask_csf=False,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with optional deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        avg_b0: Fixed image b0 image

        avg_dwi: Fixed dwi same space as b0 image

        bvals: bvalues (file or array)

        bvecs: bvecs (file or array)

        b0_idx: indices of b0

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        mask_csf: boolean

        output_directory : string
            output will be placed in this directory plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if bvals is not None and bvecs is not None:
        if isinstance(bvecs, str):
            bvals, bvecs = read_bvals_bvecs( bvals , bvecs  )
        else: # assume we already read them
            bvals = bvals.copy()
            bvecs = bvecs.copy()
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD,
            &#39;bvals&#39;:bvals,
            &#39;bvecs&#39;:bvecs
        }

    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/dti_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]
    # first get a local deformation from slice to local avg space
    # then get a global deformation from avg to ref space
    ab0, adw = get_average_dwi_b0( image )
    mask = ants.get_mask(adw)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)


    if verbose:
        print(&#34;begin global distortion correction&#34;)
    # initrig = tra_initializer(avg_b0, ab0, max_rotation=60, transform=[&#39;rigid&#39;], verbose=verbose)
    if mask_csf:
        bcsf = ants.threshold_image( avg_b0,&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf = ab0 * 0 + 1

    initrig = ants.registration( avg_b0, ab0,&#39;BOLDRigid&#39;,outprefix=ofnG)
    deftx = ants.registration( avg_dwi, adw, &#39;SyNOnly&#39;,
        syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=[50,50,20],
        multivariate_extras=[ [ &#34;CC&#34;, avg_b0, ab0, 1, 2 ]],
        initial_transform=initrig[&#39;fwdtransforms&#39;][0],
        outprefix=ofnG
        )[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;end global distortion correction&#34;)

    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 )
    for k in range(nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.n4_bias_field_correction( temp )
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k).zfill(4)+&#34;rig_&#34;
        txprefix2 = ofnL+str(k % 2).zfill(4)+&#34;def_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma, grad_step=0.1,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix2,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        if temp.numpy().var() &gt; 0:
            motion_parameters[k]=deftx+motion_parameters[k]
            img1w = ants.apply_transforms( avg_dwi,
                ants.slice_image(image, axis=idim - 1, idx=k),
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(fixed)

    if verbose:
        print(&#34;Reorient bvecs&#34;)
    if bvecs is not None:
        bvecs = bvec_reorientation( motion_parameters, bvecs )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( 1.0 )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
    }


def mc_reg(
    image,
    fixed=None,
    type_of_transform=&#34;Rigid&#34;,
    mask=None,
    total_sigma=3.0,
    fdOffset=2.0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        fixed: Fixed image to register all timepoints to.  If not provided,
            mean image is used.

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        output_directory : string
            output will be named with this prefix plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data(&#39;ch2&#39;))
    &gt;&gt;&gt; mytx = ants.motion_correction( fi )
    &#34;&#34;&#34;
    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/mc_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)

    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    if fixed is None:
        fixed = ants.get_average_of_timeseries( image )
    if mask is None:
        mask = ants.get_mask(fixed)
    FD = np.zeros(nTimePoints)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = 0
    for k in range(nTimePoints):
        mycount = round(k / nTimePoints * 100)
        if verbose and mycount == counter:
            counter = counter + 10
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;Rigid&#39;,
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myreg[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
            img1w = ants.apply_transforms( fixed,
                ants.slice_image(image, axis=idim - 1, idx=k),
                myreg[&#34;fwdtransforms&#34;] )
            motion_corrected.append(img1w)
        else:
            motion_parameters.append(&#34;NA&#34;)
            motion_corrected.append(temp)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(image, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
    }


def get_data( name=None, force_download=False, version=11, target_extension=&#39;.csv&#39; ):
    &#34;&#34;&#34;
    Get ANTsPyMM data filename

    The first time this is called, it will download data to ~/.antspymm.
    After, it will just read data from disk.  The ~/.antspymm may need to
    be periodically deleted in order to ensure data is current.

    Arguments
    ---------
    name : string
        name of data tag to retrieve
        Options:
            - &#39;all&#39;

    force_download: boolean

    version: version of data to download (integer)

    Returns
    -------
    string
        filepath of selected data

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.get_data()
    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/16912366/versions/&#34; + str(version)
        target_file_name = &#34;16912366.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )


    files = []
    for fname in os.listdir(DATA_PATH):
        if ( fname.endswith(target_extension) ) :
            fname = os.path.join(DATA_PATH, fname)
            files.append(fname)

    if len( files ) == 0 :
        download_data( version = version )
        for fname in os.listdir(DATA_PATH):
            if ( fname.endswith(target_extension) ) :
                fname = os.path.join(DATA_PATH, fname)
                files.append(fname)

    if name == &#39;all&#39;:
        return files

    datapath = None

    for fname in os.listdir(DATA_PATH):
        mystem = (Path(fname).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        if ( name == mystem and fname.endswith(target_extension) ) :
            datapath = os.path.join(DATA_PATH, fname)

    return datapath


def get_models( version=3, force_download=True ):
    &#34;&#34;&#34;
    Get ANTsPyMM data models

    force_download: boolean

    Returns
    -------
    None

    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/21718412/versions/&#34;+str(version)
        target_file_name = &#34;21718412.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )
    return



def dewarp_imageset( image_list, initial_template=None,
    iterations=None, padding=0, target_idx=[0], **kwargs ):
    &#34;&#34;&#34;
    Dewarp a set of images

    Makes simplifying heuristic decisions about how to transform an image set
    into an unbiased reference space.  Will handle plenty of decisions
    automatically so beware.  Computes an average shape space for the images
    and transforms them to that space.

    Arguments
    ---------
    image_list : list containing antsImages 2D, 3D or 4D

    initial_template : optional

    iterations : number of template building iterations

    padding:  will pad the images by an integer amount to limit edge effects

    target_idx : the target indices for the time series over which we should average;
        a list of integer indices into the last axis of the input images.

    kwargs : keyword args
        arguments passed to ants registration - these must be set explicitly

    Returns
    -------
    a dictionary with the mean image and the list of the transformed images as
    well as motion correction parameters for each image in the input list

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    outlist = []
    avglist = []
    if len(image_list[0].shape) &gt; 3:
        imagetype = 3
        for k in range(len(image_list)):
            for j in range(len(target_idx)):
                avglist.append( ants.slice_image( image_list[k], axis=3, idx=target_idx[j] ) )
    else:
        imagetype = 0
        avglist=image_list

    pw=[]
    for k in range(len(avglist[0].shape)):
        pw.append( padding )
    for k in range(len(avglist)):
        avglist[k] = ants.pad_image( avglist[k], pad_width=pw  )

    if initial_template is None:
        initial_template = avglist[0] * 0
        for k in range(len(avglist)):
            initial_template = initial_template + avglist[k]/len(avglist)

    if iterations is None:
        iterations = 2

    btp = ants.build_template(
        initial_template=initial_template,
        image_list=avglist,
        gradient_step=0.5, blending_weight=0.8,
        iterations=iterations, **kwargs )

    # last - warp all images to this frame
    mocoplist = []
    mocofdlist = []
    reglist = []
    for k in range(len(image_list)):
        if imagetype == 3:
            moco0 = ants.motion_correction( image=image_list[k], fixed=btp, type_of_transform=&#39;BOLDRigid&#39; )
            mocoplist.append( moco0[&#39;motion_parameters&#39;] )
            mocofdlist.append( moco0[&#39;FD&#39;] )
            locavg = ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=0 ) * 0.0
            for j in range(len(target_idx)):
                locavg = locavg + ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=target_idx[j] )
            locavg = locavg * 1.0 / len(target_idx)
        else:
            locavg = image_list[k]
        reg = ants.registration( btp, locavg, **kwargs )
        reglist.append( reg )
        if imagetype == 3:
            myishape = image_list[k].shape
            mytslength = myishape[ len(myishape) - 1 ]
            mywarpedlist = []
            for j in range(mytslength):
                locimg = ants.slice_image( image_list[k], axis=3, idx = j )
                mywarped = ants.apply_transforms( btp, locimg,
                    reg[&#39;fwdtransforms&#39;] + moco0[&#39;motion_parameters&#39;][j], imagetype=0 )
                mywarpedlist.append( mywarped )
            mywarped = ants.list_to_ndimage( image_list[k], mywarpedlist )
        else:
            mywarped = ants.apply_transforms( btp, image_list[k], reg[&#39;fwdtransforms&#39;], imagetype=imagetype )
        outlist.append( mywarped )

    return {
        &#39;dewarpedmean&#39;:btp,
        &#39;dewarped&#39;:outlist,
        &#39;deformable_registrations&#39;: reglist,
        &#39;FD&#39;: mocofdlist,
        &#39;motionparameters&#39;: mocoplist }


def super_res_mcimage( image,
    srmodel,
    truncation=[0.0001,0.995],
    poly_order=&#39;hist&#39;,
    target_range=[0,1],
    isotropic = False,
    verbose=False ):
    &#34;&#34;&#34;
    Super resolution on a timeseries or multi-channel image

    Arguments
    ---------
    image : an antsImage

    srmodel : a tensorflow fully convolutional model

    truncation :  quantiles at which we truncate intensities to limit impact of outliers e.g. [0.005,0.995]

    poly_order : if not None, will fit a global regression model to map
        intensity back to original histogram space; if &#39;hist&#39; will match
        by histogram matching - ants.histogram_match_image

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

    isotropic : boolean

    verbose : boolean

    Returns
    -------
    super resolution version of the image

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    mcsr = list()
    for k in range(nTimePoints):
        if verbose and (( k % 5 ) == 0 ):
            mycount = round(k / nTimePoints * 100)
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image( image, axis=idim - 1, idx=k )
        temp = ants.iMath( temp, &#34;TruncateIntensity&#34;, truncation[0], truncation[1] )
        mysr = antspynet.apply_super_resolution_model_to_image( temp, srmodel,
            target_range = target_range )
        if poly_order is not None:
            bilin = ants.resample_image_to_target( temp, mysr )
            if poly_order == &#39;hist&#39;:
                mysr = ants.histogram_match_image( mysr, bilin )
            else:
                mysr = antspynet.regression_match_image( mysr, bilin, poly_order = poly_order )
        if isotropic:
            mysr = down2iso( mysr )
        if k == 0:
            upshape = list()
            for j in range(len(ishape)-1):
                upshape.append( mysr.shape[j] )
            upshape.append( ishape[ idim-1 ] )
            if verbose:
                print(&#34;SR will be of voxel size:&#34; + str(upshape) )
        mcsr.append( mysr )

    upshape = list()
    for j in range(len(ishape)-1):
        upshape.append( mysr.shape[j] )
    upshape.append( ishape[ idim-1 ] )
    if verbose:
        print(&#34;SR will be of voxel size:&#34; + str(upshape) )

    imageup = ants.resample_image( image, upshape, use_voxels = True )
    if verbose:
        print(&#34;Done&#34;)

    return ants.list_to_ndimage( imageup, mcsr )



def segment_timeseries_by_meanvalue( image, quantile = 0.995 ):
    &#34;&#34;&#34;
    Identify indices of a time series where we assume there is a different mean
    intensity over the volumes.  The indices of volumes with higher and lower
    intensities is returned.  Can be used to automatically identify B0 volumes
    in DWI timeseries.

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    quantile : a quantile for splitting the indices of the volume - should be greater than 0.5

    Returns
    -------
    dictionary holding the two sets of indices

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    ishape = image.shape
    lastdim = len(ishape)-1
    meanvalues = list()
    for x in range(ishape[lastdim]):
        meanvalues.append(  ants.slice_image( image, axis=lastdim, idx=x ).mean() )
    myhiq = np.quantile( meanvalues, quantile )
    myloq = np.quantile( meanvalues, 1.0 - quantile )
    lowerindices = list()
    higherindices = list()
    for x in range(len(meanvalues)):
        hiabs = abs( meanvalues[x] - myhiq )
        loabs = abs( meanvalues[x] - myloq )
        if hiabs &lt; loabs:
            higherindices.append(x)
        else:
            lowerindices.append(x)

    return {
    &#39;lowermeans&#39;:lowerindices,
    &#39;highermeans&#39;:higherindices }


def get_average_rsf( x, min_t=10, max_t=35 ):
    &#34;&#34;&#34;
    automatically generates the average bold image with quick registration

    returns:
        avg_bold
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
    oavg = ants.slice_image( x, axis=3, idx=0 )
    if x.shape[3] &lt;= min_t:
        min_t=0
    if x.shape[3] &lt;= max_t:
        max_t=x.shape[3]-1
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    oavg = ants.image_clone( bavg )
    bavg = oavg * 0.0
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    return ants.n4_bias_field_correction(bavg)


def get_average_dwi_b0( x, fixed_b0=None, fixed_dwi=None, fast=False ):
    &#34;&#34;&#34;
    automatically generates the average b0 and dwi and outputs both;
    maps dwi to b0 space at end.

    x : input image

    fixed_b0 : alernative reference space

    fixed_dwi : alernative reference space

    fast : boolean

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    temp = segment_timeseries_by_meanvalue( x )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]
    if ( fixed_b0 is None and fixed_dwi is None ) or fast:
        xavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        fixed_b0_use = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        fixed_dwi_use = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
    else:
        temp_b0 = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        temp_dwi = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
        xavg = fixed_b0 * 0.0
        bavg = fixed_b0 * 0.0
        tempreg = ants.registration( fixed_b0, temp_b0,&#39;BOLDRigid&#39;)
        fixed_b0_use = tempreg[&#39;warpedmovout&#39;]
        fixed_dwi_use = ants.apply_transforms( fixed_b0, temp_dwi, tempreg[&#39;fwdtransforms&#39;] )
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        if not fast:
            if not myidx in b0_idx:
                xavg = xavg + ants.registration(fixed_dwi_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
            else:
                bavg = bavg + ants.registration(fixed_b0_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
        else:
            if not myidx in b0_idx:
                xavg = xavg + b0
            else:
                bavg = bavg + b0
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    xavg = ants.iMath( xavg, &#39;Normalize&#39; )
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    avgb0=ants.n4_bias_field_correction(bavg)
    avgdwi=ants.n4_bias_field_correction(xavg)
    avgdwi=ants.registration( avgb0, avgdwi, &#39;Rigid&#39; )[&#39;warpedmovout&#39;]
    return avgb0, avgdwi

def dti_template(
    b_image_list=None,
    w_image_list=None,
    iterations=5,
    gradient_step=0.5,
    mask_csf=False,
    average_both=True,
    verbose=False
):
    &#34;&#34;&#34;
    two channel version of build_template

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    mydeftx = tempfile.NamedTemporaryFile(delete=False,dir=output_directory).name
    tmp = tempfile.NamedTemporaryFile(delete=False,dir=output_directory,suffix=&#34;.nii.gz&#34;)
    wavgfn = tmp.name
    tmp2 = tempfile.NamedTemporaryFile(delete=False,dir=output_directory)
    comptx = tmp2.name
    weights = np.repeat(1.0 / len(b_image_list), len(b_image_list))
    weights = [x / sum(weights) for x in weights]
    w_initial_template = w_image_list[0]
    b_initial_template = b_image_list[0]
    b_initial_template = ants.iMath(b_initial_template,&#34;Normalize&#34;)
    w_initial_template = ants.iMath(w_initial_template,&#34;Normalize&#34;)
    if mask_csf:
        bcsf0 = ants.threshold_image( b_image_list[0],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
        bcsf1 = ants.threshold_image( b_image_list[1],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf0 = b_image_list[0] * 0 + 1
        bcsf1 = b_image_list[1] * 0 + 1
    bavg = b_initial_template.clone() * bcsf0
    wavg = w_initial_template.clone() * bcsf0
    bcsf = [ bcsf0, bcsf1 ]
    for i in range(iterations):
        for k in range(len(w_image_list)):
            fimg=wavg
            mimg=w_image_list[k] * bcsf[k]
            fimg2=bavg
            mimg2=b_image_list[k] * bcsf[k]
            w1 = ants.registration(
                fimg, mimg, type_of_transform=&#39;antsRegistrationSyNQuick[s]&#39;,
                    multivariate_extras= [ [ &#34;mattes&#34;, fimg2, mimg2, 1, 32 ]],
                    outprefix=mydeftx,
                    verbose=0 )
            txname = ants.apply_transforms(wavg, wavg,
                w1[&#34;fwdtransforms&#34;], compose=comptx )
            if k == 0:
                txavg = ants.image_read(txname) * weights[k]
                wavgnew = ants.apply_transforms( wavg,
                    w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                bavgnew = ants.apply_transforms( wavg,
                    b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
            else:
                txavg = txavg + ants.image_read(txname) * weights[k]
                if i &gt;= (iterations-2) and average_both:
                    wavgnew = wavgnew+ants.apply_transforms( wavg,
                        w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                    bavgnew = bavgnew+ants.apply_transforms( wavg,
                        b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
        if verbose:
            print(&#34;iteration:&#34;,str(i),str(txavg.abs().mean()))
        wscl = (-1.0) * gradient_step
        txavg = txavg * wscl
        ants.image_write( txavg, wavgfn )
        wavg = ants.apply_transforms(wavg, wavgnew, wavgfn).iMath(&#34;Normalize&#34;)
        bavg = ants.apply_transforms(bavg, bavgnew, wavgfn).iMath(&#34;Normalize&#34;)
    import shutil
    shutil.rmtree( output_directory, ignore_errors=True )
    if verbose:
        print(&#34;done&#34;)
    return bavg, wavg

def t1_based_dwi_brain_extraction(
    t1w_head,
    t1w,
    dwi,
    b0_idx = None,
    transform=&#39;Rigid&#39;,
    deform=None,
    verbose=False
):
    &#34;&#34;&#34;
    Map a t1-based brain extraction to b0 and return a mask and average b0

    Arguments
    ---------
    t1w_head : an antsImage of the hole head

    t1w : an antsImage probably but not necessarily T1-weighted

    dwi : an antsImage holding B0 and DWI

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    transform : string Rigid or other ants.registration tx type

    deform : follow up transform with deformation

    Returns
    -------
    dictionary holding the avg_b0 and its mask

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    t1w_use = ants.iMath( t1w, &#34;Normalize&#34; )
    t1bxt = ants.threshold_image( t1w_use, 0.05, 1 ).iMath(&#34;FillHoles&#34;)
    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    # first get the average b0
    if len( b0_idx ) &gt; 1:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] ).iMath(&#34;Normalize&#34;)
        for n in range(1,len(b0_idx)):
            temp = ants.slice_image( dwi, axis=3, idx=b0_idx[n] )
            reg = ants.registration( b0_avg, temp, &#39;Rigid&#39; )
            b0_avg = b0_avg + ants.iMath( reg[&#39;warpedmovout&#39;], &#34;Normalize&#34;)
    else:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] )
    b0_avg = ants.iMath(b0_avg,&#34;Normalize&#34;)
    reg = tra_initializer( b0_avg, t1w, n_simulations=12,   verbose=verbose )
    if deform is not None:
        reg = ants.registration( b0_avg, t1w,
            &#39;SyNOnly&#39;,
            total_sigma=0.5,
            initial_transform=reg[&#39;fwdtransforms&#39;][0],
            verbose=False )
    outmsk = ants.apply_transforms( b0_avg, t1bxt, reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39;).threshold_image( 0.5, 1.0 )
    return  {
    &#39;b0_avg&#39;:b0_avg,
    &#39;b0_mask&#39;:outmsk }

def mc_denoise( x, ratio = 0.5 ):
    &#34;&#34;&#34;
    ants denoising for timeseries (4D)

    Arguments
    ---------
    x : an antsImage 4D

    ratio : weight between 1 and 0 - lower weights bring result closer to initial image

    Returns
    -------
    denoised time series

    &#34;&#34;&#34;
    dwpimage = []
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        dnzb0 = ants.denoise_image( b0, p=1,r=1,noise_model=&#39;Gaussian&#39; )
        dwpimage.append( dnzb0 * ratio + b0 * (1.0-ratio) )
    return ants.list_to_ndimage( x, dwpimage )

def tsnr( x, mask, indices=None ):
    &#34;&#34;&#34;
    3D temporal snr image from a 4D time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns a 3D image
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    stdM = np.std(M, axis=0 )
    stdM[np.isnan(stdM)] = 0
    tt = round( 0.975*100 )
    threshold_std = np.percentile( stdM, tt )
    tsnrimage = ants.make_image( mask, stdM )
    return tsnrimage

def dvars( x,  mask, indices=None ):
    &#34;&#34;&#34;
    dvars on a time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    DVARS = np.zeros( M.shape[0] )
    for i in range(1, M.shape[0] ):
        vecdiff = M[i-1,:] - M[i,:]
        DVARS[i] = np.sqrt( ( vecdiff * vecdiff ).mean() )
    DVARS[0] = DVARS.mean()
    return DVARS


def slice_snr( x,  background_mask, foreground_mask, indices=None ):
    &#34;&#34;&#34;
    slice-wise SNR on a time series image

    x: image

    background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask

    foreground_mask : mask - maybe cortex or WM or brain mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    xuse=ants.iMath(x,&#34;Normalize&#34;)
    MB = ants.timeseries_to_matrix( xuse, background_mask )
    MF = ants.timeseries_to_matrix( xuse, foreground_mask )
    if indices is not None:
        MB=MB[indices,:]
        MF=MF[indices,:]
    ssnr = np.zeros( MB.shape[0] )
    for i in range( MB.shape[0] ):
        ssnr[i]=MF[i,:].mean()/MB[i,:].std()
    ssnr[np.isnan(ssnr)] = 0
    return ssnr


def impute_fa( fa, md ):
    &#34;&#34;&#34;
    impute bad values in dti, fa, md
    &#34;&#34;&#34;
    def imputeit( x, fa ):
        badfa=ants.threshold_image(fa,1,1)
        if badfa.max() == 1:
            temp=ants.image_clone(x)
            temp[badfa==1]=0
            temp=ants.iMath(temp,&#39;GD&#39;,2)
            x[ badfa==1 ]=temp[badfa==1]
        return x
    md=imputeit( md, fa )
    fa=imputeit( ants.image_clone(fa), fa )
    return fa, md

def trim_dti_mask( fa, mask, param=4.0 ):
    &#34;&#34;&#34;
    trim the dti mask to get rid of bright fa rim

    this function erodes the famask by param amount then segments the rim into
    bright and less bright parts.  the bright parts are trimmed from the mask
    and the remaining edges are cleaned up a bit with closing.

    param: closing radius unit is in physical space
    &#34;&#34;&#34;
    spacing = ants.get_spacing(mask)
    spacing_product = np.prod( spacing )
    spcmin = min( spacing )
    paramVox = int(np.round( param / spcmin ))
    trim_mask = ants.image_clone( mask )
    trim_mask = ants.iMath( trim_mask, &#34;FillHoles&#34; )
    edgemask = trim_mask - ants.iMath( trim_mask, &#34;ME&#34;, paramVox )
    maxk=4
    edgemask = ants.threshold_image( fa * edgemask, &#34;Otsu&#34;, maxk )
    edgemask = ants.threshold_image( edgemask, maxk-1, maxk )
    trim_mask[edgemask &gt;= 1 ]=0
    trim_mask = ants.iMath(trim_mask,&#34;ME&#34;,paramVox-1)
    trim_mask = ants.iMath(trim_mask,&#39;GetLargestComponent&#39;)
    trim_mask = ants.iMath(trim_mask,&#34;MD&#34;,paramVox-1)
    return trim_mask

def dipy_dti_recon(
    image,
    bvalsfn,
    bvecsfn,
    mask = None,
    b0_idx = None,
    mask_dilation = 2,
    mask_closing = 5,
    fit_method=&#39;WLS&#39;,
    trim_the_mask=2,
    verbose=False ):
    &#34;&#34;&#34;
    DiPy DTI reconstruction - building on the DiPy basic DTI example

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    bvalsfn : bvalues  obtained by dipy read_bvals_bvecs or the values themselves

    bvecsfn : bvectors obtained by dipy read_bvals_bvecs or the values themselves

    mask : brain mask for the DWI/DTI reconstruction; if it is not in the same
        space as the image, we will resample directly to the image space.  This
        could lead to problems if the inputs are really incorrect.

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    mask_dilation : integer zero or more dilates the brain mask

    mask_closing : integer zero or more closes the brain mask

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) ... if None, will not reconstruct DTI.

    trim_the_mask : boolean post-hoc method for trimming the mask

    verbose : boolean

    Returns
    -------
    dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)

    NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)

    NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect
        the tailing image volumes.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;


    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]

    if isinstance(bvecsfn, str):
        bvals, bvecs = read_bvals_bvecs( bvalsfn , bvecsfn   )
    else: # assume we already read them
        bvals = bvalsfn.copy()
        bvecs = bvecsfn.copy()

    b0 = ants.slice_image( image, axis=3, idx=b0_idx[0] )
    bxtmod=&#39;bold&#39;
    bxtmod=&#39;t2&#39;
    constant_mask=False
    if mask is not None:
        constant_mask=True
        mask = ants.resample_image_to_target( mask, b0, interp_type=&#39;nearestNeighbor&#39;)
    else:
        mask = antspynet.brain_extraction( b0, bxtmod ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    if mask_closing &gt; 0 and not constant_mask :
        mask = ants.morphology( mask, &#34;close&#34;, mask_closing ) # good
    maskdil = ants.iMath( mask, &#34;MD&#34;, mask_dilation )

    if verbose:
        print(&#34;recon dti.TensorModel&#34;,flush=True)

    def justthefit( gtab, fit_method, imagein, maskin ):
        if fit_method is None:
            return None, None, None, None
        maskedimage=[]
        for myidx in range(imagein.shape[3]):
            b0 = ants.slice_image( imagein, axis=3, idx=myidx)
            maskedimage.append( b0 * maskin )
        maskedimage = ants.list_to_ndimage( imagein, maskedimage )
        maskdata = maskedimage.numpy()
        tenmodel = dti.TensorModel(gtab,fit_method=fit_method)
        tenfit = tenmodel.fit(maskdata)
        FA = fractional_anisotropy(tenfit.evals)
        FA[np.isnan(FA)] = 1
        FA = np.clip(FA, 0, 1)
        MD1 = dti.mean_diffusivity(tenfit.evals)
        MD1 = ants.copy_image_info( b0, ants.from_numpy( MD1.astype(np.float32) ) )
        FA = ants.copy_image_info(  b0, ants.from_numpy( FA.astype(np.float32) ) )
        FA, MD1 = impute_fa( FA, MD1 )
        RGB = color_fa(FA.numpy(), tenfit.evecs)
        RGB = ants.from_numpy( RGB.astype(np.float32) )
        RGB0 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=0 ) )
        RGB1 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=1 ) )
        RGB2 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=2 ) )
        RGB = ants.merge_channels( [RGB0,RGB1,RGB2] )
        return tenfit, FA, MD1, RGB

    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1)  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, maskdil )
    if verbose:
        print(&#34;recon dti.TensorModel done&#34;,flush=True)

    # change the brain mask based on high FA values
    if trim_the_mask &gt; 0 and fit_method is not None:
        mask = trim_dti_mask( FA, mask, trim_the_mask )
        tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, mask )

    return {
        &#39;tensormodel&#39; : tenfit,
        &#39;MD&#39; : MD1 ,
        &#39;FA&#39; : FA ,
        &#39;RGB&#39; : RGB,
        &#39;dwi_mask&#39;:mask,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
        }


def concat_dewarp(
        refimg,
        originalDWI,
        physSpaceDWI,
        dwpTx,
        motion_parameters,
        motion_correct=True,
        verbose=False ):
    &#34;&#34;&#34;
    Apply concatentated motion correction and dewarping transforms to timeseries image.

    Arguments
    ---------

    refimg : an antsImage defining the reference domain (3D)

    originalDWI : the antsImage in original (not interpolated space) (4D)

    physSpaceDWI : ants antsImage defining the physical space of the mapping (4D)

    dwpTx : dewarping transform

    motion_parameters : previously computed list of motion parameters

    motion_correct : boolean

    verbose : boolean

    &#34;&#34;&#34;
    # apply the dewarping tx to the original dwi and reconstruct again
    # NOTE: refimg must be in the same space for this to work correctly
    # due to the use of ants.list_to_ndimage( originalDWI, dwpimage )
    dwpimage = []
    for myidx in range(originalDWI.shape[3]):
        b0 = ants.slice_image( originalDWI, axis=3, idx=myidx)
        concatx = dwpTx.copy()
        if motion_correct:
            concatx = concatx + motion_parameters[myidx]
        if verbose and myidx == 0:
            print(&#34;dwp parameters&#34;)
            print( dwpTx )
            print(&#34;Motion parameters&#34;)
            print( motion_parameters[myidx] )
            print(&#34;concat parameters&#34;)
            print(concatx)
        warpedb0 = ants.apply_transforms( refimg, b0, concatx,
            interpolator=&#39;nearestNeighbor&#39; )
        dwpimage.append( warpedb0 )
    return ants.list_to_ndimage( physSpaceDWI, dwpimage )


def joint_dti_recon(
    img_LR,
    bval_LR,
    bvec_LR,
    jhu_atlas,
    jhu_labels,
    reference_B0,
    reference_DWI,
    srmodel = None,
    img_RL = None,
    bval_RL = None,
    bvec_RL = None,
    t1w = None,
    brain_mask = None,
    motion_correct = None,
    dewarp_modality = &#39;FA&#39;,
    denoise=False,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;
    1. pass in subject data and 1mm JHU atlas/labels
    2. perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)
    3. dewarp the images using dewarp_modality or T1w
    4. apply dewarping to the original data
        ===&gt; may want to apply SR at this step
    5. reconstruct DTI again
    6. label images and do registration
    7. return relevant outputs

    NOTE: RL images are optional; should pass t1w in this case.

    Arguments
    ---------

    img_LR : an antsImage holding B0 and DWI LR acquisition

    bval_LR : bvalue filename LR

    bvec_LR : bvector filename LR

    jhu_atlas : atlas FA image

    jhu_labels : atlas labels

    reference_B0 : the &#34;target&#34; B0 image space

    reference_DWI : the &#34;target&#34; DW image space

    srmodel : optional h5 (tensorflow) model

    img_RL : an antsImage holding B0 and DWI RL acquisition

    bval_RL : bvalue filename RL

    bvec_RL : bvector filename RL

    t1w : antsimage t1w neuroimage (brain-extracted)

    brain_mask : mask for the DWI - just 3D

    motion_correct : None Rigid or SyN

    dewarp_modality : string average_dwi, average_b0, MD or FA

    denoise: boolean

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding the mean_fa, its summary statistics via JHU labels,
        the JHU registration, the JHU labels, the dewarping dictionary and the
        dti reconstruction dictionaries.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;Recon DTI on OR images ...&#34;)

    def fix_dwi_shape( img, bvalfn, bvecfn ):
        if isinstance(bvecfn, str):
            bvals, bvecs = read_bvals_bvecs( bvalfn , bvecfn   )
        if bvecs.shape[0] &lt; img.shape[3]:
            imgout = ants.from_numpy( img[:,:,:,0:bvecs.shape[0]] )
            imgout = ants.copy_image_info( img, imgout )
            return( imgout )
        else:
            return( img )

    img_LR = fix_dwi_shape( img_LR, bval_LR, bvec_LR )
    if denoise :
        img_LR = mc_denoise( img_LR )
    if img_RL is not None:
        img_RL = fix_dwi_shape( img_RL, bval_RL, bvec_RL )
        if denoise :
            img_RL = mc_denoise( img_RL )

    if brain_mask is not None:
        maskInRightSpace = ants.image_physical_space_consistency( brain_mask, reference_B0 )
        if not maskInRightSpace :
            raise ValueError(&#39;not maskInRightSpace ... provided brain mask should be in reference_B0 space&#39;)

    if img_RL is not None :
        if verbose:
            print(&#34;img_RL correction&#34;)
        reg_RL = dti_reg(
            img_RL,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_RL,
            bvecs=bvec_RL,
            type_of_transform=motion_correct,
            verbose=True )
    else:
        reg_RL=None


    if verbose:
        print(&#34;img_LR correction&#34;)
    reg_LR = dti_reg(
            img_LR,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_LR,
            bvecs=bvec_LR,
            type_of_transform=motion_correct,
            verbose=True )

    ts_LR_avg = None
    ts_RL_avg = None
    reg_its = [100,50,10]
    img_LRdwp = ants.image_clone( reg_LR[ &#39;motion_corrected&#39; ] )
    if img_RL is not None:
        img_RLdwp = ants.image_clone( reg_RL[ &#39;motion_corrected&#39; ] )
        if srmodel is not None:
            if verbose:
                print(&#34;convert img_RL_dwp to img_RL_dwp_SR&#34;)
            img_RLdwp = super_res_mcimage( img_RLdwp, srmodel, isotropic=True,
                        verbose=verbose )
    if srmodel is not None:
        reg_its = [100] + reg_its
        if verbose:
            print(&#34;convert img_LR_dwp to img_LR_dwp_SR&#34;)
        img_LRdwp = super_res_mcimage( img_LRdwp, srmodel, isotropic=True,
                verbose=verbose )
    if verbose:
        print(&#34;recon after distortion correction&#34;, flush=True)

    if img_RL is not None:
        img_LRdwp, bval_LR, bvec_LR = merge_dwi_data(
            img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;],
            img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;]
        )
    else:
        bval_LR=reg_LR[&#39;bvals&#39;]
        bvec_LR=reg_LR[&#39;bvecs&#39;]

    if verbose:
        print(&#34;final recon&#34;, flush=True)
        print(img_LRdwp)
    recon_LR_dewarp = dipy_dti_recon(
            img_LRdwp, bval_LR, bvec_LR,
            mask = brain_mask,
            fit_method=fit_method,
            mask_dilation=0, verbose=True )
    if verbose:
        print(&#34;recon done&#34;, flush=True)

    if img_RL is not None:
        fdjoin = [ reg_LR[&#39;FD&#39;],
                   reg_RL[&#39;FD&#39;] ]
        framewise_displacement=np.concatenate( fdjoin )
    else:
        framewise_displacement=reg_LR[&#39;FD&#39;]

    motion_count = ( framewise_displacement &gt; 1.5  ).sum()
    reconFA = recon_LR_dewarp[&#39;FA&#39;]
    reconMD = recon_LR_dewarp[&#39;MD&#39;]

    if verbose:
        print(&#34;JHU reg&#34;,flush=True)

    OR_FA2JHUreg = ants.registration( reconFA, jhu_atlas,
        type_of_transform = &#39;SyN&#39;, syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=reg_its, verbose=False )
    OR_FA_jhulabels = ants.apply_transforms( reconFA, jhu_labels,
        OR_FA2JHUreg[&#39;fwdtransforms&#39;], interpolator=&#39;genericLabel&#39;)

    df_FA_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;FA_JHU_labels_edited&#39;,
        reconFA,
        OR_FA_jhulabels)
    df_FA_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_FA_JHU_ORRL&#39; : df_FA_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    df_MD_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;MD_JHU_labels_edited&#39;,
        reconMD,
        OR_FA_jhulabels)
    df_MD_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_MD_JHU_ORRL&#39; : df_MD_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    temp = segment_timeseries_by_meanvalue( img_LRdwp )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]

    nonbrainmask = ants.iMath( recon_LR_dewarp[&#39;dwi_mask&#39;], &#34;MD&#34;,2) - recon_LR_dewarp[&#39;dwi_mask&#39;]
    fgmask = ants.threshold_image( reconFA, 0.5 , 1.0).iMath(&#34;GetLargestComponent&#34;)
    bgmask = ants.threshold_image( reconFA, 1e-4 , 0.1)
    fa_SNR = 0.0
    fa_SNR = mask_snr( reconFA, bgmask, fgmask, bias_correct=False )
    fa_evr = antspyt1w.patch_eigenvalue_ratio( reconFA, 512, [16,16,16], evdepth = 0.9, mask=recon_LR_dewarp[&#39;dwi_mask&#39;] )

    return {
        &#39;recon_fa&#39;:reconFA,
        &#39;recon_fa_summary&#39;:df_FA_JHU_ORRL_bfwide,
        &#39;recon_md&#39;:reconMD,
        &#39;recon_md_summary&#39;:df_MD_JHU_ORRL_bfwide,
        &#39;jhu_labels&#39;:OR_FA_jhulabels,
        &#39;jhu_registration&#39;:OR_FA2JHUreg,
        &#39;reg_LR&#39;:reg_LR,
        &#39;reg_RL&#39;:reg_RL,
        &#39;dtrecon_LR_dewarp&#39;:recon_LR_dewarp,
        &#39;dwi_LR_dewarped&#39;:img_LRdwp,
        &#39;bval_LR&#39;:bval_LR,
        &#39;bvec_LR&#39;:bvec_LR,
        &#39;bval_RL&#39;:bval_RL,
        &#39;bvec_RL&#39;:bvec_RL,
        &#39;b0avg&#39;: reference_B0,
        &#39;dwiavg&#39;: reference_DWI,
        &#39;framewise_displacement&#39;:framewise_displacement,
        &#39;high_motion_count&#39;: motion_count,
        &#39;tsnr_b0&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;tsnr_dwi&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;dvars_b0&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;dvars_dwi&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;ssnr_b0&#39;: slice_snr( img_LRdwp, bgmask , fgmask, b0_idx),
        &#39;ssnr_dwi&#39;: slice_snr( img_LRdwp, bgmask, fgmask, non_b0_idx),
        &#39;fa_evr&#39;: fa_evr,
        &#39;fa_SNR&#39;: fa_SNR
    }


def middle_slice_snr( x, background_dilation=5 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    &#34;&#34;&#34;
    xshp = x.shape
    xmidslice = ants.slice_image( x, 2, int( xshp[2]/2 )  )
    xmidslice = ants.iMath( xmidslice - xmidslice.min(), &#34;Normalize&#34; )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslicemask = ants.threshold_image( xmidslice, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmidslicemask, &#34;MD&#34;, background_dilation ) - xmidslicemask
    signal = (xmidslice[ xmidslicemask == 1] ).mean()
    noise = (xmidslice[ xbkgmask == 1] ).std()
    return signal / noise

def foreground_background_snr( x, background_dilation=10,
        erode_foreground=False):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    erode_foreground : boolean - 2nd option which erodes the initial
    foregound mask  to create a new foreground mask.  the background
    mask is the initial mask minus the eroded mask.

    &#34;&#34;&#34;
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xmask = ants.threshold_image( xbc, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmask, &#34;MD&#34;, background_dilation ) - xmask
    fgmask = xmask
    if erode_foreground:
        fgmask = ants.iMath( xmask, &#34;ME&#34;, background_dilation )
        xbkgmask = xmask - fgmask
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise

def quantile_snr( x,
    lowest_quantile=0.01,
    low_quantile=0.1,
    high_quantile=0.5,
    highest_quantile=0.95 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    lowest_quantile : float value &lt; 1 and &gt; 0

    low_quantile : float value &lt; 1 and &gt; 0

    high_quantile : float value &lt; 1 and &gt; 0

    highest_quantile : float value &lt; 1 and &gt; 0

    &#34;&#34;&#34;
    import numpy as np
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    y = xbc.numpy()
    ylowest = np.quantile( y[y&gt;0], lowest_quantile )
    ylo = np.quantile( y[y&gt;0], low_quantile )
    yhi = np.quantile( y[y&gt;0], high_quantile )
    yhiest = np.quantile( y[y&gt;0], highest_quantile )
    xbkgmask = ants.threshold_image( xbc, ylowest, ylo )
    fgmask = ants.threshold_image( xbc, yhi, yhiest )
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise

def mask_snr( x, background_mask, foreground_mask, bias_correct=True ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image using
    a user-defined foreground and background mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_mask : binary antsImage

    foreground_mask : binary antsImage

    bias_correct : boolean

    &#34;&#34;&#34;
    import numpy as np
    if foreground_mask.sum() &lt;= 1 or background_mask.sum() &lt;= 1:
        return 0
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    if bias_correct:
        xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    signal = (xbc[ foreground_mask == 1] ).mean()
    noise = (xbc[ background_mask == 1] ).std()
    return signal / noise


def dwi_deterministic_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1 )  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1
    dti_model = dti.TensorModel(gtab,fit_method=fit_method)
    if verbose:
        print(&#34;begin tracking fit&#34;,flush=True)
    dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while
    evecs_img = dti_fit.evecs
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion
    stopping_criterion = ThresholdStoppingCriterion(fa.numpy(), fa_thresh)
    from dipy.data import get_sphere
    sphere = get_sphere(&#39;symmetric362&#39;)
    from dipy.direction import peaks_from_model
    if peak_indices is None:
        # problems with multi-threading ...
        # see https://github.com/dipy/dipy/issues/2519
        if verbose:
            print(&#34;begin peaks&#34;,flush=True)
        mynump=1
        # if os.getenv(&#34;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#34;):
        #    mynump = os.environ[&#39;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#39;]
        # current_openblas = os.environ.get(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
        # current_mkl = os.environ.get(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)
        # os.environ[&#39;DIPY_OPENBLAS_NUM_THREADS&#39;] = current_openblas
        # os.environ[&#39;DIPY_MKL_NUM_THREADS&#39;] = current_mkl
        # os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = &#39;1&#39;
        # os.environ[&#39;MKL_NUM_THREADS&#39;] = &#39;1&#39;
        peak_indices = peaks_from_model(
            model=dti_model,
            data=dwi_data,
            sphere=sphere,
            relative_peak_threshold=.5,
            min_separation_angle=25,
            mask=dwi_mask,
            npeaks=3, return_odf=False,
            return_sh=False,
            parallel=int(mynump) &gt; 1,
            num_processes=int(mynump)
            )
        if False:
            if &#39;DIPY_OPENBLAS_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
            if &#39;DIPY_MKL_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;MKL_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_MKL_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;MKL_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)

    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(
        peak_indices, stopping_criterion, seeds, affine=affine, step_size=step_size)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines,
          &#39;peak_indices&#39;: peak_indices
          }



def dwi_closest_peak_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.core.gradients import gradient_table
    from dipy.data import small_sphere
    from dipy.direction import BootDirectionGetter, ClosestPeakDirectionGetter
    from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,
                                    auto_response_ssst)
    from dipy.reconst.shm import CsaOdfModel
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion

    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1)  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1


    response, ratio = auto_response_ssst(gtab, dwi_data, roi_radii=10, fa_thr=0.7)
    csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)
    csd_fit = csd_model.fit(dwi_data, mask=dwi_mask)
    csa_model = CsaOdfModel(gtab, sh_order=6)
    gfa = csa_model.fit(dwi_data, mask=dwi_mask).gfa
    stopping_criterion = ThresholdStoppingCriterion(gfa, .25)


    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)

    pmf = csd_fit.odf(small_sphere).clip(min=0)
    if verbose:
        print(&#34;ClosestPeakDirectionGetter begin ...&#34;, flush=True)
    peak_dg = ClosestPeakDirectionGetter.from_pmf(pmf, max_angle=30.,
                                                sphere=small_sphere)
    if verbose:
        print(&#34;local tracking begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(peak_dg, stopping_criterion, seeds,
                                            affine, step_size=.5)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines
          }

def dwi_streamline_pairwise_connectivity( streamlines, label_image, labels_to_connect=[1,None], verbose=False ):
    &#34;&#34;&#34;

    Return streamlines connecting all of the regions in the label set. Ideal
    for just 2 regions.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    labels_to_connect : list of 2 labels or [label,None]

    verbose : boolean

    Returns
    -------
    the subset of streamlines and a streamline count

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    from dipy.tracking.streamline import Streamlines
    keep_streamlines = Streamlines()
    affine = label_image.to_nibabel().affine
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, full=False ):
        if full:
            maxind=sl.shape[0]
            for index in range(maxind):
                pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
                mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
                if mylab == target_label[0] or mylab == target_label[1]:
                    return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
            mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
            if mylab == target_label[0] or mylab == target_label[1]:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    for k in range( len( streamlines ) ):
        sl = streamlines[k]
        mycheck = check_it( sl, labels_to_connect, label_image_np, index=0, full=True )
        if mycheck[&#39;ok&#39;]:
            otherind=1
            if mycheck[&#39;label&#39;] == labels_to_connect[1]:
                otherind=0
            lsl = len( sl )-1
            pt = utils._to_voxel_coordinates(sl[lsl,:], lin_T, offset)
            mylab_end = (label_image_np[ pt[0], pt[1], pt[2] ]).astype(int)
            accept_point = mylab_end == labels_to_connect[otherind]
            if verbose and accept_point:
                print( mylab_end )
            if labels_to_connect[1] is None:
                accept_point = mylab_end != 0
            if accept_point:
                keep_streamlines.append(sl)
                ct=ct+1
    return { &#39;streamlines&#39;: keep_streamlines, &#39;count&#39;: ct }

def dwi_streamline_pairwise_connectivity_old(
    streamlines,
    label_image,
    exclusion_label = None,
    verbose = False ):
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = np.unique( labels[ labels &gt; 0 ] )
    if exclusion_label is not None:
        ulabs = ulabs[ ulabs != exclusion_label ]
        exc_slice = labels == exclusion_label
    if verbose:
        print(&#34;Begin connectivity&#34;)
    tracts = []
    for k in range(len(ulabs)):
        cc_slice = labels == ulabs[k]
        cc_streamlines = utils.target(streamlines, affine, cc_slice)
        cc_streamlines = Streamlines(cc_streamlines)
        if exclusion_label is not None:
            cc_streamlines = utils.target(cc_streamlines, affine, exc_slice, include=False)
            cc_streamlines = Streamlines(cc_streamlines)
        for j in range(len(ulabs)):
            cc_slice2 = labels == ulabs[j]
            cc_streamlines2 = utils.target(cc_streamlines, affine, cc_slice2)
            cc_streamlines2 = Streamlines(cc_streamlines2)
            if exclusion_label is not None:
                cc_streamlines2 = utils.target(cc_streamlines2, affine, exc_slice, include=False)
                cc_streamlines2 = Streamlines(cc_streamlines2)
            tracts.append( cc_streamlines2 )
        if verbose:
            print(&#34;end connectivity&#34;)
    return {
          &#39;pairwise_tracts&#39;: tracts
          }


def dwi_streamline_connectivity(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    labels_to_connect = ulabs[ulabs &gt; 0]
    Ctdf = None
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, not_label = None ):
        pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
        mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
        if not_label is None:
            if ( mylab == target_label ).sum() &gt; 0 :
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            if ( mylab == target_label ).sum() &gt; 0 and ( mylab == not_label ).sum() == 0:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    which = lambda lst:list(np.where(lst)[0])
    myCount = np.zeros( [len(ulabs),len(ulabs)])
    for k in range( len( streamlines ) ):
            sl = streamlines[k]
            mycheck = check_it( sl, labels_to_connect, label_image_np, index=0 )
            if mycheck[&#39;ok&#39;]:
                exclabel=mycheck[&#39;label&#39;]
                lsl = len( sl )-1
                mycheck2 = check_it( sl, labels_to_connect, label_image_np, index=lsl, not_label=exclabel )
                if mycheck2[&#39;ok&#39;]:
                    myCount[ulabs == mycheck[&#39;label&#39;],ulabs == mycheck2[&#39;label&#39;]]+=1
                    ct=ct+1
    Ctdf = label_dataframe.copy()
    for k in range(len(ulabs)):
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
    Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
    return { &#39;connectivity_matrix&#39; :  myCount, &#39;connectivity_wide&#39; : Ctdfw }

def dwi_streamline_connectivity_old(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;streamline connections ...&#34;)

    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines

    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine

    if verbose:
        print(&#34;path length begin ... volUnit = &#34; + str( volUnit ) )
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    pathLmean = np.zeros( [len(ulabs)])
    pathLtot = np.zeros( [len(ulabs)])
    pathCt = np.zeros( [len(ulabs)])
    for k in range(len(ulabs)):
        cc_slice = labels == ulabs[k]
        cc_streamlines = utils.target(streamlines, affine, cc_slice)
        cc_streamlines = Streamlines(cc_streamlines)
        if len(cc_streamlines) &gt; 0:
            wmpl = path_length(cc_streamlines, affine, cc_slice)
            mean_path_length = wmpl[wmpl&gt;0].mean()
            total_path_length = wmpl[wmpl&gt;0].sum()
            pathLmean[int(k)] = mean_path_length
            pathLtot[int(k)] = total_path_length
            pathCt[int(k)] = len(cc_streamlines) * volUnit

    # convert paths to data frames
    pathdf = label_dataframe.copy()
    pathdf.insert(pathdf.shape[1], &#34;mean_path_length&#34;, pathLmean )
    pathdf.insert(pathdf.shape[1], &#34;total_path_length&#34;, pathLtot )
    pathdf.insert(pathdf.shape[1], &#34;streamline_count&#34;, pathCt )
    pathdfw =antspyt1w.merge_hierarchical_csvs_to_wide_format(
        {path_length:pathdf }, [&#39;mean_path_length&#39;, &#39;total_path_length&#39;, &#39;streamline_count&#39;] )
    allconnexwide = pathdfw

    if verbose:
        print(&#34;path length done ...&#34;)

    Mdfw = None
    Tdfw = None
    Mdf = None
    Tdf = None
    Ctdf = None
    Ctdfw = None
    if True:
        if verbose:
            print(&#34;Begin connectivity&#34;)
        M = np.zeros( [len(ulabs),len(ulabs)])
        T = np.zeros( [len(ulabs),len(ulabs)])
        myCount = np.zeros( [len(ulabs),len(ulabs)])
        for k in range(len(ulabs)):
            cc_slice = labels == ulabs[k]
            cc_streamlines = utils.target(streamlines, affine, cc_slice)
            cc_streamlines = Streamlines(cc_streamlines)
            for j in range(len(ulabs)):
                cc_slice2 = labels == ulabs[j]
                cc_streamlines2 = utils.target(cc_streamlines, affine, cc_slice2)
                cc_streamlines2 = Streamlines(cc_streamlines2)
                if len(cc_streamlines2) &gt; 0 :
                    wmpl = path_length(cc_streamlines2, affine, cc_slice2)
                    mean_path_length = wmpl[wmpl&gt;0].mean()
                    total_path_length = wmpl[wmpl&gt;0].sum()
                    M[int(j),int(k)] = mean_path_length
                    T[int(j),int(k)] = total_path_length
                    myCount[int(j),int(k)] = len( cc_streamlines2 ) * volUnit
        if verbose:
            print(&#34;end connectivity&#34;)
        Mdf = label_dataframe.copy()
        Tdf = label_dataframe.copy()
        Ctdf = label_dataframe.copy()
        for k in range(len(ulabs)):
            nn1 = &#34;CnxMeanPL&#34;+str(k).zfill(3)
            nn2 = &#34;CnxTotPL&#34;+str(k).zfill(3)
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Mdf.insert(Mdf.shape[1], nn1, M[k,:] )
            Tdf.insert(Tdf.shape[1], nn2, T[k,:] )
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
        Mdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkm&#39; : Mdf },  Mdf.keys()[2:Mdf.shape[1]] )
        Tdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkt&#39; : Tdf },  Tdf.keys()[2:Tdf.shape[1]] )
        Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
        allconnexwide = pd.concat( [
            pathdfw,
            Mdfw,
            Tdfw,
            Ctdfw ], axis=1 )

    return {
          &#39;connectivity&#39;: allconnexwide,
          &#39;connectivity_matrix_mean&#39;: Mdf,
          &#39;connectivity_matrix_total&#39;: Tdf,
          &#39;connectivity_matrix_count&#39;: Ctdf
          }


def hierarchical_modality_summary(
    target_image,
    hier,
    transformlist,
    modality_name,
    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;],
    verbose = False ):
    &#34;&#34;&#34;

    Use output of antspyt1w.hierarchical to summarize a modality

    Arguments
    ---------

    target_image : the image to summarize - should be brain extracted

    hier : dictionary holding antspyt1w.hierarchical output

    transformlist : spatial transformations mapping from T1 to this modality (e.g. from ants.registration)

    modality_name : adds the modality name to the data frame columns

    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;] keys to return

    verbose : boolean

    Returns
    -------
    data frame holding summary statistics in wide format

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    dfout = pd.DataFrame()
    def myhelper( target_image, seg, mytx, mapname, modname, mydf, extra=&#39;&#39;, verbose=False ):
        if verbose:
            print( mapname )
        target_image_mask = ants.image_clone( target_image ) * 0.0
        target_image_mask[ target_image != 0 ] = 1
        cortmapped = ants.apply_transforms(
            target_image,
            seg,
            mytx, interpolator=&#39;nearestNeighbor&#39; ) * target_image_mask
        mapped = antspyt1w.map_intensity_to_dataframe(
            mapname,
            target_image,
            cortmapped )
        mapped.iloc[:,1] = modname + &#39;_&#39; + extra + mapped.iloc[:,1]
        mappedw = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            { &#39;x&#39; : mapped},
            col_names = return_keys )
        if verbose:
            print( mappedw.keys() )
        if mydf.shape[0] &gt; 0:
            mydf = pd.concat( [ mydf, mappedw], axis=1 )
        else:
            mydf = mappedw
        return mydf
    if hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], transformlist,
            &#34;dkt&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose )
    if hier[&#39;deep_cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;deep_cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;deep_&#39;, verbose=verbose )
    if hier[&#39;cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    if hier[&#39;bf&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;bf&#39;], transformlist,
            &#34;nbm3CH13&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    # if hier[&#39;mtl&#39;] is not None:
    #    dfout = myhelper( target_image, hier[&#39;mtl&#39;], reg,
    #        &#34;mtl_description&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    return dfout


def tra_initializer( fixed, moving, n_simulations=32, max_rotation=30,
    transform=[&#39;rigid&#39;], verbose=False ):
    &#34;&#34;&#34;
    multi-start multi-transform registration solution - based on ants.registration

    fixed: fixed image

    moving: moving image

    n_simulations : number of simulations

    max_rotation : maximum rotation angle

    transform : list of transforms to loop through

    verbose : boolean

    &#34;&#34;&#34;
    if True:
        output_directory = tempfile.mkdtemp()
        output_directory_w = output_directory + &#34;/tra_reg/&#34;
        os.makedirs(output_directory_w,exist_ok=True)
        bestmi = math.inf
        myorig = list(ants.get_origin( fixed ))
        mymax = 0;
        for k in range(len( myorig ) ):
            if abs(myorig[k]) &gt; mymax:
                mymax = abs(myorig[k])
        maxtrans = mymax * 0.05
        bestreg=ants.registration( fixed,moving,&#39;Translation&#39;,
            outprefix=output_directory_w+&#34;trans&#34;)
        initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        for mytx in transform:
            regtx = &#39;Rigid&#39;
            with tempfile.NamedTemporaryFile(suffix=&#39;.h5&#39;) as tp:
                if mytx == &#39;translation&#39;:
                    regtx = &#39;Translation&#39;
                    rRotGenerator = ants.contrib.RandomTranslate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                elif mytx == &#39;affine&#39;:
                    regtx = &#39;Affine&#39;
                    rRotGenerator = ants.contrib.RandomRotate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                else:
                    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rotation*(-1.0), max_rotation ), reference=fixed )
                for k in range(n_simulations):
                    simtx = ants.compose_ants_transforms( [rRotGenerator.transform(), initx] )
                    ants.write_transform( simtx, tp.name )
                    if k &gt; 0:
                        reg = ants.registration( fixed, moving, regtx,
                            initial_transform=tp.name,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    else:
                        reg = ants.registration( fixed, moving,
                            regtx,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    mymi = math.inf
                    temp = reg[&#39;warpedmovout&#39;]
                    myvar = temp.numpy().var()
                    if verbose:
                        print( str(k) + &#34; : &#34; + regtx  + &#34; : &#34; + mytx + &#34; _var_ &#34; + str( myvar ) )
                    if myvar &gt; 0 :
                        mymi = ants.image_mutual_information( fixed, temp )
                        if mymi &lt; bestmi:
                            if verbose:
                                print( &#34;mi @ &#34; + str(k) + &#34; : &#34; + str(mymi), flush=True)
                            bestmi = mymi
                            bestreg = reg
        return bestreg

def neuromelanin( list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8,
    bias_correct=True,
    denoise=None,
    srmodel=None,
    target_range=[0,1],
    poly_order=&#39;hist&#39;,
    normalize_nm = False,
    verbose=False ) :

  &#34;&#34;&#34;
  Outputs the averaged and registered neuromelanin image, and neuromelanin labels

  Arguments
  ---------
  list_nm_image : list of ANTsImages
    list of neuromenlanin repeat images

  t1 : ANTsImage
    input 3-D T1 brain image

  t1_head : ANTsImage
    input 3-D T1 head image

  t1lab : ANTsImage
    t1 labels that will be propagated to the NM

  brain_stem_dilation : integer default 8
    dilates the brain stem mask to better match coverage of NM

  bias_correct : boolean

  denoise : None or integer

  srmodel : None -- this is a work in progress feature, probably not optimal

  target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

  poly_order : if not None, will fit a global regression model to map
      intensity back to original histogram space; if &#39;hist&#39; will match
      by histogram matching - ants.histogram_match_image

  normalize_nm : boolean - WIP not validated

  verbose : boolean

  Returns
  ---------
  Averaged and registered neuromelanin image and neuromelanin labels and wide csv

  &#34;&#34;&#34;

  fnt=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni.nii.gz&#34; )
  fntNM=os.path.expanduser(&#34;~/.antspymm/CIT168_T1w_700um_pad_adni_NM_norm_avg.nii.gz&#34; )
  fntbst=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni_brainstem.nii.gz&#34;)
  fnslab=os.path.expanduser(&#34;~/.antspyt1w/CIT168_MT_Slab_adni.nii.gz&#34;)
  fntseg=os.path.expanduser(&#34;~/.antspyt1w/det_atlas_25_pad_LR_adni.nii.gz&#34;)

  template = mm_read( fnt )
  templateNM = ants.iMath( mm_read( fntNM ), &#34;Normalize&#34; )
  templatebstem = mm_read( fntbst ).threshold_image( 1, 1000 )
  # reg = ants.registration( t1, template, &#39;antsRegistrationSyNQuickRepro[s]&#39; )
  reg = ants.registration( t1, template, &#39;SyN&#39; )
  # map NM avg to t1 for neuromelanin processing
  nmavg2t1 = ants.apply_transforms( t1, templateNM,
    reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39; )
  slab2t1 = ants.threshold_image( nmavg2t1, &#34;Otsu&#34;, 2 ).threshold_image(1,2).iMath(&#34;MD&#34;,1).iMath(&#34;FillHoles&#34;)
  # map brain stem and slab to t1 for neuromelanin processing
  bstem2t1 = ants.apply_transforms( t1, templatebstem,
    reg[&#39;fwdtransforms&#39;],
    interpolator=&#39;nearestNeighbor&#39; ).iMath(&#34;MD&#34;,1)
  slab2t1B = ants.apply_transforms( t1, mm_read( fnslab ),
    reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39;)
  bstem2t1 = ants.crop_image( bstem2t1, slab2t1 )
  cropper = ants.decrop_image( bstem2t1, slab2t1 ).iMath(&#34;MD&#34;,brain_stem_dilation)

  # Average images in image_list
  nm_avg = list_nm_images[0]*0.0
  for k in range(len( list_nm_images )):
    if denoise is not None:
        list_nm_images[k] = ants.denoise_image( list_nm_images[k],
            shrink_factor=1,
            p=denoise,
            r=denoise+1,
            noise_model=&#39;Gaussian&#39; )
    if bias_correct :
        n4mask = ants.threshold_image( ants.iMath(list_nm_images[k], &#34;Normalize&#34; ), 0.05, 1 )
        list_nm_images[k] = ants.n4_bias_field_correction( list_nm_images[k], mask=n4mask )
    nm_avg = nm_avg + ants.resample_image_to_target( list_nm_images[k], nm_avg ) / len( list_nm_images )

  if verbose:
      print(&#34;Register each nm image in list_nm_images to the averaged nm image (avg)&#34;)
  nm_avg_new = nm_avg * 0.0
  txlist = []
  for k in range(len( list_nm_images )):
    if verbose:
        print(str(k) + &#34; of &#34; + str(len( list_nm_images ) ) )
    current_image = ants.registration( list_nm_images[k], nm_avg,
        type_of_transform = &#39;Rigid&#39; )
    txlist.append( current_image[&#39;fwdtransforms&#39;][0] )
    current_image = current_image[&#39;warpedfixout&#39;]
    nm_avg_new = nm_avg_new + current_image / len( list_nm_images )
  nm_avg = nm_avg_new

  if verbose:
      print(&#34;do slab registration to map anatomy to NM space&#34;)
  t1c = ants.crop_image( t1_head, slab2t1 ).iMath(&#34;Normalize&#34;) # old way
  nmavg2t1c = ants.crop_image( nmavg2t1, slab2t1 ).iMath(&#34;Normalize&#34;)
  # slabreg = ants.registration( nm_avg, nmavg2t1c, &#39;Rigid&#39; )
  slabreg = tra_initializer( nm_avg, t1c, verbose=verbose )
  if False:
      slabregT1 = tra_initializer( nm_avg, t1c, verbose=verbose  )
      miNM = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg0[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      miT1 = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg1[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      if miT1 &lt; miNM:
        slabreg = slabregT1
  labels2nm = ants.apply_transforms( nm_avg, t1lab, slabreg[&#39;fwdtransforms&#39;],
    interpolator = &#39;genericLabel&#39; )
  cropper2nm = ants.apply_transforms( nm_avg, cropper, slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
  nm_avg_cropped = ants.crop_image( nm_avg, cropper2nm )

  if verbose:
      print(&#34;now map these labels to each individual nm&#34;)
  crop_mask_list = []
  crop_nm_list = []
  for k in range(len( list_nm_images )):
      concattx = []
      concattx.append( txlist[k] )
      concattx.append( slabreg[&#39;fwdtransforms&#39;][0] )
      cropmask = ants.apply_transforms( list_nm_images[k], cropper,
        concattx, interpolator = &#39;nearestNeighbor&#39; )
      crop_mask_list.append( cropmask )
      temp = ants.crop_image( list_nm_images[k], cropmask )
      crop_nm_list.append( temp )

  if srmodel is not None:
      if verbose:
          print( &#34; start sr &#34; + str(len( crop_nm_list )) )
      for k in range(len( crop_nm_list )):
          if verbose:
              print( &#34; do sr &#34; + str(k) )
              print( crop_nm_list[k] )
          temp = antspynet.apply_super_resolution_model_to_image(
                crop_nm_list[k], srmodel, target_range=target_range,
                regression_order=None )
          if poly_order is not None:
              bilin = ants.resample_image_to_target( crop_nm_list[k], temp )
              if poly_order == &#39;hist&#39;:
                  temp = ants.histogram_match_image( temp, bilin )
              else:
                  temp = antspynet.regression_match_image( temp, bilin, poly_order = poly_order )
          crop_nm_list[k] = temp

  nm_avg_cropped = crop_nm_list[0]*0.0
  if verbose:
      print( &#34;cropped average&#34; )
      print( nm_avg_cropped )
  for k in range(len( crop_nm_list )):
      nm_avg_cropped = nm_avg_cropped + ants.apply_transforms( nm_avg_cropped,
        crop_nm_list[k], txlist[k] ) / len( crop_nm_list )
  for loop in range( 3 ):
      nm_avg_cropped_new = nm_avg_cropped * 0.0
      for k in range(len( crop_nm_list )):
            myreg = ants.registration(
                ants.iMath(nm_avg_cropped,&#34;Normalize&#34;),
                ants.iMath(crop_nm_list[k],&#34;Normalize&#34;),
                &#39;BOLDRigid&#39; )
            warpednext = ants.apply_transforms(
                nm_avg_cropped_new,
                crop_nm_list[k],
                myreg[&#39;fwdtransforms&#39;] )
            nm_avg_cropped_new = nm_avg_cropped_new + warpednext
      nm_avg_cropped = nm_avg_cropped_new / len( crop_nm_list )

  slabregUpdated = tra_initializer( nm_avg_cropped, t1c, verbose=verbose  )
  tempOrig = ants.apply_transforms( nm_avg_cropped_new, t1c, slabreg[&#39;fwdtransforms&#39;] )
  tempUpdate = ants.apply_transforms( nm_avg_cropped_new, t1c, slabregUpdated[&#39;fwdtransforms&#39;] )
  miUpdate = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempUpdate,&#34;Normalize&#34;) )
  miOrig = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempOrig,&#34;Normalize&#34;) )
  if miUpdate &lt; miOrig :
      slabreg = slabregUpdated

  if normalize_nm:
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;TruncateIntensity&#34;,0.05,0.95)
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )

  labels2nm = ants.apply_transforms( nm_avg_cropped, t1lab,
        slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )

  # fix the reference region - keep top two parts
  def get_biggest_part( x, labeln ):
      temp33 = ants.threshold_image( x, labeln, labeln ).iMath(&#34;GetLargestComponent&#34;)
      x[ x == labeln] = 0
      x[ temp33 == 1 ] = labeln

  get_biggest_part( labels2nm, 33 )
  get_biggest_part( labels2nm, 34 )

  if verbose:
      print( &#34;map summary measurements to wide format&#34; )
  nmdf = antspyt1w.map_intensity_to_dataframe(
          &#39;CIT168_Reinf_Learn_v1_label_descriptions_pad&#39;,
          nm_avg_cropped,
          labels2nm)
  if verbose:
      print( &#34;merge to wide format&#34; )
  nmdf_wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;NM&#39; : nmdf},
              col_names = [&#39;Mean&#39;] )
  if verbose:
      print( &#34;nm done&#34; )

  rr_mask = ants.mask_image( labels2nm, labels2nm, [33,34] , binarize=True )
  sn_mask = ants.mask_image( labels2nm, labels2nm, [7,9,23,25] , binarize=True )
  nmavgsnr = mask_snr( nm_avg_cropped, rr_mask, sn_mask, bias_correct = False )

  snavg = nm_avg_cropped[ sn_mask == 1].mean()
  rravg = nm_avg_cropped[ rr_mask == 1].mean()
  snstd = nm_avg_cropped[ sn_mask == 1].std()
  rrstd = nm_avg_cropped[ rr_mask == 1].std()
  snvol = np.prod( ants.get_spacing(sn_mask) ) * sn_mask.sum()

  # get the mean voxel position of the SN
  if snvol &gt; 0:
      sn_z = ants.transform_physical_point_to_index( sn_mask, ants.get_center_of_mass(sn_mask ))[2]
      sn_z = sn_z/sn_mask.shape[2] # around 0.5 would be nice
  else:
      sn_z = math.nan

  nm_evr = antspyt1w.patch_eigenvalue_ratio( nm_avg, 512, [6,6,6], evdepth = 0.9, mask=cropper2nm )

  return{
      &#39;NM_avg&#39; : nm_avg,
      &#39;NM_avg_cropped&#39; : nm_avg_cropped,
      &#39;NM_labels&#39;: labels2nm,
      &#39;NM_cropped&#39;: crop_nm_list,
      &#39;NM_midbrainROI&#39;: cropper2nm,
      &#39;NM_dataframe&#39;: nmdf,
      &#39;NM_dataframe_wide&#39;: nmdf_wide,
      &#39;t1_to_NM&#39;: slabreg[&#39;warpedmovout&#39;],
      &#39;t1_to_NM_transform&#39; : slabreg[&#39;fwdtransforms&#39;],
      &#39;NM_avg_signaltonoise&#39; : nmavgsnr,
      &#39;NM_avg_substantianigra&#39; : snavg,
      &#39;NM_std_substantianigra&#39; : snstd,
      &#39;NM_volume_substantianigra&#39; : snvol,
      &#39;NM_avg_refregion&#39; : rravg,
      &#39;NM_std_refregion&#39; : rrstd,
      &#39;NM_min&#39; : nm_avg_cropped.min(),
      &#39;NM_max&#39; : nm_avg_cropped.max(),
      &#39;NM_mean&#39; : nm_avg_cropped.numpy().mean(),
      &#39;NM_sd&#39; : math.sqrt( nm_avg_cropped.numpy().mean() ),
      &#39;NM_q0pt05&#39; : np.quantile( nm_avg_cropped.numpy(), 0.05 ),
      &#39;NM_q0pt10&#39; : np.quantile( nm_avg_cropped.numpy(), 0.10 ),
      &#39;NM_q0pt90&#39; : np.quantile( nm_avg_cropped.numpy(), 0.90 ),
      &#39;NM_q0pt95&#39; : np.quantile( nm_avg_cropped.numpy(), 0.95 ),
      &#39;NM_substantianigra_z_coordinate&#39; : sn_z,
      &#39;NM_evr&#39; : nm_evr,
      &#39;NM_count&#39;: len( list_nm_images )
       }

def resting_state_fmri_networks( fmri, fmri_template, t1, t1segmentation,
    f=[0.03,0.08], FD_threshold=0.5, spa = 1.5, spt = 0.5, nc = 6, type_of_transform=&#39;Rigid&#39;,
    verbose=False ):

  &#34;&#34;&#34;
  Compute resting state network correlation maps based on the J Power labels.
  This will output a map for each of the major network systems.

  Arguments
  ---------
  fmri : BOLD fmri antsImage

  fmri_template : reference space for BOLD

  t1 : ANTsImage
    input 3-D T1 brain image (brain extracted)

  t1segmentation : ANTsImage
    t1 segmentation - a six tissue segmentation image in T1 space

  f : band pass limits for frequency filtering

  spa : gaussian smoothing for spatial component

  spt : gaussian smoothing for temporal component

  nc  : number of components for compcor filtering

  type_of_transform : SyN or Rigid

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  &#34;&#34;&#34;
  import numpy as np
  import pandas as pd
  import re
  import math
  A = np.zeros((1,1))
  powers_areal_mni_itk = pd.read_csv( get_data(&#39;powers_mni_itk&#39;, target_extension=&#34;.csv&#34;)) # power coordinates
  fmri = ants.iMath( fmri, &#39;Normalize&#39; )
  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;FillHoles&#34;)
  if verbose:
      print(&#34;Begin rsfmri motion correction&#34;)
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=type_of_transform,
    total_sigma=0.0,
    fdOffset=2.0,
    trim = 8,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5] )
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)
      # ants.image_write( corrmo[&#39;motion_corrected&#39;], &#39;/tmp/temp.nii.gz&#39; )

  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,2)
  bmask = bmask * tsnrmask
  und = fmri_template * bmask
  t1reg = ants.registration( und, t1, &#34;SyNBold&#34; )
  if verbose:
      print(&#34;t1 2 bold done&#34;)
#      ants.image_write( und, &#39;/tmp/template_bold_masked.nii.gz&#39; )
#      ants.image_write( t1reg[&#39;warpedmovout&#39;], &#39;/tmp/t1tobold.nii.gz&#39; )
  boldseg = ants.apply_transforms( und, t1segmentation,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;genericLabel&#39; ) * bmask
  gmseg = ants.threshold_image( t1segmentation, 2, 2 )
  gmseg = gmseg + ants.threshold_image( t1segmentation, 4, 4 )
  gmseg = ants.threshold_image( gmseg, 1, 4 )
  gmseg = ants.iMath( gmseg, &#39;MD&#39;, 1 )
  gmseg = ants.apply_transforms( und, gmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; ) * bmask
  csfAndWM = ( ants.threshold_image( t1segmentation, 1, 1 ) +
               ants.threshold_image( t1segmentation, 3, 3 ) ).morphology(&#34;erode&#34;,1)
  csfAndWM = ants.apply_transforms( und, csfAndWM,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask

  # get falff and alff
  mycompcor = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc, quantile=0.90, mask = csfAndWM,
    filter_type=&#39;polynomial&#39;, degree=2 )

  nt = corrmo[&#39;motion_corrected&#39;].shape[3]

  myvoxes = range(powers_areal_mni_itk.shape[0])
  anat = powers_areal_mni_itk[&#39;Anatomy&#39;]
  syst = powers_areal_mni_itk[&#39;SystemName&#39;]
  Brod = powers_areal_mni_itk[&#39;Brodmann&#39;]
  xAAL  = powers_areal_mni_itk[&#39;AAL&#39;]
  ch2 = mm_read( ants.get_ants_data( &#34;ch2&#34; ) )
  treg = ants.registration( t1, ch2, &#39;SyN&#39; )
  concatx2 = treg[&#39;invtransforms&#39;] + t1reg[&#39;invtransforms&#39;]
  pts2bold = ants.apply_transforms_to_points( 3, powers_areal_mni_itk, concatx2,
    whichtoinvert = ( True, False, True, False ) )
  locations = pts2bold.iloc[:,:3].values
  ptImg = ants.make_points_image( locations, bmask, radius = 2 )

  tr = ants.get_spacing( corrmo[&#39;motion_corrected&#39;] )[3]
  highMotionTimes = np.where( corrmo[&#39;FD&#39;] &gt;= 1.0 )
  goodtimes = np.where( corrmo[&#39;FD&#39;] &lt; 0.5 )
  smth = ( spa, spa, spa, spt ) # this is for sigmaInPhysicalCoordinates = F
  simg = ants.smooth_image(corrmo[&#39;motion_corrected&#39;], smth, sigma_in_physical_coordinates = False )

  nuisance = mycompcor[ &#39;components&#39; ]
  nuisance = np.c_[ nuisance, mycompcor[&#39;basis&#39;] ]
  nuisance = np.c_[ nuisance, corrmo[&#39;FD&#39;] ]

  gmmat = ants.timeseries_to_matrix( simg, gmseg )
  gmmat = ants.bandpass_filter_matrix( gmmat, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
  gmsignal = gmmat.mean( axis = 1 )
  nuisance = np.c_[ nuisance, gmsignal ]
  gmmat = ants.regress_components( gmmat, nuisance )
  # turn data following nuisance and gsr back to image format
  gsrbold = ants.matrix_to_timeseries(simg, gmmat, gmseg)

  myfalff=alff_image( simg, bmask, flo=f[0], fhi=f[1], nuisance=nuisance )

  outdict = {}
  outdict[&#39;meanBold&#39;] = und
  outdict[&#39;pts2bold&#39;] = pts2bold

  # add correlation matrix that captures each node pair
  # some of the spheres overlap so extract separately from each ROI
  nPoints = pts2bold[&#39;ROI&#39;].max()
  nVolumes = simg.shape[3]
  meanROI = np.zeros([nVolumes, nPoints])
  roiNames = []
  for i in range(nPoints):
    # specify name for matrix entries that&#39;s links back to ROI number and network; e.g., ROI1_Uncertain
    netLabel = re.sub( &#34; &#34;, &#34;&#34;, pts2bold.loc[i,&#39;SystemName&#39;])
    netLabel = re.sub( &#34;-&#34;, &#34;&#34;, netLabel )
    netLabel = re.sub( &#34;/&#34;, &#34;&#34;, netLabel )
    roiLabel = &#34;ROI&#34; + str(pts2bold.loc[i,&#39;ROI&#39;]) + &#39;_&#39; + netLabel
    roiNames.append( roiLabel )
    ptImage = ants.make_points_image(pts2bold.iloc[[i],:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    meanROI[:,i] = ants.timeseries_to_matrix( gsrbold, ptImage).mean(axis=1)

  # get full correlation matrix
  corMat = np.corrcoef(meanROI, rowvar=False)
  outputMat = pd.DataFrame(corMat)
  outputMat.columns = roiNames
  outputMat[&#39;ROIs&#39;] = roiNames
  # add to dictionary
  outdict[&#39;fullCorrMat&#39;] = outputMat

  networks = powers_areal_mni_itk[&#39;SystemName&#39;].unique()

  # this is just for human readability - reminds us of which we choose by default
  netnames = [&#39;Cingulo-opercular Task Control&#39;, &#39;Default Mode&#39;,
                &#39;Memory Retrieval&#39;, &#39;Ventral Attention&#39;, &#39;Visual&#39;,
                &#39;Fronto-parietal Task Control&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
                &#39;Dorsal Attention&#39;]
  # cerebellar is 12
  ct = 0
  numofnets = [3,5,6,7,8,9,10,11,13]
  for mynet in numofnets:
    netname = re.sub( &#34; &#34;, &#34;&#34;, networks[mynet] )
    netname = re.sub( &#34;-&#34;, &#34;&#34;, netname )
    ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[mynet] )[0]
    dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    if dfnImg.max() &gt;= 1:
        dfnmat = ants.timeseries_to_matrix( simg, ants.threshold_image( dfnImg, 1, dfnImg.max() ) )
        dfnmat = ants.bandpass_filter_matrix( dfnmat, tr = tr, lowf=f[0], highf=f[1]  )
        dfnmat = ants.regress_components( dfnmat, nuisance )
        dfnsignal = dfnmat.mean( axis = 1 )
        gmmatDFNCorr = np.zeros( gmmat.shape[1] )
        for k in range( gmmat.shape[1] ):
            gmmatDFNCorr[ k ] = pearsonr( dfnsignal, gmmat[:,k] )[0]
        corrImg = ants.make_image( gmseg, gmmatDFNCorr  )
        outdict[ netname ] = corrImg
    else:
        outdict[ netname ] = None
    ct = ct + 1

  A = np.zeros( ( len( numofnets ) , len( numofnets ) ) )
  A_wide = np.zeros( ( 1, len( numofnets ) * len( numofnets ) ) )
  newnames=[]
  newnames_wide=[]
  ct = 0
  for i in range( len( numofnets ) ):
      netnamei = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[i]] )
      netnamei = re.sub( &#34;-&#34;, &#34;&#34;, netnamei )
      newnames.append( netnamei  )
      binmask = ants.threshold_image( outdict[ netnamei ], 0.2, 1.0 )
      ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[numofnets[i]] )[0]
      dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
      for j in range( len( numofnets ) ):
          netnamej = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[j]] )
          netnamej = re.sub( &#34;-&#34;, &#34;&#34;, netnamej )
          newnames_wide.append( netnamei + &#34;_2_&#34; + netnamej )
          A[i,j] = outdict[ netnamej ][ dfnImg == 1].mean()
          A_wide[0,ct] = A[i,j]
          ct=ct+1

  A = pd.DataFrame( A )
  A.columns = newnames
  A[&#39;networks&#39;]=newnames
  A_wide = pd.DataFrame( A_wide )
  A_wide.columns = newnames_wide
  outdict[&#39;corr&#39;] = A
  outdict[&#39;corr_wide&#39;] = A_wide
  outdict[&#39;brainmask&#39;] = bmask
  outdict[&#39;alff&#39;] = myfalff[&#39;alff&#39;]
  outdict[&#39;falff&#39;] = myfalff[&#39;falff&#39;]
  # add global mean and standard deviation for post-hoc z-scoring
  outdict[&#39;alff_mean&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).mean()
  outdict[&#39;alff_sd&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).std()
  outdict[&#39;falff_mean&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).mean()
  outdict[&#39;falff_sd&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).std()

  for k in range(1,270):
    anatname=( pts2bold[&#39;AAL&#39;][k] )
    if isinstance(anatname, str):
        anatname = re.sub(&#34;_&#34;,&#34;&#34;,anatname)
    else:
        anatname=&#39;Unk&#39;
    fname=&#39;falffPoint&#39;+str(k)+anatname
    aname=&#39;alffPoint&#39;+str(k)+anatname
    outdict[fname]=(outdict[&#39;falff&#39;][ptImg==k]).mean()
    outdict[aname]=(outdict[&#39;alff&#39;][ptImg==k]).mean()

  rsfNuisance = pd.DataFrame( nuisance )
  rsfNuisance[&#39;FD&#39;]=corrmo[&#39;FD&#39;]

  nonbrainmask = ants.iMath( bmask, &#34;MD&#34;,2) - bmask
  trimmask = ants.iMath( bmask, &#34;ME&#34;,2)
  edgemask = ants.iMath( bmask, &#34;ME&#34;,1) - trimmask
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;brain_mask&#39;] = bmask
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;ssnr&#39;] = slice_snr( corrmo[&#39;motion_corrected&#39;], csfAndWM, gmseg )
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;high_motion_count&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum()
  outdict[&#39;high_motion_pct&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum() / rsfNuisance.shape[0]
  outdict[&#39;FD_max&#39;] = rsfNuisance[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = rsfNuisance[&#39;FD&#39;].mean()
  outdict[&#39;bold_evr&#39;] =  antspyt1w.patch_eigenvalue_ratio( und, 512, [16,16,16], evdepth = 0.9, mask = bmask )
  return outdict



def write_bvals_bvecs(bvals, bvecs, prefix ):
    &#39;&#39;&#39; Write FSL FDT bvals and bvecs files

    adapted from dipy.external code

    Parameters
    -------------
    bvals : (N,) sequence
       Vector with diffusion gradient strength (one per diffusion
       acquisition, N=no of acquisitions)
    bvecs : (N, 3) array-like
       diffusion gradient directions
    prefix : string
       path to write FDT bvals, bvecs text files
       None results in current working directory.
    &#39;&#39;&#39;
    _VAL_FMT = &#39;   %e&#39;
    bvals = tuple(bvals)
    bvecs = np.asarray(bvecs)
    bvecs[np.isnan(bvecs)] = 0
    N = len(bvals)
    fname = prefix + &#39;.bval&#39;
    fmt = _VAL_FMT * N + &#39;\n&#39;
    open(fname, &#39;wt&#39;).write(fmt % bvals)
    fname = prefix + &#39;.bvec&#39;
    bvf = open(fname, &#39;wt&#39;)
    for dim_vals in bvecs.T:
        bvf.write(fmt % tuple(dim_vals))

def crop_mcimage( x, mask, padder=None ):
    &#34;&#34;&#34;
    crop a time series (4D) image by a 3D mask

    Parameters
    -------------

    x : raw image

    mask  : mask for cropping

    &#34;&#34;&#34;
    cropmask = ants.crop_image( mask, mask )
    myorig = list( ants.get_origin(cropmask) )
    myorig.append( ants.get_origin( x )[3] )
    croplist = []
    if len(x.shape) &gt; 3:
        for k in range(x.shape[3]):
            temp = ants.slice_image( x, axis=3, idx=k )
            temp = ants.crop_image( temp, mask )
            if padder is not None:
                temp = ants.pad_image( temp, pad_width=padder )
            croplist.append( temp )
        temp = ants.list_to_ndimage( x, croplist )
        temp.set_origin( myorig )
        return temp
    else:
        return( ants.crop_image( x, mask ) )


def mm(
    t1_image,
    hier,
    rsf_image=[],
    flair_image=None,
    nm_image_list=None,
    dw_image=[], bvals=[], bvecs=[],
    srmodel=None,
    do_tractography = False,
    do_kk = False,
    do_normalization = None,
    target_range = [0,1],
    dti_motion_correct = &#39;Rigid&#39;,
    dti_denoise = False,
    test_run = False,
    verbose = False ):
    &#34;&#34;&#34;
    Multiple modality processing and normalization

    aggregates modality-specific processing under one roof.  see individual
    modality specific functions for details.

    Parameters
    -------------

    t1_image : raw t1 image

    hier  : output of antspyt1w.hierarchical ( see read hierarchical )

    rsf_image : list of resting state fmri

    flair_image : flair

    nm_image_list : list of neuromelanin images

    dw_image : list of diffusion weighted images

    bvals : list of bvals file names

    bvecs : list of bvecs file names

    srmodel : optional srmodel

    do_tractography : boolean

    do_kk : boolean to control whether we compute kelly kapowski thickness image (slow)

    do_normalization : template transformation if available

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.
    
    dti_motion_correct : None Rigid or SyN

    dti_denoise : boolean

    test_run : boolean 

    verbose : boolean

    &#34;&#34;&#34;
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_path_mm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    mycsvfn = ex_path + &#34;FA_JHU_labels_edited.csv&#34;
    citcsvfn = ex_path + &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad.csv&#34;
    dktcsvfn = ex_path + &#34;dkt.csv&#34;
    cnxcsvfn = ex_path + &#34;dkt_cortex_cit_deep_brain.csv&#34;
    JHU_atlasfn = ex_path + &#39;JHU-ICBM-FA-1mm.nii.gz&#39; # Read in JHU atlas
    JHU_labelsfn = ex_path + &#39;JHU-ICBM-labels-1mm.nii.gz&#39; # Read in JHU labels
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( mycsvfn ) or not exists( citcsvfn ) or not exists( cnxcsvfn ) or not exists( dktcsvfn ) or not exists( JHU_atlasfn ) or not exists( JHU_labelsfn ) or not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        raise ValueError(&#39;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#39;)
    mycsv = pd.read_csv(  mycsvfn )
    citcsv = pd.read_csv(  os.path.expanduser( citcsvfn ) )
    dktcsv = pd.read_csv(  os.path.expanduser( dktcsvfn ) )
    cnxcsv = pd.read_csv(  os.path.expanduser( cnxcsvfn ) )
    JHU_atlas = mm_read( JHU_atlasfn ) # Read in JHU atlas
    JHU_labels = mm_read( JHU_labelsfn ) # Read in JHU labels
    template = mm_read( templatefn ) # Read in template
    #####################
    #  T1 hierarchical  #
    #####################
    t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
    t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    mynets = list([ &#39;CinguloopercularTaskControl&#39;, &#39;DefaultMode&#39;,
        &#39;MemoryRetrieval&#39;, &#39;VentralAttention&#39;, &#39;Visual&#39;,
        &#39;FrontoparietalTaskControl&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
        &#39;DorsalAttention&#39;])
    output_dict = {
        &#39;kk&#39;: None,
        &#39;rsf&#39;: None,
        &#39;flair&#39; : None,
        &#39;NM&#39; : None,
        &#39;DTI&#39; : None,
        &#39;FA_summ&#39; : None,
        &#39;MD_summ&#39; : None,
        &#39;tractography&#39; : None,
        &#39;tractography_connectivity&#39; : None
    }
    normalization_dict = {
        &#39;kk_norm&#39;: None,
        &#39;NM_norm&#39; : None,
        &#39;FA_norm&#39; : None,
        &#39;MD_norm&#39; : None,
        &#39;alff_norm&#39; : None,
        &#39;falff_norm&#39; : None,
        &#39;CinguloopercularTaskControl_norm&#39; : None,
        &#39;DefaultMode_norm&#39; : None,
        &#39;MemoryRetrieval_norm&#39; : None,
        &#39;VentralAttention_norm&#39; : None,
        &#39;Visual_norm&#39; : None,
        &#39;FrontoparietalTaskControl_norm&#39; : None,
        &#39;Salience_norm&#39; : None,
        &#39;Subcortical_norm&#39; : None,
        &#39;DorsalAttention_norm&#39; : None
    }
    if test_run:
        return output_dict, normalization_dict

    if do_kk:
        if verbose:
            print(&#39;kk&#39;)
        output_dict[&#39;kk&#39;] = antspyt1w.kelly_kapowski_thickness( hier[&#39;brain_n4_dnz&#39;],
            labels=hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], iterations=45 )
    ################################## do the rsf .....
    if len(rsf_image) &gt; 0:
        rsf_image = [i for i in rsf_image if i is not None]
        if verbose:
            print(&#39;rsf length &#39; + str( len( rsf_image ) ) )
        if len( rsf_image ) &gt;= 2: # assume 2 is the largest possible value
            rsf_image1 = rsf_image[0]
            rsf_image2 = rsf_image[1]
            # build a template then join the images
            if verbose:
                print(&#34;initial average for rsf&#34;)
            rsfavg1=get_average_rsf(rsf_image1)
            rsfavg2=get_average_rsf(rsf_image2)
            if verbose:
                print(&#34;template average for rsf&#34;)
            init_temp = ants.image_clone( rsfavg1 )
            if rsf_image1.shape[3] &lt; rsf_image2.shape[3]:
                init_temp = ants.image_clone( rsfavg2 )
            boldTemplate = ants.build_template(
                initial_template = init_temp,
                image_list=[rsfavg1,rsfavg2],
                iterations=5, verbose=False )
            if verbose:
                print(&#34;join the 2 rsf&#34;)
            if rsf_image1.shape[3] &gt; 10 and rsf_image2.shape[3] &gt; 10:
                rsf_image = merge_timeseries_data( rsf_image1, rsf_image2 )
            elif rsf_image1.shape[3] &gt; rsf_image2.shape[3]:
                rsf_image = rsf_image1
            else:
                rsf_image = rsf_image2
        elif len( rsf_image ) == 1:
            rsf_image = rsf_image[0]
            boldTemplate=get_average_rsf(rsf_image)
        if rsf_image.shape[3] &gt; 10: # FIXME - better heuristic?
            output_dict[&#39;rsf&#39;] = resting_state_fmri_networks(
                rsf_image,
                boldTemplate,
                hier[&#39;brain_n4_dnz&#39;],
                t1atropos,
                f=[0.03,0.08],
                spa = 1.0,
                spt = 0.5,
                nc = 6, verbose=verbose )
    if nm_image_list is not None:
        if verbose:
            print(&#39;nm&#39;)
        if srmodel is None:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], verbose=verbose )
        else:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], srmodel=srmodel, target_range=target_range, verbose=verbose  )
################################## do the dti .....
    if len(dw_image) &gt; 0 :
        if verbose:
            print(&#39;dti-x&#39;)
        if len( dw_image ) == 1: # use T1 for distortion correction and brain extraction
            if verbose:
                print(&#34;We have only one DTI: &#34; + str(len(dw_image)))
            dw_image = dw_image[0]
            btpB0,btpDW=get_average_dwi_b0(dw_image)
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            btpDW = ants.apply_transforms( btpDW, btpDW,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            btpB0 = ants.apply_transforms( btpB0, btpB0,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;nearestNeighbor&#39;)
            # dwimask = ants.iMath(dwimask,&#39;MD&#39;,1)
            t12dwi = ants.apply_transforms( btpDW, hier[&#39;brain_n4_dnz&#39;], tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;linear&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image,
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                motion_correct=dti_motion_correct, # set to False if using input from qsiprep
                denoise=dti_denoise,
                verbose = verbose)
        else :  # use phase encoding acquisitions for distortion correction and T1 for brain extraction
            if verbose:
                print(&#34;We have both DTI_LR and DTI_RL: &#34; + str(len(dw_image)))
            a1b,a1w=get_average_dwi_b0(dw_image[0])
            a2b,a2w=get_average_dwi_b0(dw_image[1],fixed_b0=a1b,fixed_dwi=a1w)
            btpB0, btpDW = dti_template(
                b_image_list=[a1b,a2b],
                w_image_list=[a1w,a2w],
                iterations=7, verbose=verbose )
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image[0],
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                img_RL=dw_image[1],
                bval_RL=bvals[1],
                bvec_RL=bvecs[1],
                motion_correct=&#39;SyN&#39;, # set to False if using input from qsiprep
                denoise=True,
                verbose = verbose)
        mydti = output_dict[&#39;DTI&#39;]
        # summarize dwi with T1 outputs
        # first - register ....
        reg = ants.registration( mydti[&#39;recon_fa&#39;], hier[&#39;brain_n4_dnz&#39;], &#39;SyNBold&#39;, total_sigma=1.0 )
        ##################################################
        output_dict[&#39;FA_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_fa&#39;],
            hier=hier,
            modality_name=&#39;fa&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        ##################################################
        output_dict[&#39;MD_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_md&#39;],
            hier=hier,
            modality_name=&#39;md&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        # these inputs should come from nicely processed data
        dktmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        citmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;cit168lab&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        dktmapped[ citmapped &gt; 0]=0
        mask = ants.threshold_image( mydti[&#39;recon_fa&#39;], 0.01, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
        if do_tractography: # dwi_deterministic_tracking dwi_closest_peak_tracking
            output_dict[&#39;tractography&#39;] = dwi_deterministic_tracking(
                mydti[&#39;dwi_LR_dewarped&#39;],
                mydti[&#39;recon_fa&#39;],
                mydti[&#39;bval_LR&#39;],
                mydti[&#39;bvec_LR&#39;],
                seed_density = 1,
                mask=mask,
                verbose = verbose )
            mystr = output_dict[&#39;tractography&#39;]
            output_dict[&#39;tractography_connectivity&#39;] = dwi_streamline_connectivity( mystr[&#39;streamlines&#39;], dktmapped+citmapped, cnxcsv, verbose=verbose )
    ################################## do the flair .....
    if flair_image is not None:
        if verbose:
            print(&#39;flair&#39;)
        wmhprior = None
        priorfn = ex_path_mm + &#39;CIT168_wmhprior_700um_pad_adni.nii.gz&#39;
        if ( exists( priorfn ) ):
            wmhprior = ants.image_read( priorfn )
            wmhprior = ants.apply_transforms( t1_image, wmhprior, do_normalization[&#39;invtransforms&#39;] )
        output_dict[&#39;flair&#39;] = boot_wmh( flair_image, t1_image, t1atropos,
            prior_probability=wmhprior, verbose=verbose )
    #################################################################
    ### NOTES: deforming to a common space and writing out images ###
    ### images we want come from: DTI, NM, rsf, thickness ###########
    #################################################################
    if do_normalization is not None:
        if verbose:
            print(&#39;normalization&#39;)
        # might reconsider this template space - cropped and/or higher res?
        template = ants.resample_image( template, [1,1,1], use_voxels=False )
        # t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;], &#34;antsRegistrationSyNQuickRepro[s]&#34;)
        t1reg = do_normalization
        if do_kk:
            normalization_dict[&#39;kk_norm&#39;] = ants.apply_transforms( template, output_dict[&#39;kk&#39;][&#39;thickness_image&#39;], t1reg[&#39;fwdtransforms&#39;])
        if output_dict[&#39;DTI&#39;] is not None:
            mydti = output_dict[&#39;DTI&#39;]
            dtirig = ants.registration( hier[&#39;brain_n4_dnz&#39;], mydti[&#39;recon_fa&#39;], &#39;Rigid&#39; )
            normalization_dict[&#39;MD_norm&#39;] = ants.apply_transforms( template, mydti[&#39;recon_md&#39;],t1reg[&#39;fwdtransforms&#39;]+dtirig[&#39;fwdtransforms&#39;] )
            normalization_dict[&#39;FA_norm&#39;] = ants.apply_transforms( template, mydti[&#39;recon_fa&#39;],t1reg[&#39;fwdtransforms&#39;]+dtirig[&#39;fwdtransforms&#39;] )
        if output_dict[&#39;rsf&#39;] is not None:
            rsfpro = output_dict[&#39;rsf&#39;]
            rsfrig = ants.registration( hier[&#39;brain_n4_dnz&#39;], rsfpro[&#39;meanBold&#39;], &#39;Rigid&#39; )
            for netid in mynets:
                rsfkey = netid + &#34;_norm&#34;
                normalization_dict[rsfkey] = ants.apply_transforms(
                    template, rsfpro[netid],
                    t1reg[&#39;fwdtransforms&#39;]+rsfrig[&#39;fwdtransforms&#39;] )
        if nm_image_list is not None:
            nmpro = output_dict[&#39;NM&#39;]
            nmrig = nmpro[&#39;t1_to_NM_transform&#39;] # this is an inverse tx
            normalization_dict[&#39;NM_norm&#39;] = ants.apply_transforms( template, nmpro[&#39;NM_avg&#39;],t1reg[&#39;fwdtransforms&#39;]+nmrig,
                whichtoinvert=[False,False,True])

    if verbose:
        print(&#39;mm done&#39;)
    return output_dict, normalization_dict


def write_mm( output_prefix, mm, mm_norm=None, t1wide=None, separator=&#39;_&#39; ):
    &#34;&#34;&#34;
    write the tabular and normalization output of the mm function

    Parameters
    -------------

    output_prefix : prefix for file outputs - modality specific postfix will be added

    mm  : output of mm function for modality-space processing

    mm_norm : output of mm function for normalized processing

    t1wide : wide output data frame from t1 hierarchical

    separator : string or character separator for filenames

    Returns
    ---------

    both csv and image files written to disk.  the primary outputs will be
    output_prefix + separator + &#39;mmwide.csv&#39; and *norm.nii.gz images

    &#34;&#34;&#34;
    from dipy.io.streamline import save_tractogram
    if mm_norm is not None:
        for mykey in mm_norm.keys():
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            if mm_norm[mykey] is not None:
                image_write_with_thumbnail( mm_norm[mykey], tempfn )
    thkderk = None
    if t1wide is not None:
        thkderk = t1wide.iloc[: , 1:]
    kkderk = None
    if mm[&#39;kk&#39;] is not None:
        kkderk = mm[&#39;kk&#39;][&#39;thickness_dataframe&#39;].iloc[: , 1:]
        mykey=&#39;thickness_image&#39;
        tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
        image_write_with_thumbnail( mm[&#39;kk&#39;][mykey], tempfn )
    nmderk = None
    if mm[&#39;NM&#39;] is not None:
        nmderk = mm[&#39;NM&#39;][&#39;NM_dataframe_wide&#39;].iloc[: , 1:]
        for mykey in [&#39;NM_avg_cropped&#39;, &#39;NM_avg&#39;, &#39;NM_labels&#39; ]:
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( mm[&#39;NM&#39;][mykey], tempfn, thumb=False )

    faderk = mdderk = fat1derk = mdt1derk = None
    if mm[&#39;DTI&#39;] is not None:
        mydti = mm[&#39;DTI&#39;]
        myop = output_prefix + separator
        write_bvals_bvecs( mydti[&#39;bval_LR&#39;], mydti[&#39;bvec_LR&#39;], myop + &#39;reoriented&#39; )
        image_write_with_thumbnail( mydti[&#39;dwi_LR_dewarped&#39;],  myop + &#39;dwi.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;dtrecon_LR_dewarp&#39;][&#39;RGB&#39;] ,  myop + &#39;DTIRGB.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;jhu_labels&#39;],  myop+&#39;dtijhulabels.nii.gz&#39;, mydti[&#39;recon_fa&#39;] )
        image_write_with_thumbnail( mydti[&#39;recon_fa&#39;],  myop+&#39;dtifa.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;recon_md&#39;],  myop+&#39;dtimd.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;b0avg&#39;],  myop+&#39;b0avg.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;dwiavg&#39;],  myop+&#39;dwiavg.nii.gz&#39; )
        faderk = mm[&#39;DTI&#39;][&#39;recon_fa_summary&#39;].iloc[: , 1:]
        mdderk = mm[&#39;DTI&#39;][&#39;recon_md_summary&#39;].iloc[: , 1:]
        fat1derk = mm[&#39;FA_summ&#39;].iloc[: , 1:]
        mdt1derk = mm[&#39;MD_summ&#39;].iloc[: , 1:]
    if mm[&#39;tractography&#39;] is not None:
        ofn = output_prefix + separator + &#39;tractogram.trk&#39;
        save_tractogram( mm[&#39;tractography&#39;][&#39;tractogram&#39;], ofn )
    cnxderk = None
    if mm[&#39;tractography_connectivity&#39;] is not None:
        cnxderk = mm[&#39;tractography_connectivity&#39;][&#39;connectivity_wide&#39;].iloc[: , 1:] # NOTE: connectivity_wide is not much tested
        ofn = output_prefix + separator + &#39;dtistreamlineconn.csv&#39;
        pd.DataFrame(mm[&#39;tractography_connectivity&#39;][&#39;connectivity_matrix&#39;]).to_csv( ofn )
    mm_wide = pd.concat( [
        thkderk,
        kkderk,
        nmderk,
        faderk,
        mdderk,
        fat1derk,
        mdt1derk,
        cnxderk
        ], axis=1 )
    mm_wide = mm_wide.copy()
    if mm[&#39;NM&#39;] is not None:
        mm_wide[&#39;NM_avg_signaltonoise&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_signaltonoise&#39;]
        mm_wide[&#39;NM_avg_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_substantianigra&#39;]
        mm_wide[&#39;NM_std_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_std_substantianigra&#39;]
        mm_wide[&#39;NM_volume_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_volume_substantianigra&#39;]
        mm_wide[&#39;NM_avg_refregion&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_refregion&#39;]
        mm_wide[&#39;NM_std_refregion&#39;] = mm[&#39;NM&#39;][&#39;NM_std_refregion&#39;]
        mm_wide[&#39;NM_evr&#39;] = mm[&#39;NM&#39;][&#39;NM_evr&#39;]
        mm_wide[&#39;NM_count&#39;] = mm[&#39;NM&#39;][&#39;NM_count&#39;]
        mm_wide[&#39;NM_min&#39;] = mm[&#39;NM&#39;][&#39;NM_min&#39;]
        mm_wide[&#39;NM_max&#39;] = mm[&#39;NM&#39;][&#39;NM_max&#39;]
        mm_wide[&#39;NM_mean&#39;] = mm[&#39;NM&#39;][&#39;NM_mean&#39;]
        mm_wide[&#39;NM_sd&#39;] = mm[&#39;NM&#39;][&#39;NM_sd&#39;]
        mm_wide[&#39;NM_q0pt05&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt05&#39;]
        mm_wide[&#39;NM_q0pt10&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt10&#39;]
        mm_wide[&#39;NM_q0pt90&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt90&#39;]
        mm_wide[&#39;NM_q0pt95&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt95&#39;]
        mm_wide[&#39;NM_substantianigra_z_coordinate&#39;] = mm[&#39;NM&#39;][&#39;NM_substantianigra_z_coordinate&#39;]
    if mm[&#39;flair&#39;] is not None:
        myop = output_prefix + separator + &#39;wmh.nii.gz&#39;
        if mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;] is not None:
            image_write_with_thumbnail( mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;], myop, thumb=False )
        mm_wide[&#39;flair_wmh&#39;] = mm[&#39;flair&#39;][&#39;wmh_mass&#39;]
        mm_wide[&#39;flair_wmh_prior&#39;] = mm[&#39;flair&#39;][&#39;wmh_mass_prior&#39;]
        mm_wide[&#39;flair_evr&#39;] = mm[&#39;flair&#39;][&#39;wmh_evr&#39;]
        mm_wide[&#39;flair_SNR&#39;] = mm[&#39;flair&#39;][&#39;wmh_SNR&#39;]
    if mm[&#39;rsf&#39;] is not None:
        mynets = list([ &#39;meanBold&#39;, &#39;brain_mask&#39;, &#39;motion_corrected&#39;, &#39;alff&#39;, &#39;falff&#39;,
            &#39;CinguloopercularTaskControl&#39;, &#39;DefaultMode&#39;, &#39;MemoryRetrieval&#39;,
            &#39;VentralAttention&#39;, &#39;Visual&#39;, &#39;FrontoparietalTaskControl&#39;, &#39;Salience&#39;,
            &#39;Subcortical&#39;, &#39;DorsalAttention&#39;, &#39;tsnr&#39;] )
        rsfpro = mm[&#39;rsf&#39;]
        for mykey in mynets:
            myop = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( rsfpro[mykey], myop, thumb=True )
        rsfpro[&#39;corr_wide&#39;].set_index( mm_wide.index, inplace=True )
        mm_wide = pd.concat( [ mm_wide, rsfpro[&#39;corr_wide&#39;] ], axis=1 )
        # falff and alff
        search_key=&#39;alffPoint&#39;
        alffkeys = [key for key, val in rsfpro.items() if search_key in key]
        for myalf in alffkeys:
            mm_wide[ myalf ]=rsfpro[myalf]
        mm_wide[&#39;rsf_tsnr_mean&#39;] =  rsfpro[&#39;tsnr&#39;].mean()
        mm_wide[&#39;rsf_dvars_mean&#39;] =  rsfpro[&#39;dvars&#39;].mean()
        mm_wide[&#39;rsf_ssnr_mean&#39;] =  rsfpro[&#39;ssnr&#39;].mean()
        mm_wide[&#39;rsf_high_motion_count&#39;] =  rsfpro[&#39;high_motion_count&#39;]
        # mm_wide[&#39;rsf_high_motion_pct&#39;] = rsfpro[&#39;rsf_high_motion_pct&#39;] # BUG : rsf_high_motion_pct does not exist
        mm_wide[&#39;rsf_evr&#39;] =  rsfpro[&#39;bold_evr&#39;]
        mm_wide[&#39;rsf_FD_mean&#39;] = rsfpro[&#39;FD_mean&#39;]
        mm_wide[&#39;rsf_FD_max&#39;] = rsfpro[&#39;FD_max&#39;]
        mm_wide[&#39;rsf_alff_mean&#39;] = rsfpro[&#39;alff_mean&#39;]
        mm_wide[&#39;rsf_alff_sd&#39;] = rsfpro[&#39;alff_sd&#39;]
        mm_wide[&#39;rsf_falff_mean&#39;] = rsfpro[&#39;falff_mean&#39;]
        mm_wide[&#39;rsf_falff_sd&#39;] = rsfpro[&#39;falff_sd&#39;]
        ofn = output_prefix + separator + &#39;rsfcorr.csv&#39;
        rsfpro[&#39;corr&#39;].to_csv( ofn )
        # apply same principle to new correlation matrix, doesn&#39;t need to be incorporated with mm_wide
        ofn2 = output_prefix + separator + &#39;nodescorr.csv&#39;
        rsfpro[&#39;fullCorrMat&#39;].to_csv( ofn2 )
    if mm[&#39;DTI&#39;] is not None:
        mydti = mm[&#39;DTI&#39;]
        mm_wide[&#39;dti_tsnr_b0_mean&#39;] =  mydti[&#39;tsnr_b0&#39;].mean()
        mm_wide[&#39;dti_tsnr_dwi_mean&#39;] =  mydti[&#39;tsnr_dwi&#39;].mean()
        mm_wide[&#39;dti_dvars_b0_mean&#39;] =  mydti[&#39;dvars_b0&#39;].mean()
        mm_wide[&#39;dti_dvars_dwi_mean&#39;] =  mydti[&#39;dvars_dwi&#39;].mean()
        mm_wide[&#39;dti_ssnr_b0_mean&#39;] =  mydti[&#39;ssnr_b0&#39;].mean()
        mm_wide[&#39;dti_ssnr_dwi_mean&#39;] =  mydti[&#39;ssnr_dwi&#39;].mean()
        mm_wide[&#39;dti_fa_evr&#39;] =  mydti[&#39;fa_evr&#39;]
        mm_wide[&#39;dti_fa_SNR&#39;] =  mydti[&#39;fa_SNR&#39;]
        if mydti[&#39;framewise_displacement&#39;] is not None:
            mm_wide[&#39;dti_high_motion_count&#39;] =  mydti[&#39;high_motion_count&#39;]
            mm_wide[&#39;dti_FD_mean&#39;] = mydti[&#39;framewise_displacement&#39;].mean()
            mm_wide[&#39;dti_FD_max&#39;] = mydti[&#39;framewise_displacement&#39;].max()
            fdfn = output_prefix + separator + &#39;_fd.csv&#39;
            # mm_wide.to_csv( fdfn )
        else:
            mm_wide[&#39;dti_FD_mean&#39;] = mm_wide[&#39;dti_FD_max&#39;] = &#39;NA&#39;
    mmwidefn = output_prefix + separator + &#39;mmwide.csv&#39;
    mm_wide.to_csv( mmwidefn )
    return


def mm_nrg(
    studyid,   # pandas data frame
    sourcedir = os.path.expanduser( &#34;~/data/PPMI/MV/example_s3_b/images/PPMI/&#34; ),
    sourcedatafoldername = &#39;images&#39;, # root for source data
    processDir = &#34;processed&#34;, # where output will go - parallel to sourcedatafoldername
    mysep = &#39;-&#39;, # define a separator for filename components
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    visualize = True,
    nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;DTI&#34;,&#34;T2Flair&#34; ],
    verbose = True
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function assumes NRG format for the input data ....
    we also assume that t1w hierarchical (if already done) was written
    via its standardized write function.
    NRG = https://github.com/stnava/biomedicalDataOrganization

    this function is verbose

    Parameters
    -------------

    studyid : must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required.  rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.  see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    sourcedatafoldername : root for source data e.g. &#34;images&#34;

    processDir : where output will go - parallel to sourcedatafoldername e.g.
        &#34;processed&#34;

    mysep : define a character separator for filename components

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    visualize : True - will plot some results to png

    nrg_modality_list : list of permissible modalities - always include [T1w] as base

    verbose : boolean

    Returns
    ---------

    writes output to disk and potentially produces figures that may be
    captured in a ipynb / html file.

    &#34;&#34;&#34;
    studyid = studyid.dropna(axis=1)
    if studyid.shape[0] &lt; 1:
        raise ValueError(&#39;studyid has no rows&#39;)
    musthavecols = [&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studyid.keys():
            raise ValueError(&#39;studyid is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = &#39;-&#39; ):
        return x + separator + &#39;mmwide.csv&#39;
    if nrg_modality_list[0] != &#39;T1w&#39;:
        nrg_modality_list.insert(0, &#34;T1w&#34; )
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studyid
    sid = str(studyid[&#39;subjectID&#39;].iloc[0])
    dtid = str(studyid[&#39;date&#39;].iloc[0])
    iid = str(studyid[&#39;imageID&#39;].iloc[0])
    subjectrootpath = os.path.join(sourcedir,sid, dtid)
    if verbose:
        print(&#34;subjectrootpath: &#34;+ subjectrootpath )
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, iid, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + iid + &#39; @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    hierfn0 = re.sub( sourcedatafoldername, processDir, t1fn)
    hierfn0 = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfn0)
    hierfn = re.sub( &#34;T1w&#34;, &#34;T1wHierarchical&#34;, hierfn0)
    hierfn = hierfn + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    regout = hierfn0 + mysep + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;REGISTRATION EXISTENCE: &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfnSR = re.sub( sourcedatafoldername, processDir, t1fn)
        hierfnSR = re.sub( &#34;T1w&#34;, &#34;T1wHierarchicalSR&#34;, hierfnSR)
        hierfnSR = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfnSR)
        hierfnSR = hierfnSR + mysep
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    nimages = len(myimgsInput)
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.&#34;)
    for overmodX in nrg_modality_list:
        counter=counter+1
        if counter &gt; (len(nrg_modality_list)+1):
            print(&#34;This is weird. &#34; + str(counter))
            return
        if overmodX == &#39;T1w&#39;:
            iidOtherMod = iid
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        elif overmodX == &#39;NM2DMT&#39; and (&#39;nmid1&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;nmid1&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            for nmnum in range(2,11):
                locnmnum = &#39;nmid&#39;+str(nmnum)
                if locnmnum in studyid.keys() :
                    iidOtherMod = str( int(studyid[locnmnum].iloc[0]) )
                    mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
                    myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;rsfMRI&#39; in overmodX and ( ( &#39;rsfid1&#39; in studyid.keys() ) or (&#39;rsfid2&#39; in studyid.keys() ) ):
            myimgsr = []
            if  &#39;rsfid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;rsfid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;DTI&#39; in overmodX and (  &#39;dtid1&#39; in studyid.keys() or  &#39;dtid2&#39; in studyid.keys() ):
            myimgsr = []
            if  &#39;dtid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;dtid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;T2Flair&#39; in overmodX and (&#39;flairid&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;flairid&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        if verbose:
            print( &#34;overmod &#34; + overmodX + &#34; &#34; + iidOtherMod )
            print(f&#34;modality search path: {mod_search_path}&#34;)
        myimgsr.sort()
        if len(myimgsr) &gt; 0:
            overmodXx = str(overmodX)
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodXx )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodXx == &#39;NM2DMT&#39;:
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                subjectpropath = os.path.dirname( myimgsr2[0] )
                subjectpropath = re.sub( sourcedatafoldername, processDir,subjectpropath )
                if verbose:
                    print( &#34;subjectpropath &#34; + subjectpropath )
                mysplit = subjectpropath.split( &#34;/&#34; )
                os.makedirs( subjectpropath, exist_ok=True  )
                mysplitCount = len( mysplit )
                project = mysplit[mysplitCount-5]
                subject = mysplit[mysplitCount-4]
                date = mysplit[mysplitCount-3]
                modality = mysplit[mysplitCount-2]
                uider = mysplit[mysplitCount-1]
                identifier = mysep.join([project, subject, date, modality ])
                identifier = identifier + &#34;_&#34; + iid
                mymm = subjectpropath + &#34;/&#34; + identifier
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount = 0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( myimg )
                        subjectpropath = re.sub( sourcedatafoldername, processDir, subjectpropath )
                        mysplit = subjectpropath.split(&#34;/&#34;)
                        mysplitCount = len( mysplit )
                        project = mysplit[mysplitCount-5]
                        date = mysplit[mysplitCount-4]
                        subject = mysplit[mysplitCount-3]
                        mymod = mysplit[mysplitCount-2] # FIXME system dependent
                        uid = mysplit[mysplitCount-1] # unique image id
                        os.makedirs( subjectpropath, exist_ok=True  )
                        if mymod == &#39;T1w&#39;:
                            identifier = mysep.join([project, date, subject, mymod, uid])
                        else:  # add the T1 unique id since that drives a lot of the analysis
                            identifier = mysep.join([project, date, subject, mymod, uid ])
                            identifier = identifier + &#34;_&#34; + iid
                        mymm = subjectpropath + &#34;/&#34; + identifier
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print(identifier)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;DefaultMode&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;FrontoparietalTaskControl&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FrontoparietalTaskControl&#39;, filename=mymm+mysep+&#34;boldFrontoparietalTaskControl.png&#34;  )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                dowrite=True
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if len( dtilrfn ) == 1:
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                srmodel_DTI_mdl=None
                                if srmodel_DTI is not False:
                                    temp = ants.get_spacing(img)
                                    dtspc=[temp[0],temp[1],temp[2]]
                                    bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                    if isinstance( srmodel_DTI, str ):
                                        srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                        mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                    if exists( mdlfn ):
                                        if verbose:
                                            print(mdlfn)
                                        srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                    else:
                                        print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                tabPro, normPro = mm( t1, hier,
                                    dw_image=imgList,
                                    bvals = bvalfnList,
                                    bvecs = bvecfnList,
                                    srmodel=srmodel_DTI_mdl,
                                    do_tractography=not test_run,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                mydti = tabPro[&#39;DTI&#39;]
                                if visualize:
                                    maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                    ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA (supposed to be better)&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                    ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                    ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return



def mm_csv(
    studycsv,   # pandas data frame
    mysep = &#39;-&#39;, # or &#34;_&#34; for BIDS
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    dti_motion_correct = &#39;SyN&#39;,
    dti_denoise = True,
    nrg_modality_list = None
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function does not assume NRG format for the input data ....

    Parameters
    -------------

    studycsv : must have columns:
        - subjectID
        - date or session
        - imageID
        - modality
        - sourcedir
        - outputdir
        - filename (path to the t1 image)
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
        see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    outputdir : a study specific folder where individual output subject folders will go

    filename : the raw image filename (full path)

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    dti_motion_correct : None, Rigid or SyN

    dti_denoise : boolean

    nrg_modality_list : optional; defaults to None; use to focus on a given modality

    Returns
    ---------

    writes output to disk and produces figures

    &#34;&#34;&#34;
    visualize = True
    verbose = True
    if nrg_modality_list is None:
        nrg_modality_list = get_valid_modalities()
    if studycsv.shape[0] &lt; 1:
        raise ValueError(&#39;studycsv has no rows&#39;)
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studycsv.keys():
            raise ValueError(&#39;studycsv is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = mysep ):
        return x + separator + &#39;mmwide.csv&#39;
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studycsv
    # musthavecols = [&#39;projectID&#39;,&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    projid = str(studycsv[&#39;projectID&#39;].iloc[0])
    sid = str(studycsv[&#39;subjectID&#39;].iloc[0])
    dtid = str(studycsv[&#39;date&#39;].iloc[0])
    iid = str(studycsv[&#39;imageID&#39;].iloc[0])
    t1iidUse=iid
    modality = str(studycsv[&#39;modality&#39;].iloc[0])
    sourcedir = str(studycsv[&#39;sourcedir&#39;].iloc[0])
    outputdir = str(studycsv[&#39;outputdir&#39;].iloc[0])
    filename = str(studycsv[&#39;filename&#39;].iloc[0])
    if not exists(filename):
            raise ValueError(&#39;mm_nrg cannot find filename &#39; + filename + &#39; in mm_csv&#39; )
    def docsamson( locmod, t1iid=None, verbose=True ):
        myimgsInput = []
        myoutputPrefix = None
        imfns = [ &#39;filename&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;flairid&#39; ]
        if locmod == &#39;T1w&#39;:
            imfns=[&#39;filename&#39;]
        elif locmod == &#39;T2Flair&#39;:
            imfns=[&#39;flairid&#39;]
        elif locmod == &#39;NM2DMT&#39;:
            imfns=[]
            for i in range(11):
                imfns.append( &#39;nmid&#39; + str(i) )
        elif locmod == &#39;rsfMRI&#39;:
            imfns=[]
            for i in range(3):
                imfns.append( &#39;rsfid&#39; + str(i) )
        elif locmod == &#39;DTI&#39;:
            imfns=[]
            for i in range(3):
                imfns.append( &#39;dtid&#39; + str(i) )
        for i in imfns:
            if verbose:
                print( i + &#34; &#34; + locmod )
            if i in studycsv.keys():
                fni=str(studycsv[i].iloc[0])
                if verbose:
                    print( i + &#34; &#34; + fni + &#39; exists &#39; + str( exists( fni ) ) )
                if exists( fni ):
                    myimgsInput.append( fni )
                    temp = os.path.basename( fni )
                    mysplit = temp.split( mysep )
                    iid = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, mysplit[len(mysplit)-1] )
                    iid = re.sub( &#34;.mha&#34;, &#34;&#34;, iid )
                    iid = re.sub( &#34;.nii&#34;, &#34;&#34;, iid )
                    iid2 = iid
                    if locmod != &#39;T1w&#39; and t1iid is not None:
                        iid2=iid+&#34;_&#34;+t1iid
                    myoutputPrefix = outputdir + &#34;/&#34; + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + locmod + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + locmod + mysep + iid2
        if verbose:
            print(&#34;VERBOSE in docsamson&#34;)
            print( locmod )
            print( myimgsInput )
            print( myoutputPrefix )
        return {
            &#39;modality&#39;: locmod,
            &#39;outprefix&#39;: myoutputPrefix,
            &#39;images&#39;: myimgsInput
            }
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1fn = filename
    if not exists( t1fn ):
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + t1fn )
    t1 = mm_read( t1fn, modality=&#39;T1w&#39; )
    hierfn = outputdir + &#34;/&#34;  + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchical&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchical&#34; + mysep + iid + mysep
    hierfnSR = outputdir + &#34;/&#34; + projid + &#34;/&#34;  + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchicalSR&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchicalSR&#34; + mysep + iid + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    if verbose:
        print( hierfntest )
    regout = hierfn + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;REGISTRATION EXISTENCE: &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) and exists( templateTx[&#39;fwdtransforms&#39;][0]) and exists( templateTx[&#39;fwdtransforms&#39;][1]) and exists( templateTx[&#39;invtransforms&#39;][0]) and exists( templateTx[&#39;invtransforms&#39;][1])
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    for overmodX in nrg_modality_list:
        # define 1. input images 2. output prefix
        mydoc = docsamson( overmodX, t1iid=t1iidUse )
        myimgsr = mydoc[&#39;images&#39;]
        mymm = mydoc[&#39;outprefix&#39;]
        mymod = mydoc[&#39;modality&#39;]
        if verbose:
            print( mydoc )
        if len(myimgsr) &gt; 0:
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodX )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodX == &#39;NM2DMT&#39;:
                subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                if verbose:
                    print(&#34;subjectpropath is&#34;)
                    print(subjectpropath)
                    os.makedirs( subjectpropath, exist_ok=True  )
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount=0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                        if verbose:
                            print(&#34;subjectpropath is&#34;)
                            print(subjectpropath)
                        os.makedirs( subjectpropath, exist_ok=True  )
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;DefaultMode&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;FrontoparietalTaskControl&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FrontoparietalTaskControl&#39;, filename=mymm+mysep+&#34;boldFrontoparietalTaskControl.png&#34;  )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                missing_dti_data=False # bval, bvec or images
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if exists( dtilrfn ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                # check existence of all files expected ...
                                for dtiex in bvalfnList+bvecfnList+myimgsr:
                                    if not exists(dtiex):
                                        print(&#39;mm_csv: missing dti data &#39; + dtiex )
                                        missing_dti_data=True
                                        dowrite=False
                                if not missing_dti_data:
                                    dowrite=True
                                    srmodel_DTI_mdl=None
                                    if srmodel_DTI is not False:
                                        temp = ants.get_spacing(img)
                                        dtspc=[temp[0],temp[1],temp[2]]
                                        bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                        mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                        if isinstance( srmodel_DTI, str ):
                                            srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                            mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                        if exists( mdlfn ):
                                            if verbose:
                                                print(mdlfn)
                                            srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                        else:
                                            print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                    tabPro, normPro = mm( t1, hier,
                                        dw_image=imgList,
                                        bvals = bvalfnList,
                                        bvecs = bvecfnList,
                                        srmodel=srmodel_DTI_mdl,
                                        do_tractography=not test_run,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        dti_motion_correct = dti_motion_correct,
                                        dti_denoise = dti_denoise,
                                        test_run=test_run,
                                        verbose=True )
                                    mydti = tabPro[&#39;DTI&#39;]
                                    if visualize:
                                        maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                        ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA (supposed to be better)&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                        ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                        ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return

def spec_taper(x, p=0.1):
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    &#34;&#34;&#34;
    Computes a tapered version of x, with tapering p.

    Adapted from R&#39;s stats::spec.taper at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    &#34;&#34;&#34;

    p = np.r_[p]
    assert np.all((p &gt;= 0) &amp; (p &lt; 0.5)), &#34;&#39;p&#39; must be between 0 and 0.5&#34;

    x = np.r_[x].astype(&#39;float64&#39;)
    original_shape = x.shape

    assert len(original_shape) &lt;= 2, &#34;&#39;x&#39; must have at most 2 dimensions&#34;
    while len(x.shape) &lt; 2:
        x = np.expand_dims(x, axis=1)

    nr, nc = x.shape
    if len(p) == 1:
        p = p * np.ones(nc)
    else:
        assert len(p) == nc, &#34;length of &#39;p&#39; must be 1 or equal the number of columns of &#39;x&#39;&#34;

    for i in range(nc):
        m = int(np.floor(nr * p[i]))
        if m == 0:
            continue
        w = 0.5 * (1 - np.cos(np.pi * np.arange(1, 2 * m, step=2)/(2 * m)))
        x[:, i] = np.r_[w, np.ones(nr - 2 * m), w[::-1]] * x[:, i]

    x = np.reshape(x, original_shape)
    return x

def plot_spec(spec_res, coverage=None, ax=None, title=None):
    import matplotlib.pyplot as plt
    &#34;&#34;&#34;Convenience plotting method, also includes confidence cross in the same style as R.

    Note that the location of the cross is irrelevant; only width and height matter.&#34;&#34;&#34;
    f, Pxx = spec_res[&#39;freq&#39;], spec_res[&#39;spec&#39;]

    if coverage is not None:
        ci = spec_ci(spec_res[&#39;df&#39;], coverage=coverage)
        conf_x = (max(spec_res[&#39;freq&#39;]) - spec_res[&#39;bandwidth&#39;]) + np.r_[-0.5, 0.5] * spec_res[&#39;bandwidth&#39;]
        conf_y = max(spec_res[&#39;spec&#39;]) / ci[1]

    if ax is None:
        ax = plt.gca()

    ax.plot(f, Pxx, color=&#39;C0&#39;)
    ax.set_xlabel(&#39;Frequency&#39;)
    ax.set_ylabel(&#39;Log Spectrum&#39;)
    ax.set_yscale(&#39;log&#39;)
    if coverage is not None:
        ax.plot(np.mean(conf_x) * np.r_[1, 1], conf_y * ci, color=&#39;red&#39;)
        ax.plot(conf_x, np.mean(conf_y) * np.r_[1, 1], color=&#39;red&#39;)

    ax.set_title(spec_res[&#39;method&#39;] if title is None else title)

def spec_ci(df, coverage=0.95):
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    &#34;&#34;&#34;
    Computes the confidence interval for a spectral fit, based on the number of degrees of freedom.

    Adapted from R&#39;s stats::plot.spec at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    &#34;&#34;&#34;

    assert coverage &gt;= 0 and coverage &lt; 1, &#34;coverage probability out of range [0, 1)&#34;

    tail = 1 - coverage

    phi = stats.chi2.cdf(x=df, df=df)
    upper_quantile = 1 - tail * (1 - phi)
    lower_quantile = tail * phi

    return df / stats.chi2.ppf([upper_quantile, lower_quantile], df=df)

def spec_pgram(x, xfreq=1, spans=None, kernel=None, taper=0.1, pad=0, fast=True, demean=False, detrend=True,
               plot=True, **kwargs):
    &#34;&#34;&#34;
    Computes the spectral density estimate using a periodogram.  Optionally, it also:
    - Uses a provided kernel window, or a sequence of spans for convoluted modified Daniell kernels.
    - Tapers the start and end of the series to avoid end-of-signal effects.
    - Pads the provided series before computation, adding pad*(length of series) zeros at the end.
    - Pads the provided series before computation to speed up FFT calculation.
    - Performs demeaning or detrending on the series.
    - Plots results.

    Implemented to ensure compatibility with R&#39;s spectral functions, as opposed to reusing scipy&#39;s periodogram.

    Adapted from R&#39;s stats::spec.pgram at https://github.com/telmo-correa/time-series-analysis/blob/master/Python/spectrum.py

    example:

    import numpy as np
    import antspymm
    myx = np.random.rand(100,1)
    myspec = antspymm.spec_pgram(myx,0.5)

    &#34;&#34;&#34;
    from scipy import stats, signal, fft
    from statsmodels.regression.linear_model import yule_walker
    def daniell_window_modified(m):
        &#34;&#34;&#34; Single-pass modified Daniell kernel window.

        Weight is normalized to add up to 1, and all values are the same, other than the first and the
        last, which are divided by 2.
        &#34;&#34;&#34;
        def w(k):
            return np.where(np.abs(k) &lt; m, 1 / (2*m), np.where(np.abs(k) == m, 1/(4*m), 0))

        return w(np.arange(-m, m+1))

    def daniell_window_convolve(v):
        &#34;&#34;&#34; Convolved version of multiple modified Daniell kernel windows.

        Parameter v should be an iterable of m values.
        &#34;&#34;&#34;

        if len(v) == 0:
            return np.r_[1]

        if len(v) == 1:
            return daniell_window_modified(v[0])

        return signal.convolve(daniell_window_modified(v[0]), daniell_window_convolve(v[1:]))

    # Ensure we can store non-integers in x, and that it is a numpy object
    x = np.r_[x].astype(&#39;float64&#39;)
    original_shape = x.shape

    # Ensure correct dimensions
    assert len(original_shape) &lt;= 2, &#34;&#39;x&#39; must have at most 2 dimensions&#34;
    while len(x.shape) &lt; 2:
        x = np.expand_dims(x, axis=1)

    N, nser = x.shape
    N0 = N

    # Ensure only one of spans, kernel is provided, and build the kernel window if needed
    assert (spans is None) or (kernel is None), &#34;must specify only one of &#39;spans&#39; or &#39;kernel&#39;&#34;
    if spans is not None:
        kernel = daniell_window_convolve(np.floor_divide(np.r_[spans], 2))

    # Detrend or demean the series
    if detrend:
        t = np.arange(N) - (N - 1)/2
        sumt2 = N * (N**2 - 1)/12
        x -= (np.repeat(np.expand_dims(np.mean(x, axis=0), 0), N, axis=0) + np.outer(np.sum(x.T * t, axis=1), t/sumt2).T)
    elif demean:
        x -= np.mean(x, axis=0)

    # Compute taper and taper adjustment variables
    x = spec_taper(x, taper)
    u2 = (1 - (5/8) * taper * 2)
    u4 = (1 - (93/128) * taper * 2)

    # Pad the series with copies of the same shape, but filled with zeroes
    if pad &gt; 0:
        x = np.r_[x, np.zeros((pad * x.shape[0], x.shape[1]))]
        N = x.shape[0]

    # Further pad the series to accelerate FFT computation
    if fast:
        newN = fft.next_fast_len(N, True)
        x = np.r_[x, np.zeros((newN - N, x.shape[1]))]
        N = newN

    # Compute the Fourier frequencies (R&#39;s spec.pgram convention style)
    Nspec = int(np.floor(N/2))
    freq = (np.arange(Nspec) + 1) * xfreq / N

    # Translations to keep same row / column convention as stats::mvfft
    xfft = fft.fft(x.T).T

    # Compute the periodogram for each i, j
    pgram = np.empty((N, nser, nser), dtype=&#39;complex&#39;)
    for i in range(nser):
        for j in range(nser):
            pgram[:, i, j] = xfft[:, i] * np.conj(xfft[:, j]) / (N0 * xfreq)
            pgram[0, i, j] = 0.5 * (pgram[1, i, j] + pgram[-1, i, j])

    if kernel is None:
        # Values pre-adjustment
        df = 2
        bandwidth = np.sqrt(1 / 12)
    else:
        def conv_circular(signal, kernel):
            &#34;&#34;&#34;
            Performs 1D circular convolution, in the same style as R::kernapply,
            assuming the kernel window is centered at 0.
            &#34;&#34;&#34;
            pad = len(signal) - len(kernel)
            half_window = int((len(kernel) + 1) / 2)
            indexes = range(-half_window, len(signal) - half_window)
            orig_conv = np.real(fft.ifft(fft.fft(signal) * fft.fft(np.r_[np.zeros(pad), kernel])))
            return orig_conv.take(indexes, mode=&#39;wrap&#39;)

        # Convolve pgram with kernel with circular conv
        for i in range(nser):
            for j in range(nser):
                pgram[:, i, j] = conv_circular(pgram[:, i, j], kernel)

        df = 2 / np.sum(kernel**2)
        m = (len(kernel) - 1)/2
        k = np.arange(-m, m+1)
        bandwidth = np.sqrt(np.sum((1/12 + k**2) * kernel))

    df = df/(u4/u2**2)*(N0/N)
    bandwidth = bandwidth * xfreq/N

    # Remove padded results
    pgram = pgram[1:(Nspec+1), :, :]

    spec = np.empty((Nspec, nser))
    for i in range(nser):
        spec[:, i] = np.real(pgram[:, i, i])

    if nser == 1:
        coh = None
        phase = None
    else:
        coh = np.empty((Nspec, int(nser * (nser - 1)/2)))
        phase = np.empty((Nspec, int(nser * (nser - 1)/2)))
        for i in range(nser):
            for j in range(i+1, nser):
                index = int(i + j*(j-1)/2)
                coh[:, index] = np.abs(pgram[:, i, j])**2 / (spec[:, i] * spec[:, j])
                phase[:, index] = np.angle(pgram[:, i, j])

    spec = spec / u2
    spec = spec.squeeze()

    results = {
        &#39;freq&#39;: freq,
        &#39;spec&#39;: spec,
        &#39;coh&#39;: coh,
        &#39;phase&#39;: phase,
        &#39;kernel&#39;: kernel,
        &#39;df&#39;: df,
        &#39;bandwidth&#39;: bandwidth,
        &#39;n.used&#39;: N,
        &#39;orig.n&#39;: N0,
        &#39;taper&#39;: taper,
        &#39;pad&#39;: pad,
        &#39;detrend&#39;: detrend,
        &#39;demean&#39;: demean,
        &#39;method&#39;: &#39;Raw Periodogram&#39; if kernel is None else &#39;Smoothed Periodogram&#39;
    }

    if plot:
        plot_spec(results, coverage=0.95, **kwargs)

    return results

def alffmap( x, flo=0.01, fhi=0.1, tr=1, detrend = True ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.
    same function in ANTsR.

    x input vector for the time series of interest
    flo low frequency, typically 0.01
    fhi high frequency, typically 0.1
    tr the period associated with the vector x (inverse of frequency)
    detrend detrend the input time series

    return vector is output showing ALFF and fALFF values
    &#34;&#34;&#34;
    temp = spec_pgram( x, xfreq=1.0/tr, demean=False, detrend=detrend, taper=0, fast=True, plot=False )
    fselect = np.logical_and( temp[&#39;freq&#39;] &gt;= flo, temp[&#39;freq&#39;] &lt;= fhi )
    denom = (temp[&#39;spec&#39;]).sum()
    numer = (temp[&#39;spec&#39;][fselect]).sum()
    return {  &#39;alff&#39;:numer, &#39;falff&#39;: numer/denom }


def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.

    x - input clean resting state fmri
    mask - mask over which to compute f/alff
    flo - low frequency, typically 0.01
    fhi - high frequency, typically 0.1
    nuisance - optional nuisance matrix

    return dictionary with ALFF and fALFF images
    &#34;&#34;&#34;
    xmat = ants.timeseries_to_matrix( x, mask )
    if nuisance is not None:
        xmat = ants.regress_components( xmat, nuisance )
    alffvec = xmat[0,:]*0
    falffvec = xmat[0,:]*0
    mytr = ants.get_spacing( x )[3]
    for n in range( xmat.shape[1] ):
        temp = alffmap( xmat[:,n], flo=flo, fhi=fhi, tr=mytr )
        alffvec[n]=temp[&#39;alff&#39;]
        falffvec[n]=temp[&#39;falff&#39;]
    alffi=ants.make_image( mask, alffvec )
    falffi=ants.make_image( mask, falffvec )
    return {  &#39;alff&#39;: alffi, &#39;falff&#39;: falffi }


def down2iso( x, interpolation=&#39;linear&#39;, takemin=False ):
    &#34;&#34;&#34;
    will downsample an anisotropic image to an isotropic resolution

    x: input image

    interpolation: linear or nearestneighbor

    takemin : boolean map to min space; otherwise max

    return image downsampled to isotropic resolution
    &#34;&#34;&#34;
    spc = ants.get_spacing( x )
    if takemin:
        newspc = np.asarray(spc).min()
    else:
        newspc = np.asarray(spc).max()
    newspc = np.repeat( newspc, x.dimension )
    if interpolation == &#39;linear&#39;:
        xs = ants.resample_image( x, newspc, interp_type=0)
    else:
        xs = ants.resample_image( x, newspc, interp_type=1)
    return xs


def read_mm_csv( x, is_t1=False, colprefix=None, separator=&#39;-&#39;, verbose=False ):
    splitter=os.path.basename(x).split( separator )
    lensplit = len( splitter )-1
    temp = os.path.basename(x)
    temp = os.path.splitext(temp)[0]
    temp = re.sub(separator+&#39;mmwide&#39;,&#39;&#39;,temp)
    idcols = [&#39;u_hier_id&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;mmimageuid&#39;,&#39;t1imageuid&#39;]
    df = pd.DataFrame( columns = idcols, index=range(1) )
    valstoadd = [temp] + splitter[1:(lensplit-1)]
    if is_t1:
        valstoadd = valstoadd + [splitter[(lensplit-1)],splitter[(lensplit-1)]]
    else:
        split2=splitter[(lensplit-1)].split( &#34;_&#34; )
        if len(split2) == 1:
            split2.append( split2[0] )
        if len(valstoadd) == 3:
            valstoadd = valstoadd + [split2[0]] + [math.nan] + [split2[1]]
        else:
            valstoadd = valstoadd + [split2[0],split2[1]]
    if verbose:
        print( valstoadd )
    df.iloc[0] = valstoadd
    if verbose:
        print( &#34;read xdf: &#34; + x )
    xdf = pd.read_csv( x )
    df.reset_index()
    xdf.reset_index(drop=True)
    if &#34;Unnamed: 0&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 0&#34; )
    if &#34;Unnamed: 1&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 1&#34; )
    if &#34;u_hier_id.1&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id.1&#34; )
    if &#34;u_hier_id&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id&#34; )
    if not is_t1:
        if &#39;resnetGrade&#39; in xdf.columns:
            index_no = xdf.columns.get_loc(&#39;resnetGrade&#39;)
            xdf = xdf.drop( xdf.columns[range(index_no+1)] , axis=1)

    if xdf.shape[0] == 2:
        xdfcols = xdf.columns
        xdf = xdf.iloc[1]
        ddnum = xdf.to_numpy()
        ddnum = ddnum.reshape([1,ddnum.shape[0]])
        newcolnames = xdf.index.to_list()
        if len(newcolnames) != ddnum.shape[1]:
            print(&#34;Cannot Merge : Shape MisMatch &#34; + str( len(newcolnames) ) + &#34; &#34; + str(ddnum.shape[1]))
        else:
            xdf = pd.DataFrame(ddnum, columns=xdfcols )
    if xdf.shape[1] == 0:
        return None
    if colprefix is not None:
        xdf.columns=colprefix + xdf.columns
    return pd.concat( [df,xdf], axis=1 )

def merge_wides_to_study_dataframe( sdf, processing_dir, separator=&#39;-&#39;, sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False,
progress=False, verbose=False ):
    &#34;&#34;&#34;
    extend a study data frame with wide outputs

    sdf : the input study dataframe

    processing_dir:  the directory location of the processed data 

    separator : string usually &#39;-&#39; or &#39;_&#39;

    sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas

    date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas

    id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas

    report_missing : boolean combined with verbose will report missing modalities

    progress : integer reports percent progress modulo progress value 

    verbose : boolean
    &#34;&#34;&#34;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;fn&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in sdf.keys():
            raise ValueError(&#39;sdf is missing column &#39; +musthavecols[k] + &#39; in merge_wides_to_study_dataframe&#39; )
    possible_iids = [ &#39;imageID&#39;, &#39;imageID&#39;, &#39;imageID&#39;, &#39;flairid&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;nmid1&#39;, &#39;nmid2&#39;, &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;, &#39;nmid6&#39;, &#39;nmid7&#39;, &#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39; ]
    modality_ids = [ &#39;T1wHierarchical&#39;, &#39;T1wHierarchicalSR&#39;, &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;DTI&#39;, &#39;DTI&#39;, &#39;rsfMRI&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;]
    alldf=pd.DataFrame()
    for myk in sdf.index:
        if progress &gt; 0 and int(myk) % int(progress) == 0:
            print( str( round( myk/sdf.shape[0]*100.0)) + &#34;%...&#34;, end=&#39;&#39;, flush=True)
        if verbose:
            print( &#34;DOROW &#34; + str(myk) + &#39; of &#39; + str( sdf.shape[0] ) )
        csvrow = sdf.loc[sdf.index == myk].dropna(axis=1)
        ct=-1
        for iidkey in possible_iids:
            ct=ct+1
            mod_name = modality_ids[ct]
            if iidkey in csvrow.keys():
                if id_is_int:
                    iid = str( int( csvrow[iidkey].iloc[0] ) )
                else:
                    iid = str( csvrow[iidkey].iloc[0] )
                if verbose:
                    print( &#34;iidkey &#34; + iidkey + &#34; modality &#34; + mod_name + &#39; iid &#39;+ iid )
                pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
                if sid_is_int:
                    sid=str(int(csvrow[&#39;subjectID&#39;].iloc[0] ))
                else:
                    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
                if date_is_int:
                    dt=str(int(csvrow[&#39;date&#39;].iloc[0]))
                else:
                    dt=str(csvrow[&#39;date&#39;].iloc[0])
                if id_is_int:
                    t1iid=str(int(csvrow[&#39;imageID&#39;].iloc[0]))
                else:
                    t1iid=str(csvrow[&#39;imageID&#39;].iloc[0])
                if t1iid != iid:
                    iidj=iid+&#34;_&#34;+t1iid
                else:
                    iidj=iid
                rootid = pid +separator+ sid +separator+dt+separator+mod_name+separator+iidj
                myext = rootid +separator+&#39;mmwide.csv&#39;
                nrgwidefn=os.path.join( processing_dir, pid, sid, dt, mod_name, iid, myext )
                moddersub = mod_name
                is_t1=False
                if mod_name == &#39;T1wHierarchical&#39;:
                    is_t1=True
                    moddersub=&#39;T1Hier&#39;
                elif mod_name == &#39;T1wHierarchicalSR&#39;:
                    is_t1=True
                    moddersub=&#39;T1HSR&#39;
                if exists( nrgwidefn ):
                    if verbose:
                        print( nrgwidefn + &#34; exists&#34;)
                    mm=read_mm_csv( nrgwidefn, colprefix=moddersub+&#39;_&#39;, is_t1=is_t1, separator=separator, verbose=verbose )
                    if mm is not None:
                        if mod_name == &#39;T1wHierarchical&#39;:
                            a=list( csvrow.keys() )
                            b=list( mm.keys() )
                            abintersect=list(set(b).intersection( set(a) ) )
                            if len( abintersect  ) &gt; 0 :
                                for qq in abintersect:
                                    mm.pop( qq )
                        mm.index=csvrow.index
                        uidname = mod_name + &#39;_mmwide_filename&#39;
                        mm[ uidname ] = rootid
                        csvrow=pd.concat( [csvrow,mm], axis=1 )
                else:
                    if verbose and report_missing:
                        print( nrgwidefn + &#34; absent&#34;)
        if alldf.shape[0] == 0:
            alldf = csvrow.copy()
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
        else:
            csvrow=csvrow.loc[:,~csvrow.columns.duplicated()]
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
            alldf = pd.concat( [alldf, csvrow], axis=0, ignore_index=True)
    return alldf

def assemble_modality_specific_dataframes( mm_wide_csvs, hierdfin, nrg_modality, separator=&#39;-&#39;, progress=None, verbose=False ):
    moddersub = re.sub( &#34;[*]&#34;,&#34;&#34;,nrg_modality)
    nmdf=pd.DataFrame()
    for k in range( hierdfin.shape[0] ):
        if progress is not None:
            if k % progress == 0:
                progger = str( np.round( k / hierdfin.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        temp = mm_wide_csvs[k]
        mypartsf = temp.split(&#34;T1wHierarchical&#34;)
        myparts = mypartsf[0]
        t1iid = str(mypartsf[1].split(&#34;/&#34;)[1])
        fnsnm = glob.glob(myparts+&#34;/&#34; + nrg_modality + &#34;/*/*&#34; + t1iid + &#34;*wide.csv&#34;)
        if len( fnsnm ) &gt; 0 :
            for y in fnsnm:
                temp=read_mm_csv( y, colprefix=moddersub+&#39;_&#39;, is_t1=False, separator=separator, verbose=verbose )
                if temp is not None:
                    nmdf=pd.concat( [nmdf, temp], axis=0)
    return nmdf

def bind_wide_mm_csvs( mm_wide_csvs, merge=True, separator=&#39;-&#39;, verbose = 0 ) :
    &#34;&#34;&#34;
    will convert a list of t1w hierarchical csv filenames to a merged dataframe

    returns a pair of data frames, the left side having all entries and the
        right side having row averaged entries i.e. unique values for each visit

    set merge to False to return individual dataframes ( for debugging )

    return alldata, row_averaged_data
    &#34;&#34;&#34;
    mm_wide_csvs.sort()
    if not mm_wide_csvs:
        print(&#34;No files found with specified pattern&#34;)
        return
    # 1. row-bind the t1whier data
    # 2. same for each other modality
    # 3. merge the modalities by the keys
    hierdf = pd.DataFrame()
    for y in mm_wide_csvs:
        temp=read_mm_csv( y, colprefix=&#39;T1Hier_&#39;, separator=separator, is_t1=True )
        if temp is not None:
            hierdf=pd.concat( [hierdf, temp], axis=0)
    if verbose &gt; 0:
        mypro=50
    else:
        mypro=None
    if verbose &gt; 0:
        print(&#34;thickness&#34;)
    thkdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T1w&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;flair&#34;)
    flairdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T2Flair&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;NM&#34;)
    nmdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;NM2DMT&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;rsf&#34;)
    rsfdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;rsfMRI*&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;dti&#34;)
    dtidf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;DTI*&#39;, progress=mypro, verbose=verbose==2 )
    if not merge:
        return hierdf, thkdf, flairdf, nmdf, rsfdf, dtidf
    hierdfmix = hierdf.copy()
    modality_df_suffixes = [
        (thkdf, &#34;_thk&#34;),
        (flairdf, &#34;_flair&#34;),
        (nmdf, &#34;_nm&#34;),
        (rsfdf, &#34;_rsf&#34;),
        (dtidf, &#34;_dti&#34;),
    ]
    for pair in modality_df_suffixes:
        hierdfmix = merge_mm_dataframe(hierdfmix, pair[0], pair[1])
    hierdfmix = hierdfmix.replace(r&#39;^\s*$&#39;, np.nan, regex=True)
    return hierdfmix, hierdfmix.groupby(&#34;u_hier_id&#34;, as_index=False).mean(numeric_only=True)

def merge_mm_dataframe(hierdf, mmdf, mm_suffix):
    try:
        hierdf = hierdf.merge(mmdf, on=[&#39;sid&#39;, &#39;visitdate&#39;, &#39;t1imageuid&#39;], suffixes=(&#34;&#34;,mm_suffix),how=&#39;left&#39;)
        return hierdf
    except KeyError:
        return hierdf

def augment_image( x,  max_rot=10, nzsd=1 ):
    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rot*(-1.0), max_rot ), reference=x )
    tx = rRotGenerator.transform()
    itx = ants.invert_ants_transform(tx)
    y = ants.apply_ants_transform_to_image( tx, x, x, interpolation=&#39;linear&#39;)
    y = ants.add_noise_to_image( y,&#39;additivegaussian&#39;, [0,nzsd] )
    return y, tx, itx

def boot_wmh( flair, t1, t1seg, mmfromconvexhull = 0.0, strict=True,
        probability_mask=None, prior_probability=None, n_simulations=16,
        verbose=False ) :
    if verbose and prior_probability is None:
        print(&#34;augmented flair&#34;)
    if verbose and prior_probability is not None:
        print(&#34;augmented flair with prior&#34;)
    wmh_sum_aug = 0
    wmh_sum_prior_aug = 0
    augprob = flair * 0.0
    augprob_prior = None
    if prior_probability is not None:
        augprob_prior = flair * 0.0
    for n in range(n_simulations):
        augflair, tx, itx = augment_image( ants.iMath(flair,&#34;Normalize&#34;), 5, 0.01 )
        locwmh = wmh( augflair, t1, t1seg, mmfromconvexhull = mmfromconvexhull,
            strict=strict, probability_mask=None, prior_probability=prior_probability )
        if verbose:
            print( &#34;flair sim: &#34; + str(n) + &#34; vol: &#34; + str( locwmh[&#39;wmh_mass&#39;] )+ &#34; vol-prior: &#34; + str( locwmh[&#39;wmh_mass_prior&#39;] )+ &#34; snr: &#34; + str( locwmh[&#39;wmh_SNR&#39;] ) )
        wmh_sum_aug = wmh_sum_aug + locwmh[&#39;wmh_mass&#39;]
        wmh_sum_prior_aug = wmh_sum_prior_aug + locwmh[&#39;wmh_mass_prior&#39;]
        temp = locwmh[&#39;WMH_probability_map&#39;]
        augprob = augprob + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
        if prior_probability is not None:
            temp = locwmh[&#39;WMH_posterior_probability_map&#39;]
            augprob_prior = augprob_prior + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
    augprob = augprob * (1.0/float( n_simulations ))
    if prior_probability is not None:
        augprob_prior = augprob_prior * (1.0/float( n_simulations ))
    wmh_sum_aug = wmh_sum_aug / float( n_simulations )
    wmh_sum_prior_aug = wmh_sum_prior_aug / float( n_simulations )
    return{
      &#39;WMH_probability_map&#39; : augprob,
      &#39;WMH_posterior_probability_map&#39; : augprob_prior,
      &#39;wmh_mass&#39;: wmh_sum_aug,
      &#39;wmh_mass_prior&#39;: wmh_sum_prior_aug,
      &#39;wmh_evr&#39;: locwmh[&#39;wmh_evr&#39;],
      &#39;wmh_SNR&#39;: locwmh[&#39;wmh_SNR&#39;]  }


def threaded_bind_wide_mm_csvs( mm_wide_csvs, n_workers ):
    from concurrent.futures import as_completed
    from concurrent import futures
    import concurrent.futures
    def chunks(l, n):
        &#34;&#34;&#34;Yield n number of sequential chunks from l.&#34;&#34;&#34;
        d, r = divmod(len(l), n)
        for i in range(n):
            si = (d+1)*(i if i &lt; r else r) + d*(0 if i &lt; r else i - r)
            yield l[si:si+(d+1 if i &lt; r else d)]
    import numpy as np
    newx = list( chunks( mm_wide_csvs, n_workers ) )
    import pandas as pd
    alldf = pd.DataFrame()
    alldfavg = pd.DataFrame()
    with futures.ThreadPoolExecutor(max_workers=n_workers) as executor:
        to_do = []
        for group in range(len(newx)) :
            future = executor.submit(bind_wide_mm_csvs, newx[group] )
            to_do.append(future)
        results = []
        for future in futures.as_completed(to_do):
            res0, res1 = future.result()
            alldf=pd.concat(  [alldf, res0 ], axis=0 )
            alldfavg=pd.concat(  [alldfavg, res1 ], axis=0 )
    return alldf, alldfavg


def get_names_from_data_frame(x, demogIn, exclusions=None):
    &#34;&#34;&#34;
    data = {&#39;Name&#39;:[&#39;Tom&#39;, &#39;nick&#39;, &#39;krish&#39;, &#39;jack&#39;], &#39;Age&#39;:[20, 21, 19, 18]}
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;a&#39;,&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df, exclusions=&#39;N&#39; )
    &#34;&#34;&#34;
    def get_unique( qq ):
        unique = []
        for number in qq:
            if number in unique:
                continue
            else:
                unique.append(number)
        return unique
    outnames = list(demogIn.columns[demogIn.columns.str.contains(x[0])])
    if len(x) &gt; 1:
        for y in x[1:]:
            outnames = [i for i in outnames if y in i]
    outnames = get_unique( outnames )
    if exclusions is not None:
        toexclude = [name for name in outnames if exclusions[0] in name ]
        if len(exclusions) &gt; 1:
            for zz in exclusions[1:]:
                toexclude.extend([name for name in outnames if zz in name ])
        if len(toexclude) &gt; 0:
            outnames = [name for name in outnames if name not in toexclude]
    return outnames


def average_mm_df( jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False ):
    &#34;&#34;&#34;
    jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )
    &#34;&#34;&#34;

    jmm = jmm_in.copy()
    dxcols=[&#39;subjectid1&#39;,&#39;subjectid2&#39;,&#39;modalityid&#39;,&#39;joinid&#39;,&#39;correlation&#39;,&#39;distance&#39;]
    joinDiagnostics = pd.DataFrame( columns = dxcols )
    nanList=[math.nan]
    def rob(x, y=0.99):
        x[x &gt; np.quantile(x, y, nan_policy=&#34;omit&#34;)] = np.nan
        return x

    jmm = jmm.replace(r&#39;^\s*$&#39;, np.nan, regex=True)

    if verbose:
        print(&#34;do rsfMRI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;rsfMRI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;rsfMRI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    if len( dt0 ) &gt; 0 and len( dt1 ) &gt; 0:
        flid = dt0[0]
        wrows = []
        for i in range(jmm.shape[0]):
            if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) :
                wrows.append(i)
        for k in wrows:
            v1 = jmm.iloc[k][dt0[1:]].astype(float)
            v2 = jmm.iloc[k][dt1[1:]].astype(float)
            vvec = [v1[0], v2[0]]
            if any(~np.isnan(vvec)):
                mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
                jmm.iloc[k][dt0[0]] = &#39;rsfMRI&#39;
                if len(mynna) == 1:
                    if mynna[0] == 0:
                        jmm.iloc[k][dt0[1:]] = v1
                    if mynna[0] == 1:
                        jmm.iloc[k][dt0[1:]] = v2
                elif len(mynna) &gt; 1:
                    if len(v2) &gt; diagnostic_n:
                        v1dx=v1[0:diagnostic_n]
                        v2dx=v2[0:diagnostic_n]
                    else :
                        v1dx=v1
                        v2dx=v2
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v1dx.values, v2dx.values )[0,1]
                    myerr=np.sqrt(np.mean((v1dx.values - v2dx.values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;rsfMRI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v1.values*0.5 + v2.values*0.5
                    else:
                        jmm.loc[k, dt0[1:]] = nanList * len(v1)
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)

    if verbose:
        print(&#34;do DTI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;DTI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;DTI_LR&#34;, &#34;DTI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;DTI_LR&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    dt2 = get_names_from_data_frame( [&#34;DTI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    flid = dt0[0]
    wrows = []
    for i in range(jmm.shape[0]):
        if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) or not pd.isna(jmm[dt2[1]][i]):
            wrows.append(i)
    for k in wrows:
        v1 = jmm.loc[k, dt0[1:]].astype(float)
        v2 = jmm.loc[k, dt1[1:]].astype(float)
        v3 = jmm.loc[k, dt2[1:]].astype(float)
        checkcol = dt0[5]
        if not np.isnan(v1[checkcol]):
            if v1[checkcol] &lt; 0.25:
                v1.replace(np.nan, inplace=True)
        checkcol = dt1[5]
        if not np.isnan(v2[checkcol]):
            if v2[checkcol] &lt; 0.25:
                v2.replace(np.nan, inplace=True)
        checkcol = dt2[5]
        if not np.isnan(v3[checkcol]):
            if v3[checkcol] &lt; 0.25:
                v3.replace(np.nan, inplace=True)
        vvec = [v1[0], v2[0], v3[0]]
        if any(~np.isnan(vvec)):
            mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
            jmm.loc[k, dt0[0]] = &#39;DTI&#39;
            if len(mynna) == 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                if mynna[0] == 1:
                    jmm.loc[k, dt0[1:]] = v2
                if mynna[0] == 2:
                    jmm.loc[k, dt0[1:]] = v3
            elif len(mynna) &gt; 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                else:
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v2[0:diagnostic_n].values, v3[0:diagnostic_n].values )[0,1]
                    myerr=np.sqrt(np.mean((v2[0:diagnostic_n].values - v3[0:diagnostic_n].values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;DTI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v2.values*0.5 + v3.values*0.5
                    else: #
                        jmm.loc[k, dt0[1:]] = nanList * len( dt0[1:] )
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)


    # first task - sort by u_hier_id
    jmm = jmm.sort_values( &#34;u_hier_id&#34; )
    # get rid of junk columns
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], jmm )
    jmm=jmm.drop(badnames, axis=1)
    jmm=jmm.set_index(&#34;u_hier_id&#34;,drop=False)
    # 2nd - get rid of duplicated u_hier_id
    jmmUniq = jmm.drop_duplicates( subset=&#34;u_hier_id&#34; ) # fast and easy
    # for each modality, count which ids have more than one
    mod_names = get_valid_modalities()
    for mod_name in mod_names:
        fl_names = get_names_from_data_frame([mod_name], jmm,
            exclusions=[&#39;Unnamed&#39;,&#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;rsfMRI_RL&#34;,&#34;rsfMRI_LR&#34;])
        if len( fl_names ) &gt; 1:
            if verbose:
                print(mod_name)
                print(fl_names)
            fl_id = fl_names[0]
            n_names = len(fl_names)
            locvec = jmm[fl_names[n_names-1]].astype(float)
            boolvec=~pd.isna(locvec)
            jmmsub = jmm[boolvec][ [&#39;u_hier_id&#39;]+fl_names]
            my_tbl = Counter(jmmsub[&#39;u_hier_id&#39;])
            gtoavg = [name for name in my_tbl.keys() if my_tbl[name] == 1]
            gtoavgG1 = [name for name in my_tbl.keys() if my_tbl[name] &gt; 1]
            if verbose:
                print(&#34;Join 1&#34;)
            jmmsub1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavg)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavg:
                jmmUniq.loc[u][fl_names[1:]] = jmmsub1.loc[u][fl_names[1:]]
            if verbose and len(gtoavgG1) &gt; 1:
                print(&#34;Join &gt;1&#34;)
            jmmsubG1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavgG1)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavgG1:
                temp = jmmsubG1.loc[u][ [&#39;u_hier_id&#39;]+fl_names ]
                dropnames = get_names_from_data_frame( [&#39;MM.ID&#39;], temp )
                tempVec = temp.drop(columns=dropnames)
                joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                id1=temp[fl_id].iloc[0]
                id2=temp[fl_id].iloc[1]
                v1=tempVec.iloc[0][1:].astype(float).to_numpy()
                v2=tempVec.iloc[1][1:].astype(float).to_numpy()
                if len(v2) &gt; diagnostic_n:
                    v1=v1[0:diagnostic_n]
                    v2=v2[0:diagnostic_n]
                mycorr = np.corrcoef( v1, v2 )[0,1]
                # mycorr=temparr[np.triu_indices_from(temparr, k=1)].mean()
                myerr=np.sqrt(np.mean((v1 - v2)**2))
                joinDiagnosticsLoc.iloc[0] = [id1,id2,mod_name,&#39;rowavg&#39;,mycorr,myerr]
                if verbose:
                    print( joinDiagnosticsLoc )
                temp = jmmsubG1.loc[u][fl_names[1:]].astype(float)
                if mycorr &gt; corr_thresh or len( v1 ) &lt; 10:
                    jmmUniq.loc[u][fl_names[1:]] = temp.mean(axis=0)
                else:
                    jmmUniq.loc[u][fl_names[1:]] = nanList * temp.shape[1]
                joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)

    return jmmUniq, jmm, joinDiagnostics



def quick_viz_mm_nrg(
    sourcedir, # root folder
    projectid, # project name
    sid , # subject unique id
    dtid, # date
    extract_brain=True,
    slice_factor = 0.55,
    show_it = None, # output path
    verbose = True
):
    &#34;&#34;&#34;
    This function creates visualizations of brain images for a specific subject in a project using ANTsPy.

    Args:

    sourcedir (str): Root folder.
    
    projectid (str): Project name.
    
    sid (str): Subject unique id.
    
    dtid (str): Date.
    
    extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.
    
    slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.
    
    show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.
    
    verbose (bool): If True, information will be printed while running the function. Default is True.

    Returns:
    vizlist (list): List of image visualizations.

    &#34;&#34;&#34;
    iid=&#39;*&#39;
    import glob as glob
    from os.path import exists
    import ants
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    subjectrootpath = os.path.join(sourcedir, projectid, sid, dtid)
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, &#34;*&#34;, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;quick_viz_mm_nrg cannot find the T1w @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    nimages = len(myimgsInput)
    vizlist=[]
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.  will visualize T1 NM rsfMRI DTIB0 DTIDWI FLAIR&#34;)
    # nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;rsfMRI_LR&#34;,&#34;rsfMRI_RL&#34;,&#34;DTI&#34;,&#34;DTI_LR&#34;, &#34;T2Flair&#34; ],
    nrg_modality_list = [ &#39;T1w&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DWI1&#39;, &#39;DWI2&#39;, &#39;T2Flair&#39; ]
    for nrgNum in [0,1,2,3,4,5]:
        overmodX = nrg_modality_list[nrgNum]
        if overmodX == &#39;T1w&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, iid, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) == 0:
                if verbose:
                    print(&#34;No t1 images: &#34; + sid + dtid )
                return None
            myimgsr.sort()
            myimgsr=myimgsr[0]
            vimg=ants.image_read( myimgsr )
        elif overmodX == &#39;DWI1&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;DWI2&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[len(myimgsr)-1]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;NM2DMT&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr0=myimgsr[0]
                vimg=ants.image_read( myimgsr0 )
                for k in range(1,len(myimgsr)):
                    temp = ants.image_read( myimgsr[k])
                    vimg=vimg+ants.resample_image_to_target(temp,vimg)
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;rsfMRI&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;rsfMRI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=mm_read_to_3d( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        else :
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        if True:
            if extract_brain and overmodX == &#39;T1w&#39;:
                vimg = vimg * antspyt1w.brain_extraction(vimg)
            if verbose:
                print(f&#34;modality search path: {myimgsr}&#34; + &#34; num: &#34; + str(nrgNum))
            if len( vimg.shape ) == 4 and ( overmodX == &#34;DWI2&#34;  ):
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttdw
            elif len( vimg.shape ) == 4 and overmodX == &#34;DWI1&#34;:
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttb0
            elif len( vimg.shape ) == 4 :
                vimg=ants.get_average_of_timeseries(vimg)
            msk=ants.get_mask(vimg)
            vimg=ants.crop_image(vimg,msk)
            if overmodX == &#39;T1w&#39;:
                refimg=ants.image_clone( vimg )
                noizimg = ants.add_noise_to_image( refimg*0, &#39;additivegaussian&#39;, [100,1] )
                vizlist.append( vimg )
            else:
                vimg = ants.resample_image_to_target( vimg, refimg )
                vimg = ants.iMath( vimg, &#39;TruncateIntensity&#39;,0.01,0.98)
                vizlist.append( ants.iMath( vimg, &#39;Normalize&#39; ) * 255 )

    listlen = len( vizlist )
    vizlist = np.asarray( vizlist )
    if show_it is not None:
        filenameout=None
        if verbose:
            print( show_it )
        for a in [0,1,2]:
            n=int(np.round( refimg.shape[a] * slice_factor ))
            slices=np.repeat( int(n), listlen  )
            if isinstance(show_it,str):
                filenameout=show_it+&#39;_ax&#39;+str(int(a))+&#39;_sl&#39;+str(n)+&#39;.png&#39;
                if verbose:
                    print( filenameout )
            ants.plot_grid(vizlist.reshape(2,3), slices.reshape(2,3), title=&#39;MM Subject &#39; + sid + &#39; &#39; + dtid, rfacecolor=&#39;white&#39;, axes=a, filename=filenameout )
    if verbose:
        print(&#34;viz complete.&#34;)
    return vizlist


def blind_image_assessment(
    image,
    viz_filename=None,
    title=False,
    pull_rank=False,
    resample=None,
    verbose=False
):
    &#34;&#34;&#34;
    quick blind image assessment and triplanar visualization of an image ... 4D input will be visualized and assessed in 3D.  produces a png and csv where csv contains:

    * reflection error ( estimates asymmetry )

    * brisq ( blind quality assessment )

    * patch eigenvalue ratio ( blind quality assessment )

    * PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)

    * mask volume ( estimates foreground object size )

    * spacing

    * dimension after cropping by mask

    image : character or image object usually a nifti image

    viz_filename : character for a png output image

    title : display a summary title on the png

    pull_rank : boolean

    resample : None, numeric max or min, resamples image to isotropy

    verbose : boolean

    &#34;&#34;&#34;
    import glob as glob
    from os.path import exists
    import ants
    import matplotlib.pyplot as plt
    from PIL import Image
    from pathlib import Path
    import json
    import re
    mystem=&#39;&#39;
    if isinstance(image,list):
        isfilename=isinstance( image[0], str)
        image = image[0]
    else:
        isfilename=isinstance( image, str)
    outdf = pd.DataFrame()
    mymeta = None
    image_filename=&#39;&#39;
    if isfilename:
        image_filename = image
        if isinstance(image,list):
            image_filename=image[0]
        json_name = re.sub(&#34;.nii.gz&#34;,&#34;.json&#34;,image_filename)
        if exists( json_name ):
            with open(json_name, &#39;r&#39;) as fcc_file:
                mymeta = json.load(fcc_file, strict=False)
                if verbose:
                    print(json.dumps(mymeta, indent=4))
        mystem=Path( image ).stem
        mystem=Path( mystem ).stem
        image_reference = ants.image_read( image )
        image = ants.image_read( image )
    else:
        image_reference = ants.image_clone( image )
    ntimepoints = 1
    if image_reference.dimension == 4:
        ntimepoints = image_reference.shape[3]
        if &#34;DTI&#34; in image_filename:
            myTSseg = segment_timeseries_by_meanvalue( image_reference )
            image_b0, image_dwi = get_average_dwi_b0( image_reference, fast=True )
            image_b0 = ants.iMath( image_b0, &#39;Normalize&#39; )
            image_dwi = ants.iMath( image_dwi, &#39;Normalize&#39; )
        else:
            image_b0 = ants.get_average_of_timeseries( image_reference ).iMath(&#34;Normalize&#34;)
    else:
        image_compare = ants.smooth_image( image_reference, 3, sigma_in_physical_coordinates=False )
    for jjj in range(ntimepoints):
        modality=&#39;unknown&#39;
        if &#34;rsfMRI&#34; in image_filename:
            modality=&#39;rsfMRI&#39;
        elif &#34;T1w&#34; in image_filename:
            modality=&#39;T1w&#39;
        elif &#34;T2Flair&#34; in image_filename:
            modality=&#39;T2Flair&#39;
        elif &#34;NM2DMT&#34; in image_filename:
            modality=&#39;NM2DMT&#39;
        if image_reference.dimension == 4:
            image = ants.slice_image( image_reference, idx=int(jjj), axis=3 )
            if &#34;DTI&#34; in image_filename:
                if jjj in myTSseg[&#39;highermeans&#39;]:
                    image_compare = ants.image_clone( image_b0 )
                    modality=&#39;DTIb0&#39;
                else:
                    image_compare = ants.image_clone( image_dwi )
                    modality=&#39;DTIdwi&#39;
            else:
                image_compare = ants.image_clone( image_b0 )
        image = ants.iMath( image, &#39;TruncateIntensity&#39;,0.01,0.995)
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        if resample is not None:
            if resample == &#39;min&#39;:
                if minspc &lt; 1e-12:
                    minspc = np.max(ants.get_spacing(image))
                newspc = np.repeat( minspc, 3 )
            elif resample == &#39;max&#39;:
                newspc = np.repeat( maxspc, 3 )
            else:
                newspc = np.repeat( resample, 3 )
            image = ants.resample_image( image, newspc )
            image_compare = ants.resample_image( image_compare, newspc )
        else:
            # check for spc close to zero
            spc = list(ants.get_spacing(image))
            for spck in range(len(spc)):
                if spc[spck] &lt; 1e-12:
                    spc[spck]=1
            ants.set_spacing( image, spc )
            ants.set_spacing( image_compare, spc )
        # if &#34;NM2DMT&#34; in image_filename or &#34;FIXME&#34; in image_filename or &#34;SPECT&#34; in image_filename or &#34;UNKNOWN&#34; in image_filename:
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        msk = ants.threshold_image( ants.iMath(image,&#39;Normalize&#39;), 0.15, 1.0 )
        # else:
        #    msk = ants.get_mask( image )
        msk = ants.morphology(msk, &#34;close&#34;, 3 )
        bgmsk = msk*0+1-msk
        mskdil = ants.iMath(msk, &#34;MD&#34;, 4 )
        # ants.plot_ortho( image, msk, crop=False )
        image = ants.crop_image( image, mskdil ).iMath(&#34;Normalize&#34;)
        msk = ants.crop_image( msk, mskdil ).iMath(&#34;Normalize&#34;)
        bgmsk = ants.crop_image( bgmsk, mskdil ).iMath(&#34;Normalize&#34;)
        image_compare = ants.crop_image( image_compare, mskdil ).iMath(&#34;Normalize&#34;)
        nvox = int( msk.sum() )
        minshp = np.min( image.shape )
        npatch = int( np.round(  0.1 * nvox ) )
        npatch = np.min(  [512,npatch ] )
        patch_shape = []
        for k in range( 3 ):
            p = int( 32.0 / ants.get_spacing( image  )[k] )
            if p &gt; int( np.round( image.shape[k] * 0.5 ) ):
                p = int( np.round( image.shape[k] * 0.5 ) )
            patch_shape.append( p )
        if verbose:
            print(image)
            print( patch_shape )
            print( npatch )
        myevr = math.nan # dont want to fail if something odd happens in patch extraction
        try:
            myevr = antspyt1w.patch_eigenvalue_ratio( image, npatch, patch_shape,
                evdepth = 0.9, mask=msk )
        except:
            pass
        if pull_rank:
            image = ants.rank_intensity(image)
        imagereflect = ants.reflect_image(image, axis=0)
        asym_err = ( image - imagereflect ).abs().mean()
        # estimate noise by center cropping, denoizing and taking magnitude of difference
        nocrop=False
        if image.dimension == 3:
            if image.shape[2] == 1:
                nocrop=True        
        if maxspc/minspc &gt; 10:
            nocrop=True
        if nocrop:
            mycc = ants.image_clone( image )
        else:
            mycc = antspyt1w.special_crop( image,
                ants.get_center_of_mass( msk *0 + 1 ), patch_shape )
        myccd = ants.denoise_image( mycc, p=2,r=2,noise_model=&#39;Gaussian&#39; )
        noizlevel = ( mycc - myccd ).abs().mean()
#        ants.plot_ortho( image, crop=False, filename=viz_filename, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
#        from brisque import BRISQUE
#        obj = BRISQUE(url=False)
#        mybrisq = obj.score( np.array( Image.open( viz_filename )) )
        spc = ants.get_spacing( image )
        org = ants.get_origin( image )
        msk_vol = msk.sum() * np.prod( spc )
        bgstd = image[ bgmsk == 1 ].std()
        fgmean = image[ msk == 1 ].mean()
        bgmean = image[ bgmsk == 1 ].mean()
        snrref = fgmean / bgstd
        cnrref = ( fgmean - bgmean ) / bgstd
        psnrref = antspynet.psnr(  image_compare, image  )
        ssimref = antspynet.ssim(  image_compare, image  )
        if nocrop:
            mymi = math.inf
        else:
            mymi = ants.image_mutual_information( image_compare, image )
        mriseries=&#39;NA&#39;
        mrimfg=&#39;NA&#39;
        mrimodel=&#39;NA&#39;
        if mymeta is not None:
            # mriseries=mymeta[&#39;&#39;]
            try:
                mrimfg=mymeta[&#39;Manufacturer&#39;]
            except:
                pass
            try:
                mrimodel=mymeta[&#39;ManufacturersModelName&#39;]
            except:
                pass
        ttl=mystem + &#39; &#39;
        ttl=&#39;&#39;
        ttl=ttl + &#34;NZ: &#34; + &#34;{:0.4f}&#34;.format(noizlevel) + &#34; SNR: &#34; + &#34;{:0.4f}&#34;.format(snrref) + &#34; CNR: &#34; + &#34;{:0.4f}&#34;.format(cnrref) + &#34; PS: &#34; + &#34;{:0.4f}&#34;.format(psnrref)+ &#34; SS: &#34; + &#34;{:0.4f}&#34;.format(ssimref) + &#34; EVR: &#34; + &#34;{:0.4f}&#34;.format(myevr)+ &#34; MI: &#34; + &#34;{:0.4f}&#34;.format(mymi)
        if viz_filename is not None and ( jjj == 0 or (jjj % 30 == 0) ):
            viz_filename_use = re.sub( &#34;.png&#34;, &#34;_slice&#34;+str(jjj).zfill(4)+&#34;.png&#34;, viz_filename )
            ants.plot_ortho( image, crop=False, filename=viz_filename_use, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0,  title=ttl, titlefontsize=12, title_dy=-0.02,textfontcolor=&#39;red&#39; )
        df = pd.DataFrame([[ mystem, noizlevel, snrref, cnrref, psnrref, ssimref, mymi, asym_err, myevr, msk_vol, spc[0], spc[1], spc[2],org[0], org[1], org[2], image.shape[0], image.shape[1], image.shape[2], jjj, modality, mriseries, mrimfg, mrimodel ]], columns=[&#39;fn&#39;, &#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;,&#39;spc1&#39;,&#39;spc2&#39;,&#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;,&#39;dimx&#39;,&#39;dimy&#39;,&#39;dimz&#39;,&#39;slice&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39; ])
        outdf = pd.concat( [outdf, df ], axis=0 )
        if verbose:
            print( outdf )
    if viz_filename is not None:
        csvfn = re.sub( &#34;png&#34;, &#34;csv&#34;, viz_filename )
        outdf.to_csv( csvfn )
    return outdf


def average_blind_qc_by_modality(qc_full,verbose=False):
    &#34;&#34;&#34;
    Averages time series qc results to yield one entry per image. this also filters to &#34;known&#34; columns.

    Args:
    qc_full: pandas dataframe containing the full qc data.

    Returns:
    pandas dataframe containing the processed qc data.
    &#34;&#34;&#34;
    # Get unique modalities
    modalities = qc_full[&#39;modality&#39;].unique()
    modalities = modalities[modalities != &#39;unknown&#39;]
    # Get modalities to select
    m0sel = qc_full[&#39;modality&#39;].isin(modalities)
    # Get unique ids
    uid = qc_full[&#39;fn&#39;] + &#34;_&#34; + qc_full[&#39;modality&#39;].astype(str)
    to_average = uid.unique()
    # Define column indices
    contcols = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;, &#39;spc1&#39;, &#39;spc2&#39;, &#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;, &#39;dimx&#39;, &#39;dimy&#39;, &#39;dimz&#39;, &#39;slice&#39;]
    ocols = [&#39;fn&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39;]
    # restrict to columns we &#34;know&#34;
    qc_full = qc_full[ocols+contcols]
    # Create empty meta dataframe
    meta = pd.DataFrame(columns=ocols+contcols)
    # Process each unique id
    n = len(to_average)
    for k in range(n):
        if verbose:
            if k % 100 == 0:
                progger = str( np.round( k / n * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        m1sel = uid == to_average[k]
        if sum(m1sel) &gt; 1:
            # If more than one entry for id, take the average of continuous columns,
            # maximum of the slice column, and the first entry of the other columns
            mfsub = qc_full[m1sel]
            if mfsub.shape[0] &gt; 1:
                meta.loc[k, contcols] = mfsub.loc[:, contcols].mean(numeric_only=True)
                meta.loc[k, &#39;slice&#39;] = mfsub[&#39;slice&#39;].max()
                meta.loc[k, ocols] = mfsub[ocols].iloc[0]
        elif sum(m1sel) == 1:
            # If only one entry for id, just copy the entry
            mfsub = qc_full[m1sel]
            meta.loc[k] = mfsub.iloc[0]
    return meta

def wmh( flair, t1, t1seg,
    mmfromconvexhull = 3.0,
    strict=True,
    probability_mask=None,
    prior_probability=None,
    model=&#39;sysu&#39;,
    verbose=False ) :
    &#34;&#34;&#34;
    Outputs the WMH probability mask and a summary single measurement

    Arguments
    ---------
    flair : ANTsImage
        input 3-D FLAIR brain image (not skull-stripped).

    t1 : ANTsImage
        input 3-D T1 brain image (not skull-stripped).

    t1seg : ANTsImage
        T1 segmentation image

    mmfromconvexhull : float
        restrict WMH to regions that are WM or mmfromconvexhull mm away from the
        convex hull of the cerebrum.   we choose a default value based on
        Figure 4 from:
        https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf

    strict: boolean - if True, only use convex hull distance

    probability_mask : None - use to compute wmh just once - then this function
        just does refinement and summary

    prior_probability : optional prior probability image in space of the input t1

    model : either sysu or hyper

    verbose : boolean

    Returns
    ---------
    WMH probability map and a summary single measurement which is the sum of the WMH map

    &#34;&#34;&#34;
    import numpy as np
    import math
    t1_2_flair_reg = ants.registration(flair, t1, type_of_transform = &#39;Rigid&#39;) # Register T1 to Flair
    if probability_mask is None and model == &#39;sysu&#39;:
        if verbose:
            print(&#39;sysu&#39;)
        probability_mask = antspynet.sysu_media_wmh_segmentation( flair )
    elif probability_mask is None and model == &#39;hyper&#39;:
        if verbose:
            print(&#39;hyper&#39;)
        probability_mask = antspynet.hypermapp3r_segmentation( t1_2_flair_reg[&#39;warpedmovout&#39;], flair )
    # t1_2_flair_reg = tra_initializer( flair, t1, n_simulations=4, max_rotation=5, transform=[&#39;rigid&#39;], verbose=False )
    prior_probability_flair = None
    if prior_probability is not None:
        prior_probability_flair = ants.apply_transforms( flair, prior_probability,
            t1_2_flair_reg[&#39;fwdtransforms&#39;] )
    wmseg_mask = ants.threshold_image( t1seg,
        low_thresh = 3, high_thresh = 3).iMath(&#34;FillHoles&#34;)
    wmseg_mask_use = ants.image_clone( wmseg_mask )
    distmask = None
    if mmfromconvexhull &gt; 0:
            convexhull = ants.threshold_image( t1seg, 1, 4 )
            spc2vox = np.prod( ants.get_spacing( t1seg ) )
            voxdist = 0.0
            myspc = ants.get_spacing( t1seg )
            for k in range( t1seg.dimension ):
                voxdist = voxdist + myspc[k] * myspc[k]
            voxdist = math.sqrt( voxdist )
            nmorph = round( 2.0 / voxdist )
            convexhull = ants.morphology( convexhull, &#34;close&#34;, nmorph ).iMath(&#34;FillHoles&#34;)
            dist = ants.iMath( convexhull, &#34;MaurerDistance&#34; ) * -1.0
            distmask = ants.threshold_image( dist, mmfromconvexhull, 1.e80 )
            wmseg_mask = wmseg_mask + distmask
            if strict:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 2, 2 )
            else:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 1, 2 )
    ##############################################################################
    wmseg_2_flair = ants.apply_transforms(flair, wmseg_mask_use,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    seg_2_flair = ants.apply_transforms(flair, t1seg,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    csfmask = ants.threshold_image(seg_2_flair,1,1)
    flairsnr = mask_snr( flair, csfmask, wmseg_2_flair, bias_correct = False )
    probability_mask_WM = wmseg_2_flair * probability_mask # Remove WMH signal outside of WM
    wmh_sum = np.prod( ants.get_spacing( flair ) ) * probability_mask_WM.sum()
    wmh_sum_prior = math.nan
    probability_mask_posterior = None
    if prior_probability_flair is not None:
        probability_mask_posterior = prior_probability_flair * probability_mask # use prior
        wmh_sum_prior = np.prod( ants.get_spacing(flair) ) * probability_mask_posterior.sum()
    if math.isnan( wmh_sum ):
        wmh_sum=0
    if math.isnan( wmh_sum_prior ):
        wmh_sum_prior=0
    flair_evr = antspyt1w.patch_eigenvalue_ratio( flair, 512, [16,16,16], evdepth = 0.9, mask=wmseg_2_flair )
    return{
        &#39;WMH_probability_map_raw&#39;: probability_mask,
        &#39;WMH_probability_map&#39; : probability_mask_WM,
        &#39;WMH_posterior_probability_map&#39; : probability_mask_posterior,
        &#39;wmh_mass&#39;: wmh_sum,
        &#39;wmh_mass_prior&#39;: wmh_sum_prior,
        &#39;wmh_evr&#39; : flair_evr,
        &#39;wmh_SNR&#39; : flairsnr,
        &#39;convexhull_mask&#39;: distmask }



def novelty_detection_ee(df_train, df_test, contamination=0.05):
    &#34;&#34;&#34;
    This function performs novelty detection using Elliptic Envelope.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    import pandas as pd
    from sklearn.covariance import EllipticEnvelope
    # Fit the model on the training data
    clf = EllipticEnvelope(contamination=contamination,support_fraction=1)
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)



def novelty_detection_svm(df_train, df_test, nu=0.05, kernel=&#39;rbf&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using One-Class SVM.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)

    - kernel (str): kernel type used in the SVM algorithm (default: &#39;rbf&#39;)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    from sklearn.svm import OneClassSVM
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = OneClassSVM(nu=nu, kernel=kernel)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)



def novelty_detection_lof(df_train, df_test, n_neighbors=20):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOF (default: 20)

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, algorithm=&#39;auto&#39;,contamination=&#39;auto&#39;, novelty=True)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)


def novelty_detection_loop(df_train, df_test, n_neighbors=20, distance_metric=&#39;minkowski&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)

    - distance_metric : default minkowski

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    data = np.vstack( [scaler.transform(df_test),scaler.transform(df_train)])
    neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=distance_metric)
    neigh.fit(data)
    d, idx = neigh.kneighbors(data, return_distance=True)
    m = loop.LocalOutlierProbability(distance_matrix=d, neighbor_matrix=idx, n_neighbors=n_neighbors).fit()
    return m.local_outlier_probabilities[range(df_test.shape[0])]



def novelty_detection_quantile(df_train, df_test):
    &#34;&#34;&#34;
    This function performs novelty detection using quantiles for each column.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    Returns:

    - quantiles for the test sample at each column where values range in [0,1]
        and higher values mean the column is closer to the edge of the distribution

    &#34;&#34;&#34;
    myqs = df_test.copy()
    n = df_train.shape[0]
    df_trainkeys = df_train.keys()
    for k in range( df_train.shape[1] ):
        mykey = df_trainkeys[k]
        temp = (myqs[mykey][0] &gt;  df_train[mykey]).sum() / n
        myqs[mykey] = abs( temp - 0.5 ) / 0.5
    return myqs</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="antspymm.mm.alff_image"><code class="name flex">
<span>def <span class="ident">alff_image</span></span>(<span>x, mask, flo=0.01, fhi=0.1, nuisance=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
are related measures that quantify the amplitude of low frequency
oscillations (LFOs).
This function outputs ALFF and fALFF for the input.</p>
<p>x - input clean resting state fmri
mask - mask over which to compute f/alff
flo - low frequency, typically 0.01
fhi - high frequency, typically 0.1
nuisance - optional nuisance matrix</p>
<p>return dictionary with ALFF and fALFF images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alff_image( x, mask, flo=0.01, fhi=0.1, nuisance=None ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.

    x - input clean resting state fmri
    mask - mask over which to compute f/alff
    flo - low frequency, typically 0.01
    fhi - high frequency, typically 0.1
    nuisance - optional nuisance matrix

    return dictionary with ALFF and fALFF images
    &#34;&#34;&#34;
    xmat = ants.timeseries_to_matrix( x, mask )
    if nuisance is not None:
        xmat = ants.regress_components( xmat, nuisance )
    alffvec = xmat[0,:]*0
    falffvec = xmat[0,:]*0
    mytr = ants.get_spacing( x )[3]
    for n in range( xmat.shape[1] ):
        temp = alffmap( xmat[:,n], flo=flo, fhi=fhi, tr=mytr )
        alffvec[n]=temp[&#39;alff&#39;]
        falffvec[n]=temp[&#39;falff&#39;]
    alffi=ants.make_image( mask, alffvec )
    falffi=ants.make_image( mask, falffvec )
    return {  &#39;alff&#39;: alffi, &#39;falff&#39;: falffi }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.alffmap"><code class="name flex">
<span>def <span class="ident">alffmap</span></span>(<span>x, flo=0.01, fhi=0.1, tr=1, detrend=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
are related measures that quantify the amplitude of low frequency
oscillations (LFOs).
This function outputs ALFF and fALFF for the input.
same function in ANTsR.</p>
<p>x input vector for the time series of interest
flo low frequency, typically 0.01
fhi high frequency, typically 0.1
tr the period associated with the vector x (inverse of frequency)
detrend detrend the input time series</p>
<p>return vector is output showing ALFF and fALFF values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alffmap( x, flo=0.01, fhi=0.1, tr=1, detrend = True ):
    &#34;&#34;&#34;
    Amplitude of Low Frequency Fluctuations (ALFF; Zang et al., 2007) and
    fractional Amplitude of Low Frequency Fluctuations (f/ALFF; Zou et al., 2008)
    are related measures that quantify the amplitude of low frequency
    oscillations (LFOs).  This function outputs ALFF and fALFF for the input.
    same function in ANTsR.

    x input vector for the time series of interest
    flo low frequency, typically 0.01
    fhi high frequency, typically 0.1
    tr the period associated with the vector x (inverse of frequency)
    detrend detrend the input time series

    return vector is output showing ALFF and fALFF values
    &#34;&#34;&#34;
    temp = spec_pgram( x, xfreq=1.0/tr, demean=False, detrend=detrend, taper=0, fast=True, plot=False )
    fselect = np.logical_and( temp[&#39;freq&#39;] &gt;= flo, temp[&#39;freq&#39;] &lt;= fhi )
    denom = (temp[&#39;spec&#39;]).sum()
    numer = (temp[&#39;spec&#39;][fselect]).sum()
    return {  &#39;alff&#39;:numer, &#39;falff&#39;: numer/denom }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.assemble_modality_specific_dataframes"><code class="name flex">
<span>def <span class="ident">assemble_modality_specific_dataframes</span></span>(<span>mm_wide_csvs, hierdfin, nrg_modality, separator='-', progress=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assemble_modality_specific_dataframes( mm_wide_csvs, hierdfin, nrg_modality, separator=&#39;-&#39;, progress=None, verbose=False ):
    moddersub = re.sub( &#34;[*]&#34;,&#34;&#34;,nrg_modality)
    nmdf=pd.DataFrame()
    for k in range( hierdfin.shape[0] ):
        if progress is not None:
            if k % progress == 0:
                progger = str( np.round( k / hierdfin.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        temp = mm_wide_csvs[k]
        mypartsf = temp.split(&#34;T1wHierarchical&#34;)
        myparts = mypartsf[0]
        t1iid = str(mypartsf[1].split(&#34;/&#34;)[1])
        fnsnm = glob.glob(myparts+&#34;/&#34; + nrg_modality + &#34;/*/*&#34; + t1iid + &#34;*wide.csv&#34;)
        if len( fnsnm ) &gt; 0 :
            for y in fnsnm:
                temp=read_mm_csv( y, colprefix=moddersub+&#39;_&#39;, is_t1=False, separator=separator, verbose=verbose )
                if temp is not None:
                    nmdf=pd.concat( [nmdf, temp], axis=0)
    return nmdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.augment_image"><code class="name flex">
<span>def <span class="ident">augment_image</span></span>(<span>x, max_rot=10, nzsd=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def augment_image( x,  max_rot=10, nzsd=1 ):
    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rot*(-1.0), max_rot ), reference=x )
    tx = rRotGenerator.transform()
    itx = ants.invert_ants_transform(tx)
    y = ants.apply_ants_transform_to_image( tx, x, x, interpolation=&#39;linear&#39;)
    y = ants.add_noise_to_image( y,&#39;additivegaussian&#39;, [0,nzsd] )
    return y, tx, itx</code></pre>
</details>
</dd>
<dt id="antspymm.mm.average_blind_qc_by_modality"><code class="name flex">
<span>def <span class="ident">average_blind_qc_by_modality</span></span>(<span>qc_full, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Averages time series qc results to yield one entry per image. this also filters to "known" columns.</p>
<p>Args:
qc_full: pandas dataframe containing the full qc data.</p>
<p>Returns:
pandas dataframe containing the processed qc data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def average_blind_qc_by_modality(qc_full,verbose=False):
    &#34;&#34;&#34;
    Averages time series qc results to yield one entry per image. this also filters to &#34;known&#34; columns.

    Args:
    qc_full: pandas dataframe containing the full qc data.

    Returns:
    pandas dataframe containing the processed qc data.
    &#34;&#34;&#34;
    # Get unique modalities
    modalities = qc_full[&#39;modality&#39;].unique()
    modalities = modalities[modalities != &#39;unknown&#39;]
    # Get modalities to select
    m0sel = qc_full[&#39;modality&#39;].isin(modalities)
    # Get unique ids
    uid = qc_full[&#39;fn&#39;] + &#34;_&#34; + qc_full[&#39;modality&#39;].astype(str)
    to_average = uid.unique()
    # Define column indices
    contcols = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;, &#39;spc1&#39;, &#39;spc2&#39;, &#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;, &#39;dimx&#39;, &#39;dimy&#39;, &#39;dimz&#39;, &#39;slice&#39;]
    ocols = [&#39;fn&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39;]
    # restrict to columns we &#34;know&#34;
    qc_full = qc_full[ocols+contcols]
    # Create empty meta dataframe
    meta = pd.DataFrame(columns=ocols+contcols)
    # Process each unique id
    n = len(to_average)
    for k in range(n):
        if verbose:
            if k % 100 == 0:
                progger = str( np.round( k / n * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        m1sel = uid == to_average[k]
        if sum(m1sel) &gt; 1:
            # If more than one entry for id, take the average of continuous columns,
            # maximum of the slice column, and the first entry of the other columns
            mfsub = qc_full[m1sel]
            if mfsub.shape[0] &gt; 1:
                meta.loc[k, contcols] = mfsub.loc[:, contcols].mean(numeric_only=True)
                meta.loc[k, &#39;slice&#39;] = mfsub[&#39;slice&#39;].max()
                meta.loc[k, ocols] = mfsub[ocols].iloc[0]
        elif sum(m1sel) == 1:
            # If only one entry for id, just copy the entry
            mfsub = qc_full[m1sel]
            meta.loc[k] = mfsub.iloc[0]
    return meta</code></pre>
</details>
</dd>
<dt id="antspymm.mm.average_mm_df"><code class="name flex">
<span>def <span class="ident">average_mm_df</span></span>(<span>jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def average_mm_df( jmm_in, diagnostic_n=25, corr_thresh=0.9, verbose=False ):
    &#34;&#34;&#34;
    jmrowavg, jmmcolavg, diagnostics = antspymm.average_mm_df( jmm_in, verbose=True )
    &#34;&#34;&#34;

    jmm = jmm_in.copy()
    dxcols=[&#39;subjectid1&#39;,&#39;subjectid2&#39;,&#39;modalityid&#39;,&#39;joinid&#39;,&#39;correlation&#39;,&#39;distance&#39;]
    joinDiagnostics = pd.DataFrame( columns = dxcols )
    nanList=[math.nan]
    def rob(x, y=0.99):
        x[x &gt; np.quantile(x, y, nan_policy=&#34;omit&#34;)] = np.nan
        return x

    jmm = jmm.replace(r&#39;^\s*$&#39;, np.nan, regex=True)

    if verbose:
        print(&#34;do rsfMRI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;rsfMRI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;rsfMRI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    if len( dt0 ) &gt; 0 and len( dt1 ) &gt; 0:
        flid = dt0[0]
        wrows = []
        for i in range(jmm.shape[0]):
            if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) :
                wrows.append(i)
        for k in wrows:
            v1 = jmm.iloc[k][dt0[1:]].astype(float)
            v2 = jmm.iloc[k][dt1[1:]].astype(float)
            vvec = [v1[0], v2[0]]
            if any(~np.isnan(vvec)):
                mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
                jmm.iloc[k][dt0[0]] = &#39;rsfMRI&#39;
                if len(mynna) == 1:
                    if mynna[0] == 0:
                        jmm.iloc[k][dt0[1:]] = v1
                    if mynna[0] == 1:
                        jmm.iloc[k][dt0[1:]] = v2
                elif len(mynna) &gt; 1:
                    if len(v2) &gt; diagnostic_n:
                        v1dx=v1[0:diagnostic_n]
                        v2dx=v2[0:diagnostic_n]
                    else :
                        v1dx=v1
                        v2dx=v2
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v1dx.values, v2dx.values )[0,1]
                    myerr=np.sqrt(np.mean((v1dx.values - v2dx.values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;rsfMRI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v1.values*0.5 + v2.values*0.5
                    else:
                        jmm.loc[k, dt0[1:]] = nanList * len(v1)
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)

    if verbose:
        print(&#34;do DTI&#34;)
    # here - we first have to average within each row
    dt0 = get_names_from_data_frame([&#34;DTI&#34;], jmm, exclusions=[&#34;Unnamed&#34;, &#34;DTI_LR&#34;, &#34;DTI_RL&#34;])
    dt1 = get_names_from_data_frame([&#34;DTI_LR&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    dt2 = get_names_from_data_frame( [&#34;DTI_RL&#34;], jmm, exclusions=[&#34;Unnamed&#34;])
    flid = dt0[0]
    wrows = []
    for i in range(jmm.shape[0]):
        if not pd.isna(jmm[dt0[1]][i]) or not pd.isna(jmm[dt1[1]][i]) or not pd.isna(jmm[dt2[1]][i]):
            wrows.append(i)
    for k in wrows:
        v1 = jmm.loc[k, dt0[1:]].astype(float)
        v2 = jmm.loc[k, dt1[1:]].astype(float)
        v3 = jmm.loc[k, dt2[1:]].astype(float)
        checkcol = dt0[5]
        if not np.isnan(v1[checkcol]):
            if v1[checkcol] &lt; 0.25:
                v1.replace(np.nan, inplace=True)
        checkcol = dt1[5]
        if not np.isnan(v2[checkcol]):
            if v2[checkcol] &lt; 0.25:
                v2.replace(np.nan, inplace=True)
        checkcol = dt2[5]
        if not np.isnan(v3[checkcol]):
            if v3[checkcol] &lt; 0.25:
                v3.replace(np.nan, inplace=True)
        vvec = [v1[0], v2[0], v3[0]]
        if any(~np.isnan(vvec)):
            mynna = [i for i, x in enumerate(vvec) if ~np.isnan(x)]
            jmm.loc[k, dt0[0]] = &#39;DTI&#39;
            if len(mynna) == 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                if mynna[0] == 1:
                    jmm.loc[k, dt0[1:]] = v2
                if mynna[0] == 2:
                    jmm.loc[k, dt0[1:]] = v3
            elif len(mynna) &gt; 1:
                if mynna[0] == 0:
                    jmm.loc[k, dt0[1:]] = v1
                else:
                    joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                    mycorr = np.corrcoef( v2[0:diagnostic_n].values, v3[0:diagnostic_n].values )[0,1]
                    myerr=np.sqrt(np.mean((v2[0:diagnostic_n].values - v3[0:diagnostic_n].values)**2))
                    joinDiagnosticsLoc.iloc[0] = [jmm.loc[k,&#39;u_hier_id&#39;],math.nan,&#39;DTI&#39;,&#39;colavg&#39;,mycorr,myerr]
                    if mycorr &gt; corr_thresh:
                        jmm.loc[k, dt0[1:]] = v2.values*0.5 + v3.values*0.5
                    else: #
                        jmm.loc[k, dt0[1:]] = nanList * len( dt0[1:] )
                    if verbose:
                        print( joinDiagnosticsLoc )
                    joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)


    # first task - sort by u_hier_id
    jmm = jmm.sort_values( &#34;u_hier_id&#34; )
    # get rid of junk columns
    badnames = get_names_from_data_frame( [&#39;Unnamed&#39;], jmm )
    jmm=jmm.drop(badnames, axis=1)
    jmm=jmm.set_index(&#34;u_hier_id&#34;,drop=False)
    # 2nd - get rid of duplicated u_hier_id
    jmmUniq = jmm.drop_duplicates( subset=&#34;u_hier_id&#34; ) # fast and easy
    # for each modality, count which ids have more than one
    mod_names = get_valid_modalities()
    for mod_name in mod_names:
        fl_names = get_names_from_data_frame([mod_name], jmm,
            exclusions=[&#39;Unnamed&#39;,&#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;rsfMRI_RL&#34;,&#34;rsfMRI_LR&#34;])
        if len( fl_names ) &gt; 1:
            if verbose:
                print(mod_name)
                print(fl_names)
            fl_id = fl_names[0]
            n_names = len(fl_names)
            locvec = jmm[fl_names[n_names-1]].astype(float)
            boolvec=~pd.isna(locvec)
            jmmsub = jmm[boolvec][ [&#39;u_hier_id&#39;]+fl_names]
            my_tbl = Counter(jmmsub[&#39;u_hier_id&#39;])
            gtoavg = [name for name in my_tbl.keys() if my_tbl[name] == 1]
            gtoavgG1 = [name for name in my_tbl.keys() if my_tbl[name] &gt; 1]
            if verbose:
                print(&#34;Join 1&#34;)
            jmmsub1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavg)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavg:
                jmmUniq.loc[u][fl_names[1:]] = jmmsub1.loc[u][fl_names[1:]]
            if verbose and len(gtoavgG1) &gt; 1:
                print(&#34;Join &gt;1&#34;)
            jmmsubG1 = jmmsub.loc[jmmsub[&#39;u_hier_id&#39;].isin(gtoavgG1)][[&#39;u_hier_id&#39;]+fl_names]
            for u in gtoavgG1:
                temp = jmmsubG1.loc[u][ [&#39;u_hier_id&#39;]+fl_names ]
                dropnames = get_names_from_data_frame( [&#39;MM.ID&#39;], temp )
                tempVec = temp.drop(columns=dropnames)
                joinDiagnosticsLoc = pd.DataFrame( columns = dxcols, index=range(1) )
                id1=temp[fl_id].iloc[0]
                id2=temp[fl_id].iloc[1]
                v1=tempVec.iloc[0][1:].astype(float).to_numpy()
                v2=tempVec.iloc[1][1:].astype(float).to_numpy()
                if len(v2) &gt; diagnostic_n:
                    v1=v1[0:diagnostic_n]
                    v2=v2[0:diagnostic_n]
                mycorr = np.corrcoef( v1, v2 )[0,1]
                # mycorr=temparr[np.triu_indices_from(temparr, k=1)].mean()
                myerr=np.sqrt(np.mean((v1 - v2)**2))
                joinDiagnosticsLoc.iloc[0] = [id1,id2,mod_name,&#39;rowavg&#39;,mycorr,myerr]
                if verbose:
                    print( joinDiagnosticsLoc )
                temp = jmmsubG1.loc[u][fl_names[1:]].astype(float)
                if mycorr &gt; corr_thresh or len( v1 ) &lt; 10:
                    jmmUniq.loc[u][fl_names[1:]] = temp.mean(axis=0)
                else:
                    jmmUniq.loc[u][fl_names[1:]] = nanList * temp.shape[1]
                joinDiagnostics = pd.concat( [joinDiagnostics, joinDiagnosticsLoc], axis=0)

    return jmmUniq, jmm, joinDiagnostics</code></pre>
</details>
</dd>
<dt id="antspymm.mm.best_mmm"><code class="name flex">
<span>def <span class="ident">best_mmm</span></span>(<span>mmdf, wmod, mysep='-', outlier_column='ol_loop', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Selects the best repeats per modality.</p>
<p>Args:
wmod (str): the modality of the image ( 'T1w', 'T2Flair', 'NM2DMT' 'rsfMRI', 'DTI')</p>
<p>mysep (str, optional): the separator used in the image file names. Defaults to '-'.</p>
<p>outlier_name : column name for outlier score</p>
<p>verbose (bool, optional): default True</p>
<p>Returns:</p>
<p>list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_mmm( mmdf, wmod, mysep=&#39;-&#39;, outlier_column=&#39;ol_loop&#39;, verbose=False):
    &#34;&#34;&#34;
    Selects the best repeats per modality.

    Args:
    wmod (str): the modality of the image ( &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;NM2DMT&#39; &#39;rsfMRI&#39;, &#39;DTI&#39;)

    mysep (str, optional): the separator used in the image file names. Defaults to &#39;-&#39;.

    outlier_name : column name for outlier score

    verbose (bool, optional): default True

    Returns:

    list: a list containing two metadata dataframes - raw and filt. raw contains all the metadata for the selected modality and filt contains the metadata filtered for highest quality repeats.

    &#34;&#34;&#34;
    msel = mmdf[&#39;modality&#39;] == wmod
    if wmod == &#39;rsfMRI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;rsfMRI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;rsfMRI_RL&#39;
        msel = msel1 | msel2
        msel = msel | msel3
    if wmod == &#39;DTI&#39;:
        msel1 = mmdf[&#39;modality&#39;] == &#39;DTI&#39;
        msel2 = mmdf[&#39;modality&#39;] == &#39;DTI_LR&#39;
        msel3 = mmdf[&#39;modality&#39;] == &#39;DTI_RL&#39;
        msel4 = mmdf[&#39;modality&#39;] == &#39;DTIdwi&#39;
        msel = msel1 | msel2 | msel3 | msel4
    if sum(msel) == 0:
        return {&#39;raw&#39;: None, &#39;filt&#39;: None}
    uids = list(mmdf[&#39;fn&#39;][msel])
    metasub = mmdf[msel]

    if verbose:
        print(f&#34;{wmod} {(metasub.shape[0])} pre&#34;)

    metasub[&#39;subjectID&#39;]=math.nan
    metasub[&#39;date&#39;]=math.nan
    metasub[&#39;subjectIDdate&#39;]=math.nan
    metasub[&#39;imageID&#39;]=math.nan
    for k in range(len(uids)):
        temp = uids[k].split( mysep )
        metasub[&#39;subjectID&#39;].iloc[k] = temp[1]
        metasub[&#39;date&#39;].iloc[k] = temp[2]
        metasub[&#39;subjectIDdate&#39;].iloc[k] = temp[1] + mysep + temp[2]
        metasub[&#39;imageID&#39;].iloc[k] = temp[4]

    metasub[&#39;negol&#39;] = metasub[outlier_column].max() - metasub[outlier_column]
    if &#39;date&#39; not in metasub.keys():
        metasub[&#39;date&#39;]=&#39;NA&#39;
    metasubq = highest_quality_repeat(metasub, &#39;fn&#39;, &#39;date&#39;, &#39;negol&#39;)

    if verbose:
        print(f&#34;{wmod} {metasubq.shape[0]} post&#34;)

    return {&#39;raw&#39;: metasub, &#39;filt&#39;: metasubq}</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bids_2_nrg"><code class="name flex">
<span>def <span class="ident">bids_2_nrg</span></span>(<span>bids_filename, project_name, date, nrg_modality=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a BIDS filename to NRG path/filename.</p>
<p>Parameters:
bids_filename (str): The BIDS filename to convert
project_name (str) : Name of project (i.e. PPMI)
date (str) : Date of image acquisition</p>
<p>Returns:
str: The NRG path/filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bids_2_nrg( bids_filename, project_name, date, nrg_modality=None ):
    &#34;&#34;&#34;
    Convert a BIDS filename to NRG path/filename.

    Parameters:
    bids_filename (str): The BIDS filename to convert
    project_name (str) : Name of project (i.e. PPMI)
    date (str) : Date of image acquisition


    Returns:
    str: The NRG path/filename.
    &#34;&#34;&#34;

    bids_dirname, bids_basename = os.path.split(bids_filename)
    bids_suffix = &#39;.&#39;+ bids_basename.split(&#39;.&#39;,1)[-1]
    bids_basename = bids_basename.replace(bids_suffix, &#39;&#39;) # remove ext
    bids_parts = bids_basename.split(&#39;_&#39;)
    nrg_subject_id = bids_parts[0].replace(&#39;sub-&#39;,&#39;&#39;)
    nrg_image_id = bids_parts[1].replace(&#39;ses-&#39;, &#39;&#39;)
    bids_modality = bids_parts[2]
    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality: &#34; + get_valid_modalities(asString=True))

    if bids_modality == &#39;anat&#39; and nrg_modality is None :
        nrg_modality = &#39;T1w&#39;

    if bids_modality == &#39;dwi&#39; and nrg_modality is None  :
        nrg_modality = &#39;DTI&#39;

    if bids_modality == &#39;func&#39; and nrg_modality is None  :
        nrg_modality = &#39;rsfMRI&#39;

    nrg_suffix = bids_suffix[1:]
    nrg_filename = f&#39;{project_name}-{nrg_subject_id}-{date}-{nrg_modality}-{nrg_image_id}.{nrg_suffix}&#39;

    return os.path.join(project_name, nrg_subject_id, date, nrg_modality, nrg_image_id,nrg_filename)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bind_wide_mm_csvs"><code class="name flex">
<span>def <span class="ident">bind_wide_mm_csvs</span></span>(<span>mm_wide_csvs, merge=True, separator='-', verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>will convert a list of t1w hierarchical csv filenames to a merged dataframe</p>
<p>returns a pair of data frames, the left side having all entries and the
right side having row averaged entries i.e. unique values for each visit</p>
<p>set merge to False to return individual dataframes ( for debugging )</p>
<p>return alldata, row_averaged_data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bind_wide_mm_csvs( mm_wide_csvs, merge=True, separator=&#39;-&#39;, verbose = 0 ) :
    &#34;&#34;&#34;
    will convert a list of t1w hierarchical csv filenames to a merged dataframe

    returns a pair of data frames, the left side having all entries and the
        right side having row averaged entries i.e. unique values for each visit

    set merge to False to return individual dataframes ( for debugging )

    return alldata, row_averaged_data
    &#34;&#34;&#34;
    mm_wide_csvs.sort()
    if not mm_wide_csvs:
        print(&#34;No files found with specified pattern&#34;)
        return
    # 1. row-bind the t1whier data
    # 2. same for each other modality
    # 3. merge the modalities by the keys
    hierdf = pd.DataFrame()
    for y in mm_wide_csvs:
        temp=read_mm_csv( y, colprefix=&#39;T1Hier_&#39;, separator=separator, is_t1=True )
        if temp is not None:
            hierdf=pd.concat( [hierdf, temp], axis=0)
    if verbose &gt; 0:
        mypro=50
    else:
        mypro=None
    if verbose &gt; 0:
        print(&#34;thickness&#34;)
    thkdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T1w&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;flair&#34;)
    flairdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;T2Flair&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;NM&#34;)
    nmdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;NM2DMT&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;rsf&#34;)
    rsfdf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;rsfMRI*&#39;, progress=mypro, verbose=verbose==2)
    if verbose &gt; 0:
        print(&#34;dti&#34;)
    dtidf = assemble_modality_specific_dataframes( mm_wide_csvs, hierdf, &#39;DTI*&#39;, progress=mypro, verbose=verbose==2 )
    if not merge:
        return hierdf, thkdf, flairdf, nmdf, rsfdf, dtidf
    hierdfmix = hierdf.copy()
    modality_df_suffixes = [
        (thkdf, &#34;_thk&#34;),
        (flairdf, &#34;_flair&#34;),
        (nmdf, &#34;_nm&#34;),
        (rsfdf, &#34;_rsf&#34;),
        (dtidf, &#34;_dti&#34;),
    ]
    for pair in modality_df_suffixes:
        hierdfmix = merge_mm_dataframe(hierdfmix, pair[0], pair[1])
    hierdfmix = hierdfmix.replace(r&#39;^\s*$&#39;, np.nan, regex=True)
    return hierdfmix, hierdfmix.groupby(&#34;u_hier_id&#34;, as_index=False).mean(numeric_only=True)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.blind_image_assessment"><code class="name flex">
<span>def <span class="ident">blind_image_assessment</span></span>(<span>image, viz_filename=None, title=False, pull_rank=False, resample=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>quick blind image assessment and triplanar visualization of an image &hellip; 4D input will be visualized and assessed in 3D.
produces a png and csv where csv contains:</p>
<ul>
<li>
<p>reflection error ( estimates asymmetry )</p>
</li>
<li>
<p>brisq ( blind quality assessment )</p>
</li>
<li>
<p>patch eigenvalue ratio ( blind quality assessment )</p>
</li>
<li>
<p>PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)</p>
</li>
<li>
<p>mask volume ( estimates foreground object size )</p>
</li>
<li>
<p>spacing</p>
</li>
<li>
<p>dimension after cropping by mask</p>
</li>
</ul>
<p>image : character or image object usually a nifti image</p>
<p>viz_filename : character for a png output image</p>
<p>title : display a summary title on the png</p>
<p>pull_rank : boolean</p>
<p>resample : None, numeric max or min, resamples image to isotropy</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blind_image_assessment(
    image,
    viz_filename=None,
    title=False,
    pull_rank=False,
    resample=None,
    verbose=False
):
    &#34;&#34;&#34;
    quick blind image assessment and triplanar visualization of an image ... 4D input will be visualized and assessed in 3D.  produces a png and csv where csv contains:

    * reflection error ( estimates asymmetry )

    * brisq ( blind quality assessment )

    * patch eigenvalue ratio ( blind quality assessment )

    * PSNR and SSIM vs a smoothed reference (4D or 3D appropriate)

    * mask volume ( estimates foreground object size )

    * spacing

    * dimension after cropping by mask

    image : character or image object usually a nifti image

    viz_filename : character for a png output image

    title : display a summary title on the png

    pull_rank : boolean

    resample : None, numeric max or min, resamples image to isotropy

    verbose : boolean

    &#34;&#34;&#34;
    import glob as glob
    from os.path import exists
    import ants
    import matplotlib.pyplot as plt
    from PIL import Image
    from pathlib import Path
    import json
    import re
    mystem=&#39;&#39;
    if isinstance(image,list):
        isfilename=isinstance( image[0], str)
        image = image[0]
    else:
        isfilename=isinstance( image, str)
    outdf = pd.DataFrame()
    mymeta = None
    image_filename=&#39;&#39;
    if isfilename:
        image_filename = image
        if isinstance(image,list):
            image_filename=image[0]
        json_name = re.sub(&#34;.nii.gz&#34;,&#34;.json&#34;,image_filename)
        if exists( json_name ):
            with open(json_name, &#39;r&#39;) as fcc_file:
                mymeta = json.load(fcc_file, strict=False)
                if verbose:
                    print(json.dumps(mymeta, indent=4))
        mystem=Path( image ).stem
        mystem=Path( mystem ).stem
        image_reference = ants.image_read( image )
        image = ants.image_read( image )
    else:
        image_reference = ants.image_clone( image )
    ntimepoints = 1
    if image_reference.dimension == 4:
        ntimepoints = image_reference.shape[3]
        if &#34;DTI&#34; in image_filename:
            myTSseg = segment_timeseries_by_meanvalue( image_reference )
            image_b0, image_dwi = get_average_dwi_b0( image_reference, fast=True )
            image_b0 = ants.iMath( image_b0, &#39;Normalize&#39; )
            image_dwi = ants.iMath( image_dwi, &#39;Normalize&#39; )
        else:
            image_b0 = ants.get_average_of_timeseries( image_reference ).iMath(&#34;Normalize&#34;)
    else:
        image_compare = ants.smooth_image( image_reference, 3, sigma_in_physical_coordinates=False )
    for jjj in range(ntimepoints):
        modality=&#39;unknown&#39;
        if &#34;rsfMRI&#34; in image_filename:
            modality=&#39;rsfMRI&#39;
        elif &#34;T1w&#34; in image_filename:
            modality=&#39;T1w&#39;
        elif &#34;T2Flair&#34; in image_filename:
            modality=&#39;T2Flair&#39;
        elif &#34;NM2DMT&#34; in image_filename:
            modality=&#39;NM2DMT&#39;
        if image_reference.dimension == 4:
            image = ants.slice_image( image_reference, idx=int(jjj), axis=3 )
            if &#34;DTI&#34; in image_filename:
                if jjj in myTSseg[&#39;highermeans&#39;]:
                    image_compare = ants.image_clone( image_b0 )
                    modality=&#39;DTIb0&#39;
                else:
                    image_compare = ants.image_clone( image_dwi )
                    modality=&#39;DTIdwi&#39;
            else:
                image_compare = ants.image_clone( image_b0 )
        image = ants.iMath( image, &#39;TruncateIntensity&#39;,0.01,0.995)
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        if resample is not None:
            if resample == &#39;min&#39;:
                if minspc &lt; 1e-12:
                    minspc = np.max(ants.get_spacing(image))
                newspc = np.repeat( minspc, 3 )
            elif resample == &#39;max&#39;:
                newspc = np.repeat( maxspc, 3 )
            else:
                newspc = np.repeat( resample, 3 )
            image = ants.resample_image( image, newspc )
            image_compare = ants.resample_image( image_compare, newspc )
        else:
            # check for spc close to zero
            spc = list(ants.get_spacing(image))
            for spck in range(len(spc)):
                if spc[spck] &lt; 1e-12:
                    spc[spck]=1
            ants.set_spacing( image, spc )
            ants.set_spacing( image_compare, spc )
        # if &#34;NM2DMT&#34; in image_filename or &#34;FIXME&#34; in image_filename or &#34;SPECT&#34; in image_filename or &#34;UNKNOWN&#34; in image_filename:
        minspc = np.min(ants.get_spacing(image))
        maxspc = np.max(ants.get_spacing(image))
        msk = ants.threshold_image( ants.iMath(image,&#39;Normalize&#39;), 0.15, 1.0 )
        # else:
        #    msk = ants.get_mask( image )
        msk = ants.morphology(msk, &#34;close&#34;, 3 )
        bgmsk = msk*0+1-msk
        mskdil = ants.iMath(msk, &#34;MD&#34;, 4 )
        # ants.plot_ortho( image, msk, crop=False )
        image = ants.crop_image( image, mskdil ).iMath(&#34;Normalize&#34;)
        msk = ants.crop_image( msk, mskdil ).iMath(&#34;Normalize&#34;)
        bgmsk = ants.crop_image( bgmsk, mskdil ).iMath(&#34;Normalize&#34;)
        image_compare = ants.crop_image( image_compare, mskdil ).iMath(&#34;Normalize&#34;)
        nvox = int( msk.sum() )
        minshp = np.min( image.shape )
        npatch = int( np.round(  0.1 * nvox ) )
        npatch = np.min(  [512,npatch ] )
        patch_shape = []
        for k in range( 3 ):
            p = int( 32.0 / ants.get_spacing( image  )[k] )
            if p &gt; int( np.round( image.shape[k] * 0.5 ) ):
                p = int( np.round( image.shape[k] * 0.5 ) )
            patch_shape.append( p )
        if verbose:
            print(image)
            print( patch_shape )
            print( npatch )
        myevr = math.nan # dont want to fail if something odd happens in patch extraction
        try:
            myevr = antspyt1w.patch_eigenvalue_ratio( image, npatch, patch_shape,
                evdepth = 0.9, mask=msk )
        except:
            pass
        if pull_rank:
            image = ants.rank_intensity(image)
        imagereflect = ants.reflect_image(image, axis=0)
        asym_err = ( image - imagereflect ).abs().mean()
        # estimate noise by center cropping, denoizing and taking magnitude of difference
        nocrop=False
        if image.dimension == 3:
            if image.shape[2] == 1:
                nocrop=True        
        if maxspc/minspc &gt; 10:
            nocrop=True
        if nocrop:
            mycc = ants.image_clone( image )
        else:
            mycc = antspyt1w.special_crop( image,
                ants.get_center_of_mass( msk *0 + 1 ), patch_shape )
        myccd = ants.denoise_image( mycc, p=2,r=2,noise_model=&#39;Gaussian&#39; )
        noizlevel = ( mycc - myccd ).abs().mean()
#        ants.plot_ortho( image, crop=False, filename=viz_filename, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
#        from brisque import BRISQUE
#        obj = BRISQUE(url=False)
#        mybrisq = obj.score( np.array( Image.open( viz_filename )) )
        spc = ants.get_spacing( image )
        org = ants.get_origin( image )
        msk_vol = msk.sum() * np.prod( spc )
        bgstd = image[ bgmsk == 1 ].std()
        fgmean = image[ msk == 1 ].mean()
        bgmean = image[ bgmsk == 1 ].mean()
        snrref = fgmean / bgstd
        cnrref = ( fgmean - bgmean ) / bgstd
        psnrref = antspynet.psnr(  image_compare, image  )
        ssimref = antspynet.ssim(  image_compare, image  )
        if nocrop:
            mymi = math.inf
        else:
            mymi = ants.image_mutual_information( image_compare, image )
        mriseries=&#39;NA&#39;
        mrimfg=&#39;NA&#39;
        mrimodel=&#39;NA&#39;
        if mymeta is not None:
            # mriseries=mymeta[&#39;&#39;]
            try:
                mrimfg=mymeta[&#39;Manufacturer&#39;]
            except:
                pass
            try:
                mrimodel=mymeta[&#39;ManufacturersModelName&#39;]
            except:
                pass
        ttl=mystem + &#39; &#39;
        ttl=&#39;&#39;
        ttl=ttl + &#34;NZ: &#34; + &#34;{:0.4f}&#34;.format(noizlevel) + &#34; SNR: &#34; + &#34;{:0.4f}&#34;.format(snrref) + &#34; CNR: &#34; + &#34;{:0.4f}&#34;.format(cnrref) + &#34; PS: &#34; + &#34;{:0.4f}&#34;.format(psnrref)+ &#34; SS: &#34; + &#34;{:0.4f}&#34;.format(ssimref) + &#34; EVR: &#34; + &#34;{:0.4f}&#34;.format(myevr)+ &#34; MI: &#34; + &#34;{:0.4f}&#34;.format(mymi)
        if viz_filename is not None and ( jjj == 0 or (jjj % 30 == 0) ):
            viz_filename_use = re.sub( &#34;.png&#34;, &#34;_slice&#34;+str(jjj).zfill(4)+&#34;.png&#34;, viz_filename )
            ants.plot_ortho( image, crop=False, filename=viz_filename_use, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0,  title=ttl, titlefontsize=12, title_dy=-0.02,textfontcolor=&#39;red&#39; )
        df = pd.DataFrame([[ mystem, noizlevel, snrref, cnrref, psnrref, ssimref, mymi, asym_err, myevr, msk_vol, spc[0], spc[1], spc[2],org[0], org[1], org[2], image.shape[0], image.shape[1], image.shape[2], jjj, modality, mriseries, mrimfg, mrimodel ]], columns=[&#39;fn&#39;, &#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;, &#39;spc0&#39;,&#39;spc1&#39;,&#39;spc2&#39;,&#39;org0&#39;,&#39;org1&#39;,&#39;org2&#39;,&#39;dimx&#39;,&#39;dimy&#39;,&#39;dimz&#39;,&#39;slice&#39;,&#39;modality&#39;, &#39;mriseries&#39;, &#39;mrimfg&#39;, &#39;mrimodel&#39; ])
        outdf = pd.concat( [outdf, df ], axis=0 )
        if verbose:
            print( outdf )
    if viz_filename is not None:
        csvfn = re.sub( &#34;png&#34;, &#34;csv&#34;, viz_filename )
        outdf.to_csv( csvfn )
    return outdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.boot_wmh"><code class="name flex">
<span>def <span class="ident">boot_wmh</span></span>(<span>flair, t1, t1seg, mmfromconvexhull=0.0, strict=True, probability_mask=None, prior_probability=None, n_simulations=16, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def boot_wmh( flair, t1, t1seg, mmfromconvexhull = 0.0, strict=True,
        probability_mask=None, prior_probability=None, n_simulations=16,
        verbose=False ) :
    if verbose and prior_probability is None:
        print(&#34;augmented flair&#34;)
    if verbose and prior_probability is not None:
        print(&#34;augmented flair with prior&#34;)
    wmh_sum_aug = 0
    wmh_sum_prior_aug = 0
    augprob = flair * 0.0
    augprob_prior = None
    if prior_probability is not None:
        augprob_prior = flair * 0.0
    for n in range(n_simulations):
        augflair, tx, itx = augment_image( ants.iMath(flair,&#34;Normalize&#34;), 5, 0.01 )
        locwmh = wmh( augflair, t1, t1seg, mmfromconvexhull = mmfromconvexhull,
            strict=strict, probability_mask=None, prior_probability=prior_probability )
        if verbose:
            print( &#34;flair sim: &#34; + str(n) + &#34; vol: &#34; + str( locwmh[&#39;wmh_mass&#39;] )+ &#34; vol-prior: &#34; + str( locwmh[&#39;wmh_mass_prior&#39;] )+ &#34; snr: &#34; + str( locwmh[&#39;wmh_SNR&#39;] ) )
        wmh_sum_aug = wmh_sum_aug + locwmh[&#39;wmh_mass&#39;]
        wmh_sum_prior_aug = wmh_sum_prior_aug + locwmh[&#39;wmh_mass_prior&#39;]
        temp = locwmh[&#39;WMH_probability_map&#39;]
        augprob = augprob + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
        if prior_probability is not None:
            temp = locwmh[&#39;WMH_posterior_probability_map&#39;]
            augprob_prior = augprob_prior + ants.apply_ants_transform_to_image( itx, temp, flair, interpolation=&#39;linear&#39;)
    augprob = augprob * (1.0/float( n_simulations ))
    if prior_probability is not None:
        augprob_prior = augprob_prior * (1.0/float( n_simulations ))
    wmh_sum_aug = wmh_sum_aug / float( n_simulations )
    wmh_sum_prior_aug = wmh_sum_prior_aug / float( n_simulations )
    return{
      &#39;WMH_probability_map&#39; : augprob,
      &#39;WMH_posterior_probability_map&#39; : augprob_prior,
      &#39;wmh_mass&#39;: wmh_sum_aug,
      &#39;wmh_mass_prior&#39;: wmh_sum_prior_aug,
      &#39;wmh_evr&#39;: locwmh[&#39;wmh_evr&#39;],
      &#39;wmh_SNR&#39;: locwmh[&#39;wmh_SNR&#39;]  }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.bvec_reorientation"><code class="name flex">
<span>def <span class="ident">bvec_reorientation</span></span>(<span>motion_parameters, bvecs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bvec_reorientation( motion_parameters, bvecs ):
    if motion_parameters is None:
        return bvecs
    n = len(motion_parameters)
    if n &lt; 1:
        return bvecs
    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs
    dipymoco = np.zeros( [n,3,3] )
    for myidx in range(n):
        if myidx &lt; bvecs.shape[0]:
            dipymoco[myidx,:,:] = np.eye( 3 )
            if motion_parameters[myidx] != &#39;NA&#39;:
                temp = motion_parameters[myidx]
                if len(temp) == 4 :
                    temp1=temp[3] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                elif len(temp) == 2 :
                    temp=temp[1] # FIXME should be composite of index 1 and 3
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                elif len(temp) == 3 :
                    temp1=temp[2] # FIXME should be composite of index 1 and 3
                    temp2=temp[1] # FIXME should be composite of index 1 and 3
                    txparam1 = ants.read_transform(temp1)
                    txparam1 = ants.get_ants_transform_parameters(txparam1)[0:9].reshape( [3,3])
                    txparam2 = ants.read_transform(temp2)
                    txparam2 = ants.get_ants_transform_parameters(txparam2)[0:9].reshape( [3,3])
                    Rinv = inv( np.dot( txparam2, txparam1 ) )
                else:
                    temp=temp[0]
                    txparam = ants.read_transform(temp)
                    txparam = ants.get_ants_transform_parameters(txparam)[0:9].reshape( [3,3])
                    Rinv = inv( txparam )
                bvecs[myidx,:] = np.dot( Rinv, bvecs[myidx,:] )
    return bvecs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.collect_blind_qc_by_modality"><code class="name flex">
<span>def <span class="ident">collect_blind_qc_by_modality</span></span>(<span>modality_path, set_index_to_fn=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Collects blind QC data from multiple CSV files with the same modality.</p>
<p>Args:</p>
<p>modality_path (str): The path to the folder containing the CSV files.</p>
<p>set_index_to_fn: boolean</p>
<p>Returns:
Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def collect_blind_qc_by_modality( modality_path, set_index_to_fn=True ):
    &#34;&#34;&#34;
    Collects blind QC data from multiple CSV files with the same modality.

    Args:

    modality_path (str): The path to the folder containing the CSV files.

    set_index_to_fn: boolean

    Returns:
    Pandas DataFrame: A DataFrame containing all the blind QC data from the CSV files.
    &#34;&#34;&#34;
    import glob as glob
    fns = glob.glob( modality_path )
    fns.sort()
    jdf = pd.DataFrame()
    for k in range(len(fns)):
        temp=pd.read_csv(fns[k])
        if not &#39;fn&#39; in temp.keys():
            temp[&#39;fn&#39;]=fns[k]
        jdf=pd.concat( [jdf,temp])
    if set_index_to_fn:
        jdf.reset_index(drop=True)
        if &#34;Unnamed: 0&#34; in jdf.columns:
            holder=jdf.pop( &#34;Unnamed: 0&#34; )
        jdf.set_index(&#39;fn&#39;)
    return jdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.concat_dewarp"><code class="name flex">
<span>def <span class="ident">concat_dewarp</span></span>(<span>refimg, originalDWI, physSpaceDWI, dwpTx, motion_parameters, motion_correct=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply concatentated motion correction and dewarping transforms to timeseries image.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>refimg</code></strong> :&ensp;<code>an antsImage defining the reference domain (3D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>originalDWI</code></strong> :&ensp;<code>the antsImage in original (not interpolated space) (4D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>physSpaceDWI</code></strong> :&ensp;<code>ants antsImage defining the physical space</code> of <code>the mapping (4D)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dwpTx</code></strong> :&ensp;<code>dewarping transform</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_parameters</code></strong> :&ensp;<code>previously computed list</code> of <code>motion parameters</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concat_dewarp(
        refimg,
        originalDWI,
        physSpaceDWI,
        dwpTx,
        motion_parameters,
        motion_correct=True,
        verbose=False ):
    &#34;&#34;&#34;
    Apply concatentated motion correction and dewarping transforms to timeseries image.

    Arguments
    ---------

    refimg : an antsImage defining the reference domain (3D)

    originalDWI : the antsImage in original (not interpolated space) (4D)

    physSpaceDWI : ants antsImage defining the physical space of the mapping (4D)

    dwpTx : dewarping transform

    motion_parameters : previously computed list of motion parameters

    motion_correct : boolean

    verbose : boolean

    &#34;&#34;&#34;
    # apply the dewarping tx to the original dwi and reconstruct again
    # NOTE: refimg must be in the same space for this to work correctly
    # due to the use of ants.list_to_ndimage( originalDWI, dwpimage )
    dwpimage = []
    for myidx in range(originalDWI.shape[3]):
        b0 = ants.slice_image( originalDWI, axis=3, idx=myidx)
        concatx = dwpTx.copy()
        if motion_correct:
            concatx = concatx + motion_parameters[myidx]
        if verbose and myidx == 0:
            print(&#34;dwp parameters&#34;)
            print( dwpTx )
            print(&#34;Motion parameters&#34;)
            print( motion_parameters[myidx] )
            print(&#34;concat parameters&#34;)
            print(concatx)
        warpedb0 = ants.apply_transforms( refimg, b0, concatx,
            interpolator=&#39;nearestNeighbor&#39; )
        dwpimage.append( warpedb0 )
    return ants.list_to_ndimage( physSpaceDWI, dwpimage )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.crop_mcimage"><code class="name flex">
<span>def <span class="ident">crop_mcimage</span></span>(<span>x, mask, padder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>crop a time series (4D) image by a 3D mask</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>raw image</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>mask
: mask for cropping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_mcimage( x, mask, padder=None ):
    &#34;&#34;&#34;
    crop a time series (4D) image by a 3D mask

    Parameters
    -------------

    x : raw image

    mask  : mask for cropping

    &#34;&#34;&#34;
    cropmask = ants.crop_image( mask, mask )
    myorig = list( ants.get_origin(cropmask) )
    myorig.append( ants.get_origin( x )[3] )
    croplist = []
    if len(x.shape) &gt; 3:
        for k in range(x.shape[3]):
            temp = ants.slice_image( x, axis=3, idx=k )
            temp = ants.crop_image( temp, mask )
            if padder is not None:
                temp = ants.pad_image( temp, pad_width=padder )
            croplist.append( temp )
        temp = ants.list_to_ndimage( x, croplist )
        temp.set_origin( myorig )
        return temp
    else:
        return( ants.crop_image( x, mask ) )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dewarp_imageset"><code class="name flex">
<span>def <span class="ident">dewarp_imageset</span></span>(<span>image_list, initial_template=None, iterations=None, padding=0, target_idx=[0], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Dewarp a set of images</p>
<p>Makes simplifying heuristic decisions about how to transform an image set
into an unbiased reference space.
Will handle plenty of decisions
automatically so beware.
Computes an average shape space for the images
and transforms them to that space.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image_list</code></strong> :&ensp;<code>list containing antsImages 2D, 3D</code> or <code>4D</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>initial_template</code></strong> :&ensp;<code>optional</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>iterations</code></strong> :&ensp;<code>number</code> of <code>template building iterations</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>padding</code></strong> :&ensp;<code> will pad the images by an integer amount to limit edge effects</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_idx</code></strong> :&ensp;<code>the target indices for the time series over which we should average;</code></dt>
<dd>a list of integer indices into the last axis of the input images.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>keyword args</code></dt>
<dd>arguments passed to ants registration - these must be set explicitly</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary with the mean image and the list</code> of <code>the transformed images as</code></dt>
<dd>&nbsp;</dd>
<dt><code>well as motion correction parameters for each image in the input list</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dewarp_imageset( image_list, initial_template=None,
    iterations=None, padding=0, target_idx=[0], **kwargs ):
    &#34;&#34;&#34;
    Dewarp a set of images

    Makes simplifying heuristic decisions about how to transform an image set
    into an unbiased reference space.  Will handle plenty of decisions
    automatically so beware.  Computes an average shape space for the images
    and transforms them to that space.

    Arguments
    ---------
    image_list : list containing antsImages 2D, 3D or 4D

    initial_template : optional

    iterations : number of template building iterations

    padding:  will pad the images by an integer amount to limit edge effects

    target_idx : the target indices for the time series over which we should average;
        a list of integer indices into the last axis of the input images.

    kwargs : keyword args
        arguments passed to ants registration - these must be set explicitly

    Returns
    -------
    a dictionary with the mean image and the list of the transformed images as
    well as motion correction parameters for each image in the input list

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    outlist = []
    avglist = []
    if len(image_list[0].shape) &gt; 3:
        imagetype = 3
        for k in range(len(image_list)):
            for j in range(len(target_idx)):
                avglist.append( ants.slice_image( image_list[k], axis=3, idx=target_idx[j] ) )
    else:
        imagetype = 0
        avglist=image_list

    pw=[]
    for k in range(len(avglist[0].shape)):
        pw.append( padding )
    for k in range(len(avglist)):
        avglist[k] = ants.pad_image( avglist[k], pad_width=pw  )

    if initial_template is None:
        initial_template = avglist[0] * 0
        for k in range(len(avglist)):
            initial_template = initial_template + avglist[k]/len(avglist)

    if iterations is None:
        iterations = 2

    btp = ants.build_template(
        initial_template=initial_template,
        image_list=avglist,
        gradient_step=0.5, blending_weight=0.8,
        iterations=iterations, **kwargs )

    # last - warp all images to this frame
    mocoplist = []
    mocofdlist = []
    reglist = []
    for k in range(len(image_list)):
        if imagetype == 3:
            moco0 = ants.motion_correction( image=image_list[k], fixed=btp, type_of_transform=&#39;BOLDRigid&#39; )
            mocoplist.append( moco0[&#39;motion_parameters&#39;] )
            mocofdlist.append( moco0[&#39;FD&#39;] )
            locavg = ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=0 ) * 0.0
            for j in range(len(target_idx)):
                locavg = locavg + ants.slice_image( moco0[&#39;motion_corrected&#39;], axis=3, idx=target_idx[j] )
            locavg = locavg * 1.0 / len(target_idx)
        else:
            locavg = image_list[k]
        reg = ants.registration( btp, locavg, **kwargs )
        reglist.append( reg )
        if imagetype == 3:
            myishape = image_list[k].shape
            mytslength = myishape[ len(myishape) - 1 ]
            mywarpedlist = []
            for j in range(mytslength):
                locimg = ants.slice_image( image_list[k], axis=3, idx = j )
                mywarped = ants.apply_transforms( btp, locimg,
                    reg[&#39;fwdtransforms&#39;] + moco0[&#39;motion_parameters&#39;][j], imagetype=0 )
                mywarpedlist.append( mywarped )
            mywarped = ants.list_to_ndimage( image_list[k], mywarpedlist )
        else:
            mywarped = ants.apply_transforms( btp, image_list[k], reg[&#39;fwdtransforms&#39;], imagetype=imagetype )
        outlist.append( mywarped )

    return {
        &#39;dewarpedmean&#39;:btp,
        &#39;dewarped&#39;:outlist,
        &#39;deformable_registrations&#39;: reglist,
        &#39;FD&#39;: mocofdlist,
        &#39;motionparameters&#39;: mocoplist }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dipy_dti_recon"><code class="name flex">
<span>def <span class="ident">dipy_dti_recon</span></span>(<span>image, bvalsfn, bvecsfn, mask=None, b0_idx=None, mask_dilation=2, mask_closing=5, fit_method='WLS', trim_the_mask=2, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>DiPy DTI reconstruction - building on the DiPy basic DTI example</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvalsfn</code></strong> :&ensp;<code>bvalues
obtained by dipy read_bvals_bvecs</code> or <code>the values themselves</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecsfn</code></strong> :&ensp;<code>bvectors obtained by dipy read_bvals_bvecs</code> or <code>the values themselves</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>brain mask for the DWI/DTI reconstruction; if it is not in the same</code></dt>
<dd>space as the image, we will resample directly to the image space.
This
could lead to problems if the inputs are really incorrect.</dd>
<dt><strong><code>b0_idx</code></strong> :&ensp;<code>the indices</code> of <code>the B0; if None, use segment_timeseries_by_meanvalue to guess</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask_dilation</code></strong> :&ensp;<code>integer zero</code> or <code>more dilates the brain mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask_closing</code></strong> :&ensp;<code>integer zero</code> or <code>more closes the brain mask</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) &hellip; if None, will not reconstruct DTI.</p>
<dl>
<dt><strong><code>trim_the_mask</code></strong> :&ensp;<code>boolean post-hoc method for trimming the mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)</code></dt>
<dd>&nbsp;</dd>
<dt><code>NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)</code></dt>
<dd>&nbsp;</dd>
<dt><code>NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect</code></dt>
<dd>the tailing image volumes.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dipy_dti_recon(
    image,
    bvalsfn,
    bvecsfn,
    mask = None,
    b0_idx = None,
    mask_dilation = 2,
    mask_closing = 5,
    fit_method=&#39;WLS&#39;,
    trim_the_mask=2,
    verbose=False ):
    &#34;&#34;&#34;
    DiPy DTI reconstruction - building on the DiPy basic DTI example

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    bvalsfn : bvalues  obtained by dipy read_bvals_bvecs or the values themselves

    bvecsfn : bvectors obtained by dipy read_bvals_bvecs or the values themselves

    mask : brain mask for the DWI/DTI reconstruction; if it is not in the same
        space as the image, we will resample directly to the image space.  This
        could lead to problems if the inputs are really incorrect.

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    mask_dilation : integer zero or more dilates the brain mask

    mask_closing : integer zero or more closes the brain mask

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel) ... if None, will not reconstruct DTI.

    trim_the_mask : boolean post-hoc method for trimming the mask

    verbose : boolean

    Returns
    -------
    dictionary holding the tensorfit, MD, FA and RGB images and motion parameters (optional)

    NOTE -- see dipy reorient_bvecs(gtab, affines, atol=1e-2)

    NOTE -- if the bvec.shape[0] is smaller than the image.shape[3], we neglect
        the tailing image volumes.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;


    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]

    if isinstance(bvecsfn, str):
        bvals, bvecs = read_bvals_bvecs( bvalsfn , bvecsfn   )
    else: # assume we already read them
        bvals = bvalsfn.copy()
        bvecs = bvecsfn.copy()

    b0 = ants.slice_image( image, axis=3, idx=b0_idx[0] )
    bxtmod=&#39;bold&#39;
    bxtmod=&#39;t2&#39;
    constant_mask=False
    if mask is not None:
        constant_mask=True
        mask = ants.resample_image_to_target( mask, b0, interp_type=&#39;nearestNeighbor&#39;)
    else:
        mask = antspynet.brain_extraction( b0, bxtmod ).threshold_image(0.5,1).iMath(&#34;GetLargestComponent&#34;).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    if mask_closing &gt; 0 and not constant_mask :
        mask = ants.morphology( mask, &#34;close&#34;, mask_closing ) # good
    maskdil = ants.iMath( mask, &#34;MD&#34;, mask_dilation )

    if verbose:
        print(&#34;recon dti.TensorModel&#34;,flush=True)

    def justthefit( gtab, fit_method, imagein, maskin ):
        if fit_method is None:
            return None, None, None, None
        maskedimage=[]
        for myidx in range(imagein.shape[3]):
            b0 = ants.slice_image( imagein, axis=3, idx=myidx)
            maskedimage.append( b0 * maskin )
        maskedimage = ants.list_to_ndimage( imagein, maskedimage )
        maskdata = maskedimage.numpy()
        tenmodel = dti.TensorModel(gtab,fit_method=fit_method)
        tenfit = tenmodel.fit(maskdata)
        FA = fractional_anisotropy(tenfit.evals)
        FA[np.isnan(FA)] = 1
        FA = np.clip(FA, 0, 1)
        MD1 = dti.mean_diffusivity(tenfit.evals)
        MD1 = ants.copy_image_info( b0, ants.from_numpy( MD1.astype(np.float32) ) )
        FA = ants.copy_image_info(  b0, ants.from_numpy( FA.astype(np.float32) ) )
        FA, MD1 = impute_fa( FA, MD1 )
        RGB = color_fa(FA.numpy(), tenfit.evecs)
        RGB = ants.from_numpy( RGB.astype(np.float32) )
        RGB0 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=0 ) )
        RGB1 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=1 ) )
        RGB2 = ants.copy_image_info( b0, ants.slice_image( RGB, axis=3, idx=2 ) )
        RGB = ants.merge_channels( [RGB0,RGB1,RGB2] )
        return tenfit, FA, MD1, RGB

    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1)  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, maskdil )
    if verbose:
        print(&#34;recon dti.TensorModel done&#34;,flush=True)

    # change the brain mask based on high FA values
    if trim_the_mask &gt; 0 and fit_method is not None:
        mask = trim_dti_mask( FA, mask, trim_the_mask )
        tenfit, FA, MD1, RGB = justthefit( gtab, fit_method, image, mask )

    return {
        &#39;tensormodel&#39; : tenfit,
        &#39;MD&#39; : MD1 ,
        &#39;FA&#39; : FA ,
        &#39;RGB&#39; : RGB,
        &#39;dwi_mask&#39;:mask,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
        }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.down2iso"><code class="name flex">
<span>def <span class="ident">down2iso</span></span>(<span>x, interpolation='linear', takemin=False)</span>
</code></dt>
<dd>
<div class="desc"><p>will downsample an anisotropic image to an isotropic resolution</p>
<p>x: input image</p>
<p>interpolation: linear or nearestneighbor</p>
<p>takemin : boolean map to min space; otherwise max</p>
<p>return image downsampled to isotropic resolution</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def down2iso( x, interpolation=&#39;linear&#39;, takemin=False ):
    &#34;&#34;&#34;
    will downsample an anisotropic image to an isotropic resolution

    x: input image

    interpolation: linear or nearestneighbor

    takemin : boolean map to min space; otherwise max

    return image downsampled to isotropic resolution
    &#34;&#34;&#34;
    spc = ants.get_spacing( x )
    if takemin:
        newspc = np.asarray(spc).min()
    else:
        newspc = np.asarray(spc).max()
    newspc = np.repeat( newspc, x.dimension )
    if interpolation == &#39;linear&#39;:
        xs = ants.resample_image( x, newspc, interp_type=0)
    else:
        xs = ants.resample_image( x, newspc, interp_type=1)
    return xs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dti_reg"><code class="name flex">
<span>def <span class="ident">dti_reg</span></span>(<span>image, avg_b0, avg_dwi, bvals=None, bvecs=None, b0_idx=None, type_of_transform='Rigid', total_sigma=3.0, fdOffset=2.0, mask_csf=False, output_directory=None, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion - with optional deformation.</p>
<h2 id="arguments">Arguments</h2>
<pre><code>image: antsImage, usually ND where D=4.

avg_b0: Fixed image b0 image

avg_dwi: Fixed dwi same space as b0 image

bvals: bvalues (file or array)

bvecs: bvecs (file or array)

b0_idx: indices of b0

type_of_transform : string
    A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
    See ants registration for details.

fdOffset: offset value to use in framewise displacement calculation

mask_csf: boolean

output_directory : string
    output will be placed in this directory plus a numeric extension.

verbose: boolean

kwargs: keyword args
    extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dti_reg(
    image,
    avg_b0,
    avg_dwi,
    bvals=None,
    bvecs=None,
    b0_idx=None,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=3.0,
    fdOffset=2.0,
    mask_csf=False,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with optional deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        avg_b0: Fixed image b0 image

        avg_dwi: Fixed dwi same space as b0 image

        bvals: bvalues (file or array)

        bvecs: bvecs (file or array)

        b0_idx: indices of b0

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        mask_csf: boolean

        output_directory : string
            output will be placed in this directory plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if bvals is not None and bvecs is not None:
        if isinstance(bvecs, str):
            bvals, bvecs = read_bvals_bvecs( bvals , bvecs  )
        else: # assume we already read them
            bvals = bvals.copy()
            bvecs = bvecs.copy()
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD,
            &#39;bvals&#39;:bvals,
            &#39;bvecs&#39;:bvecs
        }

    from scipy.linalg import inv, polar
    from dipy.core.gradients import reorient_bvecs

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/dti_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( image )[&#39;highermeans&#39;]
    # first get a local deformation from slice to local avg space
    # then get a global deformation from avg to ref space
    ab0, adw = get_average_dwi_b0( image )
    mask = ants.get_mask(adw)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)


    if verbose:
        print(&#34;begin global distortion correction&#34;)
    # initrig = tra_initializer(avg_b0, ab0, max_rotation=60, transform=[&#39;rigid&#39;], verbose=verbose)
    if mask_csf:
        bcsf = ants.threshold_image( avg_b0,&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf = ab0 * 0 + 1

    initrig = ants.registration( avg_b0, ab0,&#39;BOLDRigid&#39;,outprefix=ofnG)
    deftx = ants.registration( avg_dwi, adw, &#39;SyNOnly&#39;,
        syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=[50,50,20],
        multivariate_extras=[ [ &#34;CC&#34;, avg_b0, ab0, 1, 2 ]],
        initial_transform=initrig[&#39;fwdtransforms&#39;][0],
        outprefix=ofnG
        )[&#39;fwdtransforms&#39;]
    if verbose:
        print(&#34;end global distortion correction&#34;)

    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 )
    for k in range(nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.n4_bias_field_correction( temp )
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k).zfill(4)+&#34;rig_&#34;
        txprefix2 = ofnL+str(k % 2).zfill(4)+&#34;def_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma, grad_step=0.1,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix2,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if k in b0_idx:
            fixed=ants.image_clone( ab0 )
        else:
            fixed=ants.image_clone( adw )
        if temp.numpy().var() &gt; 0:
            motion_parameters[k]=deftx+motion_parameters[k]
            img1w = ants.apply_transforms( avg_dwi,
                ants.slice_image(image, axis=idim - 1, idx=k),
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(fixed)

    if verbose:
        print(&#34;Reorient bvecs&#34;)
    if bvecs is not None:
        bvecs = bvec_reorientation( motion_parameters, bvecs )

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( 1.0 )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
        &#39;bvals&#39;:bvals,
        &#39;bvecs&#39;:bvecs
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dti_template"><code class="name flex">
<span>def <span class="ident">dti_template</span></span>(<span>b_image_list=None, w_image_list=None, iterations=5, gradient_step=0.5, mask_csf=False, average_both=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>two channel version of build_template</p>
<p>returns:
avg_b0, avg_dwi</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dti_template(
    b_image_list=None,
    w_image_list=None,
    iterations=5,
    gradient_step=0.5,
    mask_csf=False,
    average_both=True,
    verbose=False
):
    &#34;&#34;&#34;
    two channel version of build_template

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    mydeftx = tempfile.NamedTemporaryFile(delete=False,dir=output_directory).name
    tmp = tempfile.NamedTemporaryFile(delete=False,dir=output_directory,suffix=&#34;.nii.gz&#34;)
    wavgfn = tmp.name
    tmp2 = tempfile.NamedTemporaryFile(delete=False,dir=output_directory)
    comptx = tmp2.name
    weights = np.repeat(1.0 / len(b_image_list), len(b_image_list))
    weights = [x / sum(weights) for x in weights]
    w_initial_template = w_image_list[0]
    b_initial_template = b_image_list[0]
    b_initial_template = ants.iMath(b_initial_template,&#34;Normalize&#34;)
    w_initial_template = ants.iMath(w_initial_template,&#34;Normalize&#34;)
    if mask_csf:
        bcsf0 = ants.threshold_image( b_image_list[0],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
        bcsf1 = ants.threshold_image( b_image_list[1],&#34;Otsu&#34;,2).threshold_image(1,1).morphology(&#34;open&#34;,1).iMath(&#34;GetLargestComponent&#34;)
    else:
        bcsf0 = b_image_list[0] * 0 + 1
        bcsf1 = b_image_list[1] * 0 + 1
    bavg = b_initial_template.clone() * bcsf0
    wavg = w_initial_template.clone() * bcsf0
    bcsf = [ bcsf0, bcsf1 ]
    for i in range(iterations):
        for k in range(len(w_image_list)):
            fimg=wavg
            mimg=w_image_list[k] * bcsf[k]
            fimg2=bavg
            mimg2=b_image_list[k] * bcsf[k]
            w1 = ants.registration(
                fimg, mimg, type_of_transform=&#39;antsRegistrationSyNQuick[s]&#39;,
                    multivariate_extras= [ [ &#34;mattes&#34;, fimg2, mimg2, 1, 32 ]],
                    outprefix=mydeftx,
                    verbose=0 )
            txname = ants.apply_transforms(wavg, wavg,
                w1[&#34;fwdtransforms&#34;], compose=comptx )
            if k == 0:
                txavg = ants.image_read(txname) * weights[k]
                wavgnew = ants.apply_transforms( wavg,
                    w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                bavgnew = ants.apply_transforms( wavg,
                    b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
            else:
                txavg = txavg + ants.image_read(txname) * weights[k]
                if i &gt;= (iterations-2) and average_both:
                    wavgnew = wavgnew+ants.apply_transforms( wavg,
                        w_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
                    bavgnew = bavgnew+ants.apply_transforms( wavg,
                        b_image_list[k] * bcsf[k], txname ).iMath(&#34;Normalize&#34;)
        if verbose:
            print(&#34;iteration:&#34;,str(i),str(txavg.abs().mean()))
        wscl = (-1.0) * gradient_step
        txavg = txavg * wscl
        ants.image_write( txavg, wavgfn )
        wavg = ants.apply_transforms(wavg, wavgnew, wavgfn).iMath(&#34;Normalize&#34;)
        bavg = ants.apply_transforms(bavg, bavgnew, wavgfn).iMath(&#34;Normalize&#34;)
    import shutil
    shutil.rmtree( output_directory, ignore_errors=True )
    if verbose:
        print(&#34;done&#34;)
    return bavg, wavg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dvars"><code class="name flex">
<span>def <span class="ident">dvars</span></span>(<span>x, mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>dvars on a time series image &hellip; the matrix is normalized to range of 0,1</p>
<p>x: image</p>
<p>mask : mask</p>
<p>indices: indices to use</p>
<p>returns an array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dvars( x,  mask, indices=None ):
    &#34;&#34;&#34;
    dvars on a time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    DVARS = np.zeros( M.shape[0] )
    for i in range(1, M.shape[0] ):
        vecdiff = M[i-1,:] - M[i,:]
        DVARS[i] = np.sqrt( ( vecdiff * vecdiff ).mean() )
    DVARS[0] = DVARS.mean()
    return DVARS</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_closest_peak_tracking"><code class="name flex">
<span>def <span class="ident">dwi_closest_peak_tracking</span></span>(<span>dwi, fa, bvals, bvecs, num_processes=1, mask=None, label_image=None, seed_labels=None, fa_thresh=0.05, seed_density=1, step_size=0.15, peak_indices=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs deterministic tractography from the DWI and returns a tractogram
and path length data frame.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding DWI acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa</code></strong> :&ensp;<code>an antsImage holding FA values</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>bvalues</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>bvectors</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>num_processes</code></strong> :&ensp;<code>number</code> of <code>subprocesses</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>mask within which to do tracking - if None, we will make a mask using the fa_thresh</code></dt>
<dd>and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath("GetLargestComponent")</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_labels</code></strong> :&ensp;<code>list</code> of <code>label numbers from the atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa_thresh</code></strong> :&ensp;<code>0.25 defaults</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_density</code></strong> :&ensp;<code>1 default number</code> of <code>seeds per voxel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>step_size</code></strong> :&ensp;<code>for tracking</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>peak_indices</code></strong> :&ensp;<code>pass these in, if they are previously estimated.
otherwise, will</code></dt>
<dd>compute on the fly (slow)</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding tracts and stateful object.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_closest_peak_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.core.gradients import gradient_table
    from dipy.data import small_sphere
    from dipy.direction import BootDirectionGetter, ClosestPeakDirectionGetter
    from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,
                                    auto_response_ssst)
    from dipy.reconst.shm import CsaOdfModel
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion

    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1)  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1


    response, ratio = auto_response_ssst(gtab, dwi_data, roi_radii=10, fa_thr=0.7)
    csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)
    csd_fit = csd_model.fit(dwi_data, mask=dwi_mask)
    csa_model = CsaOdfModel(gtab, sh_order=6)
    gfa = csa_model.fit(dwi_data, mask=dwi_mask).gfa
    stopping_criterion = ThresholdStoppingCriterion(gfa, .25)


    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)

    pmf = csd_fit.odf(small_sphere).clip(min=0)
    if verbose:
        print(&#34;ClosestPeakDirectionGetter begin ...&#34;, flush=True)
    peak_dg = ClosestPeakDirectionGetter.from_pmf(pmf, max_angle=30.,
                                                sphere=small_sphere)
    if verbose:
        print(&#34;local tracking begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(peak_dg, stopping_criterion, seeds,
                                            affine, step_size=.5)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines
          }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_deterministic_tracking"><code class="name flex">
<span>def <span class="ident">dwi_deterministic_tracking</span></span>(<span>dwi, fa, bvals, bvecs, num_processes=1, mask=None, label_image=None, seed_labels=None, fa_thresh=0.05, seed_density=1, step_size=0.15, peak_indices=None, fit_method='WLS', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs deterministic tractography from the DWI and returns a tractogram
and path length data frame.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding DWI acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa</code></strong> :&ensp;<code>an antsImage holding FA values</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>bvalues</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>bvectors</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>num_processes</code></strong> :&ensp;<code>number</code> of <code>subprocesses</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>mask within which to do tracking - if None, we will make a mask using the fa_thresh</code></dt>
<dd>and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath("GetLargestComponent")</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_labels</code></strong> :&ensp;<code>list</code> of <code>label numbers from the atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fa_thresh</code></strong> :&ensp;<code>0.25 defaults</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>seed_density</code></strong> :&ensp;<code>1 default number</code> of <code>seeds per voxel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>step_size</code></strong> :&ensp;<code>for tracking</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>peak_indices</code></strong> :&ensp;<code>pass these in, if they are previously estimated.
otherwise, will</code></dt>
<dd>compute on the fly (slow)</dd>
<dt><strong><code>fit_method</code></strong> :&ensp;<code>string one</code> of <code>WLS LS NLLS</code> or <code>restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding tracts and stateful object.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_deterministic_tracking(
    dwi,
    fa,
    bvals,
    bvecs,
    num_processes=1,
    mask=None,
    label_image = None,
    seed_labels = None,
    fa_thresh = 0.05,
    seed_density = 1,
    step_size = 0.15,
    peak_indices = None,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;

    Performs deterministic tractography from the DWI and returns a tractogram
    and path length data frame.

    Arguments
    ---------

    dwi : an antsImage holding DWI acquisition

    fa : an antsImage holding FA values

    bvals : bvalues

    bvecs : bvectors

    num_processes : number of subprocesses

    mask : mask within which to do tracking - if None, we will make a mask using the fa_thresh
        and the code ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)

    label_image : atlas labels

    seed_labels : list of label numbers from the atlas labels

    fa_thresh : 0.25 defaults

    seed_density : 1 default number of seeds per voxel

    step_size : for tracking

    peak_indices : pass these in, if they are previously estimated.  otherwise, will
        compute on the fly (slow)

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding tracts and stateful object.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    if verbose:
        print(&#34;begin tracking&#34;,flush=True)
    dwi_img = dwi.to_nibabel()
    affine = dwi_img.affine
    if isinstance( bvals, str ) or isinstance( bvecs, str ):
        bvals, bvecs = read_bvals_bvecs(bvals, bvecs)
    import numpy as np
    if abs(np.linalg.norm(bvecs)-1) &gt; 0.009 and False:
        bvecs=bvecs/np.linalg.norm(bvecs, axis=1 )  
    gtab = gradient_table(bvals, bvecs, atol=0.1 )
    if mask is None:
        mask = ants.threshold_image( fa, fa_thresh, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
    dwi_data = dwi_img.get_fdata()
    dwi_mask = mask.numpy() == 1
    dti_model = dti.TensorModel(gtab,fit_method=fit_method)
    if verbose:
        print(&#34;begin tracking fit&#34;,flush=True)
    dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while
    evecs_img = dti_fit.evecs
    from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion
    stopping_criterion = ThresholdStoppingCriterion(fa.numpy(), fa_thresh)
    from dipy.data import get_sphere
    sphere = get_sphere(&#39;symmetric362&#39;)
    from dipy.direction import peaks_from_model
    if peak_indices is None:
        # problems with multi-threading ...
        # see https://github.com/dipy/dipy/issues/2519
        if verbose:
            print(&#34;begin peaks&#34;,flush=True)
        mynump=1
        # if os.getenv(&#34;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#34;):
        #    mynump = os.environ[&#39;ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS&#39;]
        # current_openblas = os.environ.get(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
        # current_mkl = os.environ.get(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)
        # os.environ[&#39;DIPY_OPENBLAS_NUM_THREADS&#39;] = current_openblas
        # os.environ[&#39;DIPY_MKL_NUM_THREADS&#39;] = current_mkl
        # os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = &#39;1&#39;
        # os.environ[&#39;MKL_NUM_THREADS&#39;] = &#39;1&#39;
        peak_indices = peaks_from_model(
            model=dti_model,
            data=dwi_data,
            sphere=sphere,
            relative_peak_threshold=.5,
            min_separation_angle=25,
            mask=dwi_mask,
            npeaks=3, return_odf=False,
            return_sh=False,
            parallel=int(mynump) &gt; 1,
            num_processes=int(mynump)
            )
        if False:
            if &#39;DIPY_OPENBLAS_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;OPENBLAS_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;OPENBLAS_NUM_THREADS&#39;, &#39;&#39;)
            if &#39;DIPY_MKL_NUM_THREADS&#39; in os.environ:
                os.environ[&#39;MKL_NUM_THREADS&#39;] = \
                    os.environ.pop(&#39;DIPY_MKL_NUM_THREADS&#39;, &#39;&#39;)
                if os.environ[&#39;MKL_NUM_THREADS&#39;] in [&#39;&#39;, None]:
                    os.environ.pop(&#39;MKL_NUM_THREADS&#39;, &#39;&#39;)

    if label_image is None or seed_labels is None:
        seed_mask = fa.numpy().copy()
        seed_mask[seed_mask &gt;= fa_thresh] = 1
        seed_mask[seed_mask &lt; fa_thresh] = 0
    else:
        labels = label_image.numpy()
        seed_mask = labels * 0
        for u in seed_labels:
            seed_mask[ labels == u ] = 1
    seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=seed_density)
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    if verbose:
        print(&#34;streamlines begin ...&#34;, flush=True)
    streamlines_generator = LocalTracking(
        peak_indices, stopping_criterion, seeds, affine=affine, step_size=step_size)
    streamlines = Streamlines(streamlines_generator)
    from dipy.io.stateful_tractogram import Space, StatefulTractogram
    from dipy.io.streamline import save_tractogram
    sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
    if verbose:
        print(&#34;streamlines done&#34;, flush=True)
    return {
          &#39;tractogram&#39;: sft,
          &#39;streamlines&#39;: streamlines,
          &#39;peak_indices&#39;: peak_indices
          }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_streamline_connectivity"><code class="name flex">
<span>def <span class="ident">dwi_streamline_connectivity</span></span>(<span>streamlines, label_image, label_dataframe, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Summarize network connetivity of the input streamlines between all of the
regions in the label set.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>streamlines</code></strong> :&ensp;<code>streamline object from dipy</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_dataframe</code></strong> :&ensp;<code>pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dictionary holding summary connection statistics in wide format and matrix format.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_streamline_connectivity(
    streamlines,
    label_image,
    label_dataframe,
    verbose = False ):
    &#34;&#34;&#34;

    Summarize network connetivity of the input streamlines between all of the
    regions in the label set.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    label_dataframe : pandas dataframe containing descriptions for the labels in antspy style (Label,Description columns)

    verbose : boolean

    Returns
    -------
    dictionary holding summary connection statistics in wide format and matrix format.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    import os
    import re
    import nibabel as nib
    import numpy as np
    import ants
    from dipy.io.gradients import read_bvals_bvecs
    from dipy.core.gradients import gradient_table
    from dipy.tracking import utils
    import dipy.reconst.dti as dti
    from dipy.segment.clustering import QuickBundles
    from dipy.tracking.utils import path_length
    from dipy.tracking.local_tracking import LocalTracking
    from dipy.tracking.streamline import Streamlines
    volUnit = np.prod( ants.get_spacing( label_image ) )
    labels = label_image.numpy()
    affine = label_image.to_nibabel().affine
    import numpy as np
    from dipy.io.image import load_nifti_data, load_nifti, save_nifti
    import pandas as pd
    ulabs = label_dataframe[&#39;Label&#39;]
    labels_to_connect = ulabs[ulabs &gt; 0]
    Ctdf = None
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, not_label = None ):
        pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
        mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
        if not_label is None:
            if ( mylab == target_label ).sum() &gt; 0 :
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            if ( mylab == target_label ).sum() &gt; 0 and ( mylab == not_label ).sum() == 0:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    which = lambda lst:list(np.where(lst)[0])
    myCount = np.zeros( [len(ulabs),len(ulabs)])
    for k in range( len( streamlines ) ):
            sl = streamlines[k]
            mycheck = check_it( sl, labels_to_connect, label_image_np, index=0 )
            if mycheck[&#39;ok&#39;]:
                exclabel=mycheck[&#39;label&#39;]
                lsl = len( sl )-1
                mycheck2 = check_it( sl, labels_to_connect, label_image_np, index=lsl, not_label=exclabel )
                if mycheck2[&#39;ok&#39;]:
                    myCount[ulabs == mycheck[&#39;label&#39;],ulabs == mycheck2[&#39;label&#39;]]+=1
                    ct=ct+1
    Ctdf = label_dataframe.copy()
    for k in range(len(ulabs)):
            nn3 = &#34;CnxCount&#34;+str(k).zfill(3)
            Ctdf.insert(Ctdf.shape[1], nn3, myCount[k,:] )
    Ctdfw = antspyt1w.merge_hierarchical_csvs_to_wide_format( { &#39;networkc&#39;: Ctdf },  Ctdf.keys()[2:Ctdf.shape[1]] )
    return { &#39;connectivity_matrix&#39; :  myCount, &#39;connectivity_wide&#39; : Ctdfw }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.dwi_streamline_pairwise_connectivity"><code class="name flex">
<span>def <span class="ident">dwi_streamline_pairwise_connectivity</span></span>(<span>streamlines, label_image, labels_to_connect=[1, None], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return streamlines connecting all of the regions in the label set. Ideal
for just 2 regions.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>streamlines</code></strong> :&ensp;<code>streamline object from dipy</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label_image</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>labels_to_connect</code></strong> :&ensp;<code>list</code> of <code>2 labels</code> or <code>[label,None]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>the subset</code> of <code>streamlines and a streamline count</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dwi_streamline_pairwise_connectivity( streamlines, label_image, labels_to_connect=[1,None], verbose=False ):
    &#34;&#34;&#34;

    Return streamlines connecting all of the regions in the label set. Ideal
    for just 2 regions.

    Arguments
    ---------

    streamlines : streamline object from dipy

    label_image : atlas labels

    labels_to_connect : list of 2 labels or [label,None]

    verbose : boolean

    Returns
    -------
    the subset of streamlines and a streamline count

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    from dipy.tracking.streamline import Streamlines
    keep_streamlines = Streamlines()
    affine = label_image.to_nibabel().affine
    lin_T, offset = utils._mapping_to_voxel(affine)
    label_image_np = label_image.numpy()
    def check_it( sl, target_label, label_image, index, full=False ):
        if full:
            maxind=sl.shape[0]
            for index in range(maxind):
                pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
                mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
                if mylab == target_label[0] or mylab == target_label[1]:
                    return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        else:
            pt = utils._to_voxel_coordinates(sl[index,:], lin_T, offset)
            mylab = (label_image[ pt[0], pt[1], pt[2] ]).astype(int)
            if mylab == target_label[0] or mylab == target_label[1]:
                return { &#39;ok&#39;: True, &#39;label&#39;:mylab }
        return { &#39;ok&#39;: False, &#39;label&#39;:None }
    ct=0
    for k in range( len( streamlines ) ):
        sl = streamlines[k]
        mycheck = check_it( sl, labels_to_connect, label_image_np, index=0, full=True )
        if mycheck[&#39;ok&#39;]:
            otherind=1
            if mycheck[&#39;label&#39;] == labels_to_connect[1]:
                otherind=0
            lsl = len( sl )-1
            pt = utils._to_voxel_coordinates(sl[lsl,:], lin_T, offset)
            mylab_end = (label_image_np[ pt[0], pt[1], pt[2] ]).astype(int)
            accept_point = mylab_end == labels_to_connect[otherind]
            if verbose and accept_point:
                print( mylab_end )
            if labels_to_connect[1] is None:
                accept_point = mylab_end != 0
            if accept_point:
                keep_streamlines.append(sl)
                ct=ct+1
    return { &#39;streamlines&#39;: keep_streamlines, &#39;count&#39;: ct }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.foreground_background_snr"><code class="name flex">
<span>def <span class="ident">foreground_background_snr</span></span>(<span>x, background_dilation=10, erode_foreground=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_dilation</code></strong> :&ensp;<code>integer - amount to dilate foreground mask</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>erode_foreground</code></strong> :&ensp;<code>boolean - 2nd option which erodes the initial</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>foregound mask
to create a new foreground mask.
the background
mask is the initial mask minus the eroded mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def foreground_background_snr( x, background_dilation=10,
        erode_foreground=False):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    erode_foreground : boolean - 2nd option which erodes the initial
    foregound mask  to create a new foreground mask.  the background
    mask is the initial mask minus the eroded mask.

    &#34;&#34;&#34;
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xmask = ants.threshold_image( xbc, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmask, &#34;MD&#34;, background_dilation ) - xmask
    fgmask = xmask
    if erode_foreground:
        fgmask = ants.iMath( xmask, &#34;ME&#34;, background_dilation )
        xbkgmask = xmask - fgmask
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.generate_mm_dataframe"><code class="name flex">
<span>def <span class="ident">generate_mm_dataframe</span></span>(<span>projectID, subjectID, date, imageUniqueID, modality, source_image_directory, output_image_directory, t1_filename, flair_filename=[], rsf_filenames=[], dti_filenames=[], nm_filenames=[])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_mm_dataframe(
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename=[],
        rsf_filenames=[],
        dti_filenames=[],
        nm_filenames=[]
):
    from os.path import exists
    valid_modalities = get_valid_modalities()
    if not isinstance(t1_filename, str):
        raise ValueError(&#34;t1_filename is not a string&#34;)
    if not exists(t1_filename):
        raise ValueError(&#34;t1_filename does not exist&#34;)
    if modality not in valid_modalities:
        raise ValueError(&#39;modality &#39; + str(modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))
    # if not exists( output_image_directory ):
    #    raise ValueError(&#34;output_image_directory does not exist&#34;)
    if not exists( source_image_directory ):
        raise ValueError(&#34;source_image_directory does not exist&#34;)
    if len( rsf_filenames ) &lt; 2:
        for k in range(len(rsf_filenames),2):
            rsf_filenames.append(None)
    if len( dti_filenames ) &lt; 2:
        for k in range(len(dti_filenames),2):
            dti_filenames.append(None)
    if len( nm_filenames ) &lt; 10:
        for k in range(len(nm_filenames),10):
            nm_filenames.append(None)
    # check modality names
    if not &#34;T1w&#34; in t1_filename:
        raise ValueError(&#34;T1w is not in t1 filename &#34; + t1_filename)
    if flair_filename is not None:
        if isinstance(flair_filename,list):
            if (len(flair_filename) == 0):
                flair_filename=None
            else:
                print(&#34;Take first entry from flair_filename list&#34;)
                flair_filename=flair_filename[0]
    if flair_filename is not None and not &#34;lair&#34; in flair_filename:
            raise ValueError(&#34;flair is not flair filename &#34; + flair_filename)
    for k in nm_filenames:
        if k is not None:
            if not &#34;NM&#34; in k:
                raise ValueError(&#34;NM is not flair filename &#34; + k)
    for k in dti_filenames:
        if k is not None:
            if not &#34;DTI&#34; in k and not &#34;dwi&#34; in k:
                raise ValueError(&#34;DTI/DWI is not dti filename &#34; + k)
    for k in rsf_filenames:
        if k is not None:
            if not &#34;fMRI&#34; in k and not &#34;func&#34; in k:
                raise ValueError(&#34;rsfMRI/func is not rsfmri filename &#34; + k)
    allfns = [t1_filename] + [flair_filename] + nm_filenames + dti_filenames + rsf_filenames
    for k in allfns:
        if k is not None:
            if not isinstance(k, str):
                raise ValueError(str(k) + &#34; is not a string&#34;)
            if not exists( k ):
                raise ValueError( &#34;image &#34; + k + &#34; does not exist&#34;)
    coredata = [
        projectID,
        subjectID,
        date,
        imageUniqueID,
        modality,
        source_image_directory,
        output_image_directory,
        t1_filename,
        flair_filename]
    mydata0 = coredata +  rsf_filenames + dti_filenames
    mydata = mydata0 + nm_filenames
    corecols = [
        &#39;projectID&#39;,
        &#39;subjectID&#39;,
        &#39;date&#39;,
        &#39;imageID&#39;,
        &#39;modality&#39;,
        &#39;sourcedir&#39;,
        &#39;outputdir&#39;,
        &#39;filename&#39;,
        &#39;flairid&#39;]
    mycols0 = corecols + [
        &#39;rsfid1&#39;, &#39;rsfid2&#39;,
        &#39;dtid1&#39;, &#39;dtid2&#39;]
    nmext = [
        &#39;nmid1&#39;, &#39;nmid2&#39; &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;,
        &#39;nmid6&#39;, &#39;nmid7&#39;,&#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39;, &#39;nmid11&#39;
    ]
    mycols = mycols0 + nmext
    print(len(mydata0))
    print(len(nm_filenames))
    print(len(mycols0))
    print(len(nmext))
    studycsv = pd.DataFrame([ mydata ],
        columns=mycols)
    return studycsv</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_average_dwi_b0"><code class="name flex">
<span>def <span class="ident">get_average_dwi_b0</span></span>(<span>x, fixed_b0=None, fixed_dwi=None, fast=False)</span>
</code></dt>
<dd>
<div class="desc"><p>automatically generates the average b0 and dwi and outputs both;
maps dwi to b0 space at end.</p>
<p>x : input image</p>
<p>fixed_b0 : alernative reference space</p>
<p>fixed_dwi : alernative reference space</p>
<p>fast : boolean</p>
<p>returns:
avg_b0, avg_dwi</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_dwi_b0( x, fixed_b0=None, fixed_dwi=None, fast=False ):
    &#34;&#34;&#34;
    automatically generates the average b0 and dwi and outputs both;
    maps dwi to b0 space at end.

    x : input image

    fixed_b0 : alernative reference space

    fixed_dwi : alernative reference space

    fast : boolean

    returns:
        avg_b0, avg_dwi
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    temp = segment_timeseries_by_meanvalue( x )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]
    if ( fixed_b0 is None and fixed_dwi is None ) or fast:
        xavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
        fixed_b0_use = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        fixed_dwi_use = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
    else:
        temp_b0 = ants.slice_image( x, axis=3, idx=b0_idx[0] )
        temp_dwi = ants.slice_image( x, axis=3, idx=non_b0_idx[0] )
        xavg = fixed_b0 * 0.0
        bavg = fixed_b0 * 0.0
        tempreg = ants.registration( fixed_b0, temp_b0,&#39;BOLDRigid&#39;)
        fixed_b0_use = tempreg[&#39;warpedmovout&#39;]
        fixed_dwi_use = ants.apply_transforms( fixed_b0, temp_dwi, tempreg[&#39;fwdtransforms&#39;] )
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        if not fast:
            if not myidx in b0_idx:
                xavg = xavg + ants.registration(fixed_dwi_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
            else:
                bavg = bavg + ants.registration(fixed_b0_use,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
        else:
            if not myidx in b0_idx:
                xavg = xavg + b0
            else:
                bavg = bavg + b0
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    xavg = ants.iMath( xavg, &#39;Normalize&#39; )
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    avgb0=ants.n4_bias_field_correction(bavg)
    avgdwi=ants.n4_bias_field_correction(xavg)
    avgdwi=ants.registration( avgb0, avgdwi, &#39;Rigid&#39; )[&#39;warpedmovout&#39;]
    return avgb0, avgdwi</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_average_rsf"><code class="name flex">
<span>def <span class="ident">get_average_rsf</span></span>(<span>x, min_t=10, max_t=35)</span>
</code></dt>
<dd>
<div class="desc"><p>automatically generates the average bold image with quick registration</p>
<p>returns:
avg_bold</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_rsf( x, min_t=10, max_t=35 ):
    &#34;&#34;&#34;
    automatically generates the average bold image with quick registration

    returns:
        avg_bold
    &#34;&#34;&#34;
    output_directory = tempfile.mkdtemp()
    ofn = output_directory + &#34;/w&#34;
    bavg = ants.slice_image( x, axis=3, idx=0 ) * 0.0
    oavg = ants.slice_image( x, axis=3, idx=0 )
    if x.shape[3] &lt;= min_t:
        min_t=0
    if x.shape[3] &lt;= max_t:
        max_t=x.shape[3]-1
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    bavg = ants.iMath( bavg, &#39;Normalize&#39; )
    oavg = ants.image_clone( bavg )
    bavg = oavg * 0.0
    for myidx in range(min_t,max_t):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        bavg = bavg + ants.registration(oavg,b0,&#39;Rigid&#39;,outprefix=ofn)[&#39;warpedmovout&#39;]
    import shutil
    shutil.rmtree(output_directory, ignore_errors=True )
    return ants.n4_bias_field_correction(bavg)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>name=None, force_download=False, version=11, target_extension='.csv')</span>
</code></dt>
<dd>
<div class="desc"><p>Get ANTsPyMM data filename</p>
<p>The first time this is called, it will download data to ~/.antspymm.
After, it will just read data from disk.
The ~/.antspymm may need to
be periodically deleted in order to ensure data is current.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>name of data tag to retrieve
Options:
- 'all'</dd>
<dt><strong><code>force_download</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>version</code></strong> :&ensp;<code><a title="antspymm.mm.version" href="#antspymm.mm.version">version()</a></code> of <code>data to download (integer)</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>filepath of selected data</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
&gt;&gt;&gt; antspymm.get_data()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data( name=None, force_download=False, version=11, target_extension=&#39;.csv&#39; ):
    &#34;&#34;&#34;
    Get ANTsPyMM data filename

    The first time this is called, it will download data to ~/.antspymm.
    After, it will just read data from disk.  The ~/.antspymm may need to
    be periodically deleted in order to ensure data is current.

    Arguments
    ---------
    name : string
        name of data tag to retrieve
        Options:
            - &#39;all&#39;

    force_download: boolean

    version: version of data to download (integer)

    Returns
    -------
    string
        filepath of selected data

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.get_data()
    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/16912366/versions/&#34; + str(version)
        target_file_name = &#34;16912366.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )


    files = []
    for fname in os.listdir(DATA_PATH):
        if ( fname.endswith(target_extension) ) :
            fname = os.path.join(DATA_PATH, fname)
            files.append(fname)

    if len( files ) == 0 :
        download_data( version = version )
        for fname in os.listdir(DATA_PATH):
            if ( fname.endswith(target_extension) ) :
                fname = os.path.join(DATA_PATH, fname)
                files.append(fname)

    if name == &#39;all&#39;:
        return files

    datapath = None

    for fname in os.listdir(DATA_PATH):
        mystem = (Path(fname).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        mystem = (Path(mystem).resolve().stem)
        if ( name == mystem and fname.endswith(target_extension) ) :
            datapath = os.path.join(DATA_PATH, fname)

    return datapath</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_models"><code class="name flex">
<span>def <span class="ident">get_models</span></span>(<span>version=3, force_download=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Get ANTsPyMM data models</p>
<p>force_download: boolean</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_models( version=3, force_download=True ):
    &#34;&#34;&#34;
    Get ANTsPyMM data models

    force_download: boolean

    Returns
    -------
    None

    &#34;&#34;&#34;
    os.makedirs(DATA_PATH, exist_ok=True)

    def download_data( version ):
        url = &#34;https://figshare.com/ndownloader/articles/21718412/versions/&#34;+str(version)
        target_file_name = &#34;21718412.zip&#34;
        target_file_name_path = tf.keras.utils.get_file(target_file_name, url,
            cache_subdir=DATA_PATH, extract = True )
        os.remove( DATA_PATH + target_file_name )

    if force_download:
        download_data( version = version )
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_names_from_data_frame"><code class="name flex">
<span>def <span class="ident">get_names_from_data_frame</span></span>(<span>x, demogIn, exclusions=None)</span>
</code></dt>
<dd>
<div class="desc"><p>data = {'Name':['Tom', 'nick', 'krish', 'jack'], 'Age':[20, 21, 19, 18]}
antspymm.get_names_from_data_frame( ['e'], df )
antspymm.get_names_from_data_frame( ['a','e'], df )
antspymm.get_names_from_data_frame( ['e'], df, exclusions='N' )</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_names_from_data_frame(x, demogIn, exclusions=None):
    &#34;&#34;&#34;
    data = {&#39;Name&#39;:[&#39;Tom&#39;, &#39;nick&#39;, &#39;krish&#39;, &#39;jack&#39;], &#39;Age&#39;:[20, 21, 19, 18]}
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;a&#39;,&#39;e&#39;], df )
    antspymm.get_names_from_data_frame( [&#39;e&#39;], df, exclusions=&#39;N&#39; )
    &#34;&#34;&#34;
    def get_unique( qq ):
        unique = []
        for number in qq:
            if number in unique:
                continue
            else:
                unique.append(number)
        return unique
    outnames = list(demogIn.columns[demogIn.columns.str.contains(x[0])])
    if len(x) &gt; 1:
        for y in x[1:]:
            outnames = [i for i in outnames if y in i]
    outnames = get_unique( outnames )
    if exclusions is not None:
        toexclude = [name for name in outnames if exclusions[0] in name ]
        if len(exclusions) &gt; 1:
            for zz in exclusions[1:]:
                toexclude.extend([name for name in outnames if zz in name ])
        if len(toexclude) &gt; 0:
            outnames = [name for name in outnames if name not in toexclude]
    return outnames</code></pre>
</details>
</dd>
<dt id="antspymm.mm.get_valid_modalities"><code class="name flex">
<span>def <span class="ident">get_valid_modalities</span></span>(<span>long=False, asString=False, qc=False)</span>
</code></dt>
<dd>
<div class="desc"><p>return a list of valid modality identifiers used in NRG modality designation
and that can be processed by this package.</p>
<p>long - return the long version</p>
<p>asString - concat list to string</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_valid_modalities( long=False, asString=False, qc=False ):
    &#34;&#34;&#34;
    return a list of valid modality identifiers used in NRG modality designation
    and that can be processed by this package.

    long - return the long version

    asString - concat list to string
    &#34;&#34;&#34;
    if long:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;, &#34;rsfMRI_LR&#34;, &#34;rsfMRI_RL&#34;, &#34;DTI&#34;, &#34;DTI_LR&#34;,&#34;DTI_RL&#34;,&#34;T2Flair&#34;, &#34;dwi&#34;, &#34;func&#34; ]
    elif qc:
        mymod = [ &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;,&#39;DTIdwi&#39;,&#39;DTIb0&#39;]
    else:
        mymod = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;DTI&#34;,&#34;T2Flair&#34; ]
    if not asString:
        return mymod
    else:
        mymodchar=&#34;&#34;
        for x in mymod:
            mymodchar = mymodchar + &#34; &#34; + str(x)
        return mymodchar</code></pre>
</details>
</dd>
<dt id="antspymm.mm.hierarchical_modality_summary"><code class="name flex">
<span>def <span class="ident">hierarchical_modality_summary</span></span>(<span>target_image, hier, transformlist, modality_name, return_keys=['Mean', 'Volume'], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Use output of antspyt1w.hierarchical to summarize a modality</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>target_image</code></strong> :&ensp;<code>the image to summarize - should be brain extracted</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>hier</code></strong> :&ensp;<code>dictionary holding antspyt1w.hierarchical output</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>transformlist</code></strong> :&ensp;<code>spatial transformations mapping from T1 to this modality (e.g. from ants.registration)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>modality_name</code></strong> :&ensp;<code>adds the modality name to the data frame columns</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>return_keys = ["Mean","Volume"] keys to return</p>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data frame holding summary statistics in wide format</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hierarchical_modality_summary(
    target_image,
    hier,
    transformlist,
    modality_name,
    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;],
    verbose = False ):
    &#34;&#34;&#34;

    Use output of antspyt1w.hierarchical to summarize a modality

    Arguments
    ---------

    target_image : the image to summarize - should be brain extracted

    hier : dictionary holding antspyt1w.hierarchical output

    transformlist : spatial transformations mapping from T1 to this modality (e.g. from ants.registration)

    modality_name : adds the modality name to the data frame columns

    return_keys = [&#34;Mean&#34;,&#34;Volume&#34;] keys to return

    verbose : boolean

    Returns
    -------
    data frame holding summary statistics in wide format

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    dfout = pd.DataFrame()
    def myhelper( target_image, seg, mytx, mapname, modname, mydf, extra=&#39;&#39;, verbose=False ):
        if verbose:
            print( mapname )
        target_image_mask = ants.image_clone( target_image ) * 0.0
        target_image_mask[ target_image != 0 ] = 1
        cortmapped = ants.apply_transforms(
            target_image,
            seg,
            mytx, interpolator=&#39;nearestNeighbor&#39; ) * target_image_mask
        mapped = antspyt1w.map_intensity_to_dataframe(
            mapname,
            target_image,
            cortmapped )
        mapped.iloc[:,1] = modname + &#39;_&#39; + extra + mapped.iloc[:,1]
        mappedw = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            { &#39;x&#39; : mapped},
            col_names = return_keys )
        if verbose:
            print( mappedw.keys() )
        if mydf.shape[0] &gt; 0:
            mydf = pd.concat( [ mydf, mappedw], axis=1 )
        else:
            mydf = mappedw
        return mydf
    if hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], transformlist,
            &#34;dkt&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose )
    if hier[&#39;deep_cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;deep_cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;deep_&#39;, verbose=verbose )
    if hier[&#39;cit168lab&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;cit168lab&#39;], transformlist,
            &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    if hier[&#39;bf&#39;] is not None:
        dfout = myhelper( target_image, hier[&#39;bf&#39;], transformlist,
            &#34;nbm3CH13&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    # if hier[&#39;mtl&#39;] is not None:
    #    dfout = myhelper( target_image, hier[&#39;mtl&#39;], reg,
    #        &#34;mtl_description&#34;, modality_name, dfout, extra=&#39;&#39;, verbose=verbose  )
    return dfout</code></pre>
</details>
</dd>
<dt id="antspymm.mm.highest_quality_repeat"><code class="name flex">
<span>def <span class="ident">highest_quality_repeat</span></span>(<span>mxdfin, idvar, visitvar, qualityvar)</span>
</code></dt>
<dd>
<div class="desc"><p>This function returns a subset of the input dataframe that retains only the rows
that correspond to the highest quality observation for each combination of ID and visit.</p>
<h2 id="parameters">Parameters:</h2>
<p>mxdfin: pandas.DataFrame
The input dataframe.
idvar: str
The name of the column that contains the ID variable.
visitvar: str
The name of the column that contains the visit variable.
qualityvar: str
The name of the column that contains the quality variable.</p>
<h2 id="returns">Returns:</h2>
<p>pandas.DataFrame
A subset of the input dataframe that retains only the rows that correspond
to the highest quality observation for each combination of ID and visit.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def highest_quality_repeat(mxdfin, idvar, visitvar, qualityvar):
    &#34;&#34;&#34;
    This function returns a subset of the input dataframe that retains only the rows
    that correspond to the highest quality observation for each combination of ID and visit.

    Parameters:
    ----------
    mxdfin: pandas.DataFrame
        The input dataframe.
    idvar: str
        The name of the column that contains the ID variable.
    visitvar: str
        The name of the column that contains the visit variable.
    qualityvar: str
        The name of the column that contains the quality variable.

    Returns:
    -------
    pandas.DataFrame
        A subset of the input dataframe that retains only the rows that correspond
        to the highest quality observation for each combination of ID and visit.
    &#34;&#34;&#34;
    if visitvar not in mxdfin.columns:
        raise ValueError(&#34;visitvar not in dataframe&#34;)
    if idvar not in mxdfin.columns:
        raise ValueError(&#34;idvar not in dataframe&#34;)
    if qualityvar not in mxdfin.columns:
        raise ValueError(&#34;qualityvar not in dataframe&#34;)

    vizzes = mxdfin[visitvar].unique()
    uids = mxdfin[idvar].unique()
    useit = np.zeros(mxdfin.shape[0], dtype=bool)

    for u in uids:
        losel = mxdfin[idvar] == u
        vizzesloc = mxdfin[losel][visitvar].unique()

        for v in vizzesloc:
            losel = (mxdfin[idvar] == u) &amp; (mxdfin[visitvar] == v)
            mysnr = mxdfin.loc[losel, qualityvar]
            myw = np.where(losel)[0]

            if len(myw) &gt; 1:
                if any(~np.isnan(mysnr)):
                    useit[myw[np.argmax(mysnr)]] = True
                else:
                    useit[myw] = True
            else:
                useit[myw] = True

    return mxdfin[useit]</code></pre>
</details>
</dd>
<dt id="antspymm.mm.image_write_with_thumbnail"><code class="name flex">
<span>def <span class="ident">image_write_with_thumbnail</span></span>(<span>x, fn, y=None, thumb=True)</span>
</code></dt>
<dd>
<div class="desc"><p>will write the image and (optionally) a png thumbnail with (optional) overlay/underlay</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_write_with_thumbnail( x,  fn, y=None, thumb=True ):
    &#34;&#34;&#34;
    will write the image and (optionally) a png thumbnail with (optional) overlay/underlay
    &#34;&#34;&#34;
    ants.image_write( x, fn )
    if not thumb or x.components &gt; 1:
        return
    thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_3dthumb.png&#34;,fn)
    if thumb and x.dimension == 3:
        if y is None:
            try:
                ants.plot_ortho( x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            try:
                ants.plot_ortho( y, x, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
    if thumb and x.dimension == 4:
        thumb_fn=re.sub(&#34;.nii.gz&#34;,&#34;_4dthumb.png&#34;,fn)
        nslices = x.shape[3]
        sl = np.round( nslices * 0.5 )
        if sl &gt; nslices:
            sl = nslices-1
        xview = ants.slice_image( x, axis=3, idx=int(sl) )
        if y is None:
            try:
                ants.plot_ortho( xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
            except:
                pass
        else:
            if y.dimension == 3:
                try:
                    ants.plot_ortho(y, xview, crop=True, filename=thumb_fn, flat=True, xyz_lines=False, orient_labels=False, xyz_pad=0 )
                except:
                    pass
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.impute_fa"><code class="name flex">
<span>def <span class="ident">impute_fa</span></span>(<span>fa, md)</span>
</code></dt>
<dd>
<div class="desc"><p>impute bad values in dti, fa, md</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def impute_fa( fa, md ):
    &#34;&#34;&#34;
    impute bad values in dti, fa, md
    &#34;&#34;&#34;
    def imputeit( x, fa ):
        badfa=ants.threshold_image(fa,1,1)
        if badfa.max() == 1:
            temp=ants.image_clone(x)
            temp[badfa==1]=0
            temp=ants.iMath(temp,&#39;GD&#39;,2)
            x[ badfa==1 ]=temp[badfa==1]
        return x
    md=imputeit( md, fa )
    fa=imputeit( ants.image_clone(fa), fa )
    return fa, md</code></pre>
</details>
</dd>
<dt id="antspymm.mm.joint_dti_recon"><code class="name flex">
<span>def <span class="ident">joint_dti_recon</span></span>(<span>img_LR, bval_LR, bvec_LR, jhu_atlas, jhu_labels, reference_B0, reference_DWI, srmodel=None, img_RL=None, bval_RL=None, bvec_RL=None, t1w=None, brain_mask=None, motion_correct=None, dewarp_modality='FA', denoise=False, fit_method='WLS', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>pass in subject data and 1mm JHU atlas/labels</li>
<li>perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)</li>
<li>dewarp the images using dewarp_modality or T1w</li>
<li>apply dewarping to the original data
===&gt; may want to apply SR at this step</li>
<li>reconstruct DTI again</li>
<li>label images and do registration</li>
<li>return relevant outputs</li>
</ol>
<p>NOTE: RL images are optional; should pass t1w in this case.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>img_LR</code></strong> :&ensp;<code>an antsImage holding B0 and DWI LR acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bval_LR</code></strong> :&ensp;<code>bvalue filename LR</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvec_LR</code></strong> :&ensp;<code>bvector filename LR</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>jhu_atlas</code></strong> :&ensp;<code>atlas FA image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>jhu_labels</code></strong> :&ensp;<code>atlas labels</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>reference_B0</code></strong> :&ensp;<code>the "target" B0 image space</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>reference_DWI</code></strong> :&ensp;<code>the "target" DW image space</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>optional h5 (tensorflow) model</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>img_RL</code></strong> :&ensp;<code>an antsImage holding B0 and DWI RL acquisition</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bval_RL</code></strong> :&ensp;<code>bvalue filename RL</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvec_RL</code></strong> :&ensp;<code>bvector filename RL</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1w</code></strong> :&ensp;<code>antsimage t1w neuroimage (brain-extracted)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>brain_mask</code></strong> :&ensp;<code>mask for the DWI - just 3D</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>motion_correct</code></strong> :&ensp;<code>None Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dewarp_modality</code></strong> :&ensp;<code>string average_dwi, average_b0, MD</code> or <code>FA</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fit_method</code></strong> :&ensp;<code>string one</code> of <code>WLS LS NLLS</code> or <code>restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the mean_fa, its summary statistics via JHU labels,</code></dt>
<dd>the JHU registration, the JHU labels, the dewarping dictionary and the
dti reconstruction dictionaries.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def joint_dti_recon(
    img_LR,
    bval_LR,
    bvec_LR,
    jhu_atlas,
    jhu_labels,
    reference_B0,
    reference_DWI,
    srmodel = None,
    img_RL = None,
    bval_RL = None,
    bvec_RL = None,
    t1w = None,
    brain_mask = None,
    motion_correct = None,
    dewarp_modality = &#39;FA&#39;,
    denoise=False,
    fit_method=&#39;WLS&#39;,
    verbose = False ):
    &#34;&#34;&#34;
    1. pass in subject data and 1mm JHU atlas/labels
    2. perform initial LR, RL reconstruction (2nd is optional) and motion correction (optional)
    3. dewarp the images using dewarp_modality or T1w
    4. apply dewarping to the original data
        ===&gt; may want to apply SR at this step
    5. reconstruct DTI again
    6. label images and do registration
    7. return relevant outputs

    NOTE: RL images are optional; should pass t1w in this case.

    Arguments
    ---------

    img_LR : an antsImage holding B0 and DWI LR acquisition

    bval_LR : bvalue filename LR

    bvec_LR : bvector filename LR

    jhu_atlas : atlas FA image

    jhu_labels : atlas labels

    reference_B0 : the &#34;target&#34; B0 image space

    reference_DWI : the &#34;target&#34; DW image space

    srmodel : optional h5 (tensorflow) model

    img_RL : an antsImage holding B0 and DWI RL acquisition

    bval_RL : bvalue filename RL

    bvec_RL : bvector filename RL

    t1w : antsimage t1w neuroimage (brain-extracted)

    brain_mask : mask for the DWI - just 3D

    motion_correct : None Rigid or SyN

    dewarp_modality : string average_dwi, average_b0, MD or FA

    denoise: boolean

    fit_method : string one of WLS LS NLLS or restore - see import dipy.reconst.dti as dti and help(dti.TensorModel)

    verbose : boolean

    Returns
    -------
    dictionary holding the mean_fa, its summary statistics via JHU labels,
        the JHU registration, the JHU labels, the dewarping dictionary and the
        dti reconstruction dictionaries.

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;

    if verbose:
        print(&#34;Recon DTI on OR images ...&#34;)

    def fix_dwi_shape( img, bvalfn, bvecfn ):
        if isinstance(bvecfn, str):
            bvals, bvecs = read_bvals_bvecs( bvalfn , bvecfn   )
        if bvecs.shape[0] &lt; img.shape[3]:
            imgout = ants.from_numpy( img[:,:,:,0:bvecs.shape[0]] )
            imgout = ants.copy_image_info( img, imgout )
            return( imgout )
        else:
            return( img )

    img_LR = fix_dwi_shape( img_LR, bval_LR, bvec_LR )
    if denoise :
        img_LR = mc_denoise( img_LR )
    if img_RL is not None:
        img_RL = fix_dwi_shape( img_RL, bval_RL, bvec_RL )
        if denoise :
            img_RL = mc_denoise( img_RL )

    if brain_mask is not None:
        maskInRightSpace = ants.image_physical_space_consistency( brain_mask, reference_B0 )
        if not maskInRightSpace :
            raise ValueError(&#39;not maskInRightSpace ... provided brain mask should be in reference_B0 space&#39;)

    if img_RL is not None :
        if verbose:
            print(&#34;img_RL correction&#34;)
        reg_RL = dti_reg(
            img_RL,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_RL,
            bvecs=bvec_RL,
            type_of_transform=motion_correct,
            verbose=True )
    else:
        reg_RL=None


    if verbose:
        print(&#34;img_LR correction&#34;)
    reg_LR = dti_reg(
            img_LR,
            avg_b0=reference_B0,
            avg_dwi=reference_DWI,
            bvals=bval_LR,
            bvecs=bvec_LR,
            type_of_transform=motion_correct,
            verbose=True )

    ts_LR_avg = None
    ts_RL_avg = None
    reg_its = [100,50,10]
    img_LRdwp = ants.image_clone( reg_LR[ &#39;motion_corrected&#39; ] )
    if img_RL is not None:
        img_RLdwp = ants.image_clone( reg_RL[ &#39;motion_corrected&#39; ] )
        if srmodel is not None:
            if verbose:
                print(&#34;convert img_RL_dwp to img_RL_dwp_SR&#34;)
            img_RLdwp = super_res_mcimage( img_RLdwp, srmodel, isotropic=True,
                        verbose=verbose )
    if srmodel is not None:
        reg_its = [100] + reg_its
        if verbose:
            print(&#34;convert img_LR_dwp to img_LR_dwp_SR&#34;)
        img_LRdwp = super_res_mcimage( img_LRdwp, srmodel, isotropic=True,
                verbose=verbose )
    if verbose:
        print(&#34;recon after distortion correction&#34;, flush=True)

    if img_RL is not None:
        img_LRdwp, bval_LR, bvec_LR = merge_dwi_data(
            img_LRdwp, reg_LR[&#39;bvals&#39;], reg_LR[&#39;bvecs&#39;],
            img_RLdwp, reg_RL[&#39;bvals&#39;], reg_RL[&#39;bvecs&#39;]
        )
    else:
        bval_LR=reg_LR[&#39;bvals&#39;]
        bvec_LR=reg_LR[&#39;bvecs&#39;]

    if verbose:
        print(&#34;final recon&#34;, flush=True)
        print(img_LRdwp)
    recon_LR_dewarp = dipy_dti_recon(
            img_LRdwp, bval_LR, bvec_LR,
            mask = brain_mask,
            fit_method=fit_method,
            mask_dilation=0, verbose=True )
    if verbose:
        print(&#34;recon done&#34;, flush=True)

    if img_RL is not None:
        fdjoin = [ reg_LR[&#39;FD&#39;],
                   reg_RL[&#39;FD&#39;] ]
        framewise_displacement=np.concatenate( fdjoin )
    else:
        framewise_displacement=reg_LR[&#39;FD&#39;]

    motion_count = ( framewise_displacement &gt; 1.5  ).sum()
    reconFA = recon_LR_dewarp[&#39;FA&#39;]
    reconMD = recon_LR_dewarp[&#39;MD&#39;]

    if verbose:
        print(&#34;JHU reg&#34;,flush=True)

    OR_FA2JHUreg = ants.registration( reconFA, jhu_atlas,
        type_of_transform = &#39;SyN&#39;, syn_metric=&#39;CC&#39;, syn_sampling=2,
        reg_iterations=reg_its, verbose=False )
    OR_FA_jhulabels = ants.apply_transforms( reconFA, jhu_labels,
        OR_FA2JHUreg[&#39;fwdtransforms&#39;], interpolator=&#39;genericLabel&#39;)

    df_FA_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;FA_JHU_labels_edited&#39;,
        reconFA,
        OR_FA_jhulabels)
    df_FA_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_FA_JHU_ORRL&#39; : df_FA_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    df_MD_JHU_ORRL = antspyt1w.map_intensity_to_dataframe(
        &#39;MD_JHU_labels_edited&#39;,
        reconMD,
        OR_FA_jhulabels)
    df_MD_JHU_ORRL_bfwide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
            {&#39;df_MD_JHU_ORRL&#39; : df_MD_JHU_ORRL},
            col_names = [&#39;Mean&#39;] )

    temp = segment_timeseries_by_meanvalue( img_LRdwp )
    b0_idx = temp[&#39;highermeans&#39;]
    non_b0_idx = temp[&#39;lowermeans&#39;]

    nonbrainmask = ants.iMath( recon_LR_dewarp[&#39;dwi_mask&#39;], &#34;MD&#34;,2) - recon_LR_dewarp[&#39;dwi_mask&#39;]
    fgmask = ants.threshold_image( reconFA, 0.5 , 1.0).iMath(&#34;GetLargestComponent&#34;)
    bgmask = ants.threshold_image( reconFA, 1e-4 , 0.1)
    fa_SNR = 0.0
    fa_SNR = mask_snr( reconFA, bgmask, fgmask, bias_correct=False )
    fa_evr = antspyt1w.patch_eigenvalue_ratio( reconFA, 512, [16,16,16], evdepth = 0.9, mask=recon_LR_dewarp[&#39;dwi_mask&#39;] )

    return {
        &#39;recon_fa&#39;:reconFA,
        &#39;recon_fa_summary&#39;:df_FA_JHU_ORRL_bfwide,
        &#39;recon_md&#39;:reconMD,
        &#39;recon_md_summary&#39;:df_MD_JHU_ORRL_bfwide,
        &#39;jhu_labels&#39;:OR_FA_jhulabels,
        &#39;jhu_registration&#39;:OR_FA2JHUreg,
        &#39;reg_LR&#39;:reg_LR,
        &#39;reg_RL&#39;:reg_RL,
        &#39;dtrecon_LR_dewarp&#39;:recon_LR_dewarp,
        &#39;dwi_LR_dewarped&#39;:img_LRdwp,
        &#39;bval_LR&#39;:bval_LR,
        &#39;bvec_LR&#39;:bvec_LR,
        &#39;bval_RL&#39;:bval_RL,
        &#39;bvec_RL&#39;:bvec_RL,
        &#39;b0avg&#39;: reference_B0,
        &#39;dwiavg&#39;: reference_DWI,
        &#39;framewise_displacement&#39;:framewise_displacement,
        &#39;high_motion_count&#39;: motion_count,
        &#39;tsnr_b0&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;tsnr_dwi&#39;: tsnr( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;dvars_b0&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], b0_idx),
        &#39;dvars_dwi&#39;: dvars( img_LRdwp, recon_LR_dewarp[&#39;dwi_mask&#39;], non_b0_idx),
        &#39;ssnr_b0&#39;: slice_snr( img_LRdwp, bgmask , fgmask, b0_idx),
        &#39;ssnr_dwi&#39;: slice_snr( img_LRdwp, bgmask, fgmask, non_b0_idx),
        &#39;fa_evr&#39;: fa_evr,
        &#39;fa_SNR&#39;: fa_SNR
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mask_snr"><code class="name flex">
<span>def <span class="ident">mask_snr</span></span>(<span>x, background_mask, foreground_mask, bias_correct=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image using
a user-defined foreground and background mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_mask</code></strong> :&ensp;<code>binary antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>foreground_mask</code></strong> :&ensp;<code>binary antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bias_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mask_snr( x, background_mask, foreground_mask, bias_correct=True ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image using
    a user-defined foreground and background mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_mask : binary antsImage

    foreground_mask : binary antsImage

    bias_correct : boolean

    &#34;&#34;&#34;
    import numpy as np
    if foreground_mask.sum() &lt;= 1 or background_mask.sum() &lt;= 1:
        return 0
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    if bias_correct:
        xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    signal = (xbc[ foreground_mask == 1] ).mean()
    noise = (xbc[ background_mask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.match_modalities"><code class="name flex">
<span>def <span class="ident">match_modalities</span></span>(<span>qc_dataframe, unique_identifier='fn', outlier_column='ol_loop', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the best multiple modality dataset at each time point</p>
<p>:param qc_dataframe: quality control data frame with
:param unique_identifier : the unique NRG filename for each image
:param outlier_column: outlierness score used to identify the best image (pair) at a given date
:param verbose: boolean
:return: filtered matched modality data frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match_modalities( qc_dataframe, unique_identifier=&#39;fn&#39;, outlier_column=&#39;ol_loop&#39;,  verbose=False ):
    &#34;&#34;&#34;
    Find the best multiple modality dataset at each time point

    :param qc_dataframe: quality control data frame with
    :param unique_identifier : the unique NRG filename for each image
    :param outlier_column: outlierness score used to identify the best image (pair) at a given date
    :param verbose: boolean
    :return: filtered matched modality data frame
    &#34;&#34;&#34;
    import pandas as pd
    import numpy as np
    mmdf = best_mmm( qc_dataframe, &#39;T1w&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    fldf = best_mmm( qc_dataframe, &#39;T2Flair&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    nmdf = best_mmm( qc_dataframe, &#39;NM2DMT&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    rsdf = best_mmm( qc_dataframe, &#39;rsfMRI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    dtdf = best_mmm( qc_dataframe, &#39;DTI&#39;, outlier_column=outlier_column )[&#39;filt&#39;]
    mmdf[&#39;flairid&#39;] = np.nan
    mmdf[&#39;flairfn&#39;] = np.nan
    mmdf[&#39;flairloop&#39;] = np.nan
    mmdf[&#39;flairlof&#39;] = np.nan
    mmdf[&#39;dtid1&#39;] = np.nan
    mmdf[&#39;dtfn1&#39;] = np.nan
    mmdf[&#39;dtloop1&#39;] = np.nan
    mmdf[&#39;dtlof1&#39;] = np.nan
    mmdf[&#39;dtid2&#39;] = np.nan
    mmdf[&#39;dtfn2&#39;] = np.nan
    mmdf[&#39;dtloop2&#39;] = np.nan
    mmdf[&#39;dtlof2&#39;] = np.nan
    mmdf[&#39;rsfid1&#39;] = np.nan
    mmdf[&#39;rsffn1&#39;] = np.nan
    mmdf[&#39;rsfloop1&#39;] = np.nan
    mmdf[&#39;rsflof1&#39;] = np.nan
    mmdf[&#39;rsfid2&#39;] = np.nan
    mmdf[&#39;rsffn2&#39;] = np.nan
    mmdf[&#39;rsfloop2&#39;] = np.nan
    mmdf[&#39;rsflof2&#39;] = np.nan
    for k in range(1,11):
        myid=&#39;nmid&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmfn&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmloop&#39;+str(k)
        mmdf[myid] = np.nan
        myid=&#39;nmlof&#39;+str(k)
        mmdf[myid] = np.nan
    if verbose:
        print( mmdf.shape )
    for k in range(mmdf.shape[0]):
        if verbose:
            if k % 100 == 0:
                progger = str( k ) # np.round( k / mmdf.shape[0] * 100 ) )
                print( progger, end =&#34;...&#34;, flush=True)
        if dtdf is not None:
            locsel = (dtdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k]) &amp; (dtdf[outlier_column] &lt; 0.5)
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = dtdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = dtdf[&#34;fn&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = dtdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = dtdf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = dtdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn1&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof1&#34;)] = locdf[&#39;ol_lof_decision&#39;][locsel].values[0]
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtfn2&#34;)] = locdf[&#34;fn&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;dtlof2&#34;)] = locdf[&#39;ol_lof_decision&#39;][locsel].values[1]
        if rsdf is not None:
            locsel = (rsdf[&#34;subjectIDdate&#34;] == mmdf[&#34;subjectIDdate&#34;].iloc[k]) &amp; (rsdf[outlier_column] &lt; 0.5)
            if sum(locsel) == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = rsdf[&#34;imageID&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = rsdf[&#34;fn&#34;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = rsdf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = rsdf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = rsdf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid1&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn1&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop1&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof1&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[0]
                if locdf.shape[0] &gt; 1:
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfid2&#34;)] = locdf[&#34;imageID&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsffn2&#34;)] = locdf[&#34;fn&#34;].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsfloop2&#34;)] = locdf[outlier_column].values[1]
                    mmdf.iloc[k, mmdf.columns.get_loc(&#34;rsflof2&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[1]

        if fldf is not None:
            locsel = fldf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() == 1:
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = fldf[&#39;imageID&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = fldf[&#39;fn&#39;][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = fldf[outlier_column][locsel].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = fldf[&#39;ol_lof_decision&#39;][locsel].values[0]
            elif sum(locsel) &gt; 1:
                locdf = fldf[locsel]
                dedupe = locdf[[&#34;snr&#34;,&#34;cnr&#34;]].duplicated()
                locdf = locdf[~dedupe]
                if locdf.shape[0] &gt; 1:
                    locdf = locdf.sort_values(outlier_column).iloc[:2]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairid&#34;)] = locdf[&#34;imageID&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairfn&#34;)] = locdf[&#34;fn&#34;].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairloop&#34;)] = locdf[outlier_column].values[0]
                mmdf.iloc[k, mmdf.columns.get_loc(&#34;flairlof&#34;)] = locdf[&#39;ol_lof_decision&#39;].values[0]

        if nmdf is not None:
            locsel = nmdf[&#39;subjectIDdate&#39;] == mmdf[&#39;subjectIDdate&#39;].iloc[k]
            if locsel.sum() &gt; 0:
                locdf = nmdf[locsel]
                for i in range(np.min( [10,locdf.shape[0]])):
                    nmid = &#34;nmid&#34;+str(i+1)
                    mmdf[nmid].iloc[k] = locdf[&#39;imageID&#39;].iloc[i]
                    nmfn = &#34;nmfn&#34;+str(i+1)
                    mmdf[nmfn].iloc[k] = locdf[&#39;imageID&#39;].iloc[i]
                    nmloop = &#34;nmloop&#34;+str(i+1)
                    mmdf[nmloop].iloc[k] = locdf[outlier_column].iloc[i]
                    nmloop = &#34;nmlof&#34;+str(i+1)
                    mmdf[nmloop].iloc[k] = locdf[&#39;ol_lof_decision&#39;].iloc[i]

    return mmdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_denoise"><code class="name flex">
<span>def <span class="ident">mc_denoise</span></span>(<span>x, ratio=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>ants denoising for timeseries (4D)</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage 4D</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ratio</code></strong> :&ensp;<code>weight between 1 and 0 - lower weights bring result closer to initial image</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>denoised time series</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_denoise( x, ratio = 0.5 ):
    &#34;&#34;&#34;
    ants denoising for timeseries (4D)

    Arguments
    ---------
    x : an antsImage 4D

    ratio : weight between 1 and 0 - lower weights bring result closer to initial image

    Returns
    -------
    denoised time series

    &#34;&#34;&#34;
    dwpimage = []
    for myidx in range(x.shape[3]):
        b0 = ants.slice_image( x, axis=3, idx=myidx)
        dnzb0 = ants.denoise_image( b0, p=1,r=1,noise_model=&#39;Gaussian&#39; )
        dwpimage.append( dnzb0 * ratio + b0 * (1.0-ratio) )
    return ants.list_to_ndimage( x, dwpimage )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_reg"><code class="name flex">
<span>def <span class="ident">mc_reg</span></span>(<span>image, fixed=None, type_of_transform='Rigid', mask=None, total_sigma=3.0, fdOffset=2.0, output_directory=None, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion - with deformation.</p>
<h2 id="arguments">Arguments</h2>
<pre><code>image: antsImage, usually ND where D=4.

fixed: Fixed image to register all timepoints to.  If not provided,
    mean image is used.

type_of_transform : string
    A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
    See ants registration for details.

fdOffset: offset value to use in framewise displacement calculation

output_directory : string
    output will be named with this prefix plus a numeric extension.

verbose: boolean

kwargs: keyword args
    extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
&gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data('ch2'))
&gt;&gt;&gt; mytx = ants.motion_correction( fi )
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_reg(
    image,
    fixed=None,
    type_of_transform=&#34;Rigid&#34;,
    mask=None,
    total_sigma=3.0,
    fdOffset=2.0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
        image: antsImage, usually ND where D=4.

        fixed: Fixed image to register all timepoints to.  If not provided,
            mean image is used.

        type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

        fdOffset: offset value to use in framewise displacement calculation

        output_directory : string
            output will be named with this prefix plus a numeric extension.

        verbose: boolean

        kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &gt;&gt;&gt; fi = ants.image_read(ants.get_ants_data(&#39;ch2&#39;))
    &gt;&gt;&gt; mytx = ants.motion_correction( fi )
    &#34;&#34;&#34;
    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/mc_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(output_directory_w)
        print(ofnG)
        print(ofnL)

    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    if fixed is None:
        fixed = ants.get_average_of_timeseries( image )
    if mask is None:
        mask = ants.get_mask(fixed)
    FD = np.zeros(nTimePoints)
    motion_parameters = list()
    motion_corrected = list()
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = 0
    for k in range(nTimePoints):
        mycount = round(k / nTimePoints * 100)
        if verbose and mycount == counter:
            counter = counter + 10
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;Rigid&#39;,
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    fixed, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=ofnL+str(k).zfill(4)+&#34;_&#34;,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myreg[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
            img1w = ants.apply_transforms( fixed,
                ants.slice_image(image, axis=idim - 1, idx=k),
                myreg[&#34;fwdtransforms&#34;] )
            motion_corrected.append(img1w)
        else:
            motion_parameters.append(&#34;NA&#34;)
            motion_corrected.append(temp)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(image, motion_corrected),
        &#34;motion_parameters&#34;: motion_parameters,
        &#34;FD&#34;: FD,
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mc_resample_image_to_target"><code class="name flex">
<span>def <span class="ident">mc_resample_image_to_target</span></span>(<span>x, y, interp_type='linear')</span>
</code></dt>
<dd>
<div class="desc"><p>multichannel version of resample_image_to_target</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mc_resample_image_to_target( x , y, interp_type=&#39;linear&#39; ):
    &#34;&#34;&#34;
    multichannel version of resample_image_to_target
    &#34;&#34;&#34;
    xx=ants.split_channels( x )
    yy=ants.split_channels( y )[0]
    newl=[]
    for k in range(len(xx)):
        newl.append(  ants.resample_image_to_target( xx[k], yy, interp_type=interp_type ) )
    return ants.merge_channels( newl )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_dwi_data"><code class="name flex">
<span>def <span class="ident">merge_dwi_data</span></span>(<span>img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL)</span>
</code></dt>
<dd>
<div class="desc"><p>merge motion and distortion corrected data if possible</p>
<p>img_LRdwp : image</p>
<p>bval_LR : array</p>
<p>bvec_LR : array</p>
<p>img_RLdwp : image</p>
<p>bval_RL : array</p>
<p>bvec_RL : array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_dwi_data( img_LRdwp, bval_LR, bvec_LR, img_RLdwp, bval_RL, bvec_RL ):
    &#34;&#34;&#34;
    merge motion and distortion corrected data if possible

    img_LRdwp : image

    bval_LR : array

    bvec_LR : array

    img_RLdwp : image

    bval_RL : array

    bvec_RL : array

    &#34;&#34;&#34;
    insamespace = ants.image_physical_space_consistency( img_LRdwp, img_RLdwp )
    if not insamespace :
        raise ValueError(&#39;not insamespace ... corrected image pair should occupy the same physical space&#39;)

    bval_LR = np.concatenate([bval_LR,bval_RL])
    bvec_LR = np.concatenate([bvec_LR,bvec_RL])
    # concatenate the images
    mimg=[]
    for kk in range( img_LRdwp.shape[3] ):
            mimg.append( ants.slice_image( img_LRdwp, axis=3, idx=kk ) )
    for kk in range( img_RLdwp.shape[3] ):
            mimg.append( ants.slice_image( img_RLdwp, axis=3, idx=kk ) )
    img_LRdwp = ants.list_to_ndimage( img_LRdwp, mimg )
    return img_LRdwp, bval_LR, bvec_LR</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_mm_dataframe"><code class="name flex">
<span>def <span class="ident">merge_mm_dataframe</span></span>(<span>hierdf, mmdf, mm_suffix)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_mm_dataframe(hierdf, mmdf, mm_suffix):
    try:
        hierdf = hierdf.merge(mmdf, on=[&#39;sid&#39;, &#39;visitdate&#39;, &#39;t1imageuid&#39;], suffixes=(&#34;&#34;,mm_suffix),how=&#39;left&#39;)
        return hierdf
    except KeyError:
        return hierdf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_timeseries_data"><code class="name flex">
<span>def <span class="ident">merge_timeseries_data</span></span>(<span>img_LR, img_RL, allow_resample=True)</span>
</code></dt>
<dd>
<div class="desc"><p>merge time series data into space of reference_image</p>
<p>img_LR : image</p>
<p>img_RL : image</p>
<p>allow_resample : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_timeseries_data( img_LR, img_RL, allow_resample=True ):
    &#34;&#34;&#34;
    merge time series data into space of reference_image

    img_LR : image

    img_RL : image

    allow_resample : boolean

    &#34;&#34;&#34;
    # concatenate the images into the reference space
    mimg=[]
    for kk in range( img_LR.shape[3] ):
        temp = ants.slice_image( img_LR, axis=3, idx=kk )
        mimg.append( temp )
    for kk in range( img_RL.shape[3] ):
        temp = ants.slice_image( img_RL, axis=3, idx=kk )
        if kk == 0:
            insamespace = ants.image_physical_space_consistency( temp, mimg[0] )
        if allow_resample and not insamespace :
            temp = ants.resample_image_to_target( temp, mimg[0] )
        mimg.append( temp )
    return ants.list_to_ndimage( img_LR, mimg )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.merge_wides_to_study_dataframe"><code class="name flex">
<span>def <span class="ident">merge_wides_to_study_dataframe</span></span>(<span>sdf, processing_dir, separator='-', sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False, progress=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>extend a study data frame with wide outputs</p>
<p>sdf : the input study dataframe</p>
<p>processing_dir:
the directory location of the processed data </p>
<p>separator : string usually '-' or '_'</p>
<p>sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas</p>
<p>report_missing : boolean combined with verbose will report missing modalities</p>
<p>progress : integer reports percent progress modulo progress value </p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_wides_to_study_dataframe( sdf, processing_dir, separator=&#39;-&#39;, sid_is_int=True, id_is_int=True, date_is_int=True, report_missing=False,
progress=False, verbose=False ):
    &#34;&#34;&#34;
    extend a study data frame with wide outputs

    sdf : the input study dataframe

    processing_dir:  the directory location of the processed data 

    separator : string usually &#39;-&#39; or &#39;_&#39;

    sid_is_int : boolean set to True to cast unique subject ids to int; can be useful if they are inadvertently stored as float by pandas

    date_is_int : boolean set to True to cast date to int; can be useful if they are inadvertently stored as float by pandas

    id_is_int : boolean set to True to cast unique image ids to int; can be useful if they are inadvertently stored as float by pandas

    report_missing : boolean combined with verbose will report missing modalities

    progress : integer reports percent progress modulo progress value 

    verbose : boolean
    &#34;&#34;&#34;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;fn&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in sdf.keys():
            raise ValueError(&#39;sdf is missing column &#39; +musthavecols[k] + &#39; in merge_wides_to_study_dataframe&#39; )
    possible_iids = [ &#39;imageID&#39;, &#39;imageID&#39;, &#39;imageID&#39;, &#39;flairid&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;nmid1&#39;, &#39;nmid2&#39;, &#39;nmid3&#39;, &#39;nmid4&#39;, &#39;nmid5&#39;, &#39;nmid6&#39;, &#39;nmid7&#39;, &#39;nmid8&#39;, &#39;nmid9&#39;, &#39;nmid10&#39; ]
    modality_ids = [ &#39;T1wHierarchical&#39;, &#39;T1wHierarchicalSR&#39;, &#39;T1w&#39;, &#39;T2Flair&#39;, &#39;DTI&#39;, &#39;DTI&#39;, &#39;rsfMRI&#39;, &#39;rsfMRI&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;, &#39;NM2DMT&#39;]
    alldf=pd.DataFrame()
    for myk in sdf.index:
        if progress &gt; 0 and int(myk) % int(progress) == 0:
            print( str( round( myk/sdf.shape[0]*100.0)) + &#34;%...&#34;, end=&#39;&#39;, flush=True)
        if verbose:
            print( &#34;DOROW &#34; + str(myk) + &#39; of &#39; + str( sdf.shape[0] ) )
        csvrow = sdf.loc[sdf.index == myk].dropna(axis=1)
        ct=-1
        for iidkey in possible_iids:
            ct=ct+1
            mod_name = modality_ids[ct]
            if iidkey in csvrow.keys():
                if id_is_int:
                    iid = str( int( csvrow[iidkey].iloc[0] ) )
                else:
                    iid = str( csvrow[iidkey].iloc[0] )
                if verbose:
                    print( &#34;iidkey &#34; + iidkey + &#34; modality &#34; + mod_name + &#39; iid &#39;+ iid )
                pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
                if sid_is_int:
                    sid=str(int(csvrow[&#39;subjectID&#39;].iloc[0] ))
                else:
                    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
                if date_is_int:
                    dt=str(int(csvrow[&#39;date&#39;].iloc[0]))
                else:
                    dt=str(csvrow[&#39;date&#39;].iloc[0])
                if id_is_int:
                    t1iid=str(int(csvrow[&#39;imageID&#39;].iloc[0]))
                else:
                    t1iid=str(csvrow[&#39;imageID&#39;].iloc[0])
                if t1iid != iid:
                    iidj=iid+&#34;_&#34;+t1iid
                else:
                    iidj=iid
                rootid = pid +separator+ sid +separator+dt+separator+mod_name+separator+iidj
                myext = rootid +separator+&#39;mmwide.csv&#39;
                nrgwidefn=os.path.join( processing_dir, pid, sid, dt, mod_name, iid, myext )
                moddersub = mod_name
                is_t1=False
                if mod_name == &#39;T1wHierarchical&#39;:
                    is_t1=True
                    moddersub=&#39;T1Hier&#39;
                elif mod_name == &#39;T1wHierarchicalSR&#39;:
                    is_t1=True
                    moddersub=&#39;T1HSR&#39;
                if exists( nrgwidefn ):
                    if verbose:
                        print( nrgwidefn + &#34; exists&#34;)
                    mm=read_mm_csv( nrgwidefn, colprefix=moddersub+&#39;_&#39;, is_t1=is_t1, separator=separator, verbose=verbose )
                    if mm is not None:
                        if mod_name == &#39;T1wHierarchical&#39;:
                            a=list( csvrow.keys() )
                            b=list( mm.keys() )
                            abintersect=list(set(b).intersection( set(a) ) )
                            if len( abintersect  ) &gt; 0 :
                                for qq in abintersect:
                                    mm.pop( qq )
                        mm.index=csvrow.index
                        uidname = mod_name + &#39;_mmwide_filename&#39;
                        mm[ uidname ] = rootid
                        csvrow=pd.concat( [csvrow,mm], axis=1 )
                else:
                    if verbose and report_missing:
                        print( nrgwidefn + &#34; absent&#34;)
        if alldf.shape[0] == 0:
            alldf = csvrow.copy()
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
        else:
            csvrow=csvrow.loc[:,~csvrow.columns.duplicated()]
            alldf = alldf.loc[:,~alldf.columns.duplicated()]
            alldf = pd.concat( [alldf, csvrow], axis=0, ignore_index=True)
    return alldf</code></pre>
</details>
</dd>
<dt id="antspymm.mm.middle_slice_snr"><code class="name flex">
<span>def <span class="ident">middle_slice_snr</span></span>(<span>x, background_dilation=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>background_dilation</code></strong> :&ensp;<code>integer - amount to dilate foreground mask</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def middle_slice_snr( x, background_dilation=5 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in 2D mid image from a 3D image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    background_dilation : integer - amount to dilate foreground mask

    &#34;&#34;&#34;
    xshp = x.shape
    xmidslice = ants.slice_image( x, 2, int( xshp[2]/2 )  )
    xmidslice = ants.iMath( xmidslice - xmidslice.min(), &#34;Normalize&#34; )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslice = ants.n3_bias_field_correction( xmidslice )
    xmidslicemask = ants.threshold_image( xmidslice, &#34;Otsu&#34;, 1 ).morphology(&#34;close&#34;,2).iMath(&#34;FillHoles&#34;)
    xbkgmask = ants.iMath( xmidslicemask, &#34;MD&#34;, background_dilation ) - xmidslicemask
    signal = (xmidslice[ xmidslicemask == 1] ).mean()
    noise = (xmidslice[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm"><code class="name flex">
<span>def <span class="ident">mm</span></span>(<span>t1_image, hier, rsf_image=[], flair_image=None, nm_image_list=None, dw_image=[], bvals=[], bvecs=[], srmodel=None, do_tractography=False, do_kk=False, do_normalization=None, target_range=[0, 1], dti_motion_correct='Rigid', dti_denoise=False, test_run=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Multiple modality processing and normalization</p>
<p>aggregates modality-specific processing under one roof.
see individual
modality specific functions for details.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>t1_image</code></strong> :&ensp;<code>raw t1 image</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>hier
: output of antspyt1w.hierarchical ( see read hierarchical )</p>
<dl>
<dt><strong><code>rsf_image</code></strong> :&ensp;<code>list</code> of <code>resting state fmri</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>flair_image</code></strong> :&ensp;<code>flair</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nm_image_list</code></strong> :&ensp;<code>list</code> of <code><a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> images</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dw_image</code></strong> :&ensp;<code>list</code> of <code>diffusion weighted images</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvals</code></strong> :&ensp;<code>list</code> of <code>bvals file names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>list</code> of <code>bvecs file names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>optional srmodel</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_tractography</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_kk</code></strong> :&ensp;<code>boolean to control whether we compute kelly kapowski thickness image (slow)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>do_normalization</code></strong> :&ensp;<code>template transformation if available</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>dti_motion_correct</code></strong> :&ensp;<code>None Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>test_run</code></strong> :&ensp;<code>boolean </code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm(
    t1_image,
    hier,
    rsf_image=[],
    flair_image=None,
    nm_image_list=None,
    dw_image=[], bvals=[], bvecs=[],
    srmodel=None,
    do_tractography = False,
    do_kk = False,
    do_normalization = None,
    target_range = [0,1],
    dti_motion_correct = &#39;Rigid&#39;,
    dti_denoise = False,
    test_run = False,
    verbose = False ):
    &#34;&#34;&#34;
    Multiple modality processing and normalization

    aggregates modality-specific processing under one roof.  see individual
    modality specific functions for details.

    Parameters
    -------------

    t1_image : raw t1 image

    hier  : output of antspyt1w.hierarchical ( see read hierarchical )

    rsf_image : list of resting state fmri

    flair_image : flair

    nm_image_list : list of neuromelanin images

    dw_image : list of diffusion weighted images

    bvals : list of bvals file names

    bvecs : list of bvecs file names

    srmodel : optional srmodel

    do_tractography : boolean

    do_kk : boolean to control whether we compute kelly kapowski thickness image (slow)

    do_normalization : template transformation if available

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.
    
    dti_motion_correct : None Rigid or SyN

    dti_denoise : boolean

    test_run : boolean 

    verbose : boolean

    &#34;&#34;&#34;
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_path_mm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    mycsvfn = ex_path + &#34;FA_JHU_labels_edited.csv&#34;
    citcsvfn = ex_path + &#34;CIT168_Reinf_Learn_v1_label_descriptions_pad.csv&#34;
    dktcsvfn = ex_path + &#34;dkt.csv&#34;
    cnxcsvfn = ex_path + &#34;dkt_cortex_cit_deep_brain.csv&#34;
    JHU_atlasfn = ex_path + &#39;JHU-ICBM-FA-1mm.nii.gz&#39; # Read in JHU atlas
    JHU_labelsfn = ex_path + &#39;JHU-ICBM-labels-1mm.nii.gz&#39; # Read in JHU labels
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( mycsvfn ) or not exists( citcsvfn ) or not exists( cnxcsvfn ) or not exists( dktcsvfn ) or not exists( JHU_atlasfn ) or not exists( JHU_labelsfn ) or not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        raise ValueError(&#39;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#39;)
    mycsv = pd.read_csv(  mycsvfn )
    citcsv = pd.read_csv(  os.path.expanduser( citcsvfn ) )
    dktcsv = pd.read_csv(  os.path.expanduser( dktcsvfn ) )
    cnxcsv = pd.read_csv(  os.path.expanduser( cnxcsvfn ) )
    JHU_atlas = mm_read( JHU_atlasfn ) # Read in JHU atlas
    JHU_labels = mm_read( JHU_labelsfn ) # Read in JHU labels
    template = mm_read( templatefn ) # Read in template
    #####################
    #  T1 hierarchical  #
    #####################
    t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
    t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    mynets = list([ &#39;CinguloopercularTaskControl&#39;, &#39;DefaultMode&#39;,
        &#39;MemoryRetrieval&#39;, &#39;VentralAttention&#39;, &#39;Visual&#39;,
        &#39;FrontoparietalTaskControl&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
        &#39;DorsalAttention&#39;])
    output_dict = {
        &#39;kk&#39;: None,
        &#39;rsf&#39;: None,
        &#39;flair&#39; : None,
        &#39;NM&#39; : None,
        &#39;DTI&#39; : None,
        &#39;FA_summ&#39; : None,
        &#39;MD_summ&#39; : None,
        &#39;tractography&#39; : None,
        &#39;tractography_connectivity&#39; : None
    }
    normalization_dict = {
        &#39;kk_norm&#39;: None,
        &#39;NM_norm&#39; : None,
        &#39;FA_norm&#39; : None,
        &#39;MD_norm&#39; : None,
        &#39;alff_norm&#39; : None,
        &#39;falff_norm&#39; : None,
        &#39;CinguloopercularTaskControl_norm&#39; : None,
        &#39;DefaultMode_norm&#39; : None,
        &#39;MemoryRetrieval_norm&#39; : None,
        &#39;VentralAttention_norm&#39; : None,
        &#39;Visual_norm&#39; : None,
        &#39;FrontoparietalTaskControl_norm&#39; : None,
        &#39;Salience_norm&#39; : None,
        &#39;Subcortical_norm&#39; : None,
        &#39;DorsalAttention_norm&#39; : None
    }
    if test_run:
        return output_dict, normalization_dict

    if do_kk:
        if verbose:
            print(&#39;kk&#39;)
        output_dict[&#39;kk&#39;] = antspyt1w.kelly_kapowski_thickness( hier[&#39;brain_n4_dnz&#39;],
            labels=hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;], iterations=45 )
    ################################## do the rsf .....
    if len(rsf_image) &gt; 0:
        rsf_image = [i for i in rsf_image if i is not None]
        if verbose:
            print(&#39;rsf length &#39; + str( len( rsf_image ) ) )
        if len( rsf_image ) &gt;= 2: # assume 2 is the largest possible value
            rsf_image1 = rsf_image[0]
            rsf_image2 = rsf_image[1]
            # build a template then join the images
            if verbose:
                print(&#34;initial average for rsf&#34;)
            rsfavg1=get_average_rsf(rsf_image1)
            rsfavg2=get_average_rsf(rsf_image2)
            if verbose:
                print(&#34;template average for rsf&#34;)
            init_temp = ants.image_clone( rsfavg1 )
            if rsf_image1.shape[3] &lt; rsf_image2.shape[3]:
                init_temp = ants.image_clone( rsfavg2 )
            boldTemplate = ants.build_template(
                initial_template = init_temp,
                image_list=[rsfavg1,rsfavg2],
                iterations=5, verbose=False )
            if verbose:
                print(&#34;join the 2 rsf&#34;)
            if rsf_image1.shape[3] &gt; 10 and rsf_image2.shape[3] &gt; 10:
                rsf_image = merge_timeseries_data( rsf_image1, rsf_image2 )
            elif rsf_image1.shape[3] &gt; rsf_image2.shape[3]:
                rsf_image = rsf_image1
            else:
                rsf_image = rsf_image2
        elif len( rsf_image ) == 1:
            rsf_image = rsf_image[0]
            boldTemplate=get_average_rsf(rsf_image)
        if rsf_image.shape[3] &gt; 10: # FIXME - better heuristic?
            output_dict[&#39;rsf&#39;] = resting_state_fmri_networks(
                rsf_image,
                boldTemplate,
                hier[&#39;brain_n4_dnz&#39;],
                t1atropos,
                f=[0.03,0.08],
                spa = 1.0,
                spt = 0.5,
                nc = 6, verbose=verbose )
    if nm_image_list is not None:
        if verbose:
            print(&#39;nm&#39;)
        if srmodel is None:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], verbose=verbose )
        else:
            output_dict[&#39;NM&#39;] = neuromelanin( nm_image_list, t1imgbrn, t1_image, hier[&#39;deep_cit168lab&#39;], srmodel=srmodel, target_range=target_range, verbose=verbose  )
################################## do the dti .....
    if len(dw_image) &gt; 0 :
        if verbose:
            print(&#39;dti-x&#39;)
        if len( dw_image ) == 1: # use T1 for distortion correction and brain extraction
            if verbose:
                print(&#34;We have only one DTI: &#34; + str(len(dw_image)))
            dw_image = dw_image[0]
            btpB0,btpDW=get_average_dwi_b0(dw_image)
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            btpDW = ants.apply_transforms( btpDW, btpDW,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            btpB0 = ants.apply_transforms( btpB0, btpB0,
                tempreg[&#39;invtransforms&#39;][1], interpolator=&#39;linear&#39;)
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;nearestNeighbor&#39;)
            # dwimask = ants.iMath(dwimask,&#39;MD&#39;,1)
            t12dwi = ants.apply_transforms( btpDW, hier[&#39;brain_n4_dnz&#39;], tempreg[&#39;fwdtransforms&#39;][1], interpolator=&#39;linear&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image,
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                motion_correct=dti_motion_correct, # set to False if using input from qsiprep
                denoise=dti_denoise,
                verbose = verbose)
        else :  # use phase encoding acquisitions for distortion correction and T1 for brain extraction
            if verbose:
                print(&#34;We have both DTI_LR and DTI_RL: &#34; + str(len(dw_image)))
            a1b,a1w=get_average_dwi_b0(dw_image[0])
            a2b,a2w=get_average_dwi_b0(dw_image[1],fixed_b0=a1b,fixed_dwi=a1w)
            btpB0, btpDW = dti_template(
                b_image_list=[a1b,a2b],
                w_image_list=[a1w,a2w],
                iterations=7, verbose=verbose )
            initrig = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;BOLDRigid&#39; )[&#39;fwdtransforms&#39;][0]
            tempreg = ants.registration( btpDW, hier[&#39;brain_n4_dnz&#39;], &#39;SyNOnly&#39;,
                syn_metric=&#39;mattes&#39;, syn_sampling=32,
                reg_iterations=[50,50,20],
                multivariate_extras=[ [ &#34;mattes&#34;, btpB0, hier[&#39;brain_n4_dnz&#39;], 1, 32 ]],
                initial_transform=initrig
                )
            mybxt = ants.threshold_image( ants.iMath(hier[&#39;brain_n4_dnz&#39;], &#34;Normalize&#34; ), 0.001, 1 )
            dwimask = ants.apply_transforms( btpDW, mybxt, tempreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39;)
            output_dict[&#39;DTI&#39;] = joint_dti_recon(
                dw_image[0],
                bvals[0],
                bvecs[0],
                jhu_atlas=JHU_atlas,
                jhu_labels=JHU_labels,
                brain_mask = dwimask,
                reference_B0 = btpB0,
                reference_DWI = btpDW,
                srmodel=srmodel,
                img_RL=dw_image[1],
                bval_RL=bvals[1],
                bvec_RL=bvecs[1],
                motion_correct=&#39;SyN&#39;, # set to False if using input from qsiprep
                denoise=True,
                verbose = verbose)
        mydti = output_dict[&#39;DTI&#39;]
        # summarize dwi with T1 outputs
        # first - register ....
        reg = ants.registration( mydti[&#39;recon_fa&#39;], hier[&#39;brain_n4_dnz&#39;], &#39;SyNBold&#39;, total_sigma=1.0 )
        ##################################################
        output_dict[&#39;FA_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_fa&#39;],
            hier=hier,
            modality_name=&#39;fa&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        ##################################################
        output_dict[&#39;MD_summ&#39;] = hierarchical_modality_summary(
            mydti[&#39;recon_md&#39;],
            hier=hier,
            modality_name=&#39;md&#39;,
            transformlist=reg[&#39;fwdtransforms&#39;],
            verbose = False )
        # these inputs should come from nicely processed data
        dktmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;dkt_parc&#39;][&#39;dkt_cortex&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        citmapped = ants.apply_transforms(
            mydti[&#39;recon_fa&#39;],
            hier[&#39;cit168lab&#39;],
            reg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
        dktmapped[ citmapped &gt; 0]=0
        mask = ants.threshold_image( mydti[&#39;recon_fa&#39;], 0.01, 2.0 ).iMath(&#34;GetLargestComponent&#34;)
        if do_tractography: # dwi_deterministic_tracking dwi_closest_peak_tracking
            output_dict[&#39;tractography&#39;] = dwi_deterministic_tracking(
                mydti[&#39;dwi_LR_dewarped&#39;],
                mydti[&#39;recon_fa&#39;],
                mydti[&#39;bval_LR&#39;],
                mydti[&#39;bvec_LR&#39;],
                seed_density = 1,
                mask=mask,
                verbose = verbose )
            mystr = output_dict[&#39;tractography&#39;]
            output_dict[&#39;tractography_connectivity&#39;] = dwi_streamline_connectivity( mystr[&#39;streamlines&#39;], dktmapped+citmapped, cnxcsv, verbose=verbose )
    ################################## do the flair .....
    if flair_image is not None:
        if verbose:
            print(&#39;flair&#39;)
        wmhprior = None
        priorfn = ex_path_mm + &#39;CIT168_wmhprior_700um_pad_adni.nii.gz&#39;
        if ( exists( priorfn ) ):
            wmhprior = ants.image_read( priorfn )
            wmhprior = ants.apply_transforms( t1_image, wmhprior, do_normalization[&#39;invtransforms&#39;] )
        output_dict[&#39;flair&#39;] = boot_wmh( flair_image, t1_image, t1atropos,
            prior_probability=wmhprior, verbose=verbose )
    #################################################################
    ### NOTES: deforming to a common space and writing out images ###
    ### images we want come from: DTI, NM, rsf, thickness ###########
    #################################################################
    if do_normalization is not None:
        if verbose:
            print(&#39;normalization&#39;)
        # might reconsider this template space - cropped and/or higher res?
        template = ants.resample_image( template, [1,1,1], use_voxels=False )
        # t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;], &#34;antsRegistrationSyNQuickRepro[s]&#34;)
        t1reg = do_normalization
        if do_kk:
            normalization_dict[&#39;kk_norm&#39;] = ants.apply_transforms( template, output_dict[&#39;kk&#39;][&#39;thickness_image&#39;], t1reg[&#39;fwdtransforms&#39;])
        if output_dict[&#39;DTI&#39;] is not None:
            mydti = output_dict[&#39;DTI&#39;]
            dtirig = ants.registration( hier[&#39;brain_n4_dnz&#39;], mydti[&#39;recon_fa&#39;], &#39;Rigid&#39; )
            normalization_dict[&#39;MD_norm&#39;] = ants.apply_transforms( template, mydti[&#39;recon_md&#39;],t1reg[&#39;fwdtransforms&#39;]+dtirig[&#39;fwdtransforms&#39;] )
            normalization_dict[&#39;FA_norm&#39;] = ants.apply_transforms( template, mydti[&#39;recon_fa&#39;],t1reg[&#39;fwdtransforms&#39;]+dtirig[&#39;fwdtransforms&#39;] )
        if output_dict[&#39;rsf&#39;] is not None:
            rsfpro = output_dict[&#39;rsf&#39;]
            rsfrig = ants.registration( hier[&#39;brain_n4_dnz&#39;], rsfpro[&#39;meanBold&#39;], &#39;Rigid&#39; )
            for netid in mynets:
                rsfkey = netid + &#34;_norm&#34;
                normalization_dict[rsfkey] = ants.apply_transforms(
                    template, rsfpro[netid],
                    t1reg[&#39;fwdtransforms&#39;]+rsfrig[&#39;fwdtransforms&#39;] )
        if nm_image_list is not None:
            nmpro = output_dict[&#39;NM&#39;]
            nmrig = nmpro[&#39;t1_to_NM_transform&#39;] # this is an inverse tx
            normalization_dict[&#39;NM_norm&#39;] = ants.apply_transforms( template, nmpro[&#39;NM_avg&#39;],t1reg[&#39;fwdtransforms&#39;]+nmrig,
                whichtoinvert=[False,False,True])

    if verbose:
        print(&#39;mm done&#39;)
    return output_dict, normalization_dict</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_csv"><code class="name flex">
<span>def <span class="ident">mm_csv</span></span>(<span>studycsv, mysep='-', srmodel_T1=False, srmodel_NM=False, srmodel_DTI=False, dti_motion_correct='SyN', dti_denoise=True, nrg_modality_list=None)</span>
</code></dt>
<dd>
<div class="desc"><p>too dangerous to document &hellip; use with care.</p>
<p>processes multiple modality MRI specifically:</p>
<ul>
<li>T1w</li>
<li>T2Flair</li>
<li>DTI, DTI_LR, DTI_RL</li>
<li>rsfMRI, rsfMRI_LR, rsfMRI_RL</li>
<li>NM2DMT (neuromelanin)</li>
</ul>
<p>other modalities may be added later &hellip;</p>
<p>"trust me, i know what i'm doing" - sledgehammer</p>
<p>convert to pynb via:
p2j mm.py -o</p>
<p>convert the ipynb to html via:
jupyter nbconvert ANTsPyMM/tests/mm.ipynb &ndash;execute &ndash;to html</p>
<p>this function does not assume NRG format for the input data ....</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>studycsv</code></strong> :&ensp;<code>must have columns:</code></dt>
<dd>
<ul>
<li>subjectID</li>
<li>date or session</li>
<li>imageID</li>
<li>modality</li>
<li>sourcedir</li>
<li>outputdir</li>
<li>filename (path to the t1 image)
other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
rsf=resting state fmri, flair=T2Flair.
none of these are required. only
t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
see antspymm.generate_mm_dataframe</li>
</ul>
</dd>
<dt><strong><code>sourcedir</code></strong> :&ensp;<code>a study specific folder containing individual subject folders</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>outputdir</code></strong> :&ensp;<code>a study specific folder where individual output subject folders will go</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>the raw image filename (full path)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_T1</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 2 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_NM</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_DTI</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_motion_correct</code></strong> :&ensp;<code>None, Rigid</code> or <code>SyN</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dti_denoise</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nrg_modality_list</code></strong> :&ensp;<code>optional; defaults to None; use to focus on a given modality</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>writes output to disk and produces figures</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_csv(
    studycsv,   # pandas data frame
    mysep = &#39;-&#39;, # or &#34;_&#34; for BIDS
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    dti_motion_correct = &#39;SyN&#39;,
    dti_denoise = True,
    nrg_modality_list = None
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function does not assume NRG format for the input data ....

    Parameters
    -------------

    studycsv : must have columns:
        - subjectID
        - date or session
        - imageID
        - modality
        - sourcedir
        - outputdir
        - filename (path to the t1 image)
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide filenames for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required. rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
        see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    outputdir : a study specific folder where individual output subject folders will go

    filename : the raw image filename (full path)

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    dti_motion_correct : None, Rigid or SyN

    dti_denoise : boolean

    nrg_modality_list : optional; defaults to None; use to focus on a given modality

    Returns
    ---------

    writes output to disk and produces figures

    &#34;&#34;&#34;
    visualize = True
    verbose = True
    if nrg_modality_list is None:
        nrg_modality_list = get_valid_modalities()
    if studycsv.shape[0] &lt; 1:
        raise ValueError(&#39;studycsv has no rows&#39;)
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studycsv.keys():
            raise ValueError(&#39;studycsv is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = mysep ):
        return x + separator + &#39;mmwide.csv&#39;
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studycsv
    # musthavecols = [&#39;projectID&#39;,&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;modality&#39;,&#39;sourcedir&#39;,&#39;outputdir&#39;,&#39;filename&#39;]
    projid = str(studycsv[&#39;projectID&#39;].iloc[0])
    sid = str(studycsv[&#39;subjectID&#39;].iloc[0])
    dtid = str(studycsv[&#39;date&#39;].iloc[0])
    iid = str(studycsv[&#39;imageID&#39;].iloc[0])
    t1iidUse=iid
    modality = str(studycsv[&#39;modality&#39;].iloc[0])
    sourcedir = str(studycsv[&#39;sourcedir&#39;].iloc[0])
    outputdir = str(studycsv[&#39;outputdir&#39;].iloc[0])
    filename = str(studycsv[&#39;filename&#39;].iloc[0])
    if not exists(filename):
            raise ValueError(&#39;mm_nrg cannot find filename &#39; + filename + &#39; in mm_csv&#39; )
    def docsamson( locmod, t1iid=None, verbose=True ):
        myimgsInput = []
        myoutputPrefix = None
        imfns = [ &#39;filename&#39;, &#39;rsfid1&#39;, &#39;rsfid2&#39;, &#39;dtid1&#39;, &#39;dtid2&#39;, &#39;flairid&#39; ]
        if locmod == &#39;T1w&#39;:
            imfns=[&#39;filename&#39;]
        elif locmod == &#39;T2Flair&#39;:
            imfns=[&#39;flairid&#39;]
        elif locmod == &#39;NM2DMT&#39;:
            imfns=[]
            for i in range(11):
                imfns.append( &#39;nmid&#39; + str(i) )
        elif locmod == &#39;rsfMRI&#39;:
            imfns=[]
            for i in range(3):
                imfns.append( &#39;rsfid&#39; + str(i) )
        elif locmod == &#39;DTI&#39;:
            imfns=[]
            for i in range(3):
                imfns.append( &#39;dtid&#39; + str(i) )
        for i in imfns:
            if verbose:
                print( i + &#34; &#34; + locmod )
            if i in studycsv.keys():
                fni=str(studycsv[i].iloc[0])
                if verbose:
                    print( i + &#34; &#34; + fni + &#39; exists &#39; + str( exists( fni ) ) )
                if exists( fni ):
                    myimgsInput.append( fni )
                    temp = os.path.basename( fni )
                    mysplit = temp.split( mysep )
                    iid = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, mysplit[len(mysplit)-1] )
                    iid = re.sub( &#34;.mha&#34;, &#34;&#34;, iid )
                    iid = re.sub( &#34;.nii&#34;, &#34;&#34;, iid )
                    iid2 = iid
                    if locmod != &#39;T1w&#39; and t1iid is not None:
                        iid2=iid+&#34;_&#34;+t1iid
                    myoutputPrefix = outputdir + &#34;/&#34; + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + locmod + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + locmod + mysep + iid2
        if verbose:
            print(&#34;VERBOSE in docsamson&#34;)
            print( locmod )
            print( myimgsInput )
            print( myoutputPrefix )
        return {
            &#39;modality&#39;: locmod,
            &#39;outprefix&#39;: myoutputPrefix,
            &#39;images&#39;: myimgsInput
            }
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1fn = filename
    if not exists( t1fn ):
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + t1fn )
    t1 = mm_read( t1fn, modality=&#39;T1w&#39; )
    hierfn = outputdir + &#34;/&#34;  + projid + &#34;/&#34; + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchical&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchical&#34; + mysep + iid + mysep
    hierfnSR = outputdir + &#34;/&#34; + projid + &#34;/&#34;  + sid + &#34;/&#34; + dtid + &#34;/&#34; + &#34;T1wHierarchicalSR&#34; + &#39;/&#39; + iid + &#34;/&#34; + projid + mysep + sid + mysep + dtid + mysep + &#34;T1wHierarchicalSR&#34; + mysep + iid + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    if verbose:
        print( hierfntest )
    regout = hierfn + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;REGISTRATION EXISTENCE: &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) and exists( templateTx[&#39;fwdtransforms&#39;][0]) and exists( templateTx[&#39;fwdtransforms&#39;][1]) and exists( templateTx[&#39;invtransforms&#39;][0]) and exists( templateTx[&#39;invtransforms&#39;][1])
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    for overmodX in nrg_modality_list:
        # define 1. input images 2. output prefix
        mydoc = docsamson( overmodX, t1iid=t1iidUse )
        myimgsr = mydoc[&#39;images&#39;]
        mymm = mydoc[&#39;outprefix&#39;]
        mymod = mydoc[&#39;modality&#39;]
        if verbose:
            print( mydoc )
        if len(myimgsr) &gt; 0:
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodX )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodX == &#39;NM2DMT&#39;:
                subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                if verbose:
                    print(&#34;subjectpropath is&#34;)
                    print(subjectpropath)
                    os.makedirs( subjectpropath, exist_ok=True  )
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount=0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( mydoc[&#39;outprefix&#39;] )
                        if verbose:
                            print(&#34;subjectpropath is&#34;)
                            print(subjectpropath)
                        os.makedirs( subjectpropath, exist_ok=True  )
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;DefaultMode&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;FrontoparietalTaskControl&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FrontoparietalTaskControl&#39;, filename=mymm+mysep+&#34;boldFrontoparietalTaskControl.png&#34;  )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                missing_dti_data=False # bval, bvec or images
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if exists( dtilrfn ):
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                # check existence of all files expected ...
                                for dtiex in bvalfnList+bvecfnList+myimgsr:
                                    if not exists(dtiex):
                                        print(&#39;mm_csv: missing dti data &#39; + dtiex )
                                        missing_dti_data=True
                                        dowrite=False
                                if not missing_dti_data:
                                    dowrite=True
                                    srmodel_DTI_mdl=None
                                    if srmodel_DTI is not False:
                                        temp = ants.get_spacing(img)
                                        dtspc=[temp[0],temp[1],temp[2]]
                                        bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                        mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                        if isinstance( srmodel_DTI, str ):
                                            srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                            mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                        if exists( mdlfn ):
                                            if verbose:
                                                print(mdlfn)
                                            srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                        else:
                                            print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                    tabPro, normPro = mm( t1, hier,
                                        dw_image=imgList,
                                        bvals = bvalfnList,
                                        bvecs = bvecfnList,
                                        srmodel=srmodel_DTI_mdl,
                                        do_tractography=not test_run,
                                        do_kk=False,
                                        do_normalization=templateTx,
                                        dti_motion_correct = dti_motion_correct,
                                        dti_denoise = dti_denoise,
                                        test_run=test_run,
                                        verbose=True )
                                    mydti = tabPro[&#39;DTI&#39;]
                                    if visualize:
                                        maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                        ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA (supposed to be better)&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                        ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                        ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_nrg"><code class="name flex">
<span>def <span class="ident">mm_nrg</span></span>(<span>studyid, sourcedir='/Users/stnava/data/PPMI/MV/example_s3_b/images/PPMI/', sourcedatafoldername='images', processDir='processed', mysep='-', srmodel_T1=False, srmodel_NM=False, srmodel_DTI=False, visualize=True, nrg_modality_list=['T1w', 'NM2DMT', 'rsfMRI', 'DTI', 'T2Flair'], verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>too dangerous to document &hellip; use with care.</p>
<p>processes multiple modality MRI specifically:</p>
<ul>
<li>T1w</li>
<li>T2Flair</li>
<li>DTI, DTI_LR, DTI_RL</li>
<li>rsfMRI, rsfMRI_LR, rsfMRI_RL</li>
<li>NM2DMT (neuromelanin)</li>
</ul>
<p>other modalities may be added later &hellip;</p>
<p>"trust me, i know what i'm doing" - sledgehammer</p>
<p>convert to pynb via:
p2j mm.py -o</p>
<p>convert the ipynb to html via:
jupyter nbconvert ANTsPyMM/tests/mm.ipynb &ndash;execute &ndash;to html</p>
<p>this function assumes NRG format for the input data ....
we also assume that t1w hierarchical (if already done) was written
via its standardized write function.
NRG = <a href="https://github.com/stnava/biomedicalDataOrganization">https://github.com/stnava/biomedicalDataOrganization</a></p>
<p>this function is verbose</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>studyid</code></strong> :&ensp;<code>must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID</code></dt>
<dd>other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
rsf=resting state fmri, flair=T2Flair.
none of these are required. only
t1 is required.
rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.
see antspymm.generate_mm_dataframe</dd>
<dt><strong><code>sourcedir</code></strong> :&ensp;<code>a study specific folder containing individual subject folders</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>sourcedatafoldername</code></strong> :&ensp;<code>root for source data e.g. "images"</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>processDir : where output will go - parallel to sourcedatafoldername e.g.
"processed"</p>
<dl>
<dt><strong><code>mysep</code></strong> :&ensp;<code>define a character separator for filename components</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_T1</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 2 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_NM</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel_DTI</code></strong> :&ensp;<code>False (default) - will add a great deal</code> of <code>time -</code> or <code>h5 filename, 1 chan</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>visualize</code></strong> :&ensp;<code>True - will plot some results to png</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>nrg_modality_list</code></strong> :&ensp;<code>list</code> of <code>permissible modalities - always include [T1w] as base</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>writes output to disk and potentially produces figures that may be</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>captured in a ipynb / html file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_nrg(
    studyid,   # pandas data frame
    sourcedir = os.path.expanduser( &#34;~/data/PPMI/MV/example_s3_b/images/PPMI/&#34; ),
    sourcedatafoldername = &#39;images&#39;, # root for source data
    processDir = &#34;processed&#34;, # where output will go - parallel to sourcedatafoldername
    mysep = &#39;-&#39;, # define a separator for filename components
    srmodel_T1 = False, # optional - will add a great deal of time
    srmodel_NM = False, # optional - will add a great deal of time
    srmodel_DTI = False, # optional - will add a great deal of time
    visualize = True,
    nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;DTI&#34;,&#34;T2Flair&#34; ],
    verbose = True
):
    &#34;&#34;&#34;
    too dangerous to document ... use with care.

    processes multiple modality MRI specifically:

    * T1w
    * T2Flair
    * DTI, DTI_LR, DTI_RL
    * rsfMRI, rsfMRI_LR, rsfMRI_RL
    * NM2DMT (neuromelanin)

    other modalities may be added later ...

    &#34;trust me, i know what i&#39;m doing&#34; - sledgehammer

    convert to pynb via:
        p2j mm.py -o

    convert the ipynb to html via:
        jupyter nbconvert ANTsPyMM/tests/mm.ipynb --execute --to html

    this function assumes NRG format for the input data ....
    we also assume that t1w hierarchical (if already done) was written
    via its standardized write function.
    NRG = https://github.com/stnava/biomedicalDataOrganization

    this function is verbose

    Parameters
    -------------

    studyid : must have columns 1. subjectID 2. date (in form 20220228) and 3. imageID
        other relevant columns include nmid1-10, rsfid1, rsfid2, dtid1, dtid2, flairid;
        these provide unique image IDs for these modalities: nm=neuromelanin, dti=diffusion tensor,
        rsf=resting state fmri, flair=T2Flair.  none of these are required. only
        t1 is required.  rsfid1/rsfid2 will be processed jointly. same for dtid1/dtid2 and nmid*.  see antspymm.generate_mm_dataframe

    sourcedir : a study specific folder containing individual subject folders

    sourcedatafoldername : root for source data e.g. &#34;images&#34;

    processDir : where output will go - parallel to sourcedatafoldername e.g.
        &#34;processed&#34;

    mysep : define a character separator for filename components

    srmodel_T1 : False (default) - will add a great deal of time - or h5 filename, 2 chan

    srmodel_NM : False (default) - will add a great deal of time - or h5 filename, 1 chan

    srmodel_DTI : False (default) - will add a great deal of time - or h5 filename, 1 chan

    visualize : True - will plot some results to png

    nrg_modality_list : list of permissible modalities - always include [T1w] as base

    verbose : boolean

    Returns
    ---------

    writes output to disk and potentially produces figures that may be
    captured in a ipynb / html file.

    &#34;&#34;&#34;
    studyid = studyid.dropna(axis=1)
    if studyid.shape[0] &lt; 1:
        raise ValueError(&#39;studyid has no rows&#39;)
    musthavecols = [&#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in studyid.keys():
            raise ValueError(&#39;studyid is missing column &#39; +musthavecols[k] )
    def makewideout( x, separator = &#39;-&#39; ):
        return x + separator + &#39;mmwide.csv&#39;
    if nrg_modality_list[0] != &#39;T1w&#39;:
        nrg_modality_list.insert(0, &#34;T1w&#34; )
    testloop = False
    counter=0
    import glob as glob
    from os.path import exists
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    test_run = False
    if test_run:
        visualize=False
    # get sid and dtid from studyid
    sid = str(studyid[&#39;subjectID&#39;].iloc[0])
    dtid = str(studyid[&#39;date&#39;].iloc[0])
    iid = str(studyid[&#39;imageID&#39;].iloc[0])
    subjectrootpath = os.path.join(sourcedir,sid, dtid)
    if verbose:
        print(&#34;subjectrootpath: &#34;+ subjectrootpath )
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    # hierarchical
    # NOTE: if there are multiple T1s for this time point, should take
    # the one with the highest resnetGrade
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, iid, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;mm_nrg cannot find the T1w with uid &#39; + iid + &#39; @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    hierfn0 = re.sub( sourcedatafoldername, processDir, t1fn)
    hierfn0 = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfn0)
    hierfn = re.sub( &#34;T1w&#34;, &#34;T1wHierarchical&#34;, hierfn0)
    hierfn = hierfn + mysep
    hierfntest = hierfn + &#39;snseg.csv&#39;
    regout = hierfn0 + mysep + &#34;syn&#34;
    templateTx = {
        &#39;fwdtransforms&#39;: [ regout+&#39;1Warp.nii.gz&#39;, regout+&#39;0GenericAffine.mat&#39;],
        &#39;invtransforms&#39;: [ regout+&#39;0GenericAffine.mat&#39;, regout+&#39;1InverseWarp.nii.gz&#39;]  }
    if verbose:
        print( &#34;REGISTRATION EXISTENCE: &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;fwdtransforms&#39;][1])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][0])) + &#34; &#34; +
            str(exists( templateTx[&#39;invtransforms&#39;][1])) )
    if verbose:
        print( hierfntest )
    hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
    hier = None
    if not hierexists and not testloop:
        subjectpropath = os.path.dirname( hierfn )
        if verbose:
            print( subjectpropath )
        os.makedirs( subjectpropath, exist_ok=True  )
        hier = antspyt1w.hierarchical( t1, hierfn, labels_to_register=None )
        antspyt1w.write_hierarchical( hier, hierfn )
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
        t1wide.to_csv( hierfn + &#39;mmwide.csv&#39; )
    ################# read the hierarchical data ###############################
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if srmodel_T1 is not False :
        hierfnSR = re.sub( sourcedatafoldername, processDir, t1fn)
        hierfnSR = re.sub( &#34;T1w&#34;, &#34;T1wHierarchicalSR&#34;, hierfnSR)
        hierfnSR = re.sub( &#34;.nii.gz&#34;, &#34;&#34;, hierfnSR)
        hierfnSR = hierfnSR + mysep
        hierfntest = hierfnSR + &#39;mtl.csv&#39;
        if verbose:
            print( hierfntest )
        hierexists = exists( hierfntest ) # FIXME should test this explicitly but we assume it here
        if not hierexists:
            subjectpropath = os.path.dirname( hierfnSR )
            if verbose:
                print( subjectpropath )
            os.makedirs( subjectpropath, exist_ok=True  )
            # hierarchical_to_sr(t1hier, sr_model, tissue_sr=False, blending=0.5, verbose=False)
            bestup = siq.optimize_upsampling_shape( ants.get_spacing(t1), modality=&#39;T1&#39; )
            mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_2chan_featvggL6_postseg_best_mdl.h5&#34;
            if isinstance( srmodel_T1, str ):
                mdlfn = os.path.join( ex_pathmm, srmodel_T1 )
            if verbose:
                print( mdlfn )
            if exists( mdlfn ):
                srmodel_T1_mdl = tf.keras.models.load_model( mdlfn, compile=False )
            else:
                print( mdlfn + &#34; does not exist - will not run.&#34;)
            hierSR = antspyt1w.hierarchical_to_sr( hier, srmodel_T1_mdl, blending=None, tissue_sr=False )
            antspyt1w.write_hierarchical( hierSR, hierfnSR )
            t1wideSR = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                    hierSR[&#39;dataframes&#39;], identifier=None )
            t1wideSR.to_csv( hierfnSR + &#39;mmwide.csv&#39; )
    hier = antspyt1w.read_hierarchical( hierfn )
    if exists( hierfn + &#39;mmwide.csv&#39; ) :
        t1wide = pd.read_csv( hierfn + &#39;mmwide.csv&#39; )
    elif not testloop:
        t1wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
                hier[&#39;dataframes&#39;], identifier=None )
    if not testloop:
        t1imgbrn = hier[&#39;brain_n4_dnz&#39;]
        t1atropos = hier[&#39;dkt_parc&#39;][&#39;tissue_segmentation&#39;]
    # loop over modalities and then unique image IDs
    # we treat NM in a &#34;special&#34; way -- aggregating repeats
    # other modalities (beyond T1) are treated individually
    nimages = len(myimgsInput)
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.&#34;)
    for overmodX in nrg_modality_list:
        counter=counter+1
        if counter &gt; (len(nrg_modality_list)+1):
            print(&#34;This is weird. &#34; + str(counter))
            return
        if overmodX == &#39;T1w&#39;:
            iidOtherMod = iid
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        elif overmodX == &#39;NM2DMT&#39; and (&#39;nmid1&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;nmid1&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            for nmnum in range(2,11):
                locnmnum = &#39;nmid&#39;+str(nmnum)
                if locnmnum in studyid.keys() :
                    iidOtherMod = str( int(studyid[locnmnum].iloc[0]) )
                    mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
                    myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;rsfMRI&#39; in overmodX and ( ( &#39;rsfid1&#39; in studyid.keys() ) or (&#39;rsfid2&#39; in studyid.keys() ) ):
            myimgsr = []
            if  &#39;rsfid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;rsfid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;rsfid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;DTI&#39; in overmodX and (  &#39;dtid1&#39; in studyid.keys() or  &#39;dtid2&#39; in studyid.keys() ):
            myimgsr = []
            if  &#39;dtid1&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid1&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
            if  &#39;dtid2&#39; in studyid.keys():
                iidOtherMod = str( int(studyid[&#39;dtid2&#39;].iloc[0]) )
                mod_search_path = os.path.join(subjectrootpath, overmodX+&#34;*&#34;, iidOtherMod, &#34;*nii.gz&#34;)
                myimgsr.append( glob.glob(mod_search_path)[0] )
        elif &#39;T2Flair&#39; in overmodX and (&#39;flairid&#39; in studyid.keys() ):
            iidOtherMod = str( int(studyid[&#39;flairid&#39;].iloc[0]) )
            mod_search_path = os.path.join(subjectrootpath, overmodX, iidOtherMod, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
        if verbose:
            print( &#34;overmod &#34; + overmodX + &#34; &#34; + iidOtherMod )
            print(f&#34;modality search path: {mod_search_path}&#34;)
        myimgsr.sort()
        if len(myimgsr) &gt; 0:
            overmodXx = str(overmodX)
            dowrite=False
            if verbose:
                print( &#39;overmodX is : &#39; + overmodXx )
                print( &#39;example image name is : &#39;  )
                print( myimgsr )
            if overmodXx == &#39;NM2DMT&#39;:
                myimgsr2 = myimgsr
                myimgsr2.sort()
                is4d = False
                temp = ants.image_read( myimgsr2[0] )
                if temp.dimension == 4:
                    is4d = True
                if len( myimgsr2 ) == 1 and not is4d: # check dimension
                    myimgsr2 = myimgsr2 + myimgsr2
                subjectpropath = os.path.dirname( myimgsr2[0] )
                subjectpropath = re.sub( sourcedatafoldername, processDir,subjectpropath )
                if verbose:
                    print( &#34;subjectpropath &#34; + subjectpropath )
                mysplit = subjectpropath.split( &#34;/&#34; )
                os.makedirs( subjectpropath, exist_ok=True  )
                mysplitCount = len( mysplit )
                project = mysplit[mysplitCount-5]
                subject = mysplit[mysplitCount-4]
                date = mysplit[mysplitCount-3]
                modality = mysplit[mysplitCount-2]
                uider = mysplit[mysplitCount-1]
                identifier = mysep.join([project, subject, date, modality ])
                identifier = identifier + &#34;_&#34; + iid
                mymm = subjectpropath + &#34;/&#34; + identifier
                mymmout = makewideout( mymm )
                if verbose and not exists( mymmout ):
                    print( &#34;NM &#34; + mymm  + &#39; execution &#39;)
                elif verbose and exists( mymmout ) :
                    print( &#34;NM &#34; + mymm + &#39; complete &#39; )
                if exists( mymmout ):
                    continue
                if is4d:
                    nmlist = ants.ndimage_to_list( mm_read( myimgsr2[0] ) )
                else:
                    nmlist = []
                    for zz in myimgsr2:
                        nmlist.append( mm_read( zz ) )
                srmodel_NM_mdl = None
                if srmodel_NM is not False:
                    bestup = siq.optimize_upsampling_shape( ants.get_spacing(nmlist[0]), modality=&#39;NM&#39;, roundit=True )
                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                    if isinstance( srmodel_NM, str ):
                        srmodel_NM = re.sub( &#34;bestup&#34;, bestup, srmodel_NM )
                        mdlfn = os.path.join( ex_pathmm, srmodel_NM )
                    if exists( mdlfn ):
                        if verbose:
                            print(mdlfn)
                        srmodel_NM_mdl = tf.keras.models.load_model( mdlfn, compile=False  )
                    else:
                        print( mdlfn + &#34; does not exist - wont use SR&#34;)
                if not testloop:
                    tabPro, normPro = mm( t1, hier,
                            nm_image_list = nmlist,
                            srmodel=srmodel_NM_mdl,
                            do_tractography=False,
                            do_kk=False,
                            do_normalization=templateTx,
                            test_run=test_run,
                            verbose=True )
                    if not test_run:
                        write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=None, separator=mysep )
                        nmpro = tabPro[&#39;NM&#39;]
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                    if visualize:
                        mysl = range( nmpro[&#39;NM_avg&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg&#39;],  nmpro[&#39;t1_to_NM&#39;], slices=mysl, axis=2, title=&#39;nm + t1&#39;, filename=mymm+mysep+&#34;NMavg.png&#34; )
                        mysl = range( nmpro[&#39;NM_avg_cropped&#39;].shape[2] )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop&#39;, filename=mymm+mysep+&#34;NMavgcrop.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;t1_to_NM&#39;], axis=2, slices=mysl, overlay_alpha=0.3, title=&#39;nm crop + t1&#39;, filename=mymm+mysep+&#34;NMavgcropt1.png&#34; )
                        ants.plot( nmpro[&#39;NM_avg_cropped&#39;], nmpro[&#39;NM_labels&#39;], axis=2, slices=mysl, title=&#39;nm crop + labels&#39;, filename=mymm+mysep+&#34;NMavgcroplabels.png&#34; )
            else :
                if len( myimgsr ) &gt; 0:
                    dowrite=False
                    myimgcount = 0
                    if len( myimgsr ) &gt; 0 :
                        myimg = myimgsr[myimgcount]
                        subjectpropath = os.path.dirname( myimg )
                        subjectpropath = re.sub( sourcedatafoldername, processDir, subjectpropath )
                        mysplit = subjectpropath.split(&#34;/&#34;)
                        mysplitCount = len( mysplit )
                        project = mysplit[mysplitCount-5]
                        date = mysplit[mysplitCount-4]
                        subject = mysplit[mysplitCount-3]
                        mymod = mysplit[mysplitCount-2] # FIXME system dependent
                        uid = mysplit[mysplitCount-1] # unique image id
                        os.makedirs( subjectpropath, exist_ok=True  )
                        if mymod == &#39;T1w&#39;:
                            identifier = mysep.join([project, date, subject, mymod, uid])
                        else:  # add the T1 unique id since that drives a lot of the analysis
                            identifier = mysep.join([project, date, subject, mymod, uid ])
                            identifier = identifier + &#34;_&#34; + iid
                        mymm = subjectpropath + &#34;/&#34; + identifier
                        mymmout = makewideout( mymm )
                        if verbose and not exists( mymmout ):
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; execution &#34; )
                            print( mymm )
                        elif verbose and exists( mymmout ) :
                            print(&#34;Modality specific processing: &#34; + mymod + &#34; complete &#34; )
                        if exists( mymmout ) :
                            continue
                        if verbose:
                            print(subjectpropath)
                            print(identifier)
                            print( myimg )
                        if not testloop:
                            img = mm_read( myimg )
                            ishapelen = len( img.shape )
                            if mymod == &#39;T1w&#39; and ishapelen == 3: # for a real run, set to True
                                if not exists( regout + &#34;logjacobian.nii.gz&#34; ) or not exists( regout+&#39;1Warp.nii.gz&#39; ):
                                    if verbose:
                                        print(&#39;start t1 registration&#39;)
                                    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
                                    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
                                    template = mm_read( templatefn )
                                    template = ants.resample_image( template, [1,1,1], use_voxels=False )
                                    t1reg = ants.registration( template, hier[&#39;brain_n4_dnz&#39;],
                                        &#34;antsRegistrationSyNQuickRepro[s]&#34;, outprefix = regout, verbose=False )
                                    myjac = ants.create_jacobian_determinant_image( template,
                                        t1reg[&#39;fwdtransforms&#39;][0], do_log=True, geom=True )
                                    image_write_with_thumbnail( myjac, regout + &#34;logjacobian.nii.gz&#34;, thumb=False )
                                    if visualize:
                                        ants.plot( ants.iMath(t1reg[&#39;warpedmovout&#39;],&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;warped to template&#39;, filename=regout+&#34;totemplate.png&#34; )
                                        ants.plot( ants.iMath(myjac,&#34;Normalize&#34;),  axis=2, nslices=21, ncol=7, crop=True, title=&#39;jacobian&#39;, filename=regout+&#34;jacobian.png&#34; )
                                if not exists( mymm + mysep + &#34;kk_norm.nii.gz&#34; ):
                                    dowrite=True
                                    if verbose:
                                        print(&#39;start kk&#39;)
                                    tabPro, normPro = mm( t1, hier,
                                        srmodel=None,
                                        do_tractography=False,
                                        do_kk=True,
                                        do_normalization=templateTx,
                                        test_run=test_run,
                                        verbose=True )
                                    if visualize:
                                        maxslice = np.min( [21, hier[&#39;brain_n4_dnz&#39;].shape[2] ] )
                                        ants.plot( hier[&#39;brain_n4_dnz&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;brain extraction&#39;, filename=mymm+mysep+&#34;brainextraction.png&#34; )
                                        ants.plot( tabPro[&#39;kk&#39;][&#39;thickness_image&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;kk&#39;,
                                        cmap=&#39;plasma&#39;, filename=mymm+mysep+&#34;kkthickness.png&#34; )
                            if mymod == &#39;T2Flair&#39; and ishapelen == 3:
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    flair_image = img,
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if visualize:
                                    maxslice = np.min( [21, img.shape[2] ] )
                                    ants.plot_ortho( img, crop=True, title=&#39;Flair&#39;, filename=mymm+mysep+&#34;flair.png&#34;, flat=True )
                                    ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_probability_map&#39;], crop=True, title=&#39;Flair + WMH&#39;, filename=mymm+mysep+&#34;flairWMH.png&#34;, flat=True )
                                    if tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;] is not None:
                                        ants.plot_ortho( img, tabPro[&#39;flair&#39;][&#39;WMH_posterior_probability_map&#39;],  crop=True, title=&#39;Flair + prior WMH&#39;, filename=mymm+mysep+&#34;flairpriorWMH.png&#34;, flat=True )
                            if ( mymod == &#39;rsfMRI_LR&#39; or mymod == &#39;rsfMRI_RL&#39; or mymod == &#39;rsfMRI&#39; )  and ishapelen == 4:
                                img2 = None
                                if len( myimgsr ) &gt; 1:
                                    img2 = mm_read( myimgsr[myimgcount+1] )
                                    ishapelen2 = len( img2.shape )
                                    if ishapelen2 != 4 :
                                        img2 = None
                                dowrite=True
                                tabPro, normPro = mm( t1, hier,
                                    rsf_image=[img,img2],
                                    srmodel=None,
                                    do_tractography=False,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                if tabPro[&#39;rsf&#39;] is not None and visualize:
                                    maxslice = np.min( [21, tabPro[&#39;rsf&#39;][&#39;meanBold&#39;].shape[2] ] )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;meanBOLD&#39;, filename=mymm+mysep+&#34;meanBOLD.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;alff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;ALFF&#39;, filename=mymm+mysep+&#34;boldALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], ants.iMath(tabPro[&#39;rsf&#39;][&#39;falff&#39;],&#34;Normalize&#34;),
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;fALFF&#39;, filename=mymm+mysep+&#34;boldfALFF.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;DefaultMode&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;DefaultMode&#39;, filename=mymm+mysep+&#34;boldDefaultMode.png&#34; )
                                    ants.plot( tabPro[&#39;rsf&#39;][&#39;meanBold&#39;], tabPro[&#39;rsf&#39;][&#39;FrontoparietalTaskControl&#39;],
                                        axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FrontoparietalTaskControl&#39;, filename=mymm+mysep+&#34;boldFrontoparietalTaskControl.png&#34;  )
                            if ( mymod == &#39;DTI_LR&#39; or mymod == &#39;DTI_RL&#39; or mymod == &#39;DTI&#39; ) and ishapelen == 4:
                                dowrite=True
                                bvalfn = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , myimg )
                                bvecfn = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , myimg )
                                imgList = [ img ]
                                bvalfnList = [ bvalfn ]
                                bvecfnList = [ bvecfn ]
                                if len( myimgsr ) &gt; 1:  # find DTI_RL
                                    dtilrfn = myimgsr[myimgcount+1]
                                    if len( dtilrfn ) == 1:
                                        bvalfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bval&#39; , dtilrfn )
                                        bvecfnRL = re.sub( &#39;.nii.gz&#39;, &#39;.bvec&#39; , dtilrfn )
                                        imgRL = ants.image_read( dtilrfn )
                                        imgList.append( imgRL )
                                        bvalfnList.append( bvalfnRL )
                                        bvecfnList.append( bvecfnRL )
                                srmodel_DTI_mdl=None
                                if srmodel_DTI is not False:
                                    temp = ants.get_spacing(img)
                                    dtspc=[temp[0],temp[1],temp[2]]
                                    bestup = siq.optimize_upsampling_shape( dtspc, modality=&#39;DTI&#39; )
                                    mdlfn = ex_pathmm + &#34;siq_default_sisr_&#34; + bestup + &#34;_1chan_featvggL6_best_mdl.h5&#34;
                                    if isinstance( srmodel_DTI, str ):
                                        srmodel_DTI = re.sub( &#34;bestup&#34;, bestup, srmodel_DTI )
                                        mdlfn = os.path.join( ex_pathmm, srmodel_DTI )
                                    if exists( mdlfn ):
                                        if verbose:
                                            print(mdlfn)
                                        srmodel_DTI_mdl = tf.keras.models.load_model( mdlfn, compile=False )
                                    else:
                                        print(mdlfn + &#34; does not exist - wont use SR&#34;)
                                tabPro, normPro = mm( t1, hier,
                                    dw_image=imgList,
                                    bvals = bvalfnList,
                                    bvecs = bvecfnList,
                                    srmodel=srmodel_DTI_mdl,
                                    do_tractography=not test_run,
                                    do_kk=False,
                                    do_normalization=templateTx,
                                    test_run=test_run,
                                    verbose=True )
                                mydti = tabPro[&#39;DTI&#39;]
                                if visualize:
                                    maxslice = np.min( [21, mydti[&#39;recon_fa&#39;] ] )
                                    ants.plot( mydti[&#39;recon_fa&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA (supposed to be better)&#39;, filename=mymm+mysep+&#34;FAbetter.png&#34;  )
                                    ants.plot( mydti[&#39;recon_fa&#39;], mydti[&#39;jhu_labels&#39;], axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;FA + JHU&#39;, filename=mymm+mysep+&#34;FAJHU.png&#34;  )
                                    ants.plot( mydti[&#39;recon_md&#39;],  axis=2, nslices=maxslice, ncol=7, crop=True, title=&#39;MD&#39;, filename=mymm+mysep+&#34;MD.png&#34;  )
                            if dowrite:
                                write_mm( output_prefix=mymm, mm=tabPro, mm_norm=normPro, t1wide=t1wide, separator=mysep )
                                for mykey in normPro.keys():
                                    if normPro[mykey] is not None:
                                        if visualize:
                                            ants.plot( template, normPro[mykey], axis=2, nslices=21, ncol=7, crop=True, title=mykey, filename=mymm+mysep+mykey+&#34;.png&#34;   )
        if overmodX == nrg_modality_list[ len( nrg_modality_list ) - 1 ]:
            return
        if verbose:
            print(&#34;done with &#34; + overmodX )
    if verbose:
        print(&#34;mm_nrg complete.&#34;)
    return</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_read"><code class="name flex">
<span>def <span class="ident">mm_read</span></span>(<span>x, standardize_intensity=False, modality='')</span>
</code></dt>
<dd>
<div class="desc"><p>read an image from a filename - same as ants.image_read (for now)</p>
<p>standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one</p>
<p>modality : not used</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_read( x, standardize_intensity=False, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - same as ants.image_read (for now)

    standardize_intensity : boolean ; if True will set negative values to zero and normalize into the range of zero to one

    modality : not used
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if standardize_intensity:
        img[img&lt;0.0]=0.0
        img=ants.iMath(img,&#39;Normalize&#39;)
    if modality == &#34;T1w&#34; and img.dimension == 4:
        print(&#34;WARNING: input image is 4D - we attempt a hack fix that works in some odd cases of PPMI data - please check this image: &#34; + x, flush=True )
        i1=ants.slice_image(img,3,0)
        i2=ants.slice_image(img,3,1)
        kk=np.concatenate( [i1.numpy(),i2.numpy()], axis=2 )
        kk=ants.from_numpy(kk)
        img=ants.copy_image_info(i1,kk)
    return img</code></pre>
</details>
</dd>
<dt id="antspymm.mm.mm_read_to_3d"><code class="name flex">
<span>def <span class="ident">mm_read_to_3d</span></span>(<span>x, slice=None, modality='')</span>
</code></dt>
<dd>
<div class="desc"><p>read an image from a filename - and return as 3d or None if that is not possible</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mm_read_to_3d( x, slice=None, modality=&#39;&#39; ):
    &#34;&#34;&#34;
    read an image from a filename - and return as 3d or None if that is not possible
    &#34;&#34;&#34;
    img = ants.image_read( x, reorient=False )
    if img.dimension &lt; 3:
        return None
    elif img.dimension == 4:
        nslices = img.shape[3]
        if slice is None:
            sl = np.round( nslices * 0.5 )
        else:
            sl = slice
        if sl &gt; nslices:
            sl = nslices-1
        return ants.slice_image( img, axis=3, idx=int(sl) )
    elif img.dimension == 3:
        return img
    return None</code></pre>
</details>
</dd>
<dt id="antspymm.mm.neuromelanin"><code class="name flex">
<span>def <span class="ident">neuromelanin</span></span>(<span>list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8, bias_correct=True, denoise=None, srmodel=None, target_range=[0, 1], poly_order='hist', normalize_nm=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs the averaged and registered neuromelanin image, and neuromelanin labels</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>list_nm_image</code></strong> :&ensp;<code>list</code> of <code>ANTsImages</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>list of neuromenlanin repeat images</p>
<dl>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 brain image</p>
<dl>
<dt><strong><code>t1_head</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 head image</p>
<dl>
<dt><strong><code>t1lab</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>t1 labels that will be propagated to the NM</p>
<dl>
<dt><strong><code>brain_stem_dilation</code></strong> :&ensp;<code>integer default 8</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>dilates the brain stem mask to better match coverage of NM</p>
<dl>
<dt><strong><code>bias_correct</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>denoise</code></strong> :&ensp;<code>None</code> or <code>integer</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>None -- this is a work in progress feature, probably not optimal</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>poly_order</code></strong> :&ensp;<code>if not None, will fit a global regression model to map</code></dt>
<dd>intensity back to original histogram space; if 'hist' will match
by histogram matching - ants.histogram_match_image</dd>
<dt><strong><code>normalize_nm</code></strong> :&ensp;<code>boolean - WIP not validated</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Averaged and registered <a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> image and <a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin()</a> labels and wide csv</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def neuromelanin( list_nm_images, t1, t1_head, t1lab, brain_stem_dilation=8,
    bias_correct=True,
    denoise=None,
    srmodel=None,
    target_range=[0,1],
    poly_order=&#39;hist&#39;,
    normalize_nm = False,
    verbose=False ) :

  &#34;&#34;&#34;
  Outputs the averaged and registered neuromelanin image, and neuromelanin labels

  Arguments
  ---------
  list_nm_image : list of ANTsImages
    list of neuromenlanin repeat images

  t1 : ANTsImage
    input 3-D T1 brain image

  t1_head : ANTsImage
    input 3-D T1 head image

  t1lab : ANTsImage
    t1 labels that will be propagated to the NM

  brain_stem_dilation : integer default 8
    dilates the brain stem mask to better match coverage of NM

  bias_correct : boolean

  denoise : None or integer

  srmodel : None -- this is a work in progress feature, probably not optimal

  target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

  poly_order : if not None, will fit a global regression model to map
      intensity back to original histogram space; if &#39;hist&#39; will match
      by histogram matching - ants.histogram_match_image

  normalize_nm : boolean - WIP not validated

  verbose : boolean

  Returns
  ---------
  Averaged and registered neuromelanin image and neuromelanin labels and wide csv

  &#34;&#34;&#34;

  fnt=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni.nii.gz&#34; )
  fntNM=os.path.expanduser(&#34;~/.antspymm/CIT168_T1w_700um_pad_adni_NM_norm_avg.nii.gz&#34; )
  fntbst=os.path.expanduser(&#34;~/.antspyt1w/CIT168_T1w_700um_pad_adni_brainstem.nii.gz&#34;)
  fnslab=os.path.expanduser(&#34;~/.antspyt1w/CIT168_MT_Slab_adni.nii.gz&#34;)
  fntseg=os.path.expanduser(&#34;~/.antspyt1w/det_atlas_25_pad_LR_adni.nii.gz&#34;)

  template = mm_read( fnt )
  templateNM = ants.iMath( mm_read( fntNM ), &#34;Normalize&#34; )
  templatebstem = mm_read( fntbst ).threshold_image( 1, 1000 )
  # reg = ants.registration( t1, template, &#39;antsRegistrationSyNQuickRepro[s]&#39; )
  reg = ants.registration( t1, template, &#39;SyN&#39; )
  # map NM avg to t1 for neuromelanin processing
  nmavg2t1 = ants.apply_transforms( t1, templateNM,
    reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39; )
  slab2t1 = ants.threshold_image( nmavg2t1, &#34;Otsu&#34;, 2 ).threshold_image(1,2).iMath(&#34;MD&#34;,1).iMath(&#34;FillHoles&#34;)
  # map brain stem and slab to t1 for neuromelanin processing
  bstem2t1 = ants.apply_transforms( t1, templatebstem,
    reg[&#39;fwdtransforms&#39;],
    interpolator=&#39;nearestNeighbor&#39; ).iMath(&#34;MD&#34;,1)
  slab2t1B = ants.apply_transforms( t1, mm_read( fnslab ),
    reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39;)
  bstem2t1 = ants.crop_image( bstem2t1, slab2t1 )
  cropper = ants.decrop_image( bstem2t1, slab2t1 ).iMath(&#34;MD&#34;,brain_stem_dilation)

  # Average images in image_list
  nm_avg = list_nm_images[0]*0.0
  for k in range(len( list_nm_images )):
    if denoise is not None:
        list_nm_images[k] = ants.denoise_image( list_nm_images[k],
            shrink_factor=1,
            p=denoise,
            r=denoise+1,
            noise_model=&#39;Gaussian&#39; )
    if bias_correct :
        n4mask = ants.threshold_image( ants.iMath(list_nm_images[k], &#34;Normalize&#34; ), 0.05, 1 )
        list_nm_images[k] = ants.n4_bias_field_correction( list_nm_images[k], mask=n4mask )
    nm_avg = nm_avg + ants.resample_image_to_target( list_nm_images[k], nm_avg ) / len( list_nm_images )

  if verbose:
      print(&#34;Register each nm image in list_nm_images to the averaged nm image (avg)&#34;)
  nm_avg_new = nm_avg * 0.0
  txlist = []
  for k in range(len( list_nm_images )):
    if verbose:
        print(str(k) + &#34; of &#34; + str(len( list_nm_images ) ) )
    current_image = ants.registration( list_nm_images[k], nm_avg,
        type_of_transform = &#39;Rigid&#39; )
    txlist.append( current_image[&#39;fwdtransforms&#39;][0] )
    current_image = current_image[&#39;warpedfixout&#39;]
    nm_avg_new = nm_avg_new + current_image / len( list_nm_images )
  nm_avg = nm_avg_new

  if verbose:
      print(&#34;do slab registration to map anatomy to NM space&#34;)
  t1c = ants.crop_image( t1_head, slab2t1 ).iMath(&#34;Normalize&#34;) # old way
  nmavg2t1c = ants.crop_image( nmavg2t1, slab2t1 ).iMath(&#34;Normalize&#34;)
  # slabreg = ants.registration( nm_avg, nmavg2t1c, &#39;Rigid&#39; )
  slabreg = tra_initializer( nm_avg, t1c, verbose=verbose )
  if False:
      slabregT1 = tra_initializer( nm_avg, t1c, verbose=verbose  )
      miNM = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg0[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      miT1 = ants.image_mutual_information( ants.iMath(nm_avg,&#34;Normalize&#34;),
            ants.iMath(slabreg1[&#39;warpedmovout&#39;],&#34;Normalize&#34;) )
      if miT1 &lt; miNM:
        slabreg = slabregT1
  labels2nm = ants.apply_transforms( nm_avg, t1lab, slabreg[&#39;fwdtransforms&#39;],
    interpolator = &#39;genericLabel&#39; )
  cropper2nm = ants.apply_transforms( nm_avg, cropper, slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )
  nm_avg_cropped = ants.crop_image( nm_avg, cropper2nm )

  if verbose:
      print(&#34;now map these labels to each individual nm&#34;)
  crop_mask_list = []
  crop_nm_list = []
  for k in range(len( list_nm_images )):
      concattx = []
      concattx.append( txlist[k] )
      concattx.append( slabreg[&#39;fwdtransforms&#39;][0] )
      cropmask = ants.apply_transforms( list_nm_images[k], cropper,
        concattx, interpolator = &#39;nearestNeighbor&#39; )
      crop_mask_list.append( cropmask )
      temp = ants.crop_image( list_nm_images[k], cropmask )
      crop_nm_list.append( temp )

  if srmodel is not None:
      if verbose:
          print( &#34; start sr &#34; + str(len( crop_nm_list )) )
      for k in range(len( crop_nm_list )):
          if verbose:
              print( &#34; do sr &#34; + str(k) )
              print( crop_nm_list[k] )
          temp = antspynet.apply_super_resolution_model_to_image(
                crop_nm_list[k], srmodel, target_range=target_range,
                regression_order=None )
          if poly_order is not None:
              bilin = ants.resample_image_to_target( crop_nm_list[k], temp )
              if poly_order == &#39;hist&#39;:
                  temp = ants.histogram_match_image( temp, bilin )
              else:
                  temp = antspynet.regression_match_image( temp, bilin, poly_order = poly_order )
          crop_nm_list[k] = temp

  nm_avg_cropped = crop_nm_list[0]*0.0
  if verbose:
      print( &#34;cropped average&#34; )
      print( nm_avg_cropped )
  for k in range(len( crop_nm_list )):
      nm_avg_cropped = nm_avg_cropped + ants.apply_transforms( nm_avg_cropped,
        crop_nm_list[k], txlist[k] ) / len( crop_nm_list )
  for loop in range( 3 ):
      nm_avg_cropped_new = nm_avg_cropped * 0.0
      for k in range(len( crop_nm_list )):
            myreg = ants.registration(
                ants.iMath(nm_avg_cropped,&#34;Normalize&#34;),
                ants.iMath(crop_nm_list[k],&#34;Normalize&#34;),
                &#39;BOLDRigid&#39; )
            warpednext = ants.apply_transforms(
                nm_avg_cropped_new,
                crop_nm_list[k],
                myreg[&#39;fwdtransforms&#39;] )
            nm_avg_cropped_new = nm_avg_cropped_new + warpednext
      nm_avg_cropped = nm_avg_cropped_new / len( crop_nm_list )

  slabregUpdated = tra_initializer( nm_avg_cropped, t1c, verbose=verbose  )
  tempOrig = ants.apply_transforms( nm_avg_cropped_new, t1c, slabreg[&#39;fwdtransforms&#39;] )
  tempUpdate = ants.apply_transforms( nm_avg_cropped_new, t1c, slabregUpdated[&#39;fwdtransforms&#39;] )
  miUpdate = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempUpdate,&#34;Normalize&#34;) )
  miOrig = ants.image_mutual_information(
    ants.iMath(nm_avg_cropped,&#34;Normalize&#34;), ants.iMath(tempOrig,&#34;Normalize&#34;) )
  if miUpdate &lt; miOrig :
      slabreg = slabregUpdated

  if normalize_nm:
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;TruncateIntensity&#34;,0.05,0.95)
      nm_avg_cropped = ants.iMath( nm_avg_cropped, &#34;Normalize&#34; )

  labels2nm = ants.apply_transforms( nm_avg_cropped, t1lab,
        slabreg[&#39;fwdtransforms&#39;], interpolator=&#39;nearestNeighbor&#39; )

  # fix the reference region - keep top two parts
  def get_biggest_part( x, labeln ):
      temp33 = ants.threshold_image( x, labeln, labeln ).iMath(&#34;GetLargestComponent&#34;)
      x[ x == labeln] = 0
      x[ temp33 == 1 ] = labeln

  get_biggest_part( labels2nm, 33 )
  get_biggest_part( labels2nm, 34 )

  if verbose:
      print( &#34;map summary measurements to wide format&#34; )
  nmdf = antspyt1w.map_intensity_to_dataframe(
          &#39;CIT168_Reinf_Learn_v1_label_descriptions_pad&#39;,
          nm_avg_cropped,
          labels2nm)
  if verbose:
      print( &#34;merge to wide format&#34; )
  nmdf_wide = antspyt1w.merge_hierarchical_csvs_to_wide_format(
              {&#39;NM&#39; : nmdf},
              col_names = [&#39;Mean&#39;] )
  if verbose:
      print( &#34;nm done&#34; )

  rr_mask = ants.mask_image( labels2nm, labels2nm, [33,34] , binarize=True )
  sn_mask = ants.mask_image( labels2nm, labels2nm, [7,9,23,25] , binarize=True )
  nmavgsnr = mask_snr( nm_avg_cropped, rr_mask, sn_mask, bias_correct = False )

  snavg = nm_avg_cropped[ sn_mask == 1].mean()
  rravg = nm_avg_cropped[ rr_mask == 1].mean()
  snstd = nm_avg_cropped[ sn_mask == 1].std()
  rrstd = nm_avg_cropped[ rr_mask == 1].std()
  snvol = np.prod( ants.get_spacing(sn_mask) ) * sn_mask.sum()

  # get the mean voxel position of the SN
  if snvol &gt; 0:
      sn_z = ants.transform_physical_point_to_index( sn_mask, ants.get_center_of_mass(sn_mask ))[2]
      sn_z = sn_z/sn_mask.shape[2] # around 0.5 would be nice
  else:
      sn_z = math.nan

  nm_evr = antspyt1w.patch_eigenvalue_ratio( nm_avg, 512, [6,6,6], evdepth = 0.9, mask=cropper2nm )

  return{
      &#39;NM_avg&#39; : nm_avg,
      &#39;NM_avg_cropped&#39; : nm_avg_cropped,
      &#39;NM_labels&#39;: labels2nm,
      &#39;NM_cropped&#39;: crop_nm_list,
      &#39;NM_midbrainROI&#39;: cropper2nm,
      &#39;NM_dataframe&#39;: nmdf,
      &#39;NM_dataframe_wide&#39;: nmdf_wide,
      &#39;t1_to_NM&#39;: slabreg[&#39;warpedmovout&#39;],
      &#39;t1_to_NM_transform&#39; : slabreg[&#39;fwdtransforms&#39;],
      &#39;NM_avg_signaltonoise&#39; : nmavgsnr,
      &#39;NM_avg_substantianigra&#39; : snavg,
      &#39;NM_std_substantianigra&#39; : snstd,
      &#39;NM_volume_substantianigra&#39; : snvol,
      &#39;NM_avg_refregion&#39; : rravg,
      &#39;NM_std_refregion&#39; : rrstd,
      &#39;NM_min&#39; : nm_avg_cropped.min(),
      &#39;NM_max&#39; : nm_avg_cropped.max(),
      &#39;NM_mean&#39; : nm_avg_cropped.numpy().mean(),
      &#39;NM_sd&#39; : math.sqrt( nm_avg_cropped.numpy().mean() ),
      &#39;NM_q0pt05&#39; : np.quantile( nm_avg_cropped.numpy(), 0.05 ),
      &#39;NM_q0pt10&#39; : np.quantile( nm_avg_cropped.numpy(), 0.10 ),
      &#39;NM_q0pt90&#39; : np.quantile( nm_avg_cropped.numpy(), 0.90 ),
      &#39;NM_q0pt95&#39; : np.quantile( nm_avg_cropped.numpy(), 0.95 ),
      &#39;NM_substantianigra_z_coordinate&#39; : sn_z,
      &#39;NM_evr&#39; : nm_evr,
      &#39;NM_count&#39;: len( list_nm_images )
       }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_ee"><code class="name flex">
<span>def <span class="ident">novelty_detection_ee</span></span>(<span>df_train, df_test, contamination=0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Elliptic Envelope.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)</p>
</li>
</ul>
<p>Returns:</p>
<p>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_ee(df_train, df_test, contamination=0.05):
    &#34;&#34;&#34;
    This function performs novelty detection using Elliptic Envelope.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - contamination (float): parameter controlling the proportion of outliers in the data (default: 0.05)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    import pandas as pd
    from sklearn.covariance import EllipticEnvelope
    # Fit the model on the training data
    clf = EllipticEnvelope(contamination=contamination,support_fraction=1)
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_lof"><code class="name flex">
<span>def <span class="ident">novelty_detection_lof</span></span>(<span>df_train, df_test, n_neighbors=20)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Local Outlier Factor (LOF).</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>n_neighbors (int): number of neighbors used to compute the LOF (default: 20)</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_lof(df_train, df_test, n_neighbors=20):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOF (default: 20)

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, algorithm=&#39;auto&#39;,contamination=&#39;auto&#39;, novelty=True)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_loop"><code class="name flex">
<span>def <span class="ident">novelty_detection_loop</span></span>(<span>df_train, df_test, n_neighbors=20, distance_metric='minkowski')</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using Local Outlier Factor (LOF).</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)</p>
</li>
<li>
<p>distance_metric : default minkowski</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_loop(df_train, df_test, n_neighbors=20, distance_metric=&#39;minkowski&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using Local Outlier Factor (LOF).

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - n_neighbors (int): number of neighbors used to compute the LOOP (default: 20)

    - distance_metric : default minkowski

    Returns:

    - predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)

    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    data = np.vstack( [scaler.transform(df_test),scaler.transform(df_train)])
    neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=distance_metric)
    neigh.fit(data)
    d, idx = neigh.kneighbors(data, return_distance=True)
    m = loop.LocalOutlierProbability(distance_matrix=d, neighbor_matrix=idx, n_neighbors=n_neighbors).fit()
    return m.local_outlier_probabilities[range(df_test.shape[0])]</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_quantile"><code class="name flex">
<span>def <span class="ident">novelty_detection_quantile</span></span>(<span>df_train, df_test)</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using quantiles for each column.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li>quantiles for the test sample at each column where values range in [0,1]
and higher values mean the column is closer to the edge of the distribution</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_quantile(df_train, df_test):
    &#34;&#34;&#34;
    This function performs novelty detection using quantiles for each column.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    Returns:

    - quantiles for the test sample at each column where values range in [0,1]
        and higher values mean the column is closer to the edge of the distribution

    &#34;&#34;&#34;
    myqs = df_test.copy()
    n = df_train.shape[0]
    df_trainkeys = df_train.keys()
    for k in range( df_train.shape[1] ):
        mykey = df_trainkeys[k]
        temp = (myqs[mykey][0] &gt;  df_train[mykey]).sum() / n
        myqs[mykey] = abs( temp - 0.5 ) / 0.5
    return myqs</code></pre>
</details>
</dd>
<dt id="antspymm.mm.novelty_detection_svm"><code class="name flex">
<span>def <span class="ident">novelty_detection_svm</span></span>(<span>df_train, df_test, nu=0.05, kernel='rbf')</span>
</code></dt>
<dd>
<div class="desc"><p>This function performs novelty detection using One-Class SVM.</p>
<p>Parameters:</p>
<ul>
<li>
<p>df_train (pandas dataframe): training data used to fit the model</p>
</li>
<li>
<p>df_test (pandas dataframe): test data used to predict novelties</p>
</li>
<li>
<p>nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)</p>
</li>
<li>
<p>kernel (str): kernel type used in the SVM algorithm (default: 'rbf')</p>
</li>
</ul>
<p>Returns:</p>
<p>predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def novelty_detection_svm(df_train, df_test, nu=0.05, kernel=&#39;rbf&#39;):
    &#34;&#34;&#34;
    This function performs novelty detection using One-Class SVM.

    Parameters:

    - df_train (pandas dataframe): training data used to fit the model

    - df_test (pandas dataframe): test data used to predict novelties

    - nu (float): parameter controlling the fraction of training errors and the fraction of support vectors (default: 0.05)

    - kernel (str): kernel type used in the SVM algorithm (default: &#39;rbf&#39;)

    Returns:

    predictions (pandas series): predicted labels for the test data (1 for novelties, 0 for inliers)
    &#34;&#34;&#34;
    from sklearn.svm import OneClassSVM
    # Fit the model on the training data
    df_train[ df_train == math.inf ] = 0
    df_test[ df_test == math.inf ] = 0
    clf = OneClassSVM(nu=nu, kernel=kernel)
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(df_train)
    clf.fit(scaler.transform(df_train))
    predictions = clf.predict(scaler.transform(df_test))
    predictions[predictions==1]=0
    predictions[predictions==-1]=1
    if str(type(df_train))==&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
        return pd.Series(predictions, index=df_test.index)
    else:
        return pd.Series(predictions)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_2_bids"><code class="name flex">
<span>def <span class="ident">nrg_2_bids</span></span>(<span>nrg_filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert an NRG filename to BIDS path/filename.</p>
<p>Parameters:
nrg_filename (str): The NRG filename to convert.</p>
<p>Returns:
str: The BIDS path/filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_2_bids( nrg_filename ):
    &#34;&#34;&#34;
    Convert an NRG filename to BIDS path/filename.

    Parameters:
    nrg_filename (str): The NRG filename to convert.

    Returns:
    str: The BIDS path/filename.
    &#34;&#34;&#34;

    # Split the NRG filename into its components
    nrg_dirname, nrg_basename = os.path.split(nrg_filename)
    nrg_suffix = &#39;.&#39; + nrg_basename.split(&#39;.&#39;,1)[-1]
    nrg_basename = nrg_basename.replace(nrg_suffix, &#39;&#39;) # remove ext
    nrg_parts = nrg_basename.split(&#39;-&#39;)
    nrg_subject_id = nrg_parts[1]
    nrg_modality = nrg_parts[3]
    nrg_repeat= nrg_parts[4]

    # Build the BIDS path/filename
    bids_dirname = os.path.join(nrg_dirname, &#39;bids&#39;)
    bids_subject = f&#39;sub-{nrg_subject_id}&#39;
    bids_session = f&#39;ses-{nrg_repeat}&#39;

    valid_modalities = get_valid_modalities()
    if nrg_modality is not None:
        if not nrg_modality in valid_modalities:
            raise ValueError(&#39;nrg_modality &#39; + str(nrg_modality) + &#34; not a valid mm modality:  &#34; + get_valid_modalities(asString=True))

    if nrg_modality == &#39;T1w&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;T1w&#39;

    if nrg_modality == &#39;T2Flair&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;flair&#39;

    if nrg_modality == &#39;NM2DMT&#39; :
        bids_modality_folder = &#39;anat&#39;
        bids_modality_filename = &#39;nm2dmt&#39;

    if nrg_modality == &#39;DTI&#39; or nrg_modality == &#39;DTI_RL&#39; or nrg_modality == &#39;DTI_LR&#39; :
        bids_modality_folder = &#39;dwi&#39;
        bids_modality_filename = &#39;dwi&#39;

    if nrg_modality == &#39;rsfMRI&#39; or nrg_modality == &#39;rsfMRI_RL&#39; or nrg_modality == &#39;rsfMRI_LR&#39; :
        bids_modality_folder = &#39;func&#39;
        bids_modality_filename = &#39;func&#39;

    bids_suffix = nrg_suffix[1:]
    bids_filename = f&#39;{bids_subject}_{bids_session}_{bids_modality_filename}.{bids_suffix}&#39;

    # Return bids filepath/filename
    return os.path.join(bids_dirname, bids_subject, bids_session, bids_modality_folder, bids_filename)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_filelist_to_dataframe"><code class="name flex">
<span>def <span class="ident">nrg_filelist_to_dataframe</span></span>(<span>filename_list, myseparator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>convert a list of files in nrg format to a dataframe</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>filename_list</code></strong> :&ensp;<code>globbed list</code> of <code>files</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>myseparator</code></strong> :&ensp;<code>string separator between nrg parts</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas data frame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_filelist_to_dataframe( filename_list, myseparator=&#34;-&#34; ):
    &#34;&#34;&#34;
    convert a list of files in nrg format to a dataframe

    Arguments
    ---------
    filename_list : globbed list of files

    myseparator : string separator between nrg parts

    Returns
    -------

    df : pandas data frame

    &#34;&#34;&#34;
    def getmtime(x):
        x= dt.datetime.fromtimestamp(os.path.getmtime(x)).strftime(&#34;%Y-%m-%d %H:%M:%d&#34;)
        return x
    df=pd.DataFrame(columns=[&#39;filename&#39;,&#39;file_last_mod_t&#39;,&#39;else&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;uid&#39;])
    df.set_index(&#39;filename&#39;)
    df[&#39;filename&#39;] = pd.Series([file for file in filename_list ])
    # I applied a time modified file to df[&#39;file_last_mod_t&#39;] by getmtime function
    df[&#39;file_last_mod_t&#39;] = df[&#39;filename&#39;].apply(lambda x: getmtime(x))
    for k in range(df.shape[0]):
        locfn=df[&#39;filename&#39;].iloc[k]
        splitter=os.path.basename(locfn).split( myseparator )
        df[&#39;sid&#39;].iloc[k]=splitter[1]
        df[&#39;visitdate&#39;].iloc[k]=splitter[2]
        df[&#39;modality&#39;].iloc[k]=splitter[3]
        temp = os.path.splitext(splitter[4])[0]
        df[&#39;uid&#39;].iloc[k]=os.path.splitext(temp)[0]
    return df</code></pre>
</details>
</dd>
<dt id="antspymm.mm.nrg_format_path"><code class="name flex">
<span>def <span class="ident">nrg_format_path</span></span>(<span>projectID, subjectID, date, modality, imageID, separator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>create the NRG path on disk given the project, subject id, date, modality and image id</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>projectID</code></strong> :&ensp;<code>string for the project e.g. PPMI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>subjectID</code></strong> :&ensp;<code>string uniquely identifying the subject e.g. 0001</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>date</code></strong> :&ensp;<code>string for the date usually 20550228 ie YYYYMMDD format</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>modality</code></strong> :&ensp;<code>string should be one</code> of <code>T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>imageID</code></strong> :&ensp;<code>string uniquely identifying the specific image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>separator</code></strong> :&ensp;<code>default to -</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>the path where one would write the image on disk</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nrg_format_path( projectID, subjectID, date, modality, imageID, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    create the NRG path on disk given the project, subject id, date, modality and image id

    Arguments
    ---------

    projectID : string for the project e.g. PPMI

    subjectID : string uniquely identifying the subject e.g. 0001

    date : string for the date usually 20550228 ie YYYYMMDD format

    modality : string should be one of T1w, T2Flair, rsfMRI, NM2DMT and DTI ... rsfMRI and DTI may also be DTI_LR, DTI_RL, rsfMRI_LR and rsfMRI_RL where the RL / LR relates to phase encoding direction (even if it is AP/PA)

    imageID : string uniquely identifying the specific image

    separator : default to -

    Returns
    -------
    the path where one would write the image on disk

    &#34;&#34;&#34;
    thedirectory = os.path.join( str(projectID), str(subjectID), str(date), str(modality), str(imageID) )
    thefilename = str(projectID) + separator + str(subjectID) + separator + str(date) + separator + str(modality) + separator + str(imageID)
    return os.path.join( thedirectory, thefilename )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.outlierness_by_modality"><code class="name flex">
<span>def <span class="ident">outlierness_by_modality</span></span>(<span>qcdf, uid='fn', outlier_columns=['noise', 'snr', 'cnr', 'psnr', 'ssim', 'mi', 'reflection_err', 'EVR', 'msk_vol'], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.
LOF appears to be more conservative.
This function will impute missing columns with the mean.</p>
<p>Args:
- qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
- uid: (str) Unique identifier for a subject. Default is 'fn'.
- outlier_columns: (list) List of columns containing outlier information. Default is ['noise', 'snr', 'cnr', 'psnr', 'ssim', 'mi', 'reflection_err', 'EVR', 'msk_vol'].
- verbose: (bool) If True, prints information for each modality. Default is False.</p>
<p>Returns:
- qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the 'ol_loop' and 'ol_lof' column.
Higher values near 1 are more outlying.</p>
<p>Raises:
- ValueError: If uid is not present in the dataframe.</p>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = pd.read_csv('data.csv')
&gt;&gt;&gt; outlierness_by_modality(df)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def outlierness_by_modality( qcdf, uid=&#39;fn&#39;, outlier_columns = [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;,&#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;], verbose=False ):
    &#34;&#34;&#34;
    Calculates outlierness scores for each modality in a dataframe based on given outlier columns using antspyt1w.loop_outlierness() and LOF.  LOF appears to be more conservative.  This function will impute missing columns with the mean.

    Args:
    - qcdf: (Pandas DataFrame) Dataframe containing columns with outlier information for each modality.
    - uid: (str) Unique identifier for a subject. Default is &#39;fn&#39;.
    - outlier_columns: (list) List of columns containing outlier information. Default is [&#39;noise&#39;, &#39;snr&#39;, &#39;cnr&#39;, &#39;psnr&#39;, &#39;ssim&#39;, &#39;mi&#39;, &#39;reflection_err&#39;, &#39;EVR&#39;, &#39;msk_vol&#39;].
    - verbose: (bool) If True, prints information for each modality. Default is False.

    Returns:
    - qcdf: (Pandas DataFrame) Updated dataframe with outlierness scores for each modality in the &#39;ol_loop&#39; and &#39;ol_lof&#39; column.  Higher values near 1 are more outlying.

    Raises:
    - ValueError: If uid is not present in the dataframe.

    Example:
    &gt;&gt;&gt; df = pd.read_csv(&#39;data.csv&#39;)
    &gt;&gt;&gt; outlierness_by_modality(df)
    &#34;&#34;&#34;
    from PyNomaly import loop
    from sklearn.neighbors import LocalOutlierFactor
    qcdfout = qcdf.copy()
    if uid not in qcdfout.keys():
        raise ValueError(uid + &#34; not in dataframe&#34;)
    if &#39;ol_loop&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_loop&#39;]=math.nan
    if &#39;ol_lof&#39; not in qcdfout.keys():
        qcdfout[&#39;ol_lof&#39;]=math.nan
    for mod in get_valid_modalities( qc=True ):
        lof = LocalOutlierFactor()
        locsel = qcdfout[&#34;modality&#34;] == mod
        rr = qcdfout[locsel][outlier_columns]
        with pd.option_context(&#39;mode.use_inf_as_na&#39;, True):
            for myolcol in outlier_columns:
                rr[myolcol].fillna(rr[myolcol].mean(), inplace=True)
        if rr.shape[0] &gt; 1:
            if verbose:
                print(mod)
            myneigh = np.min( [24, int(np.round(rr.shape[0]*0.5)) ] )
            temp = antspyt1w.loop_outlierness(rr.astype(float), standardize=True, extent=3, n_neighbors=myneigh, cluster_labels=None)
            qcdfout.loc[locsel,&#39;ol_loop&#39;]=temp
            yhat = lof.fit_predict(rr)
            temp = lof.negative_outlier_factor_*(-1.0)
            temp = temp - temp.min()
            yhat[ yhat == 1] = 0
            yhat[ yhat == -1] = 1 # these are outliers
            qcdfout.loc[locsel,&#39;ol_lof_decision&#39;]=yhat
            qcdfout.loc[locsel,&#39;ol_lof&#39;]=temp/temp.max()
    return qcdfout</code></pre>
</details>
</dd>
<dt id="antspymm.mm.parse_nrg_filename"><code class="name flex">
<span>def <span class="ident">parse_nrg_filename</span></span>(<span>x, separator='-')</span>
</code></dt>
<dd>
<div class="desc"><p>split a NRG filename into its named parts</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_nrg_filename( x, separator=&#39;-&#39; ):
    &#34;&#34;&#34;
    split a NRG filename into its named parts
    &#34;&#34;&#34;
    temp = x.split( separator )
    if len(temp) != 5:
        raise ValueError(x + &#34; not a valid NRG filename&#34;)
    return {
        &#39;project&#39;:temp[0],
        &#39;subjectID&#39;:temp[1],
        &#39;date&#39;:temp[2],
        &#39;modality&#39;:temp[3],
        &#39;imageID&#39;:temp[4]
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.quantile_snr"><code class="name flex">
<span>def <span class="ident">quantile_snr</span></span>(<span>x, lowest_quantile=0.01, low_quantile=0.1, high_quantile=0.5, highest_quantile=0.95)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate signal to noise ratio (SNR) in an image.
Estimates noise from a background mask which is a
dilation of the foreground mask minus the foreground mask.
Actually estimates the reciprocal of the coefficient of variation.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>lowest_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>low_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>high_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>highest_quantile</code></strong> :&ensp;<code>float value &lt; 1 and &gt; 0</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantile_snr( x,
    lowest_quantile=0.01,
    low_quantile=0.1,
    high_quantile=0.5,
    highest_quantile=0.95 ):
    &#34;&#34;&#34;

    Estimate signal to noise ratio (SNR) in an image.
    Estimates noise from a background mask which is a
    dilation of the foreground mask minus the foreground mask.
    Actually estimates the reciprocal of the coefficient of variation.

    Arguments
    ---------

    x : an antsImage

    lowest_quantile : float value &lt; 1 and &gt; 0

    low_quantile : float value &lt; 1 and &gt; 0

    high_quantile : float value &lt; 1 and &gt; 0

    highest_quantile : float value &lt; 1 and &gt; 0

    &#34;&#34;&#34;
    import numpy as np
    xshp = x.shape
    xbc = ants.iMath( x - x.min(), &#34;Normalize&#34; )
    xbc = ants.n3_bias_field_correction( xbc )
    xbc = ants.iMath( xbc - xbc.min(), &#34;Normalize&#34; )
    y = xbc.numpy()
    ylowest = np.quantile( y[y&gt;0], lowest_quantile )
    ylo = np.quantile( y[y&gt;0], low_quantile )
    yhi = np.quantile( y[y&gt;0], high_quantile )
    yhiest = np.quantile( y[y&gt;0], highest_quantile )
    xbkgmask = ants.threshold_image( xbc, ylowest, ylo )
    fgmask = ants.threshold_image( xbc, yhi, yhiest )
    signal = (xbc[ fgmask == 1] ).mean()
    noise = (xbc[ xbkgmask == 1] ).std()
    return signal / noise</code></pre>
</details>
</dd>
<dt id="antspymm.mm.quick_viz_mm_nrg"><code class="name flex">
<span>def <span class="ident">quick_viz_mm_nrg</span></span>(<span>sourcedir, projectid, sid, dtid, extract_brain=True, slice_factor=0.55, show_it=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>This function creates visualizations of brain images for a specific subject in a project using ANTsPy.</p>
<p>Args:</p>
<p>sourcedir (str): Root folder.</p>
<p>projectid (str): Project name.</p>
<p>sid (str): Subject unique id.</p>
<p>dtid (str): Date.</p>
<p>extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.</p>
<p>slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.</p>
<p>show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.</p>
<p>verbose (bool): If True, information will be printed while running the function. Default is True.</p>
<p>Returns:
vizlist (list): List of image visualizations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quick_viz_mm_nrg(
    sourcedir, # root folder
    projectid, # project name
    sid , # subject unique id
    dtid, # date
    extract_brain=True,
    slice_factor = 0.55,
    show_it = None, # output path
    verbose = True
):
    &#34;&#34;&#34;
    This function creates visualizations of brain images for a specific subject in a project using ANTsPy.

    Args:

    sourcedir (str): Root folder.
    
    projectid (str): Project name.
    
    sid (str): Subject unique id.
    
    dtid (str): Date.
    
    extract_brain (bool): If True, the function extracts the brain from the T1w image. Default is True.
    
    slice_factor (float): The slice to be visualized is determined by multiplying the image size by this factor. Default is 0.55.
    
    show_it (str): Output path. If not None, the visualizations will be saved at this location. Default is None.
    
    verbose (bool): If True, information will be printed while running the function. Default is True.

    Returns:
    vizlist (list): List of image visualizations.

    &#34;&#34;&#34;
    iid=&#39;*&#39;
    import glob as glob
    from os.path import exists
    import ants
    ex_path = os.path.expanduser( &#34;~/.antspyt1w/&#34; )
    ex_pathmm = os.path.expanduser( &#34;~/.antspymm/&#34; )
    templatefn = ex_path + &#39;CIT168_T1w_700um_pad_adni.nii.gz&#39;
    if not exists( templatefn ):
        print( &#34;**missing files** =&gt; call get_data from latest antspyt1w and antspymm.&#34; )
        antspyt1w.get_data( force_download=True )
        get_data( force_download=True )
    temp = sourcedir.split( &#34;/&#34; )
    splitCount = len( temp )
    template = mm_read( templatefn ) # Read in template
    subjectrootpath = os.path.join(sourcedir, projectid, sid, dtid)
    myimgsInput = glob.glob( subjectrootpath+&#34;/*&#34; )
    myimgsInput.sort( )
    if verbose:
        print( myimgsInput )
    t1_search_path = os.path.join(subjectrootpath, &#34;T1w&#34;, &#34;*&#34;, &#34;*nii.gz&#34;)
    if verbose:
        print(f&#34;t1 search path: {t1_search_path}&#34;)
    t1fn = glob.glob(t1_search_path)
    t1fn.sort()
    if len( t1fn ) &lt; 1:
        raise ValueError(&#39;quick_viz_mm_nrg cannot find the T1w @ &#39; + subjectrootpath )
    t1fn = t1fn[0]
    t1 = mm_read( t1fn )
    nimages = len(myimgsInput)
    vizlist=[]
    if verbose:
        print(  &#34; we have : &#34; + str(nimages) + &#34; modalities.  will visualize T1 NM rsfMRI DTIB0 DTIDWI FLAIR&#34;)
    # nrg_modality_list = [&#34;T1w&#34;, &#34;NM2DMT&#34;, &#34;rsfMRI&#34;,&#34;rsfMRI_LR&#34;,&#34;rsfMRI_RL&#34;,&#34;DTI&#34;,&#34;DTI_LR&#34;, &#34;T2Flair&#34; ],
    nrg_modality_list = [ &#39;T1w&#39;, &#39;NM2DMT&#39;, &#39;rsfMRI&#39;, &#39;DWI1&#39;, &#39;DWI2&#39;, &#39;T2Flair&#39; ]
    for nrgNum in [0,1,2,3,4,5]:
        overmodX = nrg_modality_list[nrgNum]
        if overmodX == &#39;T1w&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, iid, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) == 0:
                if verbose:
                    print(&#34;No t1 images: &#34; + sid + dtid )
                return None
            myimgsr.sort()
            myimgsr=myimgsr[0]
            vimg=ants.image_read( myimgsr )
        elif overmodX == &#39;DWI1&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;DWI2&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;DTI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[len(myimgsr)-1]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;NM2DMT&#39;:
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr0=myimgsr[0]
                vimg=ants.image_read( myimgsr0 )
                for k in range(1,len(myimgsr)):
                    temp = ants.image_read( myimgsr[k])
                    vimg=vimg+ants.resample_image_to_target(temp,vimg)
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        elif overmodX == &#39;rsfMRI&#39;:
            mod_search_path = os.path.join(subjectrootpath, &#39;rsfMRI*&#39;, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=mm_read_to_3d( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        else :
            mod_search_path = os.path.join(subjectrootpath, overmodX, &#34;*&#34;, &#34;*nii.gz&#34;)
            myimgsr = glob.glob(mod_search_path)
            if len( myimgsr ) &gt; 0:
                myimgsr.sort()
                myimgsr=myimgsr[0]
                vimg=ants.image_read( myimgsr )
            else:
                if verbose:
                    print(&#34;No &#34; + overmodX)
                vimg = noizimg
        if True:
            if extract_brain and overmodX == &#39;T1w&#39;:
                vimg = vimg * antspyt1w.brain_extraction(vimg)
            if verbose:
                print(f&#34;modality search path: {myimgsr}&#34; + &#34; num: &#34; + str(nrgNum))
            if len( vimg.shape ) == 4 and ( overmodX == &#34;DWI2&#34;  ):
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttdw
            elif len( vimg.shape ) == 4 and overmodX == &#34;DWI1&#34;:
                ttb0, ttdw=get_average_dwi_b0(vimg)
                vimg = ttb0
            elif len( vimg.shape ) == 4 :
                vimg=ants.get_average_of_timeseries(vimg)
            msk=ants.get_mask(vimg)
            vimg=ants.crop_image(vimg,msk)
            if overmodX == &#39;T1w&#39;:
                refimg=ants.image_clone( vimg )
                noizimg = ants.add_noise_to_image( refimg*0, &#39;additivegaussian&#39;, [100,1] )
                vizlist.append( vimg )
            else:
                vimg = ants.resample_image_to_target( vimg, refimg )
                vimg = ants.iMath( vimg, &#39;TruncateIntensity&#39;,0.01,0.98)
                vizlist.append( ants.iMath( vimg, &#39;Normalize&#39; ) * 255 )

    listlen = len( vizlist )
    vizlist = np.asarray( vizlist )
    if show_it is not None:
        filenameout=None
        if verbose:
            print( show_it )
        for a in [0,1,2]:
            n=int(np.round( refimg.shape[a] * slice_factor ))
            slices=np.repeat( int(n), listlen  )
            if isinstance(show_it,str):
                filenameout=show_it+&#39;_ax&#39;+str(int(a))+&#39;_sl&#39;+str(n)+&#39;.png&#39;
                if verbose:
                    print( filenameout )
            ants.plot_grid(vizlist.reshape(2,3), slices.reshape(2,3), title=&#39;MM Subject &#39; + sid + &#39; &#39; + dtid, rfacecolor=&#39;white&#39;, axes=a, filename=filenameout )
    if verbose:
        print(&#34;viz complete.&#34;)
    return vizlist</code></pre>
</details>
</dd>
<dt id="antspymm.mm.read_mm_csv"><code class="name flex">
<span>def <span class="ident">read_mm_csv</span></span>(<span>x, is_t1=False, colprefix=None, separator='-', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_mm_csv( x, is_t1=False, colprefix=None, separator=&#39;-&#39;, verbose=False ):
    splitter=os.path.basename(x).split( separator )
    lensplit = len( splitter )-1
    temp = os.path.basename(x)
    temp = os.path.splitext(temp)[0]
    temp = re.sub(separator+&#39;mmwide&#39;,&#39;&#39;,temp)
    idcols = [&#39;u_hier_id&#39;,&#39;sid&#39;,&#39;visitdate&#39;,&#39;modality&#39;,&#39;mmimageuid&#39;,&#39;t1imageuid&#39;]
    df = pd.DataFrame( columns = idcols, index=range(1) )
    valstoadd = [temp] + splitter[1:(lensplit-1)]
    if is_t1:
        valstoadd = valstoadd + [splitter[(lensplit-1)],splitter[(lensplit-1)]]
    else:
        split2=splitter[(lensplit-1)].split( &#34;_&#34; )
        if len(split2) == 1:
            split2.append( split2[0] )
        if len(valstoadd) == 3:
            valstoadd = valstoadd + [split2[0]] + [math.nan] + [split2[1]]
        else:
            valstoadd = valstoadd + [split2[0],split2[1]]
    if verbose:
        print( valstoadd )
    df.iloc[0] = valstoadd
    if verbose:
        print( &#34;read xdf: &#34; + x )
    xdf = pd.read_csv( x )
    df.reset_index()
    xdf.reset_index(drop=True)
    if &#34;Unnamed: 0&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 0&#34; )
    if &#34;Unnamed: 1&#34; in xdf.columns:
        holder=xdf.pop( &#34;Unnamed: 1&#34; )
    if &#34;u_hier_id.1&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id.1&#34; )
    if &#34;u_hier_id&#34; in xdf.columns:
        holder=xdf.pop( &#34;u_hier_id&#34; )
    if not is_t1:
        if &#39;resnetGrade&#39; in xdf.columns:
            index_no = xdf.columns.get_loc(&#39;resnetGrade&#39;)
            xdf = xdf.drop( xdf.columns[range(index_no+1)] , axis=1)

    if xdf.shape[0] == 2:
        xdfcols = xdf.columns
        xdf = xdf.iloc[1]
        ddnum = xdf.to_numpy()
        ddnum = ddnum.reshape([1,ddnum.shape[0]])
        newcolnames = xdf.index.to_list()
        if len(newcolnames) != ddnum.shape[1]:
            print(&#34;Cannot Merge : Shape MisMatch &#34; + str( len(newcolnames) ) + &#34; &#34; + str(ddnum.shape[1]))
        else:
            xdf = pd.DataFrame(ddnum, columns=xdfcols )
    if xdf.shape[1] == 0:
        return None
    if colprefix is not None:
        xdf.columns=colprefix + xdf.columns
    return pd.concat( [df,xdf], axis=1 )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.resting_state_fmri_networks"><code class="name flex">
<span>def <span class="ident">resting_state_fmri_networks</span></span>(<span>fmri, fmri_template, t1, t1segmentation, f=[0.03, 0.08], FD_threshold=0.5, spa=1.5, spt=0.5, nc=6, type_of_transform='Rigid', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute resting state network correlation maps based on the J Power labels.
This will output a map for each of the major network systems.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>fmri</code></strong> :&ensp;<code>BOLD fmri antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>fmri_template</code></strong> :&ensp;<code>reference space for BOLD</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>input 3-D T1 brain image (brain extracted)</p>
<dl>
<dt><strong><code>t1segmentation</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>t1 segmentation - a six tissue segmentation image in T1 space</p>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>band pass limits for frequency filtering</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>spa</code></strong> :&ensp;<code>gaussian smoothing for spatial component</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>spt</code></strong> :&ensp;<code>gaussian smoothing for temporal component</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>nc
: number of components for compcor filtering</p>
<dl>
<dt><strong><code>type_of_transform</code></strong> :&ensp;<code>SyN</code> or <code>Rigid</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary containing the derived network maps</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resting_state_fmri_networks( fmri, fmri_template, t1, t1segmentation,
    f=[0.03,0.08], FD_threshold=0.5, spa = 1.5, spt = 0.5, nc = 6, type_of_transform=&#39;Rigid&#39;,
    verbose=False ):

  &#34;&#34;&#34;
  Compute resting state network correlation maps based on the J Power labels.
  This will output a map for each of the major network systems.

  Arguments
  ---------
  fmri : BOLD fmri antsImage

  fmri_template : reference space for BOLD

  t1 : ANTsImage
    input 3-D T1 brain image (brain extracted)

  t1segmentation : ANTsImage
    t1 segmentation - a six tissue segmentation image in T1 space

  f : band pass limits for frequency filtering

  spa : gaussian smoothing for spatial component

  spt : gaussian smoothing for temporal component

  nc  : number of components for compcor filtering

  type_of_transform : SyN or Rigid

  verbose : boolean

  Returns
  ---------
  a dictionary containing the derived network maps

  &#34;&#34;&#34;
  import numpy as np
  import pandas as pd
  import re
  import math
  A = np.zeros((1,1))
  powers_areal_mni_itk = pd.read_csv( get_data(&#39;powers_mni_itk&#39;, target_extension=&#34;.csv&#34;)) # power coordinates
  fmri = ants.iMath( fmri, &#39;Normalize&#39; )
  bmask = antspynet.brain_extraction( fmri_template, &#39;bold&#39; ).threshold_image(0.5,1).iMath(&#34;FillHoles&#34;)
  if verbose:
      print(&#34;Begin rsfmri motion correction&#34;)
  corrmo = timeseries_reg(
    fmri, fmri_template,
    type_of_transform=type_of_transform,
    total_sigma=0.0,
    fdOffset=2.0,
    trim = 8,
    output_directory=None,
    verbose=verbose,
    syn_metric=&#39;cc&#39;,
    syn_sampling=2,
    reg_iterations=[40,20,5] )
  if verbose:
      print(&#34;End rsfmri motion correction&#34;)
      # ants.image_write( corrmo[&#39;motion_corrected&#39;], &#39;/tmp/temp.nii.gz&#39; )

  mytsnr = tsnr( corrmo[&#39;motion_corrected&#39;], bmask )
  mytsnrThresh = np.quantile( mytsnr.numpy(), 0.995 )
  tsnrmask = ants.threshold_image( mytsnr, 0, mytsnrThresh ).morphology(&#34;close&#34;,2)
  bmask = bmask * tsnrmask
  und = fmri_template * bmask
  t1reg = ants.registration( und, t1, &#34;SyNBold&#34; )
  if verbose:
      print(&#34;t1 2 bold done&#34;)
#      ants.image_write( und, &#39;/tmp/template_bold_masked.nii.gz&#39; )
#      ants.image_write( t1reg[&#39;warpedmovout&#39;], &#39;/tmp/t1tobold.nii.gz&#39; )
  boldseg = ants.apply_transforms( und, t1segmentation,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;genericLabel&#39; ) * bmask
  gmseg = ants.threshold_image( t1segmentation, 2, 2 )
  gmseg = gmseg + ants.threshold_image( t1segmentation, 4, 4 )
  gmseg = ants.threshold_image( gmseg, 1, 4 )
  gmseg = ants.iMath( gmseg, &#39;MD&#39;, 1 )
  gmseg = ants.apply_transforms( und, gmseg,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; ) * bmask
  csfAndWM = ( ants.threshold_image( t1segmentation, 1, 1 ) +
               ants.threshold_image( t1segmentation, 3, 3 ) ).morphology(&#34;erode&#34;,1)
  csfAndWM = ants.apply_transforms( und, csfAndWM,
    t1reg[&#39;fwdtransforms&#39;], interpolator = &#39;nearestNeighbor&#39; )  * bmask

  # get falff and alff
  mycompcor = ants.compcor( corrmo[&#39;motion_corrected&#39;],
    ncompcor=nc, quantile=0.90, mask = csfAndWM,
    filter_type=&#39;polynomial&#39;, degree=2 )

  nt = corrmo[&#39;motion_corrected&#39;].shape[3]

  myvoxes = range(powers_areal_mni_itk.shape[0])
  anat = powers_areal_mni_itk[&#39;Anatomy&#39;]
  syst = powers_areal_mni_itk[&#39;SystemName&#39;]
  Brod = powers_areal_mni_itk[&#39;Brodmann&#39;]
  xAAL  = powers_areal_mni_itk[&#39;AAL&#39;]
  ch2 = mm_read( ants.get_ants_data( &#34;ch2&#34; ) )
  treg = ants.registration( t1, ch2, &#39;SyN&#39; )
  concatx2 = treg[&#39;invtransforms&#39;] + t1reg[&#39;invtransforms&#39;]
  pts2bold = ants.apply_transforms_to_points( 3, powers_areal_mni_itk, concatx2,
    whichtoinvert = ( True, False, True, False ) )
  locations = pts2bold.iloc[:,:3].values
  ptImg = ants.make_points_image( locations, bmask, radius = 2 )

  tr = ants.get_spacing( corrmo[&#39;motion_corrected&#39;] )[3]
  highMotionTimes = np.where( corrmo[&#39;FD&#39;] &gt;= 1.0 )
  goodtimes = np.where( corrmo[&#39;FD&#39;] &lt; 0.5 )
  smth = ( spa, spa, spa, spt ) # this is for sigmaInPhysicalCoordinates = F
  simg = ants.smooth_image(corrmo[&#39;motion_corrected&#39;], smth, sigma_in_physical_coordinates = False )

  nuisance = mycompcor[ &#39;components&#39; ]
  nuisance = np.c_[ nuisance, mycompcor[&#39;basis&#39;] ]
  nuisance = np.c_[ nuisance, corrmo[&#39;FD&#39;] ]

  gmmat = ants.timeseries_to_matrix( simg, gmseg )
  gmmat = ants.bandpass_filter_matrix( gmmat, tr = tr, lowf=f[0], highf=f[1] ) # some would argue against this
  gmsignal = gmmat.mean( axis = 1 )
  nuisance = np.c_[ nuisance, gmsignal ]
  gmmat = ants.regress_components( gmmat, nuisance )
  # turn data following nuisance and gsr back to image format
  gsrbold = ants.matrix_to_timeseries(simg, gmmat, gmseg)

  myfalff=alff_image( simg, bmask, flo=f[0], fhi=f[1], nuisance=nuisance )

  outdict = {}
  outdict[&#39;meanBold&#39;] = und
  outdict[&#39;pts2bold&#39;] = pts2bold

  # add correlation matrix that captures each node pair
  # some of the spheres overlap so extract separately from each ROI
  nPoints = pts2bold[&#39;ROI&#39;].max()
  nVolumes = simg.shape[3]
  meanROI = np.zeros([nVolumes, nPoints])
  roiNames = []
  for i in range(nPoints):
    # specify name for matrix entries that&#39;s links back to ROI number and network; e.g., ROI1_Uncertain
    netLabel = re.sub( &#34; &#34;, &#34;&#34;, pts2bold.loc[i,&#39;SystemName&#39;])
    netLabel = re.sub( &#34;-&#34;, &#34;&#34;, netLabel )
    netLabel = re.sub( &#34;/&#34;, &#34;&#34;, netLabel )
    roiLabel = &#34;ROI&#34; + str(pts2bold.loc[i,&#39;ROI&#39;]) + &#39;_&#39; + netLabel
    roiNames.append( roiLabel )
    ptImage = ants.make_points_image(pts2bold.iloc[[i],:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    meanROI[:,i] = ants.timeseries_to_matrix( gsrbold, ptImage).mean(axis=1)

  # get full correlation matrix
  corMat = np.corrcoef(meanROI, rowvar=False)
  outputMat = pd.DataFrame(corMat)
  outputMat.columns = roiNames
  outputMat[&#39;ROIs&#39;] = roiNames
  # add to dictionary
  outdict[&#39;fullCorrMat&#39;] = outputMat

  networks = powers_areal_mni_itk[&#39;SystemName&#39;].unique()

  # this is just for human readability - reminds us of which we choose by default
  netnames = [&#39;Cingulo-opercular Task Control&#39;, &#39;Default Mode&#39;,
                &#39;Memory Retrieval&#39;, &#39;Ventral Attention&#39;, &#39;Visual&#39;,
                &#39;Fronto-parietal Task Control&#39;, &#39;Salience&#39;, &#39;Subcortical&#39;,
                &#39;Dorsal Attention&#39;]
  # cerebellar is 12
  ct = 0
  numofnets = [3,5,6,7,8,9,10,11,13]
  for mynet in numofnets:
    netname = re.sub( &#34; &#34;, &#34;&#34;, networks[mynet] )
    netname = re.sub( &#34;-&#34;, &#34;&#34;, netname )
    ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[mynet] )[0]
    dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
    if dfnImg.max() &gt;= 1:
        dfnmat = ants.timeseries_to_matrix( simg, ants.threshold_image( dfnImg, 1, dfnImg.max() ) )
        dfnmat = ants.bandpass_filter_matrix( dfnmat, tr = tr, lowf=f[0], highf=f[1]  )
        dfnmat = ants.regress_components( dfnmat, nuisance )
        dfnsignal = dfnmat.mean( axis = 1 )
        gmmatDFNCorr = np.zeros( gmmat.shape[1] )
        for k in range( gmmat.shape[1] ):
            gmmatDFNCorr[ k ] = pearsonr( dfnsignal, gmmat[:,k] )[0]
        corrImg = ants.make_image( gmseg, gmmatDFNCorr  )
        outdict[ netname ] = corrImg
    else:
        outdict[ netname ] = None
    ct = ct + 1

  A = np.zeros( ( len( numofnets ) , len( numofnets ) ) )
  A_wide = np.zeros( ( 1, len( numofnets ) * len( numofnets ) ) )
  newnames=[]
  newnames_wide=[]
  ct = 0
  for i in range( len( numofnets ) ):
      netnamei = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[i]] )
      netnamei = re.sub( &#34;-&#34;, &#34;&#34;, netnamei )
      newnames.append( netnamei  )
      binmask = ants.threshold_image( outdict[ netnamei ], 0.2, 1.0 )
      ww = np.where( powers_areal_mni_itk[&#39;SystemName&#39;] == networks[numofnets[i]] )[0]
      dfnImg = ants.make_points_image(pts2bold.iloc[ww,:3].values, bmask, radius=1).threshold_image( 1, 1e9 )
      for j in range( len( numofnets ) ):
          netnamej = re.sub( &#34; &#34;, &#34;&#34;, networks[numofnets[j]] )
          netnamej = re.sub( &#34;-&#34;, &#34;&#34;, netnamej )
          newnames_wide.append( netnamei + &#34;_2_&#34; + netnamej )
          A[i,j] = outdict[ netnamej ][ dfnImg == 1].mean()
          A_wide[0,ct] = A[i,j]
          ct=ct+1

  A = pd.DataFrame( A )
  A.columns = newnames
  A[&#39;networks&#39;]=newnames
  A_wide = pd.DataFrame( A_wide )
  A_wide.columns = newnames_wide
  outdict[&#39;corr&#39;] = A
  outdict[&#39;corr_wide&#39;] = A_wide
  outdict[&#39;brainmask&#39;] = bmask
  outdict[&#39;alff&#39;] = myfalff[&#39;alff&#39;]
  outdict[&#39;falff&#39;] = myfalff[&#39;falff&#39;]
  # add global mean and standard deviation for post-hoc z-scoring
  outdict[&#39;alff_mean&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).mean()
  outdict[&#39;alff_sd&#39;] = (myfalff[&#39;alff&#39;][myfalff[&#39;alff&#39;]!=0]).std()
  outdict[&#39;falff_mean&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).mean()
  outdict[&#39;falff_sd&#39;] = (myfalff[&#39;falff&#39;][myfalff[&#39;falff&#39;]!=0]).std()

  for k in range(1,270):
    anatname=( pts2bold[&#39;AAL&#39;][k] )
    if isinstance(anatname, str):
        anatname = re.sub(&#34;_&#34;,&#34;&#34;,anatname)
    else:
        anatname=&#39;Unk&#39;
    fname=&#39;falffPoint&#39;+str(k)+anatname
    aname=&#39;alffPoint&#39;+str(k)+anatname
    outdict[fname]=(outdict[&#39;falff&#39;][ptImg==k]).mean()
    outdict[aname]=(outdict[&#39;alff&#39;][ptImg==k]).mean()

  rsfNuisance = pd.DataFrame( nuisance )
  rsfNuisance[&#39;FD&#39;]=corrmo[&#39;FD&#39;]

  nonbrainmask = ants.iMath( bmask, &#34;MD&#34;,2) - bmask
  trimmask = ants.iMath( bmask, &#34;ME&#34;,2)
  edgemask = ants.iMath( bmask, &#34;ME&#34;,1) - trimmask
  outdict[&#39;motion_corrected&#39;] = corrmo[&#39;motion_corrected&#39;]
  outdict[&#39;brain_mask&#39;] = bmask
  outdict[&#39;nuisance&#39;] = rsfNuisance
  outdict[&#39;tsnr&#39;] = mytsnr
  outdict[&#39;ssnr&#39;] = slice_snr( corrmo[&#39;motion_corrected&#39;], csfAndWM, gmseg )
  outdict[&#39;dvars&#39;] = dvars( corrmo[&#39;motion_corrected&#39;], gmseg )
  outdict[&#39;high_motion_count&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum()
  outdict[&#39;high_motion_pct&#39;] = (rsfNuisance[&#39;FD&#39;] &gt; FD_threshold ).sum() / rsfNuisance.shape[0]
  outdict[&#39;FD_max&#39;] = rsfNuisance[&#39;FD&#39;].max()
  outdict[&#39;FD_mean&#39;] = rsfNuisance[&#39;FD&#39;].mean()
  outdict[&#39;bold_evr&#39;] =  antspyt1w.patch_eigenvalue_ratio( und, 512, [16,16,16], evdepth = 0.9, mask = bmask )
  return outdict</code></pre>
</details>
</dd>
<dt id="antspymm.mm.segment_timeseries_by_meanvalue"><code class="name flex">
<span>def <span class="ident">segment_timeseries_by_meanvalue</span></span>(<span>image, quantile=0.995)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify indices of a time series where we assume there is a different mean
intensity over the volumes.
The indices of volumes with higher and lower
intensities is returned.
Can be used to automatically identify B0 volumes
in DWI timeseries.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>quantile</code></strong> :&ensp;<code>a quantile for splitting the indices</code> of <code>the volume - should be greater than 0.5</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the two sets</code> of <code>indices</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def segment_timeseries_by_meanvalue( image, quantile = 0.995 ):
    &#34;&#34;&#34;
    Identify indices of a time series where we assume there is a different mean
    intensity over the volumes.  The indices of volumes with higher and lower
    intensities is returned.  Can be used to automatically identify B0 volumes
    in DWI timeseries.

    Arguments
    ---------
    image : an antsImage holding B0 and DWI

    quantile : a quantile for splitting the indices of the volume - should be greater than 0.5

    Returns
    -------
    dictionary holding the two sets of indices

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    ishape = image.shape
    lastdim = len(ishape)-1
    meanvalues = list()
    for x in range(ishape[lastdim]):
        meanvalues.append(  ants.slice_image( image, axis=lastdim, idx=x ).mean() )
    myhiq = np.quantile( meanvalues, quantile )
    myloq = np.quantile( meanvalues, 1.0 - quantile )
    lowerindices = list()
    higherindices = list()
    for x in range(len(meanvalues)):
        hiabs = abs( meanvalues[x] - myhiq )
        loabs = abs( meanvalues[x] - myloq )
        if hiabs &lt; loabs:
            higherindices.append(x)
        else:
            lowerindices.append(x)

    return {
    &#39;lowermeans&#39;:lowerindices,
    &#39;highermeans&#39;:higherindices }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.slice_snr"><code class="name flex">
<span>def <span class="ident">slice_snr</span></span>(<span>x, background_mask, foreground_mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>slice-wise SNR on a time series image</p>
<p>x: image</p>
<p>background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask</p>
<p>foreground_mask : mask - maybe cortex or WM or brain mask</p>
<p>indices: indices to use</p>
<p>returns an array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_snr( x,  background_mask, foreground_mask, indices=None ):
    &#34;&#34;&#34;
    slice-wise SNR on a time series image

    x: image

    background_mask : mask - maybe CSF or background or dilated brain mask minus original brain mask

    foreground_mask : mask - maybe cortex or WM or brain mask

    indices: indices to use

    returns an array
    &#34;&#34;&#34;
    xuse=ants.iMath(x,&#34;Normalize&#34;)
    MB = ants.timeseries_to_matrix( xuse, background_mask )
    MF = ants.timeseries_to_matrix( xuse, foreground_mask )
    if indices is not None:
        MB=MB[indices,:]
        MF=MF[indices,:]
    ssnr = np.zeros( MB.shape[0] )
    for i in range( MB.shape[0] ):
        ssnr[i]=MF[i,:].mean()/MB[i,:].std()
    ssnr[np.isnan(ssnr)] = 0
    return ssnr</code></pre>
</details>
</dd>
<dt id="antspymm.mm.study_dataframe_from_matched_dataframe"><code class="name flex">
<span>def <span class="ident">study_dataframe_from_matched_dataframe</span></span>(<span>matched_dataframe, rootdir, outputdir, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv</p>
<p>matched_dataframe : output of antspymm.match_modalities</p>
<p>rootdir : location for the input data root folder (in e.g. NRG format)</p>
<p>outputdir : location for the output data</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def study_dataframe_from_matched_dataframe( matched_dataframe, rootdir, outputdir, verbose=False ):
    &#34;&#34;&#34;
    converts the output of antspymm.match_modalities dataframe (one row) to that needed for a study-driving dataframe for input to mm_csv

    matched_dataframe : output of antspymm.match_modalities

    rootdir : location for the input data root folder (in e.g. NRG format)

    outputdir : location for the output data

    verbose : boolean
    &#34;&#34;&#34;
    iext=&#39;.nii.gz&#39;
    from os.path import exists
    musthavecols = [&#39;projectID&#39;, &#39;subjectID&#39;,&#39;date&#39;,&#39;imageID&#39;,&#39;fn&#39;]
    for k in range(len(musthavecols)):
        if not musthavecols[k] in matched_dataframe.keys():
            raise ValueError(&#39;matched_dataframe is missing column &#39; +musthavecols[k] + &#39; in study_dataframe_from_qc_dataframe&#39; )
    csvrow=matched_dataframe.dropna(axis=1)
    pid=str(csvrow[&#39;projectID&#39;].iloc[0] )
    sid=str(csvrow[&#39;subjectID&#39;].iloc[0] )
    dt=str(csvrow[&#39;date&#39;].iloc[0])
    iid=str(csvrow[&#39;imageID&#39;].iloc[0])
    nrgt1fn=os.path.join( rootdir, pid, sid, dt, &#39;T1w&#39;, iid, str(csvrow[&#39;fn&#39;].iloc[0]+iext) )
    if not exists( nrgt1fn ):
        raise ValueError(&#34;T1 &#34; + nrgt1fn + &#34; does not exist in study_dataframe_from_qc_dataframe&#34;)
    flList=[]
    dtList=[]
    rsfList=[]
    nmList=[]
    if &#39;flairfn&#39; in csvrow.keys():
        flid=str(int(csvrow[&#39;flairid&#39;].iloc[0]))
        nrgt2fn=os.path.join( rootdir, pid, sid, dt, &#39;T2Flair&#39;, flid, str(csvrow[&#39;flairfn&#39;].iloc[0]+iext) )
        if exists( nrgt2fn ):
            flList.append( nrgt2fn )
    if &#39;dtfn1&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid1&#39;].iloc[0]))
        dtfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn1&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn1 ):
            dtList.append( dtfn1 )
    if &#39;dtfn2&#39; in csvrow.keys():
        dtid=str(int(csvrow[&#39;dtid2&#39;].iloc[0]))
        dtfn2=glob.glob(os.path.join(rootdir, pid, sid, dt, &#39;DTI*&#39;, dtid, str(csvrow[&#39;dtfn2&#39;].iloc[0]+iext) ))[0]
        if exists( dtfn2 ):
            dtList.append( dtfn2 )
    if &#39;rsffn1&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid1&#39;].iloc[0]))
        rsfn1=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn1&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn1 ):
            rsfList.append( rsfn1 )
    if &#39;rsffn2&#39; in csvrow.keys():
        rsid=str(int(csvrow[&#39;rsfid2&#39;].iloc[0]))
        rsfn2=glob.glob(os.path.join( rootdir, pid, sid, dt, &#39;rsfMRI*&#39;, rsid, str(csvrow[&#39;rsffn2&#39;].iloc[0]+iext) ))[0]
        if exists( rsfn2 ):
            rsfList.append( rsfn2 )
    for j in range(11):
        keyname=&#34;nmfn&#34;+str(j)
        keynameid=&#34;nmid&#34;+str(j)
        if keyname in csvrow.keys() and keynameid in csvrow.keys():
            nmid=str(int(csvrow[keynameid].iloc[0]))
            nmsearchpath=os.path.join( rootdir, pid, sid, dt, &#39;NM2DMT&#39;, nmid, &#34;*&#34;+nmid+iext)
            nmfn=glob.glob( nmsearchpath )
            nmfn=nmfn[0]
            if exists( nmfn ):
                nmList.append( nmfn )
    if verbose:
        print(&#34;assembled the image lists mapping to ....&#34;)
        print(nrgt1fn)
        print(&#34;NM&#34;)
        print(nmList)
        print(&#34;FLAIR&#34;)
        print(flList)
        print(&#34;DTI&#34;)
        print(dtList)
        print(&#34;rsfMRI&#34;)
        print(rsfList)
    studycsv = generate_mm_dataframe(
        pid,
        sid,
        dt,
        iid, # the T1 id
        &#39;T1w&#39;,
        rootdir,
        outputdir,
        t1_filename=nrgt1fn,
        flair_filename=flList,
        dti_filenames=dtList,
        rsf_filenames=rsfList,
        nm_filenames=nmList)
    return studycsv.dropna(axis=1)</code></pre>
</details>
</dd>
<dt id="antspymm.mm.super_res_mcimage"><code class="name flex">
<span>def <span class="ident">super_res_mcimage</span></span>(<span>image, srmodel, truncation=[0.0001, 0.995], poly_order='hist', target_range=[0, 1], isotropic=False, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Super resolution on a timeseries or multi-channel image</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>an antsImage</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>srmodel</code></strong> :&ensp;<code>a tensorflow fully convolutional model</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>truncation</code></strong> :&ensp;<code> quantiles at which we truncate intensities to limit impact</code> of <code>outliers e.g. [0.005,0.995]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>poly_order</code></strong> :&ensp;<code>if not None, will fit a global regression model to map</code></dt>
<dd>intensity back to original histogram space; if 'hist' will match
by histogram matching - ants.histogram_match_image</dd>
<dt><strong><code>target_range</code></strong> :&ensp;<code>2-element tuple</code></dt>
<dd>a tuple or array defining the (min, max) of the input image
(e.g., [-127.5, 127.5] or [0,1]).
Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</dd>
<dt><strong><code>isotropic</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>super resolution <a title="antspymm.mm.version" href="#antspymm.mm.version">version()</a></code> of <code>the image</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def super_res_mcimage( image,
    srmodel,
    truncation=[0.0001,0.995],
    poly_order=&#39;hist&#39;,
    target_range=[0,1],
    isotropic = False,
    verbose=False ):
    &#34;&#34;&#34;
    Super resolution on a timeseries or multi-channel image

    Arguments
    ---------
    image : an antsImage

    srmodel : a tensorflow fully convolutional model

    truncation :  quantiles at which we truncate intensities to limit impact of outliers e.g. [0.005,0.995]

    poly_order : if not None, will fit a global regression model to map
        intensity back to original histogram space; if &#39;hist&#39; will match
        by histogram matching - ants.histogram_match_image

    target_range : 2-element tuple
        a tuple or array defining the (min, max) of the input image
        (e.g., [-127.5, 127.5] or [0,1]).  Output images will be scaled back to original
        intensity. This range should match the mapping used in the training
        of the network.

    isotropic : boolean

    verbose : boolean

    Returns
    -------
    super resolution version of the image

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    mcsr = list()
    for k in range(nTimePoints):
        if verbose and (( k % 5 ) == 0 ):
            mycount = round(k / nTimePoints * 100)
            print(mycount, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image( image, axis=idim - 1, idx=k )
        temp = ants.iMath( temp, &#34;TruncateIntensity&#34;, truncation[0], truncation[1] )
        mysr = antspynet.apply_super_resolution_model_to_image( temp, srmodel,
            target_range = target_range )
        if poly_order is not None:
            bilin = ants.resample_image_to_target( temp, mysr )
            if poly_order == &#39;hist&#39;:
                mysr = ants.histogram_match_image( mysr, bilin )
            else:
                mysr = antspynet.regression_match_image( mysr, bilin, poly_order = poly_order )
        if isotropic:
            mysr = down2iso( mysr )
        if k == 0:
            upshape = list()
            for j in range(len(ishape)-1):
                upshape.append( mysr.shape[j] )
            upshape.append( ishape[ idim-1 ] )
            if verbose:
                print(&#34;SR will be of voxel size:&#34; + str(upshape) )
        mcsr.append( mysr )

    upshape = list()
    for j in range(len(ishape)-1):
        upshape.append( mysr.shape[j] )
    upshape.append( ishape[ idim-1 ] )
    if verbose:
        print(&#34;SR will be of voxel size:&#34; + str(upshape) )

    imageup = ants.resample_image( image, upshape, use_voxels = True )
    if verbose:
        print(&#34;Done&#34;)

    return ants.list_to_ndimage( imageup, mcsr )</code></pre>
</details>
</dd>
<dt id="antspymm.mm.t1_based_dwi_brain_extraction"><code class="name flex">
<span>def <span class="ident">t1_based_dwi_brain_extraction</span></span>(<span>t1w_head, t1w, dwi, b0_idx=None, transform='Rigid', deform=None, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Map a t1-based brain extraction to b0 and return a mask and average b0</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>t1w_head</code></strong> :&ensp;<code>an antsImage</code> of <code>the hole head</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1w</code></strong> :&ensp;<code>an antsImage probably but not necessarily T1-weighted</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dwi</code></strong> :&ensp;<code>an antsImage holding B0 and DWI</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>b0_idx</code></strong> :&ensp;<code>the indices</code> of <code>the B0; if None, use segment_timeseries_by_meanvalue to guess</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>string Rigid</code> or <code>other ants.registration tx type</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>deform</code></strong> :&ensp;<code>follow up transform with deformation</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary holding the avg_b0 and its mask</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def t1_based_dwi_brain_extraction(
    t1w_head,
    t1w,
    dwi,
    b0_idx = None,
    transform=&#39;Rigid&#39;,
    deform=None,
    verbose=False
):
    &#34;&#34;&#34;
    Map a t1-based brain extraction to b0 and return a mask and average b0

    Arguments
    ---------
    t1w_head : an antsImage of the hole head

    t1w : an antsImage probably but not necessarily T1-weighted

    dwi : an antsImage holding B0 and DWI

    b0_idx : the indices of the B0; if None, use segment_timeseries_by_meanvalue to guess

    transform : string Rigid or other ants.registration tx type

    deform : follow up transform with deformation

    Returns
    -------
    dictionary holding the avg_b0 and its mask

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &#34;&#34;&#34;
    t1w_use = ants.iMath( t1w, &#34;Normalize&#34; )
    t1bxt = ants.threshold_image( t1w_use, 0.05, 1 ).iMath(&#34;FillHoles&#34;)
    if b0_idx is None:
        b0_idx = segment_timeseries_by_meanvalue( dwi )[&#39;highermeans&#39;]
    # first get the average b0
    if len( b0_idx ) &gt; 1:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] ).iMath(&#34;Normalize&#34;)
        for n in range(1,len(b0_idx)):
            temp = ants.slice_image( dwi, axis=3, idx=b0_idx[n] )
            reg = ants.registration( b0_avg, temp, &#39;Rigid&#39; )
            b0_avg = b0_avg + ants.iMath( reg[&#39;warpedmovout&#39;], &#34;Normalize&#34;)
    else:
        b0_avg = ants.slice_image( dwi, axis=3, idx=b0_idx[0] )
    b0_avg = ants.iMath(b0_avg,&#34;Normalize&#34;)
    reg = tra_initializer( b0_avg, t1w, n_simulations=12,   verbose=verbose )
    if deform is not None:
        reg = ants.registration( b0_avg, t1w,
            &#39;SyNOnly&#39;,
            total_sigma=0.5,
            initial_transform=reg[&#39;fwdtransforms&#39;][0],
            verbose=False )
    outmsk = ants.apply_transforms( b0_avg, t1bxt, reg[&#39;fwdtransforms&#39;], interpolator=&#39;linear&#39;).threshold_image( 0.5, 1.0 )
    return  {
    &#39;b0_avg&#39;:b0_avg,
    &#39;b0_mask&#39;:outmsk }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.threaded_bind_wide_mm_csvs"><code class="name flex">
<span>def <span class="ident">threaded_bind_wide_mm_csvs</span></span>(<span>mm_wide_csvs, n_workers)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def threaded_bind_wide_mm_csvs( mm_wide_csvs, n_workers ):
    from concurrent.futures import as_completed
    from concurrent import futures
    import concurrent.futures
    def chunks(l, n):
        &#34;&#34;&#34;Yield n number of sequential chunks from l.&#34;&#34;&#34;
        d, r = divmod(len(l), n)
        for i in range(n):
            si = (d+1)*(i if i &lt; r else r) + d*(0 if i &lt; r else i - r)
            yield l[si:si+(d+1 if i &lt; r else d)]
    import numpy as np
    newx = list( chunks( mm_wide_csvs, n_workers ) )
    import pandas as pd
    alldf = pd.DataFrame()
    alldfavg = pd.DataFrame()
    with futures.ThreadPoolExecutor(max_workers=n_workers) as executor:
        to_do = []
        for group in range(len(newx)) :
            future = executor.submit(bind_wide_mm_csvs, newx[group] )
            to_do.append(future)
        results = []
        for future in futures.as_completed(to_do):
            res0, res1 = future.result()
            alldf=pd.concat(  [alldf, res0 ], axis=0 )
            alldfavg=pd.concat(  [alldfavg, res1 ], axis=0 )
    return alldf, alldfavg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.timeseries_reg"><code class="name flex">
<span>def <span class="ident">timeseries_reg</span></span>(<span>image, avg_b0, type_of_transform='Rigid', total_sigma=1.0, fdOffset=2.0, trim=0, output_directory=None, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time-series data for motion - with deformation.</p>
<h2 id="arguments">Arguments</h2>
<p>image: antsImage, usually ND where D=4.</p>
<dl>
<dt><strong><code>avg_b0</code></strong> :&ensp;<code>Fixed image b0 image</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>type_of_transform</code></strong> :&ensp;<code>string</code></dt>
<dd>A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
See ants registration for details.</dd>
<dt><strong><code>fdOffset</code></strong> :&ensp;<code>offset value to use in framewise displacement calculation</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>trim</code></strong> :&ensp;<code>integer - trim this many images off the front</code> of <code>the time series</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>output_directory</code></strong> :&ensp;<code>string</code></dt>
<dd>output will be placed in this directory plus a numeric extension.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>keyword args</code></dt>
<dd>extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict containing follow key/value pairs:</code></dt>
<dd><code>motion_corrected</code>: Moving image warped to space of fixed image.
<code>motion_parameters</code>: transforms for each image in the time series.
<code>FD</code>: Framewise displacement generalized for arbitrary transformations.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Control extra arguments via kwargs. see ants.registration for details.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import ants
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timeseries_reg(
    image,
    avg_b0,
    type_of_transform=&#34;Rigid&#34;,
    total_sigma=1.0,
    fdOffset=2.0,
    trim = 0,
    output_directory=None,
    verbose=False, **kwargs
):
    &#34;&#34;&#34;
    Correct time-series data for motion - with deformation.

    Arguments
    ---------
    image: antsImage, usually ND where D=4.

    avg_b0: Fixed image b0 image

    type_of_transform : string
            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.
            See ants registration for details.

    fdOffset: offset value to use in framewise displacement calculation

    trim : integer - trim this many images off the front of the time series

    output_directory : string
            output will be placed in this directory plus a numeric extension.

    verbose: boolean

    kwargs: keyword args
            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.

    Returns
    -------
    dict containing follow key/value pairs:
        `motion_corrected`: Moving image warped to space of fixed image.
        `motion_parameters`: transforms for each image in the time series.
        `FD`: Framewise displacement generalized for arbitrary transformations.

    Notes
    -----
    Control extra arguments via kwargs. see ants.registration for details.

    Example
    -------
    &gt;&gt;&gt; import ants
    &#34;&#34;&#34;
    idim = image.dimension
    ishape = image.shape
    nTimePoints = ishape[idim - 1]
    FD = np.zeros(nTimePoints)
    if type_of_transform is None:
        return {
            &#34;motion_corrected&#34;: image,
            &#34;motion_parameters&#34;: None,
            &#34;FD&#34;: FD
        }

    remove_it=False
    if output_directory is None:
        remove_it=True
        output_directory = tempfile.mkdtemp()
    output_directory_w = output_directory + &#34;/ts_reg/&#34;
    os.makedirs(output_directory_w,exist_ok=True)
    ofnG = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;global_deformation&#39;,dir=output_directory_w).name
    ofnL = tempfile.NamedTemporaryFile(delete=False,suffix=&#39;local_deformation&#39;,dir=output_directory_w).name
    if verbose:
        print(&#39;bold motcorr with &#39; + type_of_transform)
        print(output_directory_w)
        print(ofnG)
        print(ofnL)
        print(&#34;remove_it &#34; + str( remove_it ) )

    # get a local deformation from slice to local avg space
    motion_parameters = list()
    motion_corrected = list()
    mask = ants.get_mask( avg_b0 )
    centerOfMass = mask.get_center_of_mass()
    npts = pow(2, idim - 1)
    pointOffsets = np.zeros((npts, idim - 1))
    myrad = np.ones(idim - 1).astype(int).tolist()
    mask1vals = np.zeros(int(mask.sum()))
    mask1vals[round(len(mask1vals) / 2)] = 1
    mask1 = ants.make_image(mask, mask1vals)
    myoffsets = ants.get_neighborhood_in_mask(
        mask1, mask1, radius=myrad, spatial_info=True
    )[&#34;offsets&#34;]
    mycols = list(&#34;xy&#34;)
    if idim - 1 == 3:
        mycols = list(&#34;xyz&#34;)
    useinds = list()
    for k in range(myoffsets.shape[0]):
        if abs(myoffsets[k, :]).sum() == (idim - 2):
            useinds.append(k)
        myoffsets[k, :] = myoffsets[k, :] * fdOffset / 2.0 + centerOfMass
    fdpts = pd.DataFrame(data=myoffsets[useinds, :], columns=mycols)
    if verbose:
        print(&#34;Progress:&#34;)
    counter = round( nTimePoints / 10 )
    for k in range( nTimePoints):
        if verbose and ( ( k % counter ) ==  0 ) or ( k == (nTimePoints-1) ):
            myperc = round( k / nTimePoints * 100)
            print(myperc, end=&#34;%.&#34;, flush=True)
        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        temp = ants.n4_bias_field_correction( temp )
        temp = ants.iMath(temp, &#34;Normalize&#34;)
        txprefix = ofnL+str(k % 2).zfill(4)+&#34;_&#34;
        if temp.numpy().var() &gt; 0:
            myrig = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;BOLDRigid&#39;,
                    outprefix=txprefix
                )
            if type_of_transform == &#39;SyN&#39;:
                myreg = ants.registration(
                    avg_b0, temp,
                    type_of_transform=&#39;SyNOnly&#39;,
                    total_sigma=total_sigma,
                    initial_transform=myrig[&#39;fwdtransforms&#39;][0],
                    outprefix=txprefix,
                    **kwargs
                )
            else:
                myreg = myrig
            fdptsTxI = ants.apply_transforms_to_points(
                idim - 1, fdpts, myrig[&#34;fwdtransforms&#34;]
            )
            if k &gt; 0 and motion_parameters[k - 1] != &#34;NA&#34;:
                fdptsTxIminus1 = ants.apply_transforms_to_points(
                    idim - 1, fdpts, motion_parameters[k - 1]
                )
            else:
                fdptsTxIminus1 = fdptsTxI
            # take the absolute value, then the mean across columns, then the sum
            FD[k] = (fdptsTxIminus1 - fdptsTxI).abs().mean().sum()
            motion_parameters.append(myreg[&#34;fwdtransforms&#34;])
        else:
            motion_parameters.append(&#34;NA&#34;)

        temp = ants.slice_image(image, axis=idim - 1, idx=k)
        if temp.numpy().var() &gt; 0:
            img1w = ants.apply_transforms( avg_b0,
                temp,
                motion_parameters[k] )
            motion_corrected.append(img1w)
        else:
            motion_corrected.append(avg_b0)

    if remove_it:
        import shutil
        shutil.rmtree(output_directory, ignore_errors=True )

    if verbose:
        print(&#34;Done&#34;)
    d4siz = list(avg_b0.shape)
    d4siz.append( 2 )
    spc = list(ants.get_spacing( avg_b0 ))
    spc.append( ants.get_spacing(image)[3] )
    mydir = ants.get_direction( avg_b0 )
    mydir4d = ants.get_direction( image )
    mydir4d[0:3,0:3]=mydir
    myorg = list(ants.get_origin( avg_b0 ))
    myorg.append( 0.0 )
    avg_b0_4d = ants.make_image(d4siz,0,spacing=spc,origin=myorg,direction=mydir4d)
    return {
        &#34;motion_corrected&#34;: ants.list_to_ndimage(avg_b0_4d, motion_corrected[trim:len(motion_corrected)]),
        &#34;motion_parameters&#34;: motion_parameters[trim:len(motion_parameters)],
        &#34;FD&#34;: FD[trim:len(FD)]
    }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.tra_initializer"><code class="name flex">
<span>def <span class="ident">tra_initializer</span></span>(<span>fixed, moving, n_simulations=32, max_rotation=30, transform=['rigid'], verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>multi-start multi-transform registration solution - based on ants.registration</p>
<p>fixed: fixed image</p>
<p>moving: moving image</p>
<p>n_simulations : number of simulations</p>
<p>max_rotation : maximum rotation angle</p>
<p>transform : list of transforms to loop through</p>
<p>verbose : boolean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tra_initializer( fixed, moving, n_simulations=32, max_rotation=30,
    transform=[&#39;rigid&#39;], verbose=False ):
    &#34;&#34;&#34;
    multi-start multi-transform registration solution - based on ants.registration

    fixed: fixed image

    moving: moving image

    n_simulations : number of simulations

    max_rotation : maximum rotation angle

    transform : list of transforms to loop through

    verbose : boolean

    &#34;&#34;&#34;
    if True:
        output_directory = tempfile.mkdtemp()
        output_directory_w = output_directory + &#34;/tra_reg/&#34;
        os.makedirs(output_directory_w,exist_ok=True)
        bestmi = math.inf
        myorig = list(ants.get_origin( fixed ))
        mymax = 0;
        for k in range(len( myorig ) ):
            if abs(myorig[k]) &gt; mymax:
                mymax = abs(myorig[k])
        maxtrans = mymax * 0.05
        bestreg=ants.registration( fixed,moving,&#39;Translation&#39;,
            outprefix=output_directory_w+&#34;trans&#34;)
        initx = ants.read_transform( bestreg[&#39;fwdtransforms&#39;][0] )
        for mytx in transform:
            regtx = &#39;Rigid&#39;
            with tempfile.NamedTemporaryFile(suffix=&#39;.h5&#39;) as tp:
                if mytx == &#39;translation&#39;:
                    regtx = &#39;Translation&#39;
                    rRotGenerator = ants.contrib.RandomTranslate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                elif mytx == &#39;affine&#39;:
                    regtx = &#39;Affine&#39;
                    rRotGenerator = ants.contrib.RandomRotate3D( ( maxtrans*(-1.0), maxtrans ), reference=fixed )
                else:
                    rRotGenerator = ants.contrib.RandomRotate3D( ( max_rotation*(-1.0), max_rotation ), reference=fixed )
                for k in range(n_simulations):
                    simtx = ants.compose_ants_transforms( [rRotGenerator.transform(), initx] )
                    ants.write_transform( simtx, tp.name )
                    if k &gt; 0:
                        reg = ants.registration( fixed, moving, regtx,
                            initial_transform=tp.name,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    else:
                        reg = ants.registration( fixed, moving,
                            regtx,
                            outprefix=output_directory_w+&#34;reg&#34;+str(k),
                            verbose=False )
                    mymi = math.inf
                    temp = reg[&#39;warpedmovout&#39;]
                    myvar = temp.numpy().var()
                    if verbose:
                        print( str(k) + &#34; : &#34; + regtx  + &#34; : &#34; + mytx + &#34; _var_ &#34; + str( myvar ) )
                    if myvar &gt; 0 :
                        mymi = ants.image_mutual_information( fixed, temp )
                        if mymi &lt; bestmi:
                            if verbose:
                                print( &#34;mi @ &#34; + str(k) + &#34; : &#34; + str(mymi), flush=True)
                            bestmi = mymi
                            bestreg = reg
        return bestreg</code></pre>
</details>
</dd>
<dt id="antspymm.mm.trim_dti_mask"><code class="name flex">
<span>def <span class="ident">trim_dti_mask</span></span>(<span>fa, mask, param=4.0)</span>
</code></dt>
<dd>
<div class="desc"><p>trim the dti mask to get rid of bright fa rim</p>
<p>this function erodes the famask by param amount then segments the rim into
bright and less bright parts.
the bright parts are trimmed from the mask
and the remaining edges are cleaned up a bit with closing.</p>
<p>param: closing radius unit is in physical space</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_dti_mask( fa, mask, param=4.0 ):
    &#34;&#34;&#34;
    trim the dti mask to get rid of bright fa rim

    this function erodes the famask by param amount then segments the rim into
    bright and less bright parts.  the bright parts are trimmed from the mask
    and the remaining edges are cleaned up a bit with closing.

    param: closing radius unit is in physical space
    &#34;&#34;&#34;
    spacing = ants.get_spacing(mask)
    spacing_product = np.prod( spacing )
    spcmin = min( spacing )
    paramVox = int(np.round( param / spcmin ))
    trim_mask = ants.image_clone( mask )
    trim_mask = ants.iMath( trim_mask, &#34;FillHoles&#34; )
    edgemask = trim_mask - ants.iMath( trim_mask, &#34;ME&#34;, paramVox )
    maxk=4
    edgemask = ants.threshold_image( fa * edgemask, &#34;Otsu&#34;, maxk )
    edgemask = ants.threshold_image( edgemask, maxk-1, maxk )
    trim_mask[edgemask &gt;= 1 ]=0
    trim_mask = ants.iMath(trim_mask,&#34;ME&#34;,paramVox-1)
    trim_mask = ants.iMath(trim_mask,&#39;GetLargestComponent&#39;)
    trim_mask = ants.iMath(trim_mask,&#34;MD&#34;,paramVox-1)
    return trim_mask</code></pre>
</details>
</dd>
<dt id="antspymm.mm.tsnr"><code class="name flex">
<span>def <span class="ident">tsnr</span></span>(<span>x, mask, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>3D temporal snr image from a 4D time series image &hellip; the matrix is normalized to range of 0,1</p>
<p>x: image</p>
<p>mask : mask</p>
<p>indices: indices to use</p>
<p>returns a 3D image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tsnr( x, mask, indices=None ):
    &#34;&#34;&#34;
    3D temporal snr image from a 4D time series image ... the matrix is normalized to range of 0,1

    x: image

    mask : mask

    indices: indices to use

    returns a 3D image
    &#34;&#34;&#34;
    M = ants.timeseries_to_matrix( x, mask )
    M = M - M.min()
    M = M / M.max()
    if indices is not None:
        M=M[indices,:]
    stdM = np.std(M, axis=0 )
    stdM[np.isnan(stdM)] = 0
    tt = round( 0.975*100 )
    threshold_std = np.percentile( stdM, tt )
    tsnrimage = ants.make_image( mask, stdM )
    return tsnrimage</code></pre>
</details>
</dd>
<dt id="antspymm.mm.version"><code class="name flex">
<span>def <span class="ident">version</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>report versions of this package and primary dependencies</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a dictionary with package name and versions</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import antspymm
&gt;&gt;&gt; antspymm.version()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def version( ):
    &#34;&#34;&#34;
    report versions of this package and primary dependencies

    Arguments
    ---------
    None

    Returns
    -------
    a dictionary with package name and versions

    Example
    -------
    &gt;&gt;&gt; import antspymm
    &gt;&gt;&gt; antspymm.version()
    &#34;&#34;&#34;
    import pkg_resources
    return {
              &#39;tensorflow&#39;: pkg_resources.require(&#34;tensorflow&#34;)[0].version,
              &#39;antspyx&#39;: pkg_resources.require(&#34;antspyx&#34;)[0].version,
              &#39;antspynet&#39;: pkg_resources.require(&#34;antspynet&#34;)[0].version,
              &#39;antspyt1w&#39;: pkg_resources.require(&#34;antspyt1w&#34;)[0].version,
              &#39;antspymm&#39;: pkg_resources.require(&#34;antspymm&#34;)[0].version
              }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.wmh"><code class="name flex">
<span>def <span class="ident">wmh</span></span>(<span>flair, t1, t1seg, mmfromconvexhull=3.0, strict=True, probability_mask=None, prior_probability=None, model='sysu', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs the WMH probability mask and a summary single measurement</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>flair</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>input 3-D FLAIR brain image (not skull-stripped).</dd>
<dt><strong><code>t1</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>input 3-D T1 brain image (not skull-stripped).</dd>
<dt><strong><code>t1seg</code></strong> :&ensp;<code>ANTsImage</code></dt>
<dd>T1 segmentation image</dd>
<dt><strong><code>mmfromconvexhull</code></strong> :&ensp;<code>float</code></dt>
<dd>restrict WMH to regions that are WM or mmfromconvexhull mm away from the
convex hull of the cerebrum.
we choose a default value based on
Figure 4 from:
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf</a></dd>
<dt><strong><code>strict</code></strong> :&ensp;<code>boolean - if True, only use convex hull distance</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>probability_mask</code></strong> :&ensp;<code>None - use to compute wmh just once - then this function</code></dt>
<dd>just does refinement and summary</dd>
<dt><strong><code>prior_probability</code></strong> :&ensp;<code>optional prior probability image in space</code> of <code>the input t1</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>either sysu</code> or <code>hyper</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>WMH probability map and a summary single measurement which is the sum</code> of <code>the WMH map</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wmh( flair, t1, t1seg,
    mmfromconvexhull = 3.0,
    strict=True,
    probability_mask=None,
    prior_probability=None,
    model=&#39;sysu&#39;,
    verbose=False ) :
    &#34;&#34;&#34;
    Outputs the WMH probability mask and a summary single measurement

    Arguments
    ---------
    flair : ANTsImage
        input 3-D FLAIR brain image (not skull-stripped).

    t1 : ANTsImage
        input 3-D T1 brain image (not skull-stripped).

    t1seg : ANTsImage
        T1 segmentation image

    mmfromconvexhull : float
        restrict WMH to regions that are WM or mmfromconvexhull mm away from the
        convex hull of the cerebrum.   we choose a default value based on
        Figure 4 from:
        https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240579/pdf/fnagi-10-00339.pdf

    strict: boolean - if True, only use convex hull distance

    probability_mask : None - use to compute wmh just once - then this function
        just does refinement and summary

    prior_probability : optional prior probability image in space of the input t1

    model : either sysu or hyper

    verbose : boolean

    Returns
    ---------
    WMH probability map and a summary single measurement which is the sum of the WMH map

    &#34;&#34;&#34;
    import numpy as np
    import math
    t1_2_flair_reg = ants.registration(flair, t1, type_of_transform = &#39;Rigid&#39;) # Register T1 to Flair
    if probability_mask is None and model == &#39;sysu&#39;:
        if verbose:
            print(&#39;sysu&#39;)
        probability_mask = antspynet.sysu_media_wmh_segmentation( flair )
    elif probability_mask is None and model == &#39;hyper&#39;:
        if verbose:
            print(&#39;hyper&#39;)
        probability_mask = antspynet.hypermapp3r_segmentation( t1_2_flair_reg[&#39;warpedmovout&#39;], flair )
    # t1_2_flair_reg = tra_initializer( flair, t1, n_simulations=4, max_rotation=5, transform=[&#39;rigid&#39;], verbose=False )
    prior_probability_flair = None
    if prior_probability is not None:
        prior_probability_flair = ants.apply_transforms( flair, prior_probability,
            t1_2_flair_reg[&#39;fwdtransforms&#39;] )
    wmseg_mask = ants.threshold_image( t1seg,
        low_thresh = 3, high_thresh = 3).iMath(&#34;FillHoles&#34;)
    wmseg_mask_use = ants.image_clone( wmseg_mask )
    distmask = None
    if mmfromconvexhull &gt; 0:
            convexhull = ants.threshold_image( t1seg, 1, 4 )
            spc2vox = np.prod( ants.get_spacing( t1seg ) )
            voxdist = 0.0
            myspc = ants.get_spacing( t1seg )
            for k in range( t1seg.dimension ):
                voxdist = voxdist + myspc[k] * myspc[k]
            voxdist = math.sqrt( voxdist )
            nmorph = round( 2.0 / voxdist )
            convexhull = ants.morphology( convexhull, &#34;close&#34;, nmorph ).iMath(&#34;FillHoles&#34;)
            dist = ants.iMath( convexhull, &#34;MaurerDistance&#34; ) * -1.0
            distmask = ants.threshold_image( dist, mmfromconvexhull, 1.e80 )
            wmseg_mask = wmseg_mask + distmask
            if strict:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 2, 2 )
            else:
                wmseg_mask_use = ants.threshold_image( wmseg_mask, 1, 2 )
    ##############################################################################
    wmseg_2_flair = ants.apply_transforms(flair, wmseg_mask_use,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    seg_2_flair = ants.apply_transforms(flair, t1seg,
        transformlist = t1_2_flair_reg[&#39;fwdtransforms&#39;],
        interpolator = &#39;nearestNeighbor&#39; )
    csfmask = ants.threshold_image(seg_2_flair,1,1)
    flairsnr = mask_snr( flair, csfmask, wmseg_2_flair, bias_correct = False )
    probability_mask_WM = wmseg_2_flair * probability_mask # Remove WMH signal outside of WM
    wmh_sum = np.prod( ants.get_spacing( flair ) ) * probability_mask_WM.sum()
    wmh_sum_prior = math.nan
    probability_mask_posterior = None
    if prior_probability_flair is not None:
        probability_mask_posterior = prior_probability_flair * probability_mask # use prior
        wmh_sum_prior = np.prod( ants.get_spacing(flair) ) * probability_mask_posterior.sum()
    if math.isnan( wmh_sum ):
        wmh_sum=0
    if math.isnan( wmh_sum_prior ):
        wmh_sum_prior=0
    flair_evr = antspyt1w.patch_eigenvalue_ratio( flair, 512, [16,16,16], evdepth = 0.9, mask=wmseg_2_flair )
    return{
        &#39;WMH_probability_map_raw&#39;: probability_mask,
        &#39;WMH_probability_map&#39; : probability_mask_WM,
        &#39;WMH_posterior_probability_map&#39; : probability_mask_posterior,
        &#39;wmh_mass&#39;: wmh_sum,
        &#39;wmh_mass_prior&#39;: wmh_sum_prior,
        &#39;wmh_evr&#39; : flair_evr,
        &#39;wmh_SNR&#39; : flairsnr,
        &#39;convexhull_mask&#39;: distmask }</code></pre>
</details>
</dd>
<dt id="antspymm.mm.write_bvals_bvecs"><code class="name flex">
<span>def <span class="ident">write_bvals_bvecs</span></span>(<span>bvals, bvecs, prefix)</span>
</code></dt>
<dd>
<div class="desc"><p>Write FSL FDT bvals and bvecs files</p>
<p>adapted from dipy.external code</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bvals</code></strong> :&ensp;<code>(N,) sequence</code></dt>
<dd>&nbsp;</dd>
<dt>Vector with diffusion gradient strength (one per diffusion</dt>
<dt>acquisition, N=no of acquisitions)</dt>
<dt><strong><code>bvecs</code></strong> :&ensp;<code>(N, 3) array-like</code></dt>
<dd>&nbsp;</dd>
<dt>diffusion gradient directions</dt>
<dt><strong><code>prefix</code></strong> :&ensp;<code>string</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>path to write FDT bvals, bvecs text files
None results in current working directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_bvals_bvecs(bvals, bvecs, prefix ):
    &#39;&#39;&#39; Write FSL FDT bvals and bvecs files

    adapted from dipy.external code

    Parameters
    -------------
    bvals : (N,) sequence
       Vector with diffusion gradient strength (one per diffusion
       acquisition, N=no of acquisitions)
    bvecs : (N, 3) array-like
       diffusion gradient directions
    prefix : string
       path to write FDT bvals, bvecs text files
       None results in current working directory.
    &#39;&#39;&#39;
    _VAL_FMT = &#39;   %e&#39;
    bvals = tuple(bvals)
    bvecs = np.asarray(bvecs)
    bvecs[np.isnan(bvecs)] = 0
    N = len(bvals)
    fname = prefix + &#39;.bval&#39;
    fmt = _VAL_FMT * N + &#39;\n&#39;
    open(fname, &#39;wt&#39;).write(fmt % bvals)
    fname = prefix + &#39;.bvec&#39;
    bvf = open(fname, &#39;wt&#39;)
    for dim_vals in bvecs.T:
        bvf.write(fmt % tuple(dim_vals))</code></pre>
</details>
</dd>
<dt id="antspymm.mm.write_mm"><code class="name flex">
<span>def <span class="ident">write_mm</span></span>(<span>output_prefix, mm, mm_norm=None, t1wide=None, separator='_')</span>
</code></dt>
<dd>
<div class="desc"><p>write the tabular and normalization output of the mm function</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>output_prefix</code></strong> :&ensp;<code>prefix for file outputs - modality specific postfix will be added</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>mm
: output of mm function for modality-space processing</p>
<dl>
<dt><strong><code>mm_norm</code></strong> :&ensp;<code>output</code> of <code><a title="antspymm.mm.mm" href="#antspymm.mm.mm">mm()</a> function for normalized processing</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>t1wide</code></strong> :&ensp;<code>wide output data frame from t1 hierarchical</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>separator</code></strong> :&ensp;<code>string</code> or <code>character separator for filenames</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>both csv and image files written to disk.
the primary outputs will be</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>output_prefix + separator + 'mmwide.csv' and *norm.nii.gz images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_mm( output_prefix, mm, mm_norm=None, t1wide=None, separator=&#39;_&#39; ):
    &#34;&#34;&#34;
    write the tabular and normalization output of the mm function

    Parameters
    -------------

    output_prefix : prefix for file outputs - modality specific postfix will be added

    mm  : output of mm function for modality-space processing

    mm_norm : output of mm function for normalized processing

    t1wide : wide output data frame from t1 hierarchical

    separator : string or character separator for filenames

    Returns
    ---------

    both csv and image files written to disk.  the primary outputs will be
    output_prefix + separator + &#39;mmwide.csv&#39; and *norm.nii.gz images

    &#34;&#34;&#34;
    from dipy.io.streamline import save_tractogram
    if mm_norm is not None:
        for mykey in mm_norm.keys():
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            if mm_norm[mykey] is not None:
                image_write_with_thumbnail( mm_norm[mykey], tempfn )
    thkderk = None
    if t1wide is not None:
        thkderk = t1wide.iloc[: , 1:]
    kkderk = None
    if mm[&#39;kk&#39;] is not None:
        kkderk = mm[&#39;kk&#39;][&#39;thickness_dataframe&#39;].iloc[: , 1:]
        mykey=&#39;thickness_image&#39;
        tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
        image_write_with_thumbnail( mm[&#39;kk&#39;][mykey], tempfn )
    nmderk = None
    if mm[&#39;NM&#39;] is not None:
        nmderk = mm[&#39;NM&#39;][&#39;NM_dataframe_wide&#39;].iloc[: , 1:]
        for mykey in [&#39;NM_avg_cropped&#39;, &#39;NM_avg&#39;, &#39;NM_labels&#39; ]:
            tempfn = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( mm[&#39;NM&#39;][mykey], tempfn, thumb=False )

    faderk = mdderk = fat1derk = mdt1derk = None
    if mm[&#39;DTI&#39;] is not None:
        mydti = mm[&#39;DTI&#39;]
        myop = output_prefix + separator
        write_bvals_bvecs( mydti[&#39;bval_LR&#39;], mydti[&#39;bvec_LR&#39;], myop + &#39;reoriented&#39; )
        image_write_with_thumbnail( mydti[&#39;dwi_LR_dewarped&#39;],  myop + &#39;dwi.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;dtrecon_LR_dewarp&#39;][&#39;RGB&#39;] ,  myop + &#39;DTIRGB.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;jhu_labels&#39;],  myop+&#39;dtijhulabels.nii.gz&#39;, mydti[&#39;recon_fa&#39;] )
        image_write_with_thumbnail( mydti[&#39;recon_fa&#39;],  myop+&#39;dtifa.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;recon_md&#39;],  myop+&#39;dtimd.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;b0avg&#39;],  myop+&#39;b0avg.nii.gz&#39; )
        image_write_with_thumbnail( mydti[&#39;dwiavg&#39;],  myop+&#39;dwiavg.nii.gz&#39; )
        faderk = mm[&#39;DTI&#39;][&#39;recon_fa_summary&#39;].iloc[: , 1:]
        mdderk = mm[&#39;DTI&#39;][&#39;recon_md_summary&#39;].iloc[: , 1:]
        fat1derk = mm[&#39;FA_summ&#39;].iloc[: , 1:]
        mdt1derk = mm[&#39;MD_summ&#39;].iloc[: , 1:]
    if mm[&#39;tractography&#39;] is not None:
        ofn = output_prefix + separator + &#39;tractogram.trk&#39;
        save_tractogram( mm[&#39;tractography&#39;][&#39;tractogram&#39;], ofn )
    cnxderk = None
    if mm[&#39;tractography_connectivity&#39;] is not None:
        cnxderk = mm[&#39;tractography_connectivity&#39;][&#39;connectivity_wide&#39;].iloc[: , 1:] # NOTE: connectivity_wide is not much tested
        ofn = output_prefix + separator + &#39;dtistreamlineconn.csv&#39;
        pd.DataFrame(mm[&#39;tractography_connectivity&#39;][&#39;connectivity_matrix&#39;]).to_csv( ofn )
    mm_wide = pd.concat( [
        thkderk,
        kkderk,
        nmderk,
        faderk,
        mdderk,
        fat1derk,
        mdt1derk,
        cnxderk
        ], axis=1 )
    mm_wide = mm_wide.copy()
    if mm[&#39;NM&#39;] is not None:
        mm_wide[&#39;NM_avg_signaltonoise&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_signaltonoise&#39;]
        mm_wide[&#39;NM_avg_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_substantianigra&#39;]
        mm_wide[&#39;NM_std_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_std_substantianigra&#39;]
        mm_wide[&#39;NM_volume_substantianigra&#39;] = mm[&#39;NM&#39;][&#39;NM_volume_substantianigra&#39;]
        mm_wide[&#39;NM_avg_refregion&#39;] = mm[&#39;NM&#39;][&#39;NM_avg_refregion&#39;]
        mm_wide[&#39;NM_std_refregion&#39;] = mm[&#39;NM&#39;][&#39;NM_std_refregion&#39;]
        mm_wide[&#39;NM_evr&#39;] = mm[&#39;NM&#39;][&#39;NM_evr&#39;]
        mm_wide[&#39;NM_count&#39;] = mm[&#39;NM&#39;][&#39;NM_count&#39;]
        mm_wide[&#39;NM_min&#39;] = mm[&#39;NM&#39;][&#39;NM_min&#39;]
        mm_wide[&#39;NM_max&#39;] = mm[&#39;NM&#39;][&#39;NM_max&#39;]
        mm_wide[&#39;NM_mean&#39;] = mm[&#39;NM&#39;][&#39;NM_mean&#39;]
        mm_wide[&#39;NM_sd&#39;] = mm[&#39;NM&#39;][&#39;NM_sd&#39;]
        mm_wide[&#39;NM_q0pt05&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt05&#39;]
        mm_wide[&#39;NM_q0pt10&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt10&#39;]
        mm_wide[&#39;NM_q0pt90&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt90&#39;]
        mm_wide[&#39;NM_q0pt95&#39;] = mm[&#39;NM&#39;][&#39;NM_q0pt95&#39;]
        mm_wide[&#39;NM_substantianigra_z_coordinate&#39;] = mm[&#39;NM&#39;][&#39;NM_substantianigra_z_coordinate&#39;]
    if mm[&#39;flair&#39;] is not None:
        myop = output_prefix + separator + &#39;wmh.nii.gz&#39;
        if mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;] is not None:
            image_write_with_thumbnail( mm[&#39;flair&#39;][&#39;WMH_probability_map&#39;], myop, thumb=False )
        mm_wide[&#39;flair_wmh&#39;] = mm[&#39;flair&#39;][&#39;wmh_mass&#39;]
        mm_wide[&#39;flair_wmh_prior&#39;] = mm[&#39;flair&#39;][&#39;wmh_mass_prior&#39;]
        mm_wide[&#39;flair_evr&#39;] = mm[&#39;flair&#39;][&#39;wmh_evr&#39;]
        mm_wide[&#39;flair_SNR&#39;] = mm[&#39;flair&#39;][&#39;wmh_SNR&#39;]
    if mm[&#39;rsf&#39;] is not None:
        mynets = list([ &#39;meanBold&#39;, &#39;brain_mask&#39;, &#39;motion_corrected&#39;, &#39;alff&#39;, &#39;falff&#39;,
            &#39;CinguloopercularTaskControl&#39;, &#39;DefaultMode&#39;, &#39;MemoryRetrieval&#39;,
            &#39;VentralAttention&#39;, &#39;Visual&#39;, &#39;FrontoparietalTaskControl&#39;, &#39;Salience&#39;,
            &#39;Subcortical&#39;, &#39;DorsalAttention&#39;, &#39;tsnr&#39;] )
        rsfpro = mm[&#39;rsf&#39;]
        for mykey in mynets:
            myop = output_prefix + separator + mykey + &#39;.nii.gz&#39;
            image_write_with_thumbnail( rsfpro[mykey], myop, thumb=True )
        rsfpro[&#39;corr_wide&#39;].set_index( mm_wide.index, inplace=True )
        mm_wide = pd.concat( [ mm_wide, rsfpro[&#39;corr_wide&#39;] ], axis=1 )
        # falff and alff
        search_key=&#39;alffPoint&#39;
        alffkeys = [key for key, val in rsfpro.items() if search_key in key]
        for myalf in alffkeys:
            mm_wide[ myalf ]=rsfpro[myalf]
        mm_wide[&#39;rsf_tsnr_mean&#39;] =  rsfpro[&#39;tsnr&#39;].mean()
        mm_wide[&#39;rsf_dvars_mean&#39;] =  rsfpro[&#39;dvars&#39;].mean()
        mm_wide[&#39;rsf_ssnr_mean&#39;] =  rsfpro[&#39;ssnr&#39;].mean()
        mm_wide[&#39;rsf_high_motion_count&#39;] =  rsfpro[&#39;high_motion_count&#39;]
        # mm_wide[&#39;rsf_high_motion_pct&#39;] = rsfpro[&#39;rsf_high_motion_pct&#39;] # BUG : rsf_high_motion_pct does not exist
        mm_wide[&#39;rsf_evr&#39;] =  rsfpro[&#39;bold_evr&#39;]
        mm_wide[&#39;rsf_FD_mean&#39;] = rsfpro[&#39;FD_mean&#39;]
        mm_wide[&#39;rsf_FD_max&#39;] = rsfpro[&#39;FD_max&#39;]
        mm_wide[&#39;rsf_alff_mean&#39;] = rsfpro[&#39;alff_mean&#39;]
        mm_wide[&#39;rsf_alff_sd&#39;] = rsfpro[&#39;alff_sd&#39;]
        mm_wide[&#39;rsf_falff_mean&#39;] = rsfpro[&#39;falff_mean&#39;]
        mm_wide[&#39;rsf_falff_sd&#39;] = rsfpro[&#39;falff_sd&#39;]
        ofn = output_prefix + separator + &#39;rsfcorr.csv&#39;
        rsfpro[&#39;corr&#39;].to_csv( ofn )
        # apply same principle to new correlation matrix, doesn&#39;t need to be incorporated with mm_wide
        ofn2 = output_prefix + separator + &#39;nodescorr.csv&#39;
        rsfpro[&#39;fullCorrMat&#39;].to_csv( ofn2 )
    if mm[&#39;DTI&#39;] is not None:
        mydti = mm[&#39;DTI&#39;]
        mm_wide[&#39;dti_tsnr_b0_mean&#39;] =  mydti[&#39;tsnr_b0&#39;].mean()
        mm_wide[&#39;dti_tsnr_dwi_mean&#39;] =  mydti[&#39;tsnr_dwi&#39;].mean()
        mm_wide[&#39;dti_dvars_b0_mean&#39;] =  mydti[&#39;dvars_b0&#39;].mean()
        mm_wide[&#39;dti_dvars_dwi_mean&#39;] =  mydti[&#39;dvars_dwi&#39;].mean()
        mm_wide[&#39;dti_ssnr_b0_mean&#39;] =  mydti[&#39;ssnr_b0&#39;].mean()
        mm_wide[&#39;dti_ssnr_dwi_mean&#39;] =  mydti[&#39;ssnr_dwi&#39;].mean()
        mm_wide[&#39;dti_fa_evr&#39;] =  mydti[&#39;fa_evr&#39;]
        mm_wide[&#39;dti_fa_SNR&#39;] =  mydti[&#39;fa_SNR&#39;]
        if mydti[&#39;framewise_displacement&#39;] is not None:
            mm_wide[&#39;dti_high_motion_count&#39;] =  mydti[&#39;high_motion_count&#39;]
            mm_wide[&#39;dti_FD_mean&#39;] = mydti[&#39;framewise_displacement&#39;].mean()
            mm_wide[&#39;dti_FD_max&#39;] = mydti[&#39;framewise_displacement&#39;].max()
            fdfn = output_prefix + separator + &#39;_fd.csv&#39;
            # mm_wide.to_csv( fdfn )
        else:
            mm_wide[&#39;dti_FD_mean&#39;] = mm_wide[&#39;dti_FD_max&#39;] = &#39;NA&#39;
    mmwidefn = output_prefix + separator + &#39;mmwide.csv&#39;
    mm_wide.to_csv( mmwidefn )
    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="antspymm" href="index.html">antspymm</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="antspymm.mm.alff_image" href="#antspymm.mm.alff_image">alff_image</a></code></li>
<li><code><a title="antspymm.mm.alffmap" href="#antspymm.mm.alffmap">alffmap</a></code></li>
<li><code><a title="antspymm.mm.assemble_modality_specific_dataframes" href="#antspymm.mm.assemble_modality_specific_dataframes">assemble_modality_specific_dataframes</a></code></li>
<li><code><a title="antspymm.mm.augment_image" href="#antspymm.mm.augment_image">augment_image</a></code></li>
<li><code><a title="antspymm.mm.average_blind_qc_by_modality" href="#antspymm.mm.average_blind_qc_by_modality">average_blind_qc_by_modality</a></code></li>
<li><code><a title="antspymm.mm.average_mm_df" href="#antspymm.mm.average_mm_df">average_mm_df</a></code></li>
<li><code><a title="antspymm.mm.best_mmm" href="#antspymm.mm.best_mmm">best_mmm</a></code></li>
<li><code><a title="antspymm.mm.bids_2_nrg" href="#antspymm.mm.bids_2_nrg">bids_2_nrg</a></code></li>
<li><code><a title="antspymm.mm.bind_wide_mm_csvs" href="#antspymm.mm.bind_wide_mm_csvs">bind_wide_mm_csvs</a></code></li>
<li><code><a title="antspymm.mm.blind_image_assessment" href="#antspymm.mm.blind_image_assessment">blind_image_assessment</a></code></li>
<li><code><a title="antspymm.mm.boot_wmh" href="#antspymm.mm.boot_wmh">boot_wmh</a></code></li>
<li><code><a title="antspymm.mm.bvec_reorientation" href="#antspymm.mm.bvec_reorientation">bvec_reorientation</a></code></li>
<li><code><a title="antspymm.mm.collect_blind_qc_by_modality" href="#antspymm.mm.collect_blind_qc_by_modality">collect_blind_qc_by_modality</a></code></li>
<li><code><a title="antspymm.mm.concat_dewarp" href="#antspymm.mm.concat_dewarp">concat_dewarp</a></code></li>
<li><code><a title="antspymm.mm.crop_mcimage" href="#antspymm.mm.crop_mcimage">crop_mcimage</a></code></li>
<li><code><a title="antspymm.mm.dewarp_imageset" href="#antspymm.mm.dewarp_imageset">dewarp_imageset</a></code></li>
<li><code><a title="antspymm.mm.dipy_dti_recon" href="#antspymm.mm.dipy_dti_recon">dipy_dti_recon</a></code></li>
<li><code><a title="antspymm.mm.down2iso" href="#antspymm.mm.down2iso">down2iso</a></code></li>
<li><code><a title="antspymm.mm.dti_reg" href="#antspymm.mm.dti_reg">dti_reg</a></code></li>
<li><code><a title="antspymm.mm.dti_template" href="#antspymm.mm.dti_template">dti_template</a></code></li>
<li><code><a title="antspymm.mm.dvars" href="#antspymm.mm.dvars">dvars</a></code></li>
<li><code><a title="antspymm.mm.dwi_closest_peak_tracking" href="#antspymm.mm.dwi_closest_peak_tracking">dwi_closest_peak_tracking</a></code></li>
<li><code><a title="antspymm.mm.dwi_deterministic_tracking" href="#antspymm.mm.dwi_deterministic_tracking">dwi_deterministic_tracking</a></code></li>
<li><code><a title="antspymm.mm.dwi_streamline_connectivity" href="#antspymm.mm.dwi_streamline_connectivity">dwi_streamline_connectivity</a></code></li>
<li><code><a title="antspymm.mm.dwi_streamline_pairwise_connectivity" href="#antspymm.mm.dwi_streamline_pairwise_connectivity">dwi_streamline_pairwise_connectivity</a></code></li>
<li><code><a title="antspymm.mm.foreground_background_snr" href="#antspymm.mm.foreground_background_snr">foreground_background_snr</a></code></li>
<li><code><a title="antspymm.mm.generate_mm_dataframe" href="#antspymm.mm.generate_mm_dataframe">generate_mm_dataframe</a></code></li>
<li><code><a title="antspymm.mm.get_average_dwi_b0" href="#antspymm.mm.get_average_dwi_b0">get_average_dwi_b0</a></code></li>
<li><code><a title="antspymm.mm.get_average_rsf" href="#antspymm.mm.get_average_rsf">get_average_rsf</a></code></li>
<li><code><a title="antspymm.mm.get_data" href="#antspymm.mm.get_data">get_data</a></code></li>
<li><code><a title="antspymm.mm.get_models" href="#antspymm.mm.get_models">get_models</a></code></li>
<li><code><a title="antspymm.mm.get_names_from_data_frame" href="#antspymm.mm.get_names_from_data_frame">get_names_from_data_frame</a></code></li>
<li><code><a title="antspymm.mm.get_valid_modalities" href="#antspymm.mm.get_valid_modalities">get_valid_modalities</a></code></li>
<li><code><a title="antspymm.mm.hierarchical_modality_summary" href="#antspymm.mm.hierarchical_modality_summary">hierarchical_modality_summary</a></code></li>
<li><code><a title="antspymm.mm.highest_quality_repeat" href="#antspymm.mm.highest_quality_repeat">highest_quality_repeat</a></code></li>
<li><code><a title="antspymm.mm.image_write_with_thumbnail" href="#antspymm.mm.image_write_with_thumbnail">image_write_with_thumbnail</a></code></li>
<li><code><a title="antspymm.mm.impute_fa" href="#antspymm.mm.impute_fa">impute_fa</a></code></li>
<li><code><a title="antspymm.mm.joint_dti_recon" href="#antspymm.mm.joint_dti_recon">joint_dti_recon</a></code></li>
<li><code><a title="antspymm.mm.mask_snr" href="#antspymm.mm.mask_snr">mask_snr</a></code></li>
<li><code><a title="antspymm.mm.match_modalities" href="#antspymm.mm.match_modalities">match_modalities</a></code></li>
<li><code><a title="antspymm.mm.mc_denoise" href="#antspymm.mm.mc_denoise">mc_denoise</a></code></li>
<li><code><a title="antspymm.mm.mc_reg" href="#antspymm.mm.mc_reg">mc_reg</a></code></li>
<li><code><a title="antspymm.mm.mc_resample_image_to_target" href="#antspymm.mm.mc_resample_image_to_target">mc_resample_image_to_target</a></code></li>
<li><code><a title="antspymm.mm.merge_dwi_data" href="#antspymm.mm.merge_dwi_data">merge_dwi_data</a></code></li>
<li><code><a title="antspymm.mm.merge_mm_dataframe" href="#antspymm.mm.merge_mm_dataframe">merge_mm_dataframe</a></code></li>
<li><code><a title="antspymm.mm.merge_timeseries_data" href="#antspymm.mm.merge_timeseries_data">merge_timeseries_data</a></code></li>
<li><code><a title="antspymm.mm.merge_wides_to_study_dataframe" href="#antspymm.mm.merge_wides_to_study_dataframe">merge_wides_to_study_dataframe</a></code></li>
<li><code><a title="antspymm.mm.middle_slice_snr" href="#antspymm.mm.middle_slice_snr">middle_slice_snr</a></code></li>
<li><code><a title="antspymm.mm.mm" href="#antspymm.mm.mm">mm</a></code></li>
<li><code><a title="antspymm.mm.mm_csv" href="#antspymm.mm.mm_csv">mm_csv</a></code></li>
<li><code><a title="antspymm.mm.mm_nrg" href="#antspymm.mm.mm_nrg">mm_nrg</a></code></li>
<li><code><a title="antspymm.mm.mm_read" href="#antspymm.mm.mm_read">mm_read</a></code></li>
<li><code><a title="antspymm.mm.mm_read_to_3d" href="#antspymm.mm.mm_read_to_3d">mm_read_to_3d</a></code></li>
<li><code><a title="antspymm.mm.neuromelanin" href="#antspymm.mm.neuromelanin">neuromelanin</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_ee" href="#antspymm.mm.novelty_detection_ee">novelty_detection_ee</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_lof" href="#antspymm.mm.novelty_detection_lof">novelty_detection_lof</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_loop" href="#antspymm.mm.novelty_detection_loop">novelty_detection_loop</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_quantile" href="#antspymm.mm.novelty_detection_quantile">novelty_detection_quantile</a></code></li>
<li><code><a title="antspymm.mm.novelty_detection_svm" href="#antspymm.mm.novelty_detection_svm">novelty_detection_svm</a></code></li>
<li><code><a title="antspymm.mm.nrg_2_bids" href="#antspymm.mm.nrg_2_bids">nrg_2_bids</a></code></li>
<li><code><a title="antspymm.mm.nrg_filelist_to_dataframe" href="#antspymm.mm.nrg_filelist_to_dataframe">nrg_filelist_to_dataframe</a></code></li>
<li><code><a title="antspymm.mm.nrg_format_path" href="#antspymm.mm.nrg_format_path">nrg_format_path</a></code></li>
<li><code><a title="antspymm.mm.outlierness_by_modality" href="#antspymm.mm.outlierness_by_modality">outlierness_by_modality</a></code></li>
<li><code><a title="antspymm.mm.parse_nrg_filename" href="#antspymm.mm.parse_nrg_filename">parse_nrg_filename</a></code></li>
<li><code><a title="antspymm.mm.quantile_snr" href="#antspymm.mm.quantile_snr">quantile_snr</a></code></li>
<li><code><a title="antspymm.mm.quick_viz_mm_nrg" href="#antspymm.mm.quick_viz_mm_nrg">quick_viz_mm_nrg</a></code></li>
<li><code><a title="antspymm.mm.read_mm_csv" href="#antspymm.mm.read_mm_csv">read_mm_csv</a></code></li>
<li><code><a title="antspymm.mm.resting_state_fmri_networks" href="#antspymm.mm.resting_state_fmri_networks">resting_state_fmri_networks</a></code></li>
<li><code><a title="antspymm.mm.segment_timeseries_by_meanvalue" href="#antspymm.mm.segment_timeseries_by_meanvalue">segment_timeseries_by_meanvalue</a></code></li>
<li><code><a title="antspymm.mm.slice_snr" href="#antspymm.mm.slice_snr">slice_snr</a></code></li>
<li><code><a title="antspymm.mm.study_dataframe_from_matched_dataframe" href="#antspymm.mm.study_dataframe_from_matched_dataframe">study_dataframe_from_matched_dataframe</a></code></li>
<li><code><a title="antspymm.mm.super_res_mcimage" href="#antspymm.mm.super_res_mcimage">super_res_mcimage</a></code></li>
<li><code><a title="antspymm.mm.t1_based_dwi_brain_extraction" href="#antspymm.mm.t1_based_dwi_brain_extraction">t1_based_dwi_brain_extraction</a></code></li>
<li><code><a title="antspymm.mm.threaded_bind_wide_mm_csvs" href="#antspymm.mm.threaded_bind_wide_mm_csvs">threaded_bind_wide_mm_csvs</a></code></li>
<li><code><a title="antspymm.mm.timeseries_reg" href="#antspymm.mm.timeseries_reg">timeseries_reg</a></code></li>
<li><code><a title="antspymm.mm.tra_initializer" href="#antspymm.mm.tra_initializer">tra_initializer</a></code></li>
<li><code><a title="antspymm.mm.trim_dti_mask" href="#antspymm.mm.trim_dti_mask">trim_dti_mask</a></code></li>
<li><code><a title="antspymm.mm.tsnr" href="#antspymm.mm.tsnr">tsnr</a></code></li>
<li><code><a title="antspymm.mm.version" href="#antspymm.mm.version">version</a></code></li>
<li><code><a title="antspymm.mm.wmh" href="#antspymm.mm.wmh">wmh</a></code></li>
<li><code><a title="antspymm.mm.write_bvals_bvecs" href="#antspymm.mm.write_bvals_bvecs">write_bvals_bvecs</a></code></li>
<li><code><a title="antspymm.mm.write_mm" href="#antspymm.mm.write_mm">write_mm</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>