---
title: antspymm data dictionary summary
output: html_document
---

```{r,echo=FALSE,include=FALSE}
dev.flush()
library("permute")
library(MGMM) # GMM methods (FIXME)
library(WeightedCluster) # cluster quality (FIXME)
library( kmed ) # silhouette plots and such
library( clustree ) # cluster validation tools
library( factoextra )
library(tidyverse)
library(magrittr)
library(cluster)
library(cluster.datasets)
library(cowplot)
library(NbClust)
library(clValid)
library(ggfortify)
library(clustree)
library(dendextend)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(GGally)
library(ANTsR)
library(subtyper)
library(plyr)
library(data.table)
library(ztable)
library(moonBook)
library(kableExtra)
library(flextable)
library(plotly)
library( ztable )
library(ggpubr)
library(gridExtra)
library(ggsci)
options(digits=3)
library(lmerTest)
library(lme4)
options( ztable.type="html" )
tblcmd = ztable
rr=read.csv("~/code/ANTsPyMM/antspymm_data_dictionary.csv")
ss=rr[,c("Atlas","Measurement",'Modality' )]
```


The `ANTsPyMM` system takes advantage of template-based priors. 

* We quantify cortex with the Desikan-Killiany-Tourville parcellation ([DKT](https://doi.org/10.3389/fnins.2012.00171)).

* Subcortical segmentation with deep learning and also SyN registration leverages the CIT168 atlas [10.1101/211201](https://doi.org/10.1101/211201).

* A medial temporal lobe parcellation is based on manual labels derived from M. Yassa's research group ([preprint](https://doi.org/10.1101/2023.01.17.23284693)).

* A cerebellum parcellation based on a template from the [CoBrALab](https://www.cobralab.ca/cerebellum-lobules) with additional manual editing by the Tustison family (publication in progress).  The parcellation scheme is defined using the Schmahmann nomenclature ([reviewed here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6271471/)).  The core tool is named `cerebellum_morphology` and based on a concatentation of two U-nets.

* Brain stem is subdivided into the mid-brain, pons and medulla; This segmentation derives from registration between the individual T1w and the manually labeled CIT168 template.

* We segment anatomy related to the basal forebrain and associated cholinergic neurons with a deep learning method (`deepNBM`) derived from manual labeling of ADNI data.  

    * This approach is based on anatomical landmarks proposed in [Liu, A. et al. (2015)](https://doi.org/10.1007/s00401-015-1392-5).  The `deepNBM` method uses super-resolution segmentation to take advantage of manual labels performed on super-resolution training data.

    * The classic [Zaborszky, L. et al. (2008) "Stereotaxic probabilistic maps of the magnocellular cell groups in human basal forebrain." Neuroimage 42: 1127--1141](https://www.sciencedirect.com/science/article/abs/pii/S1053811908006903) also informed the manual labeling.

* The Mori JHU white matter atlas provides a parcellation of white matter regions ([paper here](https://www.sciencedirect.com/science/article/abs/pii/S105381190700688X?via%3Dihub)) which are applied to diffusion weighted images.

* Jonathan Power's coordinates from "Functional Network Organization of the Human Brain" [10.1016/j.neuron.2011.09.006](10.1016/j.neuron.2011.09.006) guide our analysis of resting state function MRI (rsfMRI).

The `ANTsPyMM` data dictionary labels associates each column name with each of the above anatomical references.  Table 1 below summarizes the number of variables associated with each modality and anatomical prior space.  DTI-derived connectivity yields the largest number of variables because we pairwise map each DKT cortical region as well as the primary CIT168 regions.


### Table 1
```{r,echo=FALSE,results='asis',warning=FALSE,message=FALSE}
myt=mytable( Modality~. ,data=ss )
tblcmd( myt )
```

```{r detailsandcitations,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=TRUE}
# powers points 10.1016/j.conb.2012.12.009
powers=read.csv("~/.antspymm/powers_mni_itk.csv")
# 10.1016/j.neuroimage.2008.07.009
# https://doi.org/10.1016/j.neuroimage.2007.07.053
jhu=read.csv("~/.antspyt1w/FA_JHU_labels_edited.csv")
# doi: 10.3389/fnins.2012.00171
# http://dx.doi.org/10.1016/j.neuroimage.2006.01.021
dktcsv=read.csv("~/.antspyt1w/dkt.csv")
dktcsv=dktcsv[dktcsv$Label>0,]
# hipp https://doi.org/10.1101/2023.01.17.23284693
hipp=read.csv("~/.antspyt1w/mtl_description.csv")
hipp$Anatomy=hipp$Description
hipp$Anatomy=gsub("alEC"," antero-lateral entorhinal cortex",hipp$Anatomy)
hipp$Anatomy=gsub("pMEC"," postero-medial entorhinal cortex",hipp$Anatomy)
hipp$Anatomy=gsub("DG"," dentate gyrus",hipp$Anatomy)
hipp$Anatomy=gsub("CA"," cornu ammonis", hipp$Anatomy)

# https://doi.org/10.1101/211201
cit=read.csv("~/.antspyt1w/CIT168_Reinf_Learn_v1_label_descriptions_pad.csv")
cit$Anatomy=NA
cit$Anatomy[  grep("STR_Ca", cit$Description )] = 'caudate'
cit$Anatomy[  grep("STR_Pu", cit$Description )] = 'putamen'
cit$Anatomy[  grep("STR_NAC", cit$Description )] = 'Nucleus Accumbens'
cit$Anatomy[  grep("VTA", cit$Description )] = 'Ventral Tegmental Area'
cit$Anatomy[  grep("PBP", cit$Description )] = 'Parabrachial Pigmented Nucleus'
cit$Anatomy[  grep("SNc", cit$Description )] = 'Substantia Nigra pars compacta'
cit$Anatomy[  grep("SNr", cit$Description )] = 'Substantia Nigra pars reticulated'
cit$Anatomy[  grep("GPe", cit$Description )] = 'globus pallidus externa'
cit$Anatomy[  grep("GPi", cit$Description )] = 'globus pallidus interna'
cit$Anatomy[  grep("RN", cit$Description )] = 'red nucleus'
cit$Anatomy[  grep("STH", cit$Description )] = 'Subthalamic Nucleus'
cit$Anatomy[  grep("HTH", cit$Description )] = 'Hypothalamus'
cit$Anatomy[  grep("HN", cit$Description )] = 'Habenular Nuclei'
cit$Anatomy[  grep("EXA", cit$Description )] = 'extended amygdala'
cit$Anatomy[  grep("BNST", cit$Description )] = 'bed nuclei of the stria terminali'
cit$Anatomy[  grep("MN", cit$Description )] = 'mammillary nucleus'
cit$Anatomy[  grep("SLEA", cit$Description )] = 'sublenticular extended amygdala'
cit$Anatomy[  grep("VeP", cit$Description )] = 'ventral pallidum'

interpretcnx<-function( x ) {
    breaker=gsub("DTI_cnxcount","",x)
    temp = unlist(strsplit(breaker,"_"))
    ind=temp[1]
    anat=paste( temp[-1],collapse='_')
    return( paste( anat, "to", dktcsv[as.integer(ind),'Description'] ) )
}
interpretcnx2<-function( x ) {
    breaker=gsub("DTI_cnxcount","",x)
    temp = unlist(strsplit(breaker,"_"))
    ind=temp[1]
    anat=paste( temp[-1],collapse='_')
    return( dktcsv[as.integer(ind),'Description'] )
}

if ( ! exists("dd") ) {
    dfn='~/code/multidisorder/data/ppmi_gwas/ppmi_matched_qc_mm_srfirst.csv'
    dd=read.csv( dfn )
    ddnms=names(dd)
}

# dd=read.csv("joined_mm_or2.csv")
zz=data.frame( Label=colnames(dd))
qcrows=min(grep("RandBasis",zz$Label)):grep("resnetGrade", zz$Label)
zz$Modality='Other'
zz[ grep("T1Hier", zz$Label), 'Modality']='T1 hierarchical processing'
zz[ grep("T1w", zz$Label), 'Modality']='T1 DiReCT thickness processing'
zz[ grep("DTI", zz$Label), 'Modality']='DTI'
zz[ grep("NM2DMT", zz$Label), 'Modality']='Neuromelanin'
zz[ grep("rsfMRI", zz$Label), 'Modality']='restingStatefMRI'
zz[ grep("lair", zz$Label), 'Modality']='Flair'
zz[ grep("left", zz$Label), 'side']='left'
zz[ grep("right", zz$Label), 'side']='right'
zz$Atlas='ANTs'
zz[ grep("dkt", zz$Label), 'Atlas']='desikan-killiany-tourville'
zz[ grep("cnxcou", zz$Label), 'Atlas']='desikan-killiany-tourville'
zz[ grep("jhu", zz$Label), 'Atlas']='johns hopkins white matter'
zz[ grep("cit", zz$Label), 'Atlas']='CIT168'
zz[ grep("nbm", zz$Label), 'Atlas']='BF'
zz[ grep("ch13", zz$Label), 'Atlas']='BF'
zz[ grep("mtl", zz$Label), 'Atlas']='MTL'
zz[ grep("rsfMRI", zz$Label),'Atlas']='power peterson fMRI meta-analyses'
zz[qcrows,'Atlas']='quality control metrics'
zz[qcrows,'Measurement']='QC'
zz$Measurement[  grep("FD", zz$Label)]='motion statistic on framewise displacement'
zz$Measurement[  grep("thk", zz$Label)]='geometry/thickness'
zz$Measurement[  grep("area", zz$Label)]='geometry/area'
zz$Measurement[  grep("vol", zz$Label)]='geometry/volume'
zz$Measurement[  grep("mean_md", zz$Label)]='mean diffusion'
zz$Measurement[  grep("mean_fa", zz$Label)]='fractional anisotropy'
zz$Measurement[  grep("cnx", zz$Label)]='tractography-based connectivity'
zz$Anatomy = zz$Label
zz$Anatomy = gsub("_thk_","", zz$Anatomy)
zz$Anatomy = gsub("_area_","", zz$Anatomy)
zz$Anatomy = gsub("_volume_","", zz$Anatomy)
zz$Anatomy = gsub("DTI_cnxcount","", zz$Anatomy)
zz$Anatomy = gsub("DTI_mean_md","", zz$Anatomy)
zz$Anatomy = gsub("DTI_mean_fa","", zz$Anatomy)
zz$Anatomy = gsub("T1Hier_","", zz$Anatomy)
zz$Anatomy = gsub("T1Hier","", zz$Anatomy)
# fix dkt
dktlabs=dktcsv$Description
dktlabs=gsub("right ","",dktlabs)
dktlabs=gsub("left ","",dktlabs)
dktlabs2=gsub(" ","_",dktlabs)
for ( k in 1:length(dktlabs) ) {
    gg=grep( dktlabs[k], zz$Label)
    zz[ gg, "Atlas"]="desikan-killiany-tourville"
    zz[ gg, "Anatomy"]=dktlabs[k]
    gg=grep( dktlabs2[k], zz$Label)
    zz[ gg, "Atlas"]="desikan-killiany-tourville"
    zz[ gg, "Anatomy"]=dktlabs[k]
}

# fix cit
citlabs=tolower( cit$Description)
for ( k in 1:length(citlabs) ) {
    gg=grep( citlabs[k], zz$Label)
    zz[ gg, "Atlas"]="CIT168"
    zz[ gg, "Anatomy"]=cit$Anatomy[k]
}
zz$Anatomy = gsub("DTIfa","", zz$Anatomy)
zz$Anatomy = gsub("DTImd","", zz$Anatomy)
zz$Anatomy = gsub("dktregions","", zz$Anatomy)
zz$Anatomy = gsub("dktcortex"," cortex only ", zz$Anatomy)
zz$Anatomy = gsub("_right_","", zz$Anatomy)
zz$Anatomy = gsub("_left_","", zz$Anatomy)
zz$Anatomy = gsub("right","", zz$Anatomy)
zz$Anatomy = gsub("left","", zz$Anatomy)
zz$Anatomy = gsub("jhu_icbm_labels_1mm","", zz$Anatomy)
zz[ grep("u_hier_id", zz$Label), -1 ]='unique id'
cnxrows=grep("DTI_cnxcount",zz$Label)
for ( k in cnxrows )
    zz$Anatomy[k]=interpretcnx( zz[k,'Label'] )

zz[ multigrep( c("rsfMRI","R"), zz$Label, intersect=TRUE), 'side'  ]='right'
zz[ multigrep( c("rsfMRI","L"), zz$Label, intersect=TRUE), 'side'  ]='left'
zz$Measurement[ multigrep( c("rsfMRI","_2_"), zz$Label, intersect=TRUE) ]='network correlation'
zz$Measurement[ multigrep(c("rsfMRI","_alff"), zz$Label, intersect=TRUE) ]='amplitude of low frequency fluctuations ALFF'
zz$Measurement[ multigrep( c("rsfMRI","_falff"), zz$Label, intersect=TRUE) ]='fractional amplitude of low frequency fluctuations fALFF'
zz$Anatomy = gsub("rsfMRI_", "", zz$Anatomy )
zz$Anatomy = gsub("falffPoint", "", zz$Anatomy )
zz$Anatomy = gsub("alffPoint", "", zz$Anatomy )
noncnx=1:1888
# for ( k in sample(noncnx, 3) ) print( zz[k,c("Label","Atlas","Anatomy")] )

zz[ zz$Label == 'Flair', 'Measurement' ]='white matter hyper-intensity'
zz[ zz$Label == 'T2Flair_flair_wmh_prior', 'Measurement' ]='prior-constrained white matter hyper-intensity'

zz[ multigrep( c("NM2DMT", "q0pt"),  zz$Label, intersect=TRUE), "Measurement"  ]='neuromelanin intensity quantile'
gg=grep("mmwide_filename",zz$Label)
zz[ gg,'Anatomy']=NA
zz[ gg,'Measurement']="unique NRG format filename identifier"
zz[ gg,'Atlas']=NA
zz[ gg,'side']=NA
zz[ zz$Label == 'T1wHierarchical_mmwide_filename','Modality']='T1 hierarchical processing'
zz[ zz$Label == 'T1w_mmwide_filename','Modality']='T1 DiReCT thickness processing'
zz[ zz$Label == 'rsfMRI_mmwide_filename','Modality']='restingStatefMRI'
zz[ zz$Label == 'DTI_mmwide_filename','Modality']='DTI'
zz[ zz$Label == 'T2Flair_mmwide_filename','Modality']='Flair'
zz[ zz$Label == 'NM2DMT_mmwide_filename','Modality']='Neuromelanin'
zz[ grep("SNR",zz$Label),'Measurement']='QC'
zz[ grep("fn",zz$Label),'Measurement']='original source data filename'
zz[ grep("noise",zz$Label),'Measurement']='QC'
zz[ grep("snr",zz$Label),'Measurement']='QC'
zz[ grep("cnr",zz$Label),'Measurement']='QC'
zz[ grep("X",zz$Label),'Measurement']='ignore'
zz[ grep("ssim",zz$Label),'Measurement']='QC'
zz[ grep("loop",zz$Label),'Measurement']='QC'
zz[ grep("high_motion",zz$Label),'Measurement']='QC'
zz[ grep("lof",zz$Label),'Measurement']='QC'
zz[ grep("nmid",zz$Label),'Measurement']='NM unique filename'
zz[ grep("_dvars",zz$Label),'Measurement']='QC'
zz[ grep("_evr",zz$Label),'Measurement']='QC'
zz[ grep("slice",zz$Label),'Measurement']='slice number in time series (ignore)'
zz[ grep("subjectID",zz$Label),'Measurement']='unique subject ID'
zz[ zz$Label=='NM2DMT_NM_substantianigra_z_coordinate','Measurement']='Estimate of the normalize (zero to one) z-coordinate of the substantia nigra in a neuromelanin scan; higher values mean higher in the slab'
zz[ zz$Label=='sid','Measurement']='unique subject ID'
zz[ grep("mrimfg",zz$Label),'Measurement']='MRI manufacturer (often missing)'
zz[ grep("mrimodel",zz$Label),'Measurement']='MRI model (often missing)'
zz[ grep("T1w_mean_",zz$Label),'Measurement']='Regional average of DiReCT estimated thickness'
zz[ grep("NM2DMT_mean",zz$Label),'Measurement']='Neuromelanin signal summary'
zz[ grep("NM2DMT_NM_avg",zz$Label),'Measurement']='Neuromelanin signal summary'
zz[ grep("NM2DMT_NM_std",zz$Label),'Measurement']='Neuromelanin signal summary'
zz[ grep("NM2DMT_NM_count",zz$Label),'Measurement']='count of neuromelanin scans that were averaged at this date'
zz[ grep("NM2DMT_NM_m",zz$Label),'Measurement']='Neuromelanin signal summary'
zz[ grep("NM2DMT_NM_sd",zz$Label),'Measurement']='Neuromelanin signal summary'
zz[ zz$Label %in% c("flairid",'nmid1','nmid2','nmid3','nmid4','nmid5','nmid6','nmid7','nmid8','nmid9','nmid10','nmid11','rsfid1','rsfid2','dtid1','dtid2'),'Measurement']='unique image id for modalities or their components (e.g. LR RL acquisitions for DTI or rsfMRI)'
zz[ zz$Label == 'T2Flair_flair_wmh','Measurement']='project ID or name eg ADNI'
zz[ zz$Label == 'projectID','Measurement']='project ID or name eg ADNI'
zz[ zz$Label == 'modality','Measurement']='generic modality name'
zz[ zz$Label == 'negol','Measurement']='negative outlier variable (higher is better)'
zz[ zz$Label == 'negative_outlier_factor','Measurement']='negative outlier variable (higher is better)'
zz[ zz$Label == 'mmimageuid','Measurement']='unique id for the T1w used in ANTsPyMM same as t1imageuid'
zz[ zz$Label == 't1imageuid','Measurement']='unique id for the T1w used in ANTsPyMM should equal mmimageuid'
zz[ zz$Label == 'visitdate','Measurement']='image acquisition date'
zz[ zz$Label == 'date','Measurement']='image acquisition date'
zz[ zz$Label == 'subjectIDdate','Measurement']='concatenation of subject ID and date'
zz[ zz$Label == 'imageID','Measurement']='unique image ID (ideally unique but not always)'
zz[ grep("brainstem",zz$Label),'Modality']='T1 hierarchical processing'
zz[ grep("brainstem",zz$Label),'side']=NA
zz[ grep("brainstem",zz$Label),'Atlas']='CIT168'
zz[ grep("brainstem",zz$Label),'Anatomy']='brainstem subdivision'
zz[ grep("cerebellum",zz$Label),'Modality']='T1 hierarchical processing'

cerenames = getNamesFromDataframe("cerebellum",dd,exclusions=c("dkt","tissu"))
for ( ccc in cerenames ) {
    zz[zz$Label == ccc,'Atlas']='TustisonCobra'
    zz[zz$Label == ccc,'Anatomy']='cerebellum label using Schmahmann nomenclature'
    zz[zz$Label == ccc,'side']='left'
    if ( length(grep("_r_",ccc) == 1 ) ) zz[zz$Label == ccc,'side']='right'
}
zz[zz$Label %in% c("mi",'EVR','reflection_err','org0','org1','org2','spc0','spc1','spc2','dimz','dimy','dimx'),"Measurement"]='QC'
zz[ subtyper::fs(zz$Label == zz$Anatomy),'Anatomy']=NA
write.csv( zz, "~/code/ANTsPyMM/antspymm_data_dictionary.csv", row.names=FALSE)
```

## Quality control metrics

Automated (blind) QC is part of standard ANTsPyMM processing.  QC metrics 
are therefore present in the standard output tables.  Notes on the meaning of these 
metrics, along with examples of the metrics on images, are [here](https://htmlpreview.github.io/?https://github.com/stnava/ANTsPyMM/blob/main/docs/blind_qc.html).

The most important QC metric is `T1Hier_resnetGrade` which rejects truly bad images.  We recommend rejecting images with `T1Hier_resnetGrade < 1.01` where higher thresholds may be useful in some cases.  This grading function uses deep learning to generate a pseudocontinuous measurement of aggregate T1w image quality.  Several factors will contribute to these scores and it is not a perfect approach but it is well-defined and evaluated based on manual ratings [here](https://doi.org/10.1101/2023.02.02.23285376).

The `outlierness` function produces additional blind QC measurements via automated outlierness calculations.  These measurements are denoted by Local Outlier Probability (LOOP `*loop*` ) and local outlier factor ( LOF `*lof*` ) column names.

Time series images may have additional QC metrics such as:

* TSNR: temporal signal to noise ratio

* SSNR: spatial signal to noise ratio on the mean image (different from TSNR)

* DVARS: the spatial root mean square of the data after temporal differencing

* Neuromelanin (NM) has its own set of variables including:

    * count: the number of acquisitions at that date 

    * min/max/mean/sd: a statistic on the raw image signal after averaging the acquisitions

    * `avg/std_refregion` : average and standard deviation of signal in the reference region

    * `avg/std_substantianigra` : average and standard deviation of signal in the substantia nigra or a related CIT168 region (determined by deepCIT168)

    * `NM2DMT_NM_substantianigra_z_coordinate`: estimate of the normalized (zero to one) z-coordinate of the substantia nigra in a neuromelanin scan; higher values mean higher in the slab.

* the framewise displacement (FD) values are 10x in DTI data compared to rsfMRI data. E.g. if 0.3 were a reasonable high motion threshold in rsfMRI; then 3.0 would be a comparable threshold for DTI.

## the full data dictionary 

A sortable version of the data dictionary is below (if viewing on local machine).

### Table 2

```{r printdict,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
reactable::reactable( zz[-grep("cnx",zz$Label),] , highlight = TRUE, bordered = TRUE, striped = TRUE, compact = FALSE, defaultPageSize = 12000, static = TRUE )
```



```{r checking,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
# find the missing names
good=ddnms[  (ddnms %in% zz$Label) ]
bad=ddnms[ ! (ddnms %in% zz$Label) ]
stopifnot(length(bad)==0)
bad2=zz[ is.na(zz$Measurement),'Label']
# print( bad2 )
# print( length( bad2 ) )
```


## Joining with clinical data: PPMI

We provide an example of how to join derived `ANTsPyMM` summary data with clinical variables from PPMI. 

```{r joiner,eval=FALSE,echo=FALSE,warning=FALSE,message=FALSE}
if ( ! exists( "clin" ) ) {
demog=read.csv("Demographics_22Sep2023.csv")
clin=read.csv("PPMI_Curated_Data_Cut_Public_20230612.csv")
demog[demog=='.']=NA
clin[clin=='.']=NA
dd$PATNO=dd$subjectID
# subjects with imaging that have clinical data
table( dd$PATNO %in% clin$PATNO )
# subjects with clinical data that have imaging
table( clin$PATNO %in% dd$PATNO )
commonids = intersect( clin$PATNO, dd$PATNO )
commonids = intersect( commonids, demog$PATNO )
ee = dd[ dd$PATNO %in% commonids, ]
clin = clin[ clin$PATNO %in% commonids, ]
clin = merge( clin, demog, by='PATNO', all.x=TRUE )
rmnames=names(clin)[ grep("[.]y",names(clin))]
clin=clin[,!(names(clin) %in% rmnames)]
names(clin)=gsub("[.]x","",names(clin))
clin$birthdate=clin$BIRTHDT
# convert birtdate to NRG format
for ( k in 1:nrow(clin) ) {
    temp=unlist(strsplit(clin$BIRTHDT[k], "/"))
    clin$birthdate[k]=as.numeric(paste0(temp[2],temp[1],15)) # add the 15th as the estimated date
}
# now we can compute age at imaging using imaging date in addition to BIRTHDT
ee$ageatimaging=NA
for ( k in 1:nrow( ee ) ) {
    subjectbdate = unique( clin$birthdate[ clin$PATNO == ee$PATNO[k] ] )
    ee$ageatimaging[k] = as.numeric( 
            difftime( 
                nrgDateToRDate( ee$date[k] ), 
                nrgDateToRDate( subjectbdate ), units='weeks' )/52.0)
    }
###############################################
clin$imagedatediff=NA
yearthresh=35/365 # max allowed year difference
# find the best imaging vist for each demographic time point
ct=0
for ( k in 1:nrow( clin ) ) {
    if ( k %% 100 == 0 ) cat( paste0(k,'...'))
    pat = clin$PATNO[k]
    patage = clin$age_at_visit[k]
    isel = which( ee$PATNO == pat & !is.na(ee$T1Hier_resnetGrade) )
    iage = ee$ageatimaging[ isel ]
    if ( length(iage) > 0 ) {
        minagediff = min( abs( iage - patage ) )
        minage = which.min( abs( iage - patage ) )
        iselind = isel[ minage ]
        clin[k,names(ee)]=ee[iselind,]
        clin$imagedatediff[k]=minagediff
        ct=ct+1
    }
}
table( !is.na( clin$T1Hier_resnetGrade ))
clin$DX = NA
clin$DX = 'CN'
clin$DX[ clin$CONCOHORT == 1 ]='PD'
clin$DX[ clin$CONCOHORT == 4 ]='Prodromal'
clin$DXSubRaw=paste0( clin$DX, "_", clin$subgroup )
clin$DXSub=NA
clin$DXSub[ clin$DX == 'CN' ]='CN'
ispd = which( clin$DX == 'PD' )
ispro = which( clin$DX == 'Prodromal' )
isgba = grep("GBA",clin$subgroup)
islrrk2 = grep("LRRK2",clin$subgroup)
isprkn = grep("PRKN",clin$subgroup)
issnca = grep("SNCA",clin$subgroup)
issporadic = grep("Sporadic",clin$subgroup)
clin$DXSub[ intersect(ispd,issporadic) ]='PDSporadic'
clin$DXSub[ intersect(ispd,islrrk2) ]='PDLRRK2'
clin$DXSub[ intersect(ispd,isgba) ]='PDGBA'
clin$DXSub[ intersect(ispro,issporadic) ]='ProdromalSporadic'
clin$DXSub[ intersect(ispro,islrrk2) ]='ProdromalLRRK2'
clin$DXSub[ intersect(ispro,isgba) ]='ProdromalGBA'
# identify asyn status for each subject
saasubs = unique( clin$PATNO[  !is.na( clin$CSFSAA ) ] )
# 3 categories: Negative, Positive, Other
clin$AsynStatus=NA
for ( u in saasubs ) {
    usel = clin$PATNO == u
    if ( any( fs(clin$CSFSAA[usel] == "1") ) ) {
        asynstat='Positive'
    } else if ( any( fs(clin$CSFSAA[usel] %in% c("0"))) ) {
        asynstat='Negative'
    } else if ( any( fs(clin$CSFSAA[usel] %in% c("2","3"))) ) {
        asynstat='Other'
    }
    clin[usel,'AsynStatus']=asynstat
}
############################
isbl = clin$EVENT_ID == 'BL'
print( table( clin$DXSub[isbl], clin$AsynStatus[isbl] ) )
isv4 = clin$EVENT_ID == 'V04'
print( table( clin$DXSub[isv4], clin$AsynStatus[isv4] ) )
clin$DXSubAsyn=NA
nna=!is.na(clin$AsynStatus)
clin$DXSubAsyn[ nna ]=paste0( clin$DXSub[nna], clin$AsynStatus[nna] )
clin$DXSubAsyn[ is.na( clin$AsynStatus)|is.na(clin$DXSub)]=NA
}
```


```{r joiner2,eval=TRUE,echo=FALSE,warning=FALSE,message=FALSE}
# use age at visit as well ....
if ( ! exists( "clin2" ) ) {
    demog=read.csv("Demographics_22Sep2023.csv")
    ageviz=read.csv("Age_at_visit_22Sep2023.csv")
    clin2=read.csv("PPMI_Curated_Data_Cut_Public_20230612.csv")
    demog[demog=='.']=NA
    clin2[clin2=='.']=NA
    dd$PATNO=dd$subjectID
    # subjects with imaging that have clinical data
    table( dd$PATNO %in% clin2$PATNO )
    # subjects with clinical data that have imaging
    table( clin2$PATNO %in% dd$PATNO )
    commonids = intersect( clin2$PATNO, dd$PATNO )
    commonids = intersect( commonids, demog$PATNO )
    ee = dd[ dd$PATNO %in% commonids, ]
    clin2 = clin2[ clin2$PATNO %in% commonids, ]
    clin2 = merge( clin2, demog, by='PATNO', all.x=TRUE )
    rmnames=names(clin2)[ grep("[.]y",names(clin2))]
    clin2=clin2[,!(names(clin2) %in% rmnames)]
    names(clin2)=gsub("[.]x","",names(clin2))
    clin2$birthdate=clin2$BIRTHDT
    # convert birtdate to NRG format
    for ( k in 1:nrow(clin2) ) {
        temp=unlist(strsplit(clin2$BIRTHDT[k], "/"))
        clin2$birthdate[k]=as.numeric(paste0(temp[2],temp[1],15)) # add the 15th as the estimated date
    }
    # now we can compute age at imaging using imaging date in addition to BIRTHDT
    ee$ageatimaging=NA
    ee$EVENT_ID=NA
    ee$clin_imaging_mismatch=TRUE
    for ( k in 1:nrow( ee ) ) {
        subjectbdate = unique( clin2$birthdate[ clin2$PATNO == ee$PATNO[k] ] )
        ee$ageatimaging[k] = as.numeric( 
                difftime( 
                    nrgDateToRDate( ee$date[k] ), 
                    nrgDateToRDate( subjectbdate ), units='weeks' )/52.0)
        # find the closest EVENT_ID using ageviz
        agesel=which( ageviz$PATNO == ee$PATNO[k] )
        locages=ageviz[agesel,]
        closest=which.min( abs(ee$ageatimaging[k]-locages$AGE_AT_VISIT))
        ee$EVENT_ID[k]=locages[closest,'EVENT_ID']
        # select clin
        wclin = which(clin2$PATNO == ee$PATNO[k] & clin2$EVENT_ID ==  ee$EVENT_ID[k])
        if ( length(wclin) == 1 ) {
            if ( ! exists("clin2add" ) ) {
                clin2add=names(clin2)[ !(names(clin2) %in% names(ee) )]
                }
            ee[k,clin2add]=clin2[wclin,clin2add]
            ee$clin_imaging_mismatch[k]=FALSE
            } else {
                wclin = which(clin2$PATNO == ee$PATNO[k] )
                # find next closest match
                if ( length(wclin) > 0 ) {
                    locclin=clin2[wclin,]
                    closest=which.min( abs(ee$ageatimaging[k]-locclin$age_at_visit))
                    ee[k,clin2add]=locclin[closest,clin2add]
                    }
            }
        }
    clin2 = ee
    clin2$DX = NA
    clin2$DX = 'CN'
    clin2$DX[ clin2$CONCOHORT == 1 ]='PD'
    clin2$DX[ clin2$CONCOHORT == 4 ]='Prodromal'
    clin2$DXSubRaw=paste0( clin2$DX, "_", clin2$subgroup )
    clin2$DXSub=NA
    clin2$DXSub[ clin2$DX == 'CN' ]='CN'
    ispd = which( clin2$DX == 'PD' )
    ispro = which( clin2$DX == 'Prodromal' )
    isgba = grep("GBA",clin2$subgroup)
    islrrk2 = grep("LRRK2",clin2$subgroup)
    isprkn = grep("PRKN",clin2$subgroup)
    issnca = grep("SNCA",clin2$subgroup)
    issporadic = grep("Sporadic",clin2$subgroup)
    isprodspor = which( clin2$subgroup %in% c("Hyposmia","RBD","Sporadic","RBD + Hyposmia") )
    clin2$DXSub[ intersect(ispd,issporadic) ]='PDSporadic'
    clin2$DXSub[ intersect(ispd,islrrk2) ]='PDLRRK2'
    clin2$DXSub[ intersect(ispd,isgba) ]='PDGBA'
    clin2$DXSub[ intersect(ispro,isprodspor) ]='ProdromalSporadic'
    clin2$DXSub[ intersect(ispro,islrrk2) ]='ProdromalLRRK2'
    clin2$DXSub[ intersect(ispro,isgba) ]='ProdromalGBA'
    # identify asyn status for each subject
    saasubs = unique( clin2$PATNO[  !is.na( clin2$CSFSAA ) ] )
    # 3 categories: Negative, Positive, Other
    clin2$AsynStatus=NA
    for ( u in saasubs ) {
        usel = clin2$PATNO == u
        if ( any( fs(clin2$CSFSAA[usel] == "1") ) ) {
            asynstat='Positive'
        } else if ( any( fs(clin2$CSFSAA[usel] %in% c("0"))) ) {
            asynstat='Negative'
        } else if ( any( fs(clin2$CSFSAA[usel] %in% c("2","3"))) ) {
            asynstat='Other'
        }
        clin2[usel,'AsynStatus']=asynstat
    }
    if ( TRUE ) {
        if ( ! exists("suppasyn") ) {
            suppasyn=read.csv("~/code/multidisorder/data/ppmi_gwas/ppmi_asyn_milestones_or_dtidenoise_may_asyn_20230710.csv")
            }
        uids = unique( suppasyn$Subject.ID[ !is.na( suppasyn$asynstatus)] )
        for ( u in uids ) {
            clin2sel=clin2$PATNO == u
            if ( sum(clin2sel) > 0 ) {
                suppas = unique(suppasyn[ suppasyn$Subject.ID == u, 'asynstatus'])
                clin2[clin2sel,'AsynStatus']=suppas
                }
            }
        }
    ############################
    isbl = clin2$EVENT_ID == 'BL'
    print( table( clin2$DXSub[isbl], clin2$AsynStatus[isbl] ) )
    isv4 = clin2$EVENT_ID == 'V04'
    print( table( clin2$DXSub[isv4], clin2$AsynStatus[isv4] ) )
    clin2$DXSubAsyn=NA
    nna=!is.na(clin2$AsynStatus)
    clin2$DXSubAsyn[ nna ]=paste0( clin2$DXSub[nna], clin2$AsynStatus[nna] )
    clin2$DXSubAsyn[ is.na( clin2$AsynStatus)|is.na(clin2$DXSub)]=NA

    # get the baseline age for imaging and the change in time
    clin2$yearsbl=NA
    clin2$age_BL=NA
    clin2$imaging_EVENT_ID=NA
    usubs=unique(clin2$PATNO)
    for ( u in usubs ) {
        seller=clin2$PATNO == u
        losel = clin2[seller, ]
        minage=min(losel$ageatimaging,na.rm=T)
        clin2$age_BL[seller]=minage
        loy=losel$ageatimaging-minage
        clin2$yearsbl[seller]=loy
        clin2$imaging_EVENT_ID[seller]=paste0("V",round(loy*4))
        }
    clin2$brainVolume = rowSums( clin2[,getNamesFromDataframe( c("T1Hier","vol","hemis"), clin2 )])
    clin2$brainVolume = clin2$brainVolume/mean(clin2$brainVolume,na.rm=T)
    clin2$mrimfg[ clin2$mrimfg == ""]="Unk"
    clin2$APOE[ clin2$APOE == "" ] = "e3/e3"
    clin2$abeta = as.numeric( clin2$abeta )
    clin2$tau = as.numeric( clin2$tau )
    }    
```


```{r helpers,eval=TRUE,echo=FALSE,warning=FALSE,message=FALSE}
showtest <- function( predictor, mycoeffs, searcher='PD', qthresh=0.001 ) {
    isasym = length( grep("asym",predictor) > 0 )
    mycoeffs2 = mycoeffs[ grep(searcher,rownames(mycoeffs)), ]
    signs=sign(-1)
    if ( isasym ) signs=sign(1)
    wsig=mycoeffs2[,"Pr(>|t|)"]<=qthresh
    if ( any(wsig) ) {
        myt=mycoeffs2[wsig,"t value"]
        if ( any( sign(myt) == signs ) )
            return( TRUE)
    }
    return( FALSE )
}

baseimpute <-function( mydf, varofinterest ) {
    vobl = paste0(varofinterest,"_BL")
    vodl = paste0(varofinterest,"_delta")
    isbl=mydf$imaging_EVENT_ID =='V0'
    isna=is.na( mydf[,vobl] )
    mydf[isna,vobl]=mean(na.omit(mydf[!isna & isbl,vobl]))
    disna=is.na( mydf[,vodl] )
    mydf[disna,vodl]=mydf[disna,varofinterest]-mydf[disna,vobl]
    return( mydf )
    }

visitimpute <-function( mydf, varofinterest, scaler=5 ) {
    yearr = round( sort(mydf$yearsbl*scaler))
    vobl = paste0(varofinterest,"_BL")
    vodl = paste0(varofinterest,"_delta")
    udx = unique( mydf$DXSubAsyn )
    for ( v in unique(yearr) ) {
        for ( u in udx ) {
            isviz=fs(yearr == v & mydf$DXSubAsyn==u)
            isna=isviz & is.na( mydf[,varofinterest] )
            mydf[isna,varofinterest]=mean(na.omit(mydf[!isna & isviz,varofinterest]))
            }
        }
    mydf[,vodl]=mydf[,varofinterest]-mydf[,vobl]
    return( mydf )
    }

backimpute <-function( mydf, varofinterest, patidvar, timevar, timethresh=Inf, verbose=FALSE ) {
    nabl = is.na( mydf[, paste0(varofinterest,"_BL") ] )
    idswithmissingbl=unique( mydf[nabl,patidvar])
    if ( verbose ) {
    #    print(idswithmissingbl)
    }
    for ( u in idswithmissingbl ) {
        usel=mydf[,patidvar]==u
        anyavail = which( usel & !is.na(mydf[,varofinterest] ) )
        if ( length(anyavail) > 0 ) {
            availtimes = min(mydf[anyavail,timevar],na.rm=T)
            anyavail = which( usel & !is.na(mydf[,varofinterest] ) & 
                 mydf[,timevar] == min(availtimes) )[1]
            imputedblval = mydf[anyavail,varofinterest]
            if ( verbose ) { 
                print(u)
                print( anyavail )
                print( paste( imputedblval, mydf[anyavail,'imaging_EVENT_ID'] ) )
            }
            if ( min(availtimes) < timethresh ) {
                mydf[usel, paste0(varofinterest,"_BL") ]=imputedblval
                mydf[usel, paste0(varofinterest,"_delta") ]=
                    mydf[usel, paste0(varofinterest) ]-
                    mydf[usel, paste0(varofinterest,"_BL") ]
            }
        }
    }
    return(mydf)
}

getnstring <- function(dxname) {
    temp=studydata[names(predict(mdl)),]
    dxs = levels( studydata[,dxname])
    nstringb='Base N: '
    nstring='Long N: '
    for ( k in 1:length(dxs)) {
                dxct=length( unique( 
                    temp$PATNO[temp$DXSubAsyn == dxs[k] & 
                    temp$imaging_EVENT_ID == "V0"] ) )
                dxtemp=gsub("ative","",dxs[k])
                dxtemp=gsub("itive","",dxtemp)
                nstringb=paste0(nstringb,dxtemp,":",dxct," / ")
                dxct=length( unique( 
                    temp$PATNO[temp$DXSubAsyn == dxs[k] & 
                    temp$imaging_EVENT_ID != "V0"] ))
                dxtemp=gsub("ative","",dxs[k])
                dxtemp=gsub("itive","",dxtemp)
                nstring=paste0(nstring,dxtemp,":",dxct," / ")
                }
    nstring=paste(nstringb,"\n",nstring)
    nstring=gsub("Pos","+",nstring)
    nstring=gsub("Neg","-",nstring)
    nstring=gsub("PD","",nstring)
    nstring=gsub("Sporadic","Sp",nstring)
    return( nstring )
}

```

<!--
### quick example longitudinal regression
-->

```{r lmerex,echo=FALSE,eval=TRUE,fig.width=12,fig.height=4,message=FALSE,warning=FALSE,cache=TRUE}
clin=clin2 # sets the source data
#################
clin[ fs(clin$mrimfg == ""), "mrimfg"] = "Unk"
clin[ is.na(clin$mrimfg), "mrimfg"] = "Unk"
clin[ fs(clin$mrimodel == ""), "mrimodel"] = "Unk"
clin[ is.na(clin$mrimodel), "mrimodel"] = "Unk"
clin$mrimodel[ grep("Symphony",clin$mrimodel)]='Symphony'
clin$mrimodel[ grep("chieva",clin$mrimodel)]='achieva'
clin$mrimodel[ grep("DISCOVERY",clin$mrimodel)]='DISCOVERY'
clin$mrimodel[ grep("MAGNETOM_Prisma",clin$mrimodel)]='MAGNETOM_Prisma'
clin$mrimodel[ grep("SIGNA",clin$mrimodel)]='SIGNA'
clin$mrimodel[ grep("Signa",clin$mrimodel)]='SIGNA'
clin$mrimodel[ grep("Ingenia",clin$mrimodel)]='Ingenia'
clin$mrimodel[ grep("MAGNETOM",clin$mrimodel)]='MAGNETOM'
clin$mrimodel[ grep("DicomCleaner",clin$mrimodel)]='Unk'
clin$mrimodel[ grep("Vantage_Elan",clin$mrimodel)]='Unk'
recentdates = 1:nrow(clin) %in% multigrep( c(2020,2021,2022,2023), clin$date, intersect=FALSE )
#################
library(lmerTest)
midnames = getNamesFromDataframe( c("T1Hier_vol",'brainstem'), dd, 
            exclusions=c("_BL","_delta","evratio","Grade","mhdist","RandB","outli","templateL1","hemispher",'u_hier_id','filena','snseg','tcit','tissues','lobes','cleanup','dktregions','dktlobes') )
t1names=c( 
        getNamesFromDataframe( c("T1Hier_vol",'mtl'), dd, 
            exclusions=c("_BL","_delta","evratio","Grade","mhdist","RandB","outli","templateL1","hemispher",'u_hier_id','filena','snseg','tcit','tissues','lobes','cleanup','dktregions','dktlobes','area') ),
        getNamesFromDataframe( c("T1Hier_vol",'cerebellum'), dd, 
            exclusions=c("_BL","_delta","evratio","Grade","mhdist","RandB","outli","templateL1","hemispher",'u_hier_id','filena','snseg','tcit','tissues','lobes','cleanup','dktregions','dktlobes') ),    
        getNamesFromDataframe( "T1Hier_vol", dd, 
            exclusions=c("_BL","_delta","evratio","Grade","mhdist","RandB","outli","templateL1","hemispher",'u_hier_id','filena','snseg','tcit','cerebellum','brainstem','dktregions','dktlobes') ),
        getNamesFromDataframe( c("T1Hier_thk"), dd, 
            exclusions=c("_BL","_delta","evratio","Grade","mhdist","RandB","outli","templateL1",'filename','u_hier_id',"hemispher",'snseg','tcit','cerebellum','brainstem','dktregions','dktlobes') ) )
t1names = unique( t1names[ 
    multigrep(c( "fusiform", "mtl", "nbm", "supra","temporal","parietal","central","snc","_pu_","_ca_","_snr","_gpi","_gpe","cerebellum","pons","medulla","midbrain"), t1names ) ] )
dtinames=c(
    getNamesFromDataframe( c("DTI","mean_md_deep"), dd, exclusions=c("_BL","_delta","FD","motion","SNR","evr","ssnr","dvars","tsnr","volume",'filename','u_hier_id','cnx','snseg','tcit','reference') ) )
#    getNamesFromDataframe( c("DTI","mean_fa","jhu"), dd, exclusions=c("_BL","_delta","FD","motion","SNR","evr","ssnr","dvars","tsnr","volume",'filename','u_hier_id','cnx','snseg','tcit','reference') ) )
for ( zz in c( "temporal","usiform","entral","hippocamp","rontal","ingulat","mtl","supramarginal","arietal" ) )
    dtinames = c( dtinames, 
        getNamesFromDataframe( c("DTI","mean_md",zz), dd, exclusions=c("_BL","_delta","FD","motion","SNR","evr","ssnr","dvars","tsnr","volume",'filename','u_hier_id','cnx','snseg','tcit','reference')  ) )

rsfnames=getNamesFromDataframe( "rsfMRI"  , dd, exclusions=c("_BL","_delta","cnx","FD","motion","SNR","evr","ssnr","dvars","tsnr","volume","_alff",'filename','u_hier_id','snseg','tcit') )

thknames = getNamesFromDataframe( c("T1Hier_thk","dktcortex"), dd )
mdnames = getNamesFromDataframe( c("DTI_mean_md_"), dd )
cnxnames = getNamesFromDataframe( c("DTI","cnx"), dd )
coggers = c( "ess", "gds",'lns','moca','NP1APAT','NP1ANXS',
    "mean_striatum",'NP1DPRS', 'pigd', 'rem', 'quip','scopa','stai','VLTANIM',
    'nfl_serum', 'abeta', 'tau',
    #upsit"lexical",'MODBNT',
    getNamesFromDataframe("score",clin), 
    getNamesFromDataframe("HVLT",clin), 
    getNamesFromDataframe("hvlt_",clin) )
#    getNamesFromDataframe("pm_",clin) )
for ( cog in coggers )
    clin[,cog]=as.numeric(clin[,cog])
mymiles = c("pm_adl_any","pm_fd_any","pm_auto_any", "pm_cog_any",           "pm_mc_any" ,           "pm_wb_any")
# clin$milestonesum = rowSums( clin[,mymiles] )
commcov = " brainVolume_BL + EDUCYRS + ( Age1 + Age2 ) + SEX  "
commcov = " brainVolume_BL + EDUCYRS + meanthick + meanmd + snr + EVR + psnr + mi + ssim + ol_loop + T1Hier_resnetGrade + ( Age1 + Age2 ) + SEX  "
commcov = " (1|PATNO) + (1|SITE)+EVR + brainVolume_BL + hy_BL + moca_BL + EDUCYRS + ( Age1 + Age2 ) * SEX "
commcov = " (1|PATNO) + (1|SITE) + T1Hier_resnetGrade + brainVolume_BL + hy_BL + EDUCYRS + ( Age1 + Age2 ) + SEX "
covars0x = commcov
covars0 = paste("testvol_delta ~ testvol_BL + ", commcov )
# covars0 = paste("testvol_delta ~ (1|PATNO) + (1|SITE) + ", commcov )
dticovars=" + DTI_dti_FD_mean "
#################################################
clin$ptau = as.numeric( clin$ptau )
clin$tau = as.numeric( clin$tau )
clin$hy[ is.na( clin$hy )] = "0"
clin$hy = as.numeric( clin$hy )
clin$moca = ANTsRCore::antsrimpute( clin$moca )
clin$age_BL=ANTsRCore::antsrimpute(as.numeric(clin$age_BL))
corrmeth='BH'
winsval=0.001
qthresh=5e-5
qthresh=0.001
ythresh=4.25
print( paste("PARAMS: corrmeth",corrmeth,"winsval",winsval,"qthresh",qthresh,"ythresh", ythresh ))
commonsel = !is.na( clin$AsynStatus) & fs(
    clin$T1Hier_resnetGrade >= 1.02 &
    clin$yearsbl <= ythresh  &
    !clin$mrimodel %in% c("SIGNA") )
#    !(clin$mrimfg %in% c("Toshiba")) )
table(commonsel)
runstats=TRUE
runstatsG=FALSE
#############
```

```{r lmerextab,echo=FALSE,eval=runstats,fig.width=12,fig.height=6,message=FALSE,warning=FALSE,cache=TRUE}
###################################################
pvaluedf = tvaluedf = data.frame()
meffdall = data.frame()
ct = 0
subtypes = c( 'LRRK2', 'Sporadic' ) # GBA
# subtypes = c('LRRK2' ) # GBA
for (  subtype in subtypes ) {
    dxs = c("CNNegative", paste0("PD",subtype,c("Negative","Positive") ) )
    ssel = fs( clin$DXSubAsyn %in% dxs ) & commonsel
    studydata = clin[ssel,]
    print( table(round(studydata$yearsbl), studydata$DXSubAsyn) )
    sage=data.frame( stats::poly( studydata$age_BL , 2 ) )
    colnames(sage)=c("Age1","Age2")
    studydata=cbind(studydata,sage)
    studydata$SEX = factor( studydata$SEX )
    if ( FALSE ) {
        studydata$DXSubAsyn = paste0( studydata$DXSubAsyn, studydata$SEX )
        dxs2=c()
        for ( dx in dxs ) dxs2=c(dxs2,paste0(dx,levels(studydata$SEX)))
        dxs=dxs2
        }
    studydata[,'DXSubAsyn']=factor(studydata[,'DXSubAsyn'],levels=dxs)
    studydata$duration_yrs = as.numeric( studydata$duration_yrs )
    studydata$cnxtot = rowSums( studydata[,cnxnames] )
    studydata[,cnxnames]=studydata[,cnxnames]/studydata$cnxtot
    normalizeit=FALSE
    if ( normalizeit ) {
        studydata[,mdnames]=studydata[,mdnames]/studydata$meanmd
        studydata[,thknames]=studydata[,thknames]/studydata$meanthick
        }
    testnames = unique( c( t1names, dtinames, rsfnames ) )
    if ( winsval == 0.0 ) {
        isna=is.na( studydata[,testnames] )
        temp = ANTsR::robustMatrixTransform(studydata[,testnames])
        temp[ isna ]=NA
        studydata[,testnames]=temp
        }
    ####################################
    studydata=mapAsymVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
    studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
    studydata=mapAsymVar( studydata, 
        testnames[ grep("_left", testnames) ] )
    studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_left", testnames) ] )
    testnames = c( 
        getNamesFromDataframe( "Asym" , studydata ),
        getNamesFromDataframe( "LRAVG" , studydata ) )
    countdtinz=rep(NA,length(testnames))
    for ( x in 1:length(testnames) ) {
        countdtinz[x]=sum( !is.na(studydata[,testnames[x]]) & studydata[,testnames[x]] > 0)
    }
    testnames=testnames[ countdtinz > 100 ]
#    testnames = testnames[ -grep("Asym",testnames)]
    studydata$meanthick = rowMeans( studydata[,thknames])
    studydata$meanmd = rowMeans( studydata[,mdnames])
    testnames = c( testnames, midnames )
    studydata = fillBaselineColumn( studydata,
        c('meanthick','meanmd','brainVolume',testnames,'hy','moca'), 
        'PATNO', 'imaging_EVENT_ID', 'V0', 
        fast=T, verbose=F )[[1]]
    for ( x in  c('meanthick','meanmd','brainVolume',testnames) ) {
#        studydata=baseimpute( studydata, x )
#        studydata=visitimpute( studydata, x, 2 )
        }
    if ( FALSE )
        testnames = c( 
            "T1Hier_vol_bn_gp_gpe_LRAVGdeep_cit168",
            'T1Hier_vol_bn_str_pu_LRAVGdeep_cit168','DTI_mean_md_Asym_rostral_middle_frontal')
    for ( testvols in testnames ) {
        ct = ct + 1
        studydata$testvol = studydata[ ,testvols]
        studydata$testvol_BL = studydata[ ,paste0(testvols,"_BL")]
        studydata$testvol_delta = studydata[ ,paste0(testvols,"_delta")]
        studydata$testvol_delta = psych::winsor(studydata$testvol_delta,tr=winsval)
        studydata$SEX = factor( studydata$SEX )
        toscale = c('snr','psnr','EVR','age_BL','DTI_dti_FD_mean','T1Hier_resnetGrade','DTI_dti_tsnr_b0_mean','testvol_BL','brainVolume_BL','EDUCYRS', 'moca_BL', 'hy_BL' )
        studydata$EDUCYRS=as.numeric(studydata$EDUCYRS)
        studydata[,toscale]=scale(studydata[,toscale])
        studydata$EDUCYRS = scale(ANTsRCore::antsrimpute(as.numeric( studydata$EDUCYRS )))
        covars=covars0
        covarsx=covars0x
        if ( length(grep("DTI_",testvols)>1 ) ) {
            covars=paste(covars0,dticovars)
            covarsx=paste(covars0x,dticovars)
        }
        bform=paste( covars, " + yearsbl ")
        myform=paste( covars, " + yearsbl * ( DXSubAsyn )")
        # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281513/
        # section: Advantages and Disadvantages of Fixed Main Effect for Site
        bformx=paste( "testvol~",covarsx, " + yearsbl ")
        myformx=paste( "testvol~",covarsx, " + yearsbl * ( DXSubAsyn )")
        isblsub = studydata$PATNO[ studydata$imaging_EVENT_ID=='V0' ]
        isfsub = studydata$PATNO[ studydata$imaging_EVENT_ID !='V0' ]
        isboth = intersect( isblsub, isfsub )
        studydatasub = studydata[ studydata$PATNO %in% isboth,]
        bmdl = try( lmer( bform,data=studydata ) )
        mdl = try( lmer( myform,data=studydata ) )
        bmdlx = lmer( bformx,data=studydata )
        mdlx = lmer( myformx,data=studydata )
        if ( FALSE ) {
            # simple regression for BL vs follow
            lmdata = data.frame( )
            fillvars = all.vars( as.formula( myform ) )
            rmers = multigrep( c("testvol_delta","testvol","PATNO",#"yearsbl",
                "DTI_dti_tsnr_b0_mean","mrimfg"), fillvars, intersect=FALSE )
            lmform = paste( fillvars[1], "~(1|PATNO)+testvol_BL+",paste(fillvars[-rmers],collapse="+"))
            mdlLM = lmer( lmform,data=studydatasub)
#            mycoffsX = coefficients(summary( mdlLM ))
#            if ( any(tail(mycoffsX[,"Pr(>|t|)"],2) < 0.005 )) {
#                print( visreg::visreg(mdlLM,'DXSubAsyn',gg=TRUE)+ggtitle(testvols))
#                print( mycoffsX )
#                print( testvols )
#                }
            }
        if ( !is( mdl, "try-error" ) ) {
            mycoffx = coefficients(summary(mdlx))[-c(1:2),-c(1:2)]
            mycoffx = mycoffx[ grep(subtype,rownames(mycoffx)), ]
            mycoffx = mycoffx[ -grep("yearsbl",rownames(mycoffx)),]
            mycoff = coefficients(summary(mdl))[-c(1:2),-c(1:2)]
#            mycoff = mycoff[ grep(subtype,rownames(mycoff)), ]
            mycoff = rbind(
                mycoffx[grep(subtype,rownames(mycoffx)),],
                mycoff[multigrep(c("yearsbl",subtype),rownames(mycoff),intersect=T),])
            if ( nrow( pvaluedf ) == 0 ) {
                myoc = rownames(mycoff)
                myoc = gsub("yearsbl:","y.",myoc)
                myoc = gsub("Negative","Neg",myoc)
                myoc = gsub("Positive","Pos",myoc)
                myoc = gsub("DXSubAsyn","",myoc)
                myoc = gsub(paste0("PD",subtypes[1]),"",myoc)
                outcomes = c("subtype",  myoc )
                noutcomes = length(outcomes)
                pvaluedf = data.frame( matrix(ncol=noutcomes) )
                colnames(pvaluedf )=outcomes
                tvaluedf=pvaluedf
            }
            tvaluedf[ct, outcomes] = c(subtype,mycoff[,"t value"])
            pvaluedf[ct, outcomes] = c(subtype,mycoff[,"Pr(>|t|)"])
            anvx = anova(bmdlx,mdlx)$Pr[2]
            anv = anova(bmdl,mdl)$Pr[2]
            pvaluedf[ct,'anova'] = anv
            pvaluedf[ct,'anovax'] = anvx
            tvaluedf[ct,'anat'] = pvaluedf[ct,'anat']=testvols
            if (  pvaluedf[ct,'anova'] < qthresh | pvaluedf[ct,'anovax'] < qthresh  )
                {
                nstring = getnstring( 'DXSubAsyn')
                pvformattedx=insight::format_p( anvx, stars=TRUE, digits=4 )
                pvformatted=insight::format_p( pvaluedf[ct,'anova'], stars=TRUE, digits=4 )
                cat( paste0( "\n\n****************************************************************\n\n" ) )
                cat( paste0( testvols," anv ", pvaluedf[ct,'anova'], " ****************\n\n" ) )
                print( mycoff[,-1] )
                mydegfree = round( (mycoff[,'df']) )
                meff = effectsize::t_to_d( mycoff[,'t value'], mydegfree )
                rownames(meff) = rownames(mycoff)
                myrownames = rownames(mycoff)
                myrownames = gsub("yearsbl","years",myrownames)
                myrownames = gsub("DXSubAsynPD","",myrownames)
                meffd = data.frame(meff)
                meffd$eff=myrownames
                meffd$anat = testvols
                meffd$dx = "Pos"
                meffd$dx[ grep("Neg",myrownames)]='Neg'
                if ( nrow(meffdall) == 0 ) meffdall=meffd else meffdall = rbind(meffdall,meffd)
                print( ggbarplot( meffd, 'eff','d', color='dx', fill='dx', 
                    palette='npg' ) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5))+ggtitle(paste("Long and cross effect sizes (d):",testvols)) + geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.1,
                    position=position_dodge(.5))  )
                mypal = 'lancet'
                (prplot( mdlx,'yearsbl',  'DXSubAsyn',color='DXSubAsyn', addpoints=1, palette=mypal )+ ggtitle(paste(testvols,pvformattedx,"\n",nstring))) %>% print()
#                (prplot( mdl,  'yearsbl', 'DXSubAsyn', color='DXSubAsyn', addpoints=1, palette=mypal )+ ggtitle(paste(testvols,pvformatted,"\n",unlist(strsplit(nstring,"\n"))[2]))) %>% print()
                studydatasub$yearr=round( studydatasub$yearsbl )
                temp = table( studydatasub[,'PATNO'] )
                tsel = ( studydatasub$yearr %in% c(0,1,2,4) ) & 
                    studydatasub$PATNO %in% names(temp)[temp>=2]
                yername=gsub("T1Hier_","",testvols)
                yername=gsub("DTI_","",yername)
                yername=gsub("dktregions","",yername)
                yername=gsub("jhu","",yername)
                if ( TRUE ) {
                    nlevs = length( levels( studydatasub[,'DXSubAsyn'] ))
                    manualColors = pal_lancet("lanonc", alpha = 0.9)(nlevs)
                    print( plotSubtypeChange( studydatasub[tsel,],
                        idvar='PATNO', 'DXSubAsyn',
                        measurement="testvol_delta",
                        vizname='yearr', 'se', xlab='yr from v0' ) + 
                        ggtitle(paste(yername," : change")) +
                        scale_colour_manual(values = manualColors ) )
                    print( plotSubtypeChange( studydatasub[tsel,],
                        idvar='PATNO', 'DXSubAsyn',
                        measurement="testvol",
                        vizname='yearr', 'se', xlab='yr from v0' ) + 
                        ggtitle(paste(yername," : raw")) +
                        scale_colour_manual(values = manualColors ) )
#                    ggscatter( studydata, 'yearsbl', "brainVolume", facet.by='DXSubAsyn', color='DXSubAsyn', add='reg.line', conf.int=T, cor.coef=T, parse=T, palette=manualColors ) %>% print()

                    # now test the TPL hypotheses
                    testcog=TRUE
                    if ( testcog ) {
                        subcohort = studydatasub[ studydatasub$DXSubAsyn != 'CNNegative',]
                        subcohortbl = studydatasub[ studydatasub$DXSubAsyn !=     
                            'CNNegative' &
                            studydatasub$imaging_EVENT_ID == 'V0', ]
                        myst = trainSubtypeUni( subcohortbl, "testvol",
                            c("Alow","Amid","Ahigh"), quantiles = c(0.33,0.66) )
                        subcohort = predictSubtypeUni( subcohort, myst, 'PATNO', 
                            'imaging_EVENT_ID', 'V0')
                        for ( cog in coggers ) {
                            cogform=paste( cog , "~", commcov, "+AsynStatus+subtype*yearsbl" )
                            cogmdl = try( lmer( cogform, data=subcohort ) )
                            cogcoff=coefficients(summary(cogmdl))
                            cogcoff=cogcoff[grep("subtype",rownames(cogcoff)),]
                            if ( any( cogcoff[,"Pr(>|t|)"] < 0.001 ) ) {
                                message(paste(testvols,cog))
                                print(paste("COGGER",cog))
                                print( cogcoff[,-c(1:2)] )
                                cogpvform = insight::format_p( 
                                    min(cogcoff[,"Pr(>|t|)"]),
                                    stars=TRUE, digits=4 )
                                (prplot( cogmdl,'yearsbl',  'subtype',color='subtype', addpoints=1, palette=mypal )+ ggtitle(paste(testvols,"COGGER",cog,"\n",cogpvform))) %>% print()
                                pvaluedf[ct,cog]=min(cogcoff[,"Pr(>|t|)"])
                            }
                        }
                    }

                }
            }
        }
    }
    cat("****************\n\n")
} # subtype loop
##########################################################
##########################################################
if ( FALSE )
for ( subtype in subtypes[1:2] ) {
    print(subtype)
    pvaluedfsub = pvaluedf[ pvaluedf$subtype == subtype, ]
    sel=p.adjust( pvaluedfsub[,'anova'], corrmet ) <= 0.05
    print( pvaluedfsub[ sel, c("Neg","Pos","Y.Neg","Y.Pos","anat")] )
    cat(">>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<\n\n")
}
##########################################################
##########################################################
```

<!-- ## GBA results table -->

```{r printgba,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
makethetable <- function( ss, qvt=0.01 ) {
    pvaluedfsub = pvaluedf[ 
        pvaluedf$subtype == ss,
            c("anat","anovax","anova", myoc ) ]
    sel= ( 
        p.adjust( pvaluedfsub[,'anova'], corrmeth ) <= qvt | 
        p.adjust( pvaluedfsub[,'anovax'], corrmeth ) <= qvt  )
    pvaluedfsub=pvaluedfsub[sel,]
    for ( x in c( "anovax",  "anova", myoc ) ) {
        rowsel = as.numeric(pvaluedfsub[,x])>0.001
        pvaluedfsub[rowsel,x]=NA
        pvrow = which( !rowsel )
        for ( j in pvrow ) {
          pvaluedfsub[j,x]=insight::format_p( as.numeric(pvaluedfsub[j,x]),
            stars=TRUE, digits=4 )
        }
    }
    reactable::reactable( pvaluedfsub, highlight = TRUE, bordered = TRUE, striped = TRUE, compact = FALSE, defaultPageSize = 120, static = FALSE, sortable=TRUE )
}
# makethetable("GBA")
```

## LRRK2 results table

```{r printlrrk2,echo=FALSE,eval=runstats,warning=FALSE,message=FALSE}
makethetable("LRRK2")
```

## sporadic results table
 
```{r printsporadic,echo=FALSE,eval=runstats,warning=FALSE,message=FALSE}
makethetable('Sporadic')
```


```{r lmerexallgroups,echo=FALSE,eval=runstatsG,fig.width=12,fig.height=8,message=FALSE,warning=FALSE}
###################################################
dxstbl = table( clin$DXSubAsyn  )
dxs = names(dxstbl[dxstbl>10])
dxs = dxs[ -2 ]
ct = 0
ssel = fs( clin$DXSubAsyn %in% dxs ) & commonsel
##############################################
outcomes = c( dxs[-1], paste0("Y.",dxs[-1]))
noutcomes = length(outcomes)
pvaluedfG = data.frame( matrix(ncol=noutcomes) )
colnames(pvaluedfG)=outcomes
tvaluedfG=pvaluedfG
meffdallG = data.frame()
#######################
studydata = clin[ssel,]
studydata[,'DXSubAsyn'] = factor( studydata[,'DXSubAsyn'], levels = dxs )
studydata = fillBaselineColumn( studydata,
        c('brainVolume'), 'PATNO', 'imaging_EVENT_ID', 'V0', 
        fast=T, verbose=F )[[1]]
testnames = c( t1names, dtinames, rsfnames )
studydata=mapAsymVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
studydata=mapAsymVar( studydata, 
        testnames[ grep("_left", testnames) ] )
studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_left", testnames) ] )
testnames = c(
        getNamesFromDataframe( "Asym" , studydata ),
        getNamesFromDataframe( "LRAVG" , studydata ) ) %>% unique()
countdtinz=rep(NA,length(testnames))
for ( x in 1:length(testnames) ) {
    countdtinz[x]=sum( !is.na(studydata[,testnames[x]]) & studydata[,testnames[x]] > 0)
    }
testnames=testnames[ countdtinz > 100 ]
#######################################
for ( testvols in ( testnames ) ) {
        ct = ct + 1
        studydata$testvol = studydata[ ,testvols]
        studydata$testvol = psych::winsor(studydata$testvol,tr=winsval)
        studydata$SEX = factor( studydata$SEX )
        toscale = c('snr','psnr','EVR','age_BL','DTI_dti_FD_mean','DTI_dti_tsnr_b0_mean')
        studydata[,toscale]=scale(studydata[,toscale])
        studydata$EDUCYRS = scale(ANTsRCore::antsrimpute(as.numeric( studydata$EDUCYRS )))
        if ( length(grep("DTI_",testvols)>1 ) ) covars=paste(covars,dticovars)
        bform=paste( covars, " + yearsbl ")
        bmdl = try( lmer( bform,data=studydata ) )
        myform=paste( covars, " + yearsbl * DXSubAsyn")
        mdl = try( lmer( myform,data=studydata ) )
        if ( !is(mdl, "try-error") ) {
            mycoff = coefficients(summary(mdl))[-c(1:2),-c(1:2)]
            mycoff = mycoff[grep('PD',rownames(mycoff)),]
            tvaluedfG[ct, outcomes] = c(mycoff[,"t value"])
            pvaluedfG[ct, outcomes] = c(mycoff[,"Pr(>|t|)"])
            pvaluedfG[ct,'anova'] = anova(bmdl,mdl)$Pr[2]
            tvaluedfG[ct,'anat']=pvaluedfG[ct,'anat']=testvols
            if (  pvaluedfG[ct,'anova'] < qthresh  )
                {
                nstring = getnstring()
                pvformatted=insight::format_p( pvaluedfG[ct,'anova'], stars=TRUE, digits=4 )
                cat( paste0( "\n\n****************************************************************\n\n" ) )
                cat( paste0( testvols," anv ", pvaluedfG[ct,'anova'], " ****************\n\n" ) )
                print( mycoff[,-1] )
                mydegfree = round( (mycoff[,'df']) )
                meff = effectsize::t_to_d( mycoff[,'t value'], mydegfree )
                rownames(meff) = rownames(mycoff)
                myrownames = rownames(mycoff)
                myrownames = gsub("yearsbl","years",myrownames)
                myrownames = gsub("DXSubAsynPD","",myrownames)
                meffd = data.frame(meff)
                meffd$eff=myrownames
                meffd$anat = testvols
                meffd$dx = "Pos"
                meffd$dx[ grep("Neg",myrownames)]='Neg'
                if ( nrow(meffdallG) == 0 ) meffdallG=meffd else meffdallG = rbind(meffdallG,meffd)
                print( ggbarplot( meffd, 'eff','d', color='dx', fill='dx', 
                    palette='npg' ) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5))+ggtitle(paste("Long and cross effect sizes (d):",testvols)) + geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.1,
                    position=position_dodge(.5) ) )
                (prplot( mdl,  'yearsbl', 'DXSubAsyn', color='DXSubAsyn', addpoints=1 )+ ggtitle(paste(testvols,pvformatted,"\n",nstring))) %>% print()
                }
        }
    }
##########################################################
for ( x in names(pvaluedfG)[1:(length(names(pvaluedfG))-2)] ) {
#    print( x  )
    sel=p.adjust( pvaluedfG[,x], corrmeth ) <= 0.05
 #   print( pvaluedfG[ sel, "anat"] )
  #  cat(">>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<\n\n")
    }
##########################################################
```



<!-- ## single model group results -->

```{r printintegrated,echo=FALSE,eval=runstatsG,warning=FALSE,message=FALSE}
dxnames = names( pvaluedfG )
dxnames = dxnames[ 1:(length(dxnames)-2)]
sel=p.adjust( pvaluedfG[,'anova'], corrmeth ) <= 0.05
pvaluedfsub = pvaluedfG[sel,c("anat","anova", dxnames) ]
for ( x in c( "anova", dxnames ) ) {
    rowsel = as.numeric(pvaluedfsub[,x])>0.001
    pvaluedfsub[rowsel,x]=NA
    pvrow = which( !rowsel )
    for ( j in pvrow ) {
        pvaluedfsub[j,x]=insight::format_p( as.numeric(pvaluedfsub[j,x]),
            stars=TRUE, digits=4 )
        }
    }
reactable::reactable( pvaluedfsub, highlight = TRUE, bordered = TRUE, striped = TRUE, compact = FALSE, defaultPageSize = 12000, static = F )
```



```{r lmerexallgroups2,echo=FALSE,eval=FALSE,fig.width=12,fig.height=8,message=FALSE,warning=FALSE}
###################################################
clin$DXAsyn = as.character(clin$DXSubAsyn)
clin$DXAsyn = gsub("Sporadic","",clin$DXAsyn)
clin$DXAsyn = gsub("LRRK2","",clin$DXAsyn)
clin$DXAsyn = gsub("GBA","",clin$DXAsyn)
winsval=0.005
qthresh=1e-4
dxstbl = table( clin$DXAsyn  )
dxs = names(dxstbl[dxstbl>16])
# dxs = dxs[ -2 ]
ct = 0
ssel = fs( clin$DXAsyn %in% dxs ) & 
        !is.na(clin$T1Hier_resnetGrade) &
        fs( !clin$mrimodel %in% c("SIGNA") ) &
    #   fs( clin$mrimfg %in% c( "Siemens", "Phillips",  "Unk" ) ) & 
        fs(clin$T1Hier_resnetGrade >= 1.01)
##############################################
outcomes = c( dxs[-1], paste0("Y.",dxs[-1]))
noutcomes = length(outcomes)
pvaluedfG = data.frame( matrix(ncol=noutcomes) )
colnames(pvaluedfG)=outcomes
tvaluedfG=pvaluedfG
meffdallG = data.frame()
#######################
studydata = clin[ssel,]
studydata[,'DXAsyn'] = factor( studydata[,'DXAsyn'], levels = dxs )
studydata = fillBaselineColumn( studydata,
        c('brainVolume'), 'PATNO', 'imaging_EVENT_ID', 'V0', 
        fast=T, verbose=F )[[1]]
testnames = c( t1names, dtinames, rsfnames )
studydata=mapAsymVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
studydata=mapAsymVar( studydata, 
        testnames[ grep("_left", testnames) ] )
studydata=mapLRAverageVar( studydata, 
        testnames[ grep("_left", testnames) ] )
testnames = c( 
        getNamesFromDataframe( "Asym" , studydata ),
        getNamesFromDataframe( "LRAVG" , studydata ) )
countdtinz=rep(NA,length(testnames))
for ( x in 1:length(testnames) ) {
    countdtinz[x]=sum( !is.na(studydata[,testnames[x]]) & studydata[,testnames[x]] > 0)
    }
testnames=testnames[ countdtinz > 100 ]
#######################################
for ( testvols in ( testnames ) ) {
        ct = ct + 1
        studydata$testvol = studydata[ ,testvols]
        studydata$testvol = psych::winsor(studydata$testvol,tr=winsval)
        studydata$SEX = factor( studydata$SEX )
        toscale = c('snr','psnr','EVR','age_BL','DTI_dti_FD_mean','DTI_dti_tsnr_b0_mean')
        studydata[,toscale]=scale(studydata[,toscale])
        studydata$EDUCYRS = scale(ANTsRCore::antsrimpute(as.numeric( studydata$EDUCYRS )))
        if ( length(grep("DTI_",testvols)>1 ) ) covars=paste(covars,dticovars)
        bform=paste( covars, " + yearsbl ")
        bmdl = try( lmer( bform,data=studydata ) )
        myform=paste( covars, " + yearsbl * DXAsyn")
        mdl = try( lmer( myform,data=studydata ) )
        if ( !is(mdl, "try-error") ) {
            mycoff = coefficients(summary(mdl))[-c(1:2),-c(1:2)]
            mycoff = mycoff[grep('PD',rownames(mycoff)),]
            tvaluedfG[ct, outcomes] = c('PD',mycoff[,"t value"])
            pvaluedfG[ct, outcomes] = c('PD',mycoff[,"Pr(>|t|)"])
            pvaluedfG[ct,'anova'] = anova(bmdl,mdl)$Pr[2]
            tvaluedfG[ct,'anat']=pvaluedfG[ct,'anat']=testvols
            if (  pvaluedfG[ct,'anova'] < qthresh  )
                {
                nstring = getnstring()
                pvformatted=insight::format_p( pvaluedfG[ct,'anova'], stars=TRUE, digits=4 )
                cat( paste0( "\n\n****************************************************************\n\n" ) )
                cat( paste0( testvols," anv ", pvaluedfG[ct,'anova'], " ****************\n\n" ) )
                print( mycoff[,-1] )
                mydegfree = round( (mycoff[,'df']) )
                meff = effectsize::t_to_d( mycoff[,'t value'], mydegfree )
                rownames(meff) = rownames(mycoff)
                myrownames = rownames(mycoff)
                myrownames = gsub("yearsbl","years",myrownames)
                myrownames = gsub("DXAsynPD","",myrownames)
                meffd = data.frame(meff)
                meffd$eff=myrownames
                meffd$anat = testvols
                meffd$dx = "Pos"
                meffd$dx[ grep("Neg",myrownames)]='Neg'
                if ( nrow(meffdallG) == 0 ) meffdallG=meffd else meffdallG = rbind(meffdallG,meffd)
                print( ggbarplot( meffd, 'eff','d', color='dx', fill='dx', 
                    palette='npg' ) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5))+ggtitle(paste("Long and cross effect sizes (d):",testvols)) + geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.1,
                    position=position_dodge(.5))  )
                (prplot( mdl,  'yearsbl', 'DXAsyn', color='DXAsyn', addpoints=1 )+ ggtitle(paste(testvols,pvformatted,"\n",nstring))) %>% print()
                }
        }
    }
##########################################################

```


## some references for methods

modeling site variability [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281513/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281513/)

temporoparietal junction [https://pubmed.ncbi.nlm.nih.gov/28057458/](https://pubmed.ncbi.nlm.nih.gov/28057458/)


## test the anatomical relationship with cognition and clinical measurements

```{r cogresults,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
cogindex = names( pvaluedf)  %in% coggers
cognames = c( 'subtype','anat', names(pvaluedf)[cogindex] )
cogresults = data.frame( matrix(nrow=1,ncol=length(cognames)))
colnames(cogresults)=cognames
ct = 1
for ( x in names(pvaluedf)[cogindex] ) { 
    sel=fs(p.adjust( pvaluedf[,x], 'bonf' ) <= 0.05)
    temo=pvaluedf[sel,c('subtype','anat',x)]
    cogresults[ct:(ct+sum(sel)-1),c('subtype','anat',x)]=temo
    ct=ct+sum(sel)
}

# reactable::reactable( cogresults, highlight = TRUE, bordered = TRUE, striped = TRUE, compact = FALSE, defaultPageSize = 120, static = FALSE, sortable=TRUE )

cogclean = tidyr::pivot_longer( cogresults, names(cogresults)[-c(1:2)] )
names(cogclean)[names(cogclean)=='value']='pvalue'
names(cogclean)[names(cogclean)=='name']='cogclin'
cogclean = cogclean[ !is.na(cogclean$pvalue), ]
for ( x in 1:nrow(cogclean)){
    cogclean$pvalue[x]=insight::format_p( cogclean$pvalue[x],
            stars=TRUE, digits=4 )
}
reactable::reactable( cogclean, highlight = TRUE, bordered = TRUE, striped = TRUE, compact = FALSE, defaultPageSize = 120, static = FALSE, sortable=TRUE )

```




## multivariate subtyping

```{r mvst2setup,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=TRUE}
######################################################################
for ( m in mymiles ) {
    clin[,m]=as.numeric(clin[,m])
    }
clin$ptau = as.numeric( clin$ptau )
clin$tau = as.numeric( clin$tau )
clin$EDUCYRS = ANTsRCore::antsrimpute(as.numeric( clin$EDUCYRS ))
clin$hy[ is.na( clin$hy )] = "0"
clin$hy = as.numeric( clin$hy )
clin$moca = ANTsRCore::antsrimpute(as.numeric(clin$moca ))
clin$age_BL=ANTsRCore::antsrimpute(as.numeric(clin$age_BL))
ssel = fs( clin$T1Hier_resnetGrade >= 1.02 & !clin$mrimodel %in% c("SIGNA") )
clustdata = clin[ssel,]
print( table(round(clustdata$yearsbl), clustdata$DXSubAsyn) )
sage=data.frame( stats::poly( clustdata$age_BL , 2 ) )
colnames(sage)=c("Age1","Age2")
clustdata=cbind(clustdata,sage)
clustdata$SEX = factor( clustdata$SEX )
clustdata$duration_yrs = as.numeric( clustdata$duration_yrs )
clustdata$cnxtot = rowSums( clustdata[,cnxnames] )
clustdata[,cnxnames]=clustdata[,cnxnames]/clustdata$cnxtot
testnames = unique( c( t1names, dtinames, rsfnames ) )
clustdata=mapAsymVar( clustdata,
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
clustdata=mapLRAverageVar( clustdata, 
        testnames[ grep("_l_", testnames) ], '_l_', "_r_" )
clustdata=mapAsymVar( clustdata, 
        testnames[ grep("_left", testnames) ] )
clustdata=mapLRAverageVar( clustdata, 
        testnames[ grep("_left", testnames) ] )
testnames = c( 
        getNamesFromDataframe( "Asym" , clustdata ),
        getNamesFromDataframe( "LRAVG" , clustdata ), 
        midnames )
countdtinz=rep(NA,length(testnames))
for ( x in 1:length(testnames) ) {
    countdtinz[x]=sum( !is.na(clustdata[,testnames[x]]) & 
        clustdata[,testnames[x]] > 0)
    }
testnames=testnames[ countdtinz > 100 ]
clustdata = fillBaselineColumn( clustdata,
        c('brainVolume',testnames,'hy','moca'), 
        'PATNO', 'imaging_EVENT_ID', 'V0', 
        fast=T, verbose=F )[[1]]
#############################################################################
basesel = fs( clustdata$imaging_EVENT_ID == 'V0' )
trainsel = fs( basesel & clustdata$DX %in% c( "PD" ) )#  & subcohort$SEX==0)
trainsel = fs( clustdata$DX != "Prodromal" & basesel )
trainsel = fs( basesel & clustdata$DXSub %in% c('PDSporadic') )
trainsel = fs( basesel & clustdata$DXSubAsyn %in% c('PDSporadicPositive') )
clustdata$istrain = FALSE
clustdata$istrain[ trainsel ] = TRUE
#############################################################################
mcnames = c( testnames[ -multigrep(c("DTI","Asym"), testnames) ] )
mcnames = c( testnames[ -multigrep(c("DTI"), testnames) ] )
clustdata[,mcnames]=ANTsRCore::antsrimpute(clustdata[,mcnames])
corrmethCL='BH'
```


```{r mvst2adjust,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=TRUE}
#############################################################################
# adjust each mcname variable by the covariates 
# adjustByCovariates(mxdfin, adjustmentFormula, groupVariable, group) 
#############################################################################
clustdatADJ=clustdata
for ( x in mcnames ) {
    stcovars = "  ~ T1Hier_resnetGrade + brainVolume_BL + EDUCYRS + ( Age1 + Age2 ) + SEX " 
#    stcovars = "  ~ EDUCYRS + ( Age1 + Age2 ) + SEX " 
    adjform = paste( x, stcovars )
    clustdatADJ=adjustByCovariates( clustdatADJ, adjform, 'istrain', TRUE )
}
mcnames = getNamesFromDataframe( "_adjusted", clustdatADJ )
clustdata = clustdatADJ
rm( clustdatADJ )
clustdata[,mcnames]=ANTsRCore::antsrimpute(clustdata[,mcnames])
#    clustdata[,mcnames]=ANTsR::robustMatrixTransform(clustdata[,mcnames])
scaledTrainData = scale(clustdata[clustdata$istrain==TRUE,mcnames])
clustdata[clustdata$istrain==TRUE,mcnames] = scaledTrainData
scaledTestData = scale(clustdata[clustdata$istrain==FALSE,mcnames], 
    center=attr(scaledTrainData, "scaled:center"), 
    scale=attr(scaledTrainData, "scaled:scale"))
clustdata[clustdata$istrain==FALSE,mcnames] = scaledTestData
mvcl='MVCX'
desiredk = 2 # 2,3,4,5,6
nsimlr = 1
minsubcount = 1
vizclustmeth = 'neuralgas'
vizclustmeth = 'kmeansflex'
vizclustmeth = 'hierarchicalCluster'
vizclustmeth = 'pamCluster'
vizclustmeth = 'GMM'
vizclustmeth = 'kmedians'
vizclustmeth = 'cckmeans'
vizclustmeth = 'angle'
```


### simlr (optional)

```{r simlr,echo=FALSE,eval=TRUE,warning=FALSE,message=TRUE,cache=FALSE}
##########
if ( nsimlr > 0 ) {
    # simlr on mcnames and coggers in training data
    matlist = list(
        scale(antsrimpute(data.matrix( clustdata[clustdata$istrain,mcnames]) )),
        scale(antsrimpute(data.matrix( clustdata[clustdata$istrain,coggers] ))) )
    write.csv( matlist[[1]], '/tmp/data1.csv', row.names=FALSE )
    write.csv( matlist[[2]], '/tmp/data2.csv', row.names=FALSE )
    matlistTest = list(
        scale(antsrimpute(data.matrix( clustdata[!clustdata$istrain,mcnames]) )),
        scale(antsrimpute(data.matrix( clustdata[!clustdata$istrain,coggers] ))) )

    res.pca <- PCA(matlist[[2]],  graph = FALSE)
    mymin = round(min( dim(matlist[[2]])) * 0.9)
    fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50), ncp=mymin)

    # find the best nsimlr based on the cog data
    mysvdd = cumsum(svd( scale((matlist[[2]])))$d)
    mysvdd = cumsum(svd( matlist[[2]] )$d )
#    mysvdd = cumsum(svd( scale(cbind(matlist[[1]],matlist[[2]])))$d)
    mysvdd = mysvdd/max(mysvdd)
    mysvdd
    nsimlr = which.min( abs(0.8 - (mysvdd/max(mysvdd)) ))
#    nsimlr = desiredk
    nsimlr = mymin - 1 # based on cog dim
    nsimlr = 2 # based on PCA plot
    message(paste('nsimlr',nsimlr))
    print(paste('nsimlr',nsimlr))
    regs = regularizeSimlr( matlist, fraction=0.05, sigma=c(3.0,3.0) )
    regs[[1]][1,]
    regs[[2]][1,]
    # set up parameters for permutation tests
    myjr = TRUE
    prescaling = c( 'centerAndScale', 'sqrtnp' )
    prescaling = c( 'robust', 'sqrtnp'  )
    pizzer = c( "positive", "either" )
    objectiver = 'cca'
    optimus = 'lineSearch'
    maxits = 100
    mixer = 'pca'
    ebber = 0.5
    nperms = 10
    nsimlrsearch = 7 # 2:8
    nsimlrsearchTvals = data.frame( )
    quantval = 0.5
    sparval = c(0.5,0.5)
    for ( sparsearch in 1:1 ) {
        set.seed(as.integer( Sys.time() ))
        sparval = rnorm(2,0.75,0.15 )
        if ( sparsearch == 1 ) sparval = c(0.5, 0.5)
        if ( sparsearch == 2 ) sparval = c(0.8, 0.8)
        sparval[ sparval > 0.98 ]=0.98
        sparval[ sparval < 0.5 ]=0.5
        for ( nsimlr in nsimlrsearch ) {
            nsimlrct = nrow(nsimlrsearchTvals)+1
            initu = initializeSimlr(
                matlist,
                nsimlr,
                jointReduction = myjr,
                zeroUpper = FALSE,
                uAlgorithm = "pca",
                addNoise = 0 )
            simlrX = simlr( matlist, 
                    regs, 
                    iterations=maxits, 
                    verbose=FALSE,
                    randomSeed = 0,
                    mixAlg=mixer,
                    energyType=objectiver,
                    scale = prescaling,
                    sparsenessQuantiles=sparval,
                    positivities = pizzer, expBeta=ebber,
                    optimizationStyle=optimus,
                    initialUMatrix=initu )
            simlrpred = predictSimlr( matlist, simlrX, 
                targetMatrix=2, sourceMatrices=1 )
            simlrpvals = rep(NA,nperms)  
            # begin permutation
            myseeds = sample(1:10000,nperms)
            for ( nperm in c(1:nperms) ) {
                matlistperm = matlist
                for ( jj in 1:length(matlist) ) {
                    myperm = shuffle( as.integer( 1:nrow(matlist[[jj]])) )
                    matlistperm[[jj]]=matlist[[jj]][myperm,]
                }
                initu = initializeSimlr(
                    matlistperm,
                    nsimlr,
                    jointReduction = myjr,
                    zeroUpper = FALSE,
                    uAlgorithm = "pca",
                    addNoise = 0 )
                simlrXperm = simlr( matlistperm, 
                    regs, 
                    iterations=maxits, 
                    verbose=FALSE,
                    randomSeed = 0,
                    mixAlg=mixer,
                    energyType=objectiver,
                    scale = prescaling,
                    sparsenessQuantiles=sparval,
                    positivities = pizzer, expBeta = ebber,
                    optimizationStyle=optimus,
                    initialUMatrix=initu )
                simlrpredperm = predictSimlr( matlistperm, simlrXperm, 
                    targetMatrix=2, sourceMatrices=1 )
                simlrpvals[nperm]=quantile( simlrpredperm$varxfull[[1]], quantval )
                # print( paste(nperm,simlrpvals[nperm], mean(simlrpredperm$varx) ) )
                set.seed( myseeds[nperm] )
            }
            refvarxval = quantile( simlrpred$varxfull[[1]], quantval )
            mytt = t.test( refvarxval - simlrpvals )
            nsimlrsearchTvals[nsimlrct,c('energy','mix','opt')]=c(objectiver,mixer,optimus)
            nsimlrsearchTvals[nsimlrct,c('sp1','sp2','elast')]=c(sparval,ebber)
            nsimlrsearchTvals[nsimlrct,c('varx')]=refvarxval
            nsimlrsearchTvals[nsimlrct,c('n', 't','pval')]=c(nsimlr,as.numeric(mytt$stat),sum(simlrpvals>mean(simlrpred$varx))/nperm)
            print( nsimlrsearchTvals[nsimlrct,] )
            } # nsimlrsearch
        } # sparval search
    print( nsimlrsearchTvals )
    #######################
    # subset the solution #
    #######################
    for ( jj in 1:length( simlrX$v ) ) {
        simlrX$v[[jj]]=simlrX$v[[jj]][, simlrpred$uOrder[1:2] ]
        simlrX$v[[jj]]=simlrX$v[[jj]]/norm(simlrX$v[[jj]],'F')
    }
    print( simlrpred$varx )
    mcnamesorig = mcnames
    projmati = matlist[[1]] %*% simlrX$v[[1]]
    projmatc = matlist[[2]] %*% simlrX$v[[2]]
    pheatmap::pheatmap( abs( cor(projmati, projmatc )) , cluster_cols=F, cluster_rows=F)
    plot( projmati[,1], projmatc[,1] )
    projimgs = data.matrix(clustdata[,mcnames]) %*% simlrX$v[[1]]
    projcogs = data.matrix(clustdata[,coggers]) %*% simlrX$v[[2]]
    mcnames=colnames(projimgs)
    clustdata=cbind(clustdata,projimgs)
    message("simlr done")
    print("simlr done")
} 
diagnostics=FALSE
```


### define subcohorts

```{r subcohorts,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=FALSE}
osex='SEX'
yth=4.5
# this is training for model selection
subcohortPD = clustdata[ fs(
    clustdata$DXSubAsyn %in% c('PDSporadicPositive') &
#    clustdata$DXSub %in% c('PDSporadic') &
#    clustdata$DX %in% c('PD') &
    clustdata$yearsbl <= yth),]
# this is testing model selection
subcohortProdromal = clustdata[ fs(
#    clustdata$DXSub %in% c("ProdromalSporadic") &
    clustdata$DXSubAsyn %in% c("ProdromalSporadicPositive","CNPositive") &
#    clustdata$DX %in% c("Prodromal") &
    clustdata$yearsbl <= yth),]
# names of the predicted clusters
subcohortGen = clustdata[ fs(
    clustdata$DXSubAsyn %in% 
#    c(  "PDLRRK2Positive",'ProdromalLRRK2Positive' ) &
    c( "PDGBAPositive", "ProdromalGBAPositive" ) &
#    c("ProdromalGBAPositive", "PDGBAPositive", "PDLRRK2Positive", "ProdromalLRRK2Positive" ) &
#     c("PDLRRK2Positive", "PDGBAPositive","ProdromalGBAPositive","ProdromalLRRK2Positive","CNPositive", "ProdromalSporadicPositive" ) &
#    c("PDLRRK2Positive", "ProdromalLRRK2Positive","PDLRRK2Negative", "ProdromalLRRK2Negative") &
    clustdata$yearsbl <= yth),]
# names of the predicted clusters
```

```{r mvst2Functions,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
clearcolname = function( mydf, mycolname ) {
    if ( mycolname %in% colnames( mydf ) ) {
        mydf=mydf[,-grep(mycolname,colnames( mydf))]
    }
    return( mydf )
}

```

## find the elbow 

```{r elbowtool,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=FALSE}
set.seed(31)
subcohort = clustdata
subcohorttr=subcohort[trainsel,mcnames]
fviz_nbclust(subcohorttr, kmeans, method = "wss", k.max = 20) + theme_minimal() + ggtitle("Elbow plot to determine number of clusters")
# function to compute total within-cluster sum of squares

```

## find the gap 

```{r gap,echo=FALSE,eval=diagnostics,warning=FALSE,message=FALSE,cache=FALSE}
nboot = 200
gap_stat <- clusGap(subcohorttr, FUN = kmeans, nstart = 30, K.max = 20, B = nboot)
fviz_gap_stat(gap_stat) + theme_minimal() + ggtitle("fviz_gap_stat: Gap Statistic")
# my interpretation: search between 4 and 8 
```

## silly approach

```{r silly,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=FALSE}
fviz_nbclust(subcohorttr, kmeans, method = "silhouette", k.max = 20) + theme_minimal() + ggtitle("The Silhouette Plot")
```

## ssc approach 

```{r ssc,echo=FALSE,eval=TRUE,cache=FALSE}
km2 <- kmeans(subcohorttr, 2)
km3 <- kmeans(subcohorttr, 3)
km4 <- kmeans(subcohorttr, 4)
km5 <- kmeans(subcohorttr, 5)
km6 <- kmeans(subcohorttr, 6)
km7 <- kmeans(subcohorttr, 7)
km8 <- kmeans(subcohorttr, 8)

ssc <- data.frame(
  kmeans = c(2,3,4,5,6,7,8),
  within_ss = c(mean(km2$withinss), mean(km3$withinss), mean(km4$withinss), mean(km5$withinss), mean(km6$withinss), mean(km7$withinss), mean(km8$withinss)),
  between_ss = c(km2$betweenss, km3$betweenss, km4$betweenss, km5$betweenss, km6$betweenss, km7$betweenss, km8$betweenss)
)
ssc %<>% gather(., key = "measurement", value = value, -kmeans)
#ssc$value <- log10(ssc$value)
ssc %>% ggplot(., aes(x=kmeans, y=log10(value), fill = measurement)) + geom_bar(stat = "identity", position = "dodge") + ggtitle("Cluster Model Comparison") + xlab("Number of Clusters") + ylab("Log10 Total Sum of Squares") + scale_x_discrete(name = "Number of Clusters", limits = c("0", "2", "3", "4", "5", "6", "7", "8"))
```

## NbClust

```{r nbclust,echo=FALSE,eval=diagnostics,cache=FALSE}
res.nbclust <- NbClust(subcohorttr, distance = "euclidean",
                  min.nc = 2, max.nc = 20, 
                  method = "complete", index ="all")
```

## clustree


```{r clustree,echo=FALSE,eval=diagnostics,cache=FALSE}
tmp <- NULL
for (k in 1:11){
  tmp[k] <- kmeans(subcohorttr, k, nstart = 30)
}
df <- data.frame(tmp)
# add a prefix to the column names
colnames(df) <- seq(1:11)
colnames(df) <- paste0("k",colnames(df))
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
ind.coord <- df.pca$x
ind.coord <- ind.coord[,1:2]
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))
clustree(df, prefix = "k")


df_subset <- df %>% select(1:8,12:13)
clustree_overlay(df_subset, prefix = "k", x_value = "PC1", y_value = "PC2")

overlay_list <- clustree_overlay(df_subset, prefix = "k", x_value = "PC1",
                                 y_value = "PC2", plot_sides = TRUE)
overlay_list$x_side
overlay_list$y_side
```

## cl valid

see [this](https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92) for commentary

```{r clvalid,echo=FALSE,eval=diagnostics,cache=FALSE}
clmeths = c( "hierarchical", "kmeans", "diana", "fanny",
          "som", "model", "sota", "pam", "clara", "agnes")
intern <- clValid(scale(subcohorttr), nClust = 2:12,
              clMethods = clmeths, validation = "internal")
# Summary
summary(intern) %>% print()

```

## pamk

```{r pamk,echo=FALSE,eval=diagnostics,cache=FALSE}
library(fpc)
pamk.best <- pamk(subcohorttr)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(subcohorttr, pamk.best$nc))
```

## Calinski

```{r Calinski,echo=FALSE,eval=diagnostics,cache=FALSE}
require(vegan)
fit <- cascadeKM(scale(subcohorttr, center = TRUE,  scale = TRUE), 1, 10, iter = 1000)
plot(fit, sortg = TRUE, grpmts.plot = TRUE)
calinski.best <- as.numeric(which.max(fit$results[2,]))
cat("Calinski criterion optimal number of clusters:", calinski.best, "\n")
```

## BIC

```{r bic,echo=FALSE,eval=diagnostics,cache=FALSE}
library(mclust)
d_clust <- Mclust(as.matrix(subcohorttr), G=1:20)
m.best <- dim(d_clust$z)[2]
cat("model-based optimal number of clusters:", m.best, "\n")
# 4 clusters
# plot(d_clust)
```

## affinity 

```{r aff,echo=FALSE,eval=diagnostics,cache=FALSE}
library(apcluster)
d.apclus <- apcluster(negDistMat(r=2), subcohorttr)
cat("affinity propogation optimal number of clusters:", length(d.apclus@clusters), "\n")
# 4
heatmap(d.apclus)
plot(d.apclus, subcohorttr)
#
# show(d.apclus)
#
```

## train the models

```{r mvst2trainclust,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=FALSE}
## BUILD THE TRAINED MODELS
###################################################
###################################################
clustlist = c(  "hierarchicalCluster",  "GMM", "pamCluster", 
    "kmeansflex", "kmedians",  "angle",  "ejaccard", 
    "hardcl","neuralgas", "cckmeans" )
clustlist = c( "GMM", "pamCluster", 
    "kmedians", "angle", "ejaccard", 
    "hardcl", "neuralgas", "cckmeans" )
sildf = data.frame()
clustmodels = list()
clustmodelQual = list()
for ( thek in 2:10 ) {
    for ( myclust in clustlist ) {
        clustmodels[[ length( clustmodels ) + 1 ]] =
            trainSubtypeClusterMulti( subcohorttr, mcnames, myclust, 
                desiredk=thek )
        temp = predictSubtypeClusterMulti( subcohort[trainsel,], 
            mcnames, clustmodels[[ length( clustmodels ) ]], mvcl, 
            'PATNO', 'imaging_EVENT_ID', 'V0')
        # dissimilarity
        mydiss = dist( (subcohorttr), diag=T, upper=T )
        clustmodelQual[[length( clustmodels )]] = wcClusterQuality(mydiss, temp[,mvcl] )
        mysil = cluster::silhouette( as.integer(temp[,mvcl]), mydiss)
        clustmodelQual[[length( clustmodels )]]$stats['mean_sil']=mean(mysil[,3])
        # print( paste( "myclust", myclust, 'sil',clustmodelQual[[length( clustmodels )]]$stats['mean_sil'], ' k ', thek ) )
    #    print(  clustmodelQual[[length( clustmodels )]]$stats )
        # temp[,mvcl]
        rm( temp )
        n=nrow(sildf)+1
        sildf[n,'model']=myclust
        sildf[n,'k']=thek
        stanames=names(clustmodelQual[[length( clustmodels )]]$stats)
        sildf[n,stanames]=clustmodelQual[[length( clustmodels )]]$stats
        print(sildf[n,])
        }
    }

for ( nm in names(sildf)[-c(1:2)] ) {
    cat("*********************\n")
    wmx = which.max(sildf[,nm])
    print( sildf[wmx,c("model","k",nm)] )
    }

clustmodels = list()
clustmodelQual = list()
for ( myclust in clustlist ) {
        clustmodels[[ length( clustmodels ) + 1 ]] =
            trainSubtypeClusterMulti( subcohorttr, mcnames, myclust, 
                desiredk=desiredk )
}
names( clustmodels ) = paste0(clustlist)


```


### model selection in sporadic PD$+$

```{r mvst2,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE,cache=FALSE}
## EVALUATE THE TRAINED MODELS in PD
coggersX = c( "gds", "lns", "moca", "NP1APAT", "pigd", "quip", "scopa", "stai", "updrs1_score" , "updrs2_score", "updrs3_score", "updrs3_score_on", "updrs_totscore", "updrs_totscore_on", "hvlt_discrimination", "hvlt_immediaterecall", "hvlt_retention" )
mygroup='PD'
clustdf = data.frame( )
# effdf = data.frame( matrix( nrow = length( coggersX )*2, ncol = desiredk ) )
for ( myclust in clustlist ) {
    myst = clustmodels[[myclust]]
    subcohortPD=clearcolname(subcohortPD, mvcl )
    subcohortPD = predictSubtypeClusterMulti( subcohortPD, 
        mcnames, myst, mvcl, 
        'PATNO', 'imaging_EVENT_ID', 'V0')
    subcohortPD$CDX = paste0( subcohortPD[,mvcl], "_", subcohortPD$AsynStatus )
    subcohortPD$CDX=subcohortPD[,mvcl]
    for ( cog in coggersX ) {
        thedf = subcohortPD
        temp = table( thedf$PATNO )
        thedf$yearr =round( thedf$yearsbl)
        tsel = ( thedf$yearr %in% c(0,1,2,4) ) & 
                thedf$PATNO %in% names(temp)[temp>=minsubcount]
        thedf = thedf[tsel,]
        cogformb=paste( cog , "~", gsub("SEX",osex,commcov), "+(yearsbl)" )
        cogform=paste( cogformb, "+CDX+yearsbl:CDX" )
        cogmdlb = lmer( cogformb, data=thedf )
        cogmdl = lmer( cogform, data=thedf )
        cogcoff=coefficients(summary(cogmdl))
        greppers = unique(multigrep(c(mvcl,"yearsb"),rownames(cogcoff)))
        cogcoff=cogcoff[greppers,]
        nr=nrow(clustdf) + 1
        clustdf[nr,c( 'method', 'cog','pvalue','group')] =
                c(myclust,cog,anova(cogmdlb,cogmdl)$Pr[2],mygroup)
        if ( as.numeric(clustdf[nr,c('pvalue')]) < 0.005 & myclust == vizclustmeth ) {
            ggtit = paste(mvcl,"COGGER",cog,myclust,mygroup,"\n",cogpvform)
            message(paste('mvclust',cog))
            print( cogcoff[,-c(1:2)] )
            cogpvform = insight::format_p( 
                    clustdf[nr,c('pvalue')],
                    stars=TRUE, digits=4 )
            if (FALSE)
                print( plotSubtypeChange( thedf,
                                idvar='PATNO', 'CDX',
                                measurement=cog,
                                vizname='yearr', 'se', xlab='yr from v0' ) + 
                                ggtitle(paste(cog," : raw"))  )
            thedf$temp = as.character( thedf[,'DXSub'])
            subcohortg=thedf[!is.na(thedf$temp),]
#                (ggscatter( subcohortg, 'yearsbl', cog, facet.by='CDX', color='AsynStatus', add='reg.line', conf.int=T, cor.coef=T, parse=T ) + ggtitle(ggtit)) %>% print()
        #        ggscatter( subcohortg, 'yearsbl', cog, facet.by='hy', color=mvcl, add='reg.line', conf.int=T, cor.coef=T, parse=T ) %>% print()
        #        if ( FALSE )
            (prplot( cogmdl,'yearsbl', 'CDX', color='CDX', 
                    addpoints=1, palette=mypal ) +
                    ggtitle(ggtit) ) %>% print()
            }
        }
    }
##########
clustdfPD = clustdf
qvals = p.adjust( as.numeric(clustdfPD$pvalue), corrmethCL )
table( clustdfPD$method[  qvals <= 0.05 ] ) %>% print()
clustlistPro = as.character( unique( clustdfPD$method[  qvals <= 0.05 ] ))
cog2test = as.character( unique( clustdfPD$cog[  qvals <= 0.05 ]  ) )
```


## visualize each cluster with respect to each significant clinical domain

```{r vizinpd,echo=FALSE,eval=TRUE,fig.width=9,fig.height=4.5}
myst = clustmodels[[vizclustmeth]]
subcohortPD=clearcolname(subcohortPD, mvcl )
subcohortPD = predictSubtypeClusterMulti( subcohortPD, 
        mcnames, myst, mvcl, 
        'PATNO', 'imaging_EVENT_ID', 'V0')
if ( FALSE ) {
    library(ggstatsplot)
    ggbetweenstats(
    data = subcohortPD,
    x = MVCX,
    y = updrs_totscore
    )
    }
subcohortPD$yearr = round( subcohortPD$yearsbl )
for ( cog in cog2test ) {
    toviz = subcohortPD[ subcohortPD$yearr %in% c(0,1,2,4), ]
    toviz = toviz[ !is.na( toviz[,cog]),]
    mytbl = table( toviz$PATNO )
    highid = names( mytbl[ mytbl > 2  ] )
    toviz = toviz[ toviz$PATNO %in% highid, ]
    print( plotSubtypeChange( toviz,
        idvar='PATNO', 
        measurement=cog,
        subtype=mvcl,
        vizname='yearr',
        'se',
        xlab='yr from v0' ) + ggtitle(paste(cog," : raw") ) )
    }
#####
```



## prodromal evaluation

```{r mvst2prodromaleval,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
mygroup='Prodromal'
clustdf = data.frame( )
for ( myclust in clustlistPro ) {
    myst = clustmodels[[myclust]]
    subcohortProdromal=clearcolname(subcohortProdromal, mvcl )
    subcohortProdromal = predictSubtypeClusterMulti( subcohortProdromal, 
        mcnames, myst, mvcl, 
        'PATNO', 'imaging_EVENT_ID', 'V0')
    subcohortProdromal$CDX = paste0( subcohortProdromal[,mvcl], "_", 
        subcohortProdromal$AsynStatus )
    subcohortProdromal$CDX=subcohortProdromal[,mvcl]
    for ( cog in cog2test ) {
        thedf = subcohortProdromal
        temp = table( thedf$PATNO )
        thedf$yearr =round( thedf$yearsbl)
        tsel = ( thedf$yearr %in% c(0,1,2,4) ) & 
                thedf$PATNO %in% names(temp)[temp>=minsubcount]
        thedf = thedf[tsel,]
        cogformb=paste( cog , "~", gsub("SEX",osex,commcov), "+(yearsbl)" )
        cogform=paste( cogformb, "+CDX+yearsbl:CDX" )
        cogmdlb = lmer( cogformb, data=thedf )
        cogmdl = lmer( cogform, data=thedf )
        cogcoff=coefficients(summary(cogmdl))
        greppers = unique(multigrep(c(mvcl,"yearsb"),rownames(cogcoff)))
        cogcoff=cogcoff[greppers,]
        nr=nrow(clustdf) + 1
        clustdf[nr,c( 'method', 'cog','pvalue','group')] =
                c(myclust,cog,anova(cogmdlb,cogmdl)$Pr[2],mygroup)
        if ( as.numeric(clustdf[nr,c('pvalue')]) < 0.01 & myclust == vizclustmeth ) {
            ggtit = paste(mvcl,"COGGER",cog,myclust,mygroup,"\n",cogpvform)
            message(paste('mvclust',cog))
            print( cogcoff[,-c(1:2)] )
            cogpvform = insight::format_p( 
                    clustdf[nr,c('pvalue')],
                    stars=TRUE, digits=4 )
            thedf$temp = as.character( thedf[,'DXSub'])
            subcohortg=thedf[!is.na(thedf$temp),]
            (prplot( cogmdl,'yearsbl', 'CDX', color='CDX', 
                    addpoints=1, palette=mypal ) +
                    ggtitle(ggtit) ) %>% print()
            }
        }
    }
```

## print prodromal sporadic evaluation

```{r prodromalsporevalprint,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
#########################################################
for ( cmeth in clustlistPro ) {
    myg='PD'
    gsel = clustdfPD$method == cmeth
    clustdfsubPD = clustdfPD[gsel,]
    qvalsPD = p.adjust( as.numeric(clustdfsubPD$pvalue),corrmethCL )
    myg='Prodromal'
    gsel = clustdf$group == myg  & clustdf$method == cmeth
    clustdfsub = clustdf[gsel,]
    qvals = p.adjust( as.numeric(clustdfsub$pvalue),corrmethCL )
#    cat("\n\n\n")
#    print(cmeth)
#    print( clustdfsubPD[  qvalsPD < 0.05,  ] )
    seller=qvals < 0.05 &  clustdfsub$cog %in% clustdfsubPD[  qvalsPD < 0.05, "cog" ]
    if ( sum(seller)>0 ) {
        cat("\n\n***************************\n")
        print( clustdfsub[ seller,  ] )
    }
}
##########
```

## genetic evaluation

```{r mvst2pgeneval,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
subcohortGen = clustdata[ fs(
    clustdata$DXSubAsyn %in%  c( "PDGBAPositive" ) &
    clustdata$yearsbl <= yth),]
subcohortGen = clustdata[ fs(
    clustdata$DXSubAsyn %in%  c( "PDLRRK2Positive",  "PDGBAPositive") &
    clustdata$yearsbl <= yth),]
mygroup='GEN'
clustdf = data.frame( )
for ( myclust in clustlistPro ) {
    myst = clustmodels[[myclust]]
    subcohortGen=clearcolname(subcohortGen, mvcl )
    subcohortGen = predictSubtypeClusterMulti( subcohortGen, 
        mcnames, myst, mvcl, 
        'PATNO', 'imaging_EVENT_ID', 'V0')
    subcohortGen$CDX = paste0( subcohortGen[,mvcl], "_", 
        subcohortGen$AsynStatus )
    subcohortGen$CDX=subcohortGen[,mvcl]
    for ( cog in cog2test ) {
        thedf = subcohortGen
        temp = table( thedf$PATNO )
        thedf$yearr =round( thedf$yearsbl)
        tsel = ( thedf$yearr %in% c(0,1,2,4) ) & 
                thedf$PATNO %in% names(temp)[temp>=minsubcount]
        thedf = thedf[tsel,]
        cogformb=paste( cog , "~", gsub("SEX",osex,commcov), "+(yearsbl)" )
        cogform=paste( cogformb, "+CDX+yearsbl:CDX" )
        cogmdlb = lmer( cogformb, data=thedf )
        cogmdl = lmer( cogform, data=thedf )
        cogcoff=coefficients(summary(cogmdl))
        greppers = unique(multigrep(c(mvcl,"yearsb"),rownames(cogcoff)))
        cogcoff=cogcoff[greppers,]
        nr=nrow(clustdf) + 1
        clustdf[nr,c( 'method', 'cog','pvalue','group')] =
                c(myclust,cog,anova(cogmdlb,cogmdl)$Pr[2],mygroup)
        if ( as.numeric(clustdf[nr,c('pvalue')]) < 0.01 & myclust == vizclustmeth ) {
            ggtit = paste(mvcl,"COGGER",cog,myclust,mygroup,"\n",cogpvform)
            message(paste('mvclust',cog))
            print( cogcoff[,-c(1:2)] )
            cogpvform = insight::format_p(
                    clustdf[nr,c('pvalue')],
                    stars=TRUE, digits=4 )
            thedf$temp = as.character( thedf[,'DXSub'])
            subcohortg=thedf[!is.na(thedf$temp),]
            (prplot( cogmdl,'yearsbl', 'CDX', color='CDX', 
                    addpoints=1, palette=mypal ) +
                    ggtitle(ggtit) ) %>% print()
            }
        }
    }
#####
```


## print genetic evaluation

```{r mvst2pgenevalp,echo=FALSE,eval=TRUE,warning=FALSE,message=FALSE}
#########################################################
for ( cmeth in clustlistPro ) {
    myg='PD'
    gsel = clustdfPD$method == cmeth
    clustdfsubPD = clustdfPD[gsel,]
    qvalsPD = p.adjust( as.numeric(clustdfsubPD$pvalue),corrmethCL )
    myg='GEN'
    gsel = clustdf$group == myg  & clustdf$method == cmeth
    clustdfsub = clustdf[gsel,]
    qvals = p.adjust( as.numeric(clustdfsub$pvalue),corrmethCL )
    seller=qvals < 0.05 &  clustdfsub$cog %in% clustdfsubPD[  qvalsPD < 0.05, "cog" ]
    if ( sum(seller)>0 ) {
        cat("\n\n***************************\n")
        print( clustdfsub[ seller,  ] )
    }
}
##########
```

<!-- ## print OG evaluation -->

```{r OGeval,echo=FALSE,eval=FALSE,warning=FALSE,message=FALSE}
#########################################################
for ( cmeth in clustlistPro ) {
    gsel = clustdfPD$method == cmeth
    clustdfsubPD = clustdfPD[gsel,]
    qvalsPD = p.adjust( as.numeric(clustdfsubPD$pvalue),corrmethCL )
    seller=qvalsPD < 0.05
    if ( sum(seller)>0 ) {
        cat("\n\n***************************\n")
        print( clustdfsubPD[ seller,  ] )
    }
}
##########
```


## Visualize feature importance for sporadic PD$+$

```{r fimp,echo=FALSE,eval=TRUE,fig.width=12,fig.height=6}
myclust='cckmeans'
myclust='kmedians'
myclust = vizclustmeth
vizcohort = subcohortPD
myst = clustmodels[[myclust]]
vizcohort=clearcolname(vizcohort, mvcl )
vizcohort = predictSubtypeClusterMulti( vizcohort, 
        mcnames, myst, mvcl, 
        'PATNO', 'imaging_EVENT_ID', 'V0')
fimp = featureImportanceForSubtypes(
       vizcohort,
       vizcohort[,mvcl],
       vizcohort[,mcnames],
       associationType = "subtypes2features",
       covariates = "EDUCYRS + ( Age1 + Age2 ) + SEX", # stcovars,
       transform = "effect_sizes",
       significance_level = 0.001,
       visualize = FALSE
     )
showcols = which( colSums( abs( fimp$subtypeFeatureTScoresSignificant ) )  > 0.5)
temp=fimp$subtypeFeatureTScoresSignificant[,showcols]
coller = colnames(temp)
coller=gsub("_adjusted","",coller)
coller=gsub("T1Hier_","",coller)
colnames(temp)=coller
pheatmap::pheatmap(temp)

print( summary(lmer( tau ~ (1|PATNO)+( SEX + age_BL ) * MVCX, data=subcohortPD )) )
print( summary(lmer( abeta ~  (1|PATNO)+( SEX + age_BL ) * MVCX, data=subcohortPD )) )
print( summary(lmer( ageatimaging ~  (1|PATNO)+( SEX ) * MVCX, data=subcohortPD )) )

```



### to do 

explore the parameters:

* `desiredk = 2` to 5 perhaps up to 6

* `nsimlr = 0` vs something larger

* `minsubcount = 2` alternatively 1



<!-- ## selection of 250 -->

```{r sel250,echo=FALSE,eval=FALSE}

#############################
# criteria for remaining 250:
### has SAA
### 1/2 prodromal 1/2 PD ( we assume we have sufficient controls -- probable SAA negative -- already )
### has all "reasonable quality" modalities
### not a SIGNA scanner
# questions:
## site distribution?
## mfg/model distribution? probably SIEMENS
###########################################
isBL=clin2$imaging_EVENT_ID == 'V0'
hasSAA=!is.na( clin2$AsynStatus )
hasT1 = clin2$T1Hier_resnetGrade > 1.02
hasMod = hasT1 & !is.na(clin2$rsfid1) &
    !is.na( clin2$nmid1 ) & !is.na( clin2$dtid1 ) & 
    !is.na( clin2$flairid )
hasMod2 = hasT1 & !is.na(clin2$rsfid1) & !is.na( clin2$dtid1 )
onepass = isBL & hasSAA & hasMod2
second250=clin2[onepass,c("u_hier_id","flairid","dtid1","rsfid1","nmid1","DXSubAsyn","T1Hier_resnetGrade","mrimfg","mrimodel")]
write.csv( second250, "~/Downloads/PPMI500_part2_n281.csv", row.names=FALSE )
```

